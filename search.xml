<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker之Registry]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8BRegistry%2F</url>
    <content type="text"><![CDATA[Docker RegistryRegistry用于保存docker镜像，包括镜像的层次结构和元数据 用户可自建Registry，也可使用官方的Docker Hub 分类 Sponsor Registry：第三方的registry，供客户和Docker社区使用 Mirror Registry：第三方的registry，只让客户使用 Vendor Registry：由发布Docker镜像的供应商提供的registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供的registry Registry(repository and index) Repository 由某特定的docker镜像的所有迭代版本组成的镜像仓库 一个 Registry中可以存在多个Repository Repository可分为“顶层仓库”和“用户仓库” 用户仓库名称格式为“用户名/仓库名” 每个仓库可以包含多个Tag(标签) ，每个标签对应一个镜像 Index 维护用户帐户、镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 从Docker hub获取，站点：https://hub.docker.com/ Docker Registries有两重功能 1、提供镜像存储的仓库 2、用户来获取镜像的认证，当前服务器上所有可用镜像的搜索功能等 repository ---&gt; repo 一个仓库只放一个应用程序镜像；可以放同一程序的不同版本，仓库名+标签来唯一标识一个镜像；一个镜像可有多个标签(tag)，不给标签名默认使用latest最新 公共仓库RegistryDocker Hubquay.io 用户可以将自己的镜像保存到免费的 repository 中 在Dokcer host上验证登录 docker login 推送到你注册的用户名下 docker pull [username]/xxx:tag 在Docker上搭建本地的 RegistryDocker Hub 虽然非常方便，但还是有些限制，比如： 需要 internet 连接，而且下载和上传速度慢。 上传到 Docker Hub 的镜像任何人都能够访问，虽然可以用私有 repository，但不是免费的。 安全原因很多组织不允许将镜像放到外网。 搭建本地的 Registry是解决以上问题的一种选择 基于docker-distribution 的搭建安装docker-distribution包，在extras仓库里 yum -y install docker-distribution 查看/etc/docker-distribution/registry/config.yml文件 默认不做修改，启动服务 systemctl start docker-distribution.service 启动成功后，服务监听在5000端口 默认docker不支持不安全的http协议，需要在docker的json配置文件写入&quot;insecure-registries&quot;:[]这个配置项。如果能够解析主机名，也可以写 主机名:5000,如下 重启docker服务,会使用http协议连接仓库 systemctl restart docker.service 推送到仓库的镜像打标签 docker tag nginx:v1 192.168.80.7:5000/testdis_nginx:v1 docker push 192.168.80.7:5000/testdis_nginx:v1 报错出现如下的报错，registry有两个版本的接口，v1和v2,可能是docker-ce推送时调用的是v2版本接口，但是docker-distribution不支持版本v2,只支持v1，这里默认找v2版本。导致出现如下的报错 Get https://192.168.80.7:5000/v2/: http: server gave HTTP response to HTTPS client 可以借助nginx来实现安全认证 Docker private Registry的Nginx反代配置方式： client_max_body_size 0; location / { proxy_pass http://registrysrvs; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_redirect off; proxy_buffering off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; auth_basic &quot;Docker Registry Service&quot;; auth_basic_user_file &quot;/etc/nginx/.ngxpasswd&quot;; } Docker-distribution配置 基于harbor 仓库搭建Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器，通过添加一些企业必需的功能特性 基于角色的访问控制 镜像复制 图形化用户界面 AD/LDAP 支持 审计管理 部署简单 - 提供在线和离线两种安装工具 安装配置向导参考手册 vmware harbor得借助于docker的单机编排工具：docker-compose Harbor安装部署 tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/ cd /usr/local/harbor/ vim harbor.cfg #注意，这个配置文件，如果不更改，里面的选项都是会自动创建，所以要看清楚，包括路径是否和本地其他文件有冲突 #主要修改以下三个配置，其他配置可使用默认 hostname= IP/hostname db_password=root123 #管理登录密码 harbor_admin_password = Harbor12345 ./install.sh 成功标志 ? ----Harbor has been installed and started successfully.---- docker没有实现安全访问，因此需要把harbor的主机写入insecure-registries配置段 连接， 域名解析时需要添加主机名解析 推送镜像前要进行登录验证 docker login harbor.server.com 推送到仓库的镜像打标签 docker tag php harbor.server.com/test/php:v1 #test为创建的仓库项目名 docker push harbor.server.com/test/php:v1 停止harbor服务，通过docker-compose来实现，所有harbor服务会被停止 注意，命令必须在/usr/local/harbor/路径下执行 docker-compose stop 启动服务 docker-compose start]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker之Dckerfile]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8BDckerfile%2F</url>
    <content type="text"><![CDATA[Dockerfile docker commit实现 分层机制 aufs overlay2 cow 写实复制 容器在启动时没有指定只读时，会创建一个可写层，可写层附加在它底层依赖的镜像之上，层层链式依赖关系，挂载出镜像栈，并联合挂载在一起，成为一个运行环境， 镜像分层结构，链式的依赖下一层 基于同一个镜像，启动多个容器，它们之间是共享镜像层的 基于当前的可写层，构建一个镜像层，使用docker commit，可以添加所需要的程序或文件 把容器的可读写层转化成只读层，即从容器状态【可读写文件系统】变为镜像状态【只读文件系统】，可理解为【固化】 相比之Dockerfile的方法会更加自动化，更加方便快捷，而且功能也更强大。 Docker build方法底层里也是在基础镜像下启动容器然后commit的，但是这些不需要我们手动去commit以及rm，都是自动化的 dockerfile是为快速构建docker image而设计的， 当你使用docker build命令的时候，docker 会读取当前目录下的命名为Dockerfile(首字母大写)的纯文本文件并执行里面的指令构建出一个docker image Docker 镜像、容器和 Dockerfile 三者之间的关系 使用 Dockerfile 定义镜像，运行镜像启动容器 Dockerfile基本要求1.必须有一个工作目录， 只能放置Dockerfile相关资源、配置的文件，作为根目录 目录下文件名为Dockerfile和Dockerfile中定义要复制的文件 此目录作为起始目录 2.语法 Dockerfile就是一个纯文本文件 约定俗成指令要求大写，顺序语句，没有多余语法，文件名 第一条指令必须为‘FROM’，用于指定其后构建新镜像所使用的基础镜像，Docker将会基于该镜像构建新镜像，其后的命令也会基于这个基础镜像。 在一个Dockerfile文件中创建多个镜像时，FROM可以多次出现。只需在每个新命令FROM之前，记录提交上次的镜像ID。 tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 3.每一条指令都会生成单一的镜像层，尽量关系紧密的放置一个层 4.镜像内唯一要运行的程序一定必须要运行在前台 .dockerignore文件1.dockerignore是工作目录中专门记录需要忽略的文件列表 2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件 Dockerfile FORMATMAINTANIER用于指定作者信息，用于声明作者，并应该放在FROM的后面 MAINTAIN &lt;name&gt; 例：MAINTAINER xavi XXX@XXXX.com ENV设置环境变量,形式为： variable=value ....可以写多个 variable value 只能写一个 ${variable;-word} -：variable没值，使用word ${variable;+word} +:variable有值，使用word，否则返回为空 $variable_name或是${variable_name}，这两种格式被同等对待，但是括号可以处理空格的状态， 如果某个环境变量的值是由一组英文单词构成，那么你可以将其使用&quot;&quot;进行圈起来 例： TITLE=&quot;iphone&quot; var=123 echo $var echo ${var;-100} LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定，不受文件系统控制的指令 一个镜像可以有多个label。 要指定多个labels，Docker推荐尽可能地把多个labels合并到一个LABEL指令中去。 每一个LABEL指令会生成一个新的镜像层，如果使用多个label，将导致构建出一个低效的镜像 label是累积的，包括FROM镜像的lable。 如果Docker遇到一个label/key已经存在，那么新的值将覆盖这个label/key 例： LABEL multi.label1=&quot;value1&quot; multi.label2=&quot;value2&quot; other=&quot;value3&quot; 要查看一个镜像的label，使用docker inspect命令 docker inspect --format &apos;{{json .Config.Labels}}&apos; wordpress | python -m json.tool COPYCOPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 例子： COPY /data/ /usr/local/ 注意： 1. src：必须为build上下文中的路径，可使用相对路径 2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制 等于cp -r /src/* /dest/ 3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾 4. 如果dest事先不存在，它将会被自动创建 ADDADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能 注意： 1.如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest， 2.如src为URL时且dest以/结尾，则会下载指定的文件并保存为dest/FILENAME ，但是其权限被自动设置成了600，需要额外增加一层RUN命令进行更改 建议只用一层RUN，使用curl或者wget工具进行下载，并更改权限，然后进行解压缩，最后清理无用文件 2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件则不会自动展开，即在本地的就展开，互联网的就不展开 3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾， 则被视为一个普通文件，src的内容将被直接追加写入到dest文件中 ADD /my_folder /data VOLUMEVOLUME &lt;路径&gt; VOLUME [“&lt;路径1&gt;”, “&lt;路径2&gt;”, …] 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷 注意： 1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个 路径建立关联关系 2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时 指定-v选项 3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 4.可以通过docker run命令中指定-v参数来进行覆盖 例： vim Dockerfile .... VOLUME /data/web/html/ #docker run --name c1 -it --rm myimg:v6 /bin/sh [root@test]# docker inspect c1 | egrep -A 5 &quot;Mounts|Volumes&quot; &quot;Mounts&quot;: [ { &quot;Source&quot;: &quot;/var/lib/docker/volumes/c6f35c8233da83765fab0ab3ab0f318cd37eae7448d2ba40ea1bf7e712f30cfc/_data&quot;, &quot;Destination&quot;: &quot;/data/web/html&quot;, &quot;Volumes&quot;: { &quot;/data/web/html/&quot;: {} EXPOSE端口暴露 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] 这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务,并不会自动在宿主进行端口映射 docker run -P时，才会自动随机映射 EXPOSE 的端口。 使用docker port id名查看 ARGarg是在build阶段进行传值，替换dockerfile中的值 ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值 构建参数ARG和ENV指令一样，都是设置环境变量。 与之不同的是，ARG设置的环境变量只是在镜像构建时所设置的，在将来容器运行时是不会存在这些环境变量的 arg是在build阶段进行传值，替换dockerfile中的值 在ARG指令定义变量之前引用这个变量的得，都会得到空值 ARG构建参数可以通过docker run命令中的--build-arg参数来进行覆盖 当build创建镜像时没有传值，则使用在dockerfile中设置的默认值 不推荐在构建期间的命令行传递密码如github密钥，用户凭证等数据。 ARG home=&quot;/data&quot; docker image build --build-arg home=&quot;/web&quot; -t myimg:v1 RUNRUN指令使用的是CMD命令。run可以有多个命令，每一个指令都会建立一层 格式为 RUN &lt;command&gt; RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;] 使用一个 RUN 指令，并使用 &amp;&amp; 将各个所需命令串联起来。将其简化为了1 层。 docker run命令指定要执行的命令可以覆盖RUN指令 Dockerfile 支持 行尾添加 \ 的命令换行，以及行首 # 进行注释的格式。 镜像是多层存储，每一层的东西并不会在下一层被删除，因此镜像构建时，任何无关的东西都应该清理掉。 例： RUN yum install httpd &amp;&amp; mkdir -p /usr/src/redis &amp;&amp; yum clean all RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] CMDshell格式：CMD &lt;命令&gt; exec格式：CMD [“可执行文件”, “参数1”, “参数2”, …] 使用shell格式，那么实际的命令会被包装成为sh -c的参数的形式进行执行 Dockerfile可以有多条 CMD 指令，但只有最后一条指令有效 docker run中指定了CMD命令，并且在Dockerfile中也指定了CMD命令，最终只会执行docker run命令中指定的命令 Docker容器后台运行,就必须有一个前台进程. CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFORGROUND&quot;] 不以shell进程进行，运行在前台可以被覆盖 例： CMD echo &quot;Hello Docker!&quot; CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;Hello Docker!&quot;] ENTRYPOINT ENTRYPOINT &lt;command&gt; ENTRYPOINT [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;] 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖 只允许被--entrypoint &quot;cmd&quot;覆盖 每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个起效 ENTRYPOINT与CMD同时存在，CMD命令就是ENTRYPOINT的参数 一般ENTRYPOINT后面跟脚本，CMD命令作为脚本的参数 例：容器启动时会显示 Hello docker! CMD &quot;Hello docker!&quot; ENTRYPOINT echo 容器最终执行的命令是curl -s -i http://ip，-i参数被传递到ENTRYPOINT中，最终在控制台中会输出HTTP头信息 ENTRYPOINT [&quot;curl&quot;, &quot;-s&quot;, &quot;http://ip&quot;] docker run -it centos:7 -i USERUSER [UID] USER命令用于设置运行容器的UID 可以在docker run命令中的-u参数进行覆盖 默认是root 例： USER 751 WORKDIRWORKDIR /path 用于设置CMD指明的命令的运行目录。 1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录 2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对 路径，也可以写成绝对路径 3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围 4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层 5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了 6.可以通过docker run命令中的-w参数来进行覆盖 HEALTHCHECK格式： HEALTHCHECK [options] CMD &lt;命令&gt;：检查容器健康状态的命令 HEALTHCHECK NONE：如果基础镜像有健康检查指令，这一行将会屏蔽掉其健康检查指令 选项： –interval=&lt;间隔&gt;：两次检查的时间间隔，默认为30s –timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查将会判定为失败，默认为30s –retries=&lt;次数&gt;：当连续失败指定次数之后，则将容器状态视为unhealthy，默认为3次 HEALTHCHECK允许额外加一层，加一个命令，模拟客户端向容器发起请求，判断健康状况 当一个容器设置了healthcheck之后，除了正常的状态，它多了一个health状态。 当健康检查通过后，它变成了healthy(不管之前是什么状态)当连续出现几次失败后，就变成unhealthy 有多个HEALTHCHECK指令，那么只有最后一个才会生效！！！ 例： HEALTHCHECK --interval=5s --timeout=3s CMD curl -fs http://localhost/ || exit 1 健康检查状态 docker inspect --format &apos;{{json .State.Health}}&apos; wordpress | python -m json.tool SHELL允许默认的shell形式被命令形式覆盖 在Linux系统中默认shell形式为 [&quot;/bin/sh&quot;, &quot;-c&quot;], 在 Windows上是[&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]。 SHELL指令必须用Dockerfile中的JSON格式写入。 SHELL指令在Windows上特别有用，其中有两个常用的和完全不同的本机shell cmd和powershell，以及包括sh的备用shell。 SHELL指令可以出现多次。每个SHELL指令都会覆盖所有以前的SHELL指令，并影响所有后续指令。 ONBUILDONBUILD是一个特殊的指令，它后面跟着的是其他指令，比如COPY、RUN等，而这些命令在当前镜像被构建时，并不会被执行。只有以当前镜像为基础镜像去构建下一级镜像时，才会被执行 ONBUILD &lt;其他指令&gt; 例： ONBUILD RUN mkdir test 查看构建历史 docker image history --help 例]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker之Volume]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8BVolume%2F</url>
    <content type="text"><![CDATA[什么是volumeDocker镜像由多个只读层叠加而成，启动容器时，Docker会加载只读镜像层并在镜像栈顶部添加一个读写层 也存在如下问题： 1.存储于联合文件系统中，不易于宿主机访问； 2.容器间数据共享不便 3.删除容器其数据会丢失 Docker的数据持久化即使数据不随着container的结束而结束 解决方案：“卷（Volume） 要么存在于宿主机的某个指定目录中（使用bind mount） 要么使用docker自己管理的volume（/var/lib/docker/volumes下） volume机制volume存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系 1.volume在容器创建时就初始化，在容器运行时就可以使用其中的文件 2.volume能在不同的容器之间共享和重用 3.对volume中的数据的操作会马上生效 4.对volume中数据操作不会影响到镜像本身 5.volume的生存周期独立于容器的生存周期，即使删除容器，volume仍然会存在，没有任何容器使用的volume也不会被Docker删除 卷为docker提供了独立于容器的数据管理机制 可以把“镜像”想像成静态文件，镜像可以重用，而卷可以共享； 卷实现了“程序”和“数据”分离，用户制作镜像时无须再考虑镜像运行的容器所在的主机的环境 volume类型每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同； Bind mount绑定挂载卷，永久生效 容器内目录和宿主机中的目录都是由用户自己指定的 注意： 宿主机的目录路径必须为全路径(要以/或~/开始的路径) 如果宿主机的目录不存在，docker会自动创建该目录 如果container中的目录不存在，docker会自动创建该目录 如果container中的目录已经有内容，那么docker会使用host上的目录将其覆盖掉 Docker管理卷容器中的卷是用户自己指定的， 宿主机上的目录是由docker-daemon进程自行，与存储卷路径建立关联关系（目录名称通常为ID号） 在/var/lib/docker/volumes下 备份、恢复与迁移数据卷1.备份数据卷 创建了一个名为c1容器，并在容器中创建了一个/data的数据卷。 docker run -it --name c1 –v /data busybox 可以在创建容器使用--volumes-from参数来挂载这个数据卷，并对数据进行备份： docker run --volumes-from c1 -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data 在这个操作中，我们通过busybox镜像创建了一个容器，创建容器时通过--volumes-from参数共享了数据卷容器中的数据， 并将当前目录($(pwd))挂载到了数据卷中。容器运行后，使用tar命令对数据卷进行了备份。 命令执行结束后，容器就会停止，之后就可以在本地当前操作目录下找到所备份的数据。 2.备份数据卷 数据备份后，可以在创建容器恢复备份数据到容器内的数据卷中，从而实现数据的迁移。 首先，创建并运行容器并添加一个数据卷： docker run --name c2 -it -v /data -d busybox /bin/bash 然后通过tar命令恢复备份数据： docker run --rm --volumes-from c2 -v $(pwd):/backup busybox bash -c &quot;cd /data &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot; 这样，数据就被恢复到了容器c2的/data目录下，我们可以容器中操作和使用这些数据。 相关命令docker run -v 运行时，指定存储卷 --volumes-from list 复制其他容器的卷，达到共享卷的目的 --sorkdir string docker volume ls：列出当前已和宿主建立关联关系的存储卷 create： inspect name:查看一个卷的详细信息 prune rm: 将卷从硬盘上移除，必须使用docker rm -v docker container inspect 看到的容器内的详细信息是JSON格式的 通过过滤特殊字段显示查询的信息 docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}} 1.Docker-managed volume 临时创建挂载一个data(容器内目录)卷 docker run -it --name c1 –v /data busybox docker inspect -f {{.Mounts}} c1 注意： 创建容器的时候加-–rm选项时，停止容器后，宿主机上的卷也会被删除的 不加-–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的 2.Bind-mount Volume docker run --name c2 -it -v HOSTDIR:VOLUMEDIR busybox docker inspect -f {{.Mounts}} c2 宿主机上的目录/data/c2 容器目录/my docker run --name c2 -it --rm -v /data/c2:/my busybox:latest docker container inspect c2 即使容器被删除，宿主机目录数据还在存在的 3.多个容器使用同一主机目录 docker run –it --name c1 -v /data:/my busybox docker run –it --name c2 -v /data:/my busybox 4.复制共享使用其它容器的卷 docker run –it --name c1 -v /data:/my busybox docker run –it --name c2 --volumes-from c1 busybox]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker之Network]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8BNetwork%2F</url>
    <content type="text"><![CDATA[Network docker安装后，默认会创建三种网络类型，bridge、host和none，可通过如下命令查看 Docker网络参考文档 bridge:网络桥接 Docker默认的网络设置，此模式会为每一个容器分配Network Namespace 当Docker server启动时，会在主机上创建一个名为docker0的虚拟网桥 每次docker容器重启时会按照顺序获取对应ip地址，ip都发生变化 这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器 host：主机网络 和宿主机共用一个Network Namespace。 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。 none Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置 这个Docker容器没有网卡、IP、路由等信息。 有需要时，我们自己为Docker容器添加网卡、配置IP等。 共享 ： Docker 容器会共享其他容器的网络环境 共享桥的原理： 共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈 而mount user PID还是隔离的，文件系统也是隔离的 注意 端口只能绑定在产生网卡的容器上 联盟式网络彼此间端口存在冲突可能，通常只会在多个容器需要loopback接口通信，或对某已存在的容器属性进行监控时才使用 相关命令docker run 命令中涉及网络的相关命令 --network 启动容器时，指定使用的网络 [bridge|host|none|container:name] --hostname 启动容器时，指定容器的主机名 --add-host list 启动容器时，指定内部的hosts解析文件 --dns 启动容器时，指定DNS地址 --ip string 启动容器时，指定容器的iPv4地址 -p|--publish 因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则 例： 启动为none类型的网络 docker run --name c1 -it --rm --network none busybox:latest 启动为bridge类型的网络:docker默认的网络模型 docker run --name c2 -it --rm --network bridge busybox:latest 启动为host宿主机类型的网络 docker run --name c3 -it --rm --network host busybox:latest 此时hostname,Net都是和宿主机是一样的 此时在容器内部启动nginx服务，其他主机是可以通过宿主机提供服务的 启动为共享类型的网络 c4共享的是c1的nono,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的 docker run --name c4 -it --rm --network container:c3 busybox:latest docker run --add-host c1:192.168.10.1 busybox:latest cat /etc/hosts可以看到添加的解析 docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest cat /etc/resolve可以看到指定的DNS地址 docker network: ls：显示docker内部的全部网络 connect: 让容器连接到某个网络上 disconnect: 把容器从某个网络断开 create: 创建自定义网络，和KVM创建网络类似 inspect:查看某个网络是怎么定义的 prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令 rm: 删除docker内部的网络 自定义网络docker network create connect:相当于创建一对网卡，一半在桥上，一半在容器中 而且默认创建的网络都是SNAT桥 选项： -d|--driver string 创建时，要指定桥的类型 默认是bridge，当然还有 host macvlan null overlay四种类型 --gateway strings 默认是定义的子网的第一个IP地址 --subnet strings 子网地址 --ip-range strings 地址分配的IP地址范围 修改默认的bridge，docker0桥 自定义docker0桥的网络属性信息：/etc/docker/daemon.json文件 { &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;] } 核心选项为bip，即bridge ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出 查看bridge信息 docker inspect bridge 创建一个名叫 mynet 的网络，并设置其网段为192.168.0.0/16的网络 docker network create --subnet=192.168.80.0/16 mynet 启动Docker容器的时候，网络是在启动时依照ip地址顺序分派的，可以手动指定 docker run --name web -it -d --network mynet -p 8080:80 --ip 172.17.0.5 centos bash 端口暴露docker run -p|--publish docker提供了一个-p选项来自动生成DNAT防火墙规则 -p选项的用法和使用格式： &lt;containerPort&gt; 指定的容器端口映射至主机所有地址的一个动态端口 &lt;hostPort&gt;:&lt;containerPort&gt; 容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt; &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口 &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口， 指定了映射的端口后，可以使用命令查看映射关系： docker container port [name] 例： docker run -it --name c1 -p 80 busybox]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker之Compose]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8BCompose%2F</url>
    <content type="text"><![CDATA[Compose介绍容器编排工具 Docker-Compose 是 Docker 的一种编排服务，是一个用于在Docker上定义并运行复杂应用的工具，可以让用户在集群中部署分布式应用。 通过 Docker-Compose 用户可以很容易地用一个配置文件定义一个多容器的应用， 可以快捷高效地管理容器的启动、停止以及重启等操作，和批量管理容器， 它类似于linux下的shell脚本，基于yaml语法，在该文件里我们可以描述应用的架构，比如用什么镜像、数据卷、网络模式、监听端口等信息。 可以在一个compose文件中定义一个多容器的应用（比如jumpserver），然后通过该compose来启动这个应用 Docker-Compose 解决了容器与容器之间如何管理编排的问题 Compose 中有两个重要的概念： 服务 (service) ：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project) ：由一组关联的应用容器组成的一个完整业务单元，在docker-compose.yml 文件中定义。 Compose安装Install Docker Compose 安装，从官网获取 curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose compose管理命令Compose具有管理应用程序整个生命周期的命令： 启动，停止和重建服务 查看正在运行的服务的状态 流式传输运行服务的日志输出 在服务上运行一次性命令 须在工作目录执行命令 查看帮助 docker-compose --help -f #用于指定配置文件 -p #用于指定项目名称 docker-compose 运行时是需要指定service名称，可以同时指定多个，也可以不指定。不指定时默认就是对配置文件中所有的service执行命令。 用来创建或重新创建服务使用的镜像 docker-compose build [service_name] 创建一个镜像名叫service_a docker-compose build service_a 用于通过容器发送SIGKILL信号强行停止服务 docker-compose kill [service_name] 显示service的日志信息 docker-compose logs [service_name] 暂停/恢复服务 docker-compose pause/unpause [service_name] 用于查看服务中的端口与物理机的映射关系 docker-compose port [service_name] 查看服务中80端口映射到物理机上的那个端口 docker-compose port [service_name] 80 用于显示当前项目下的容器 dokcer-compose ps [service_name] 注意，此命令与docker ps不同作用，此命令会显示停止后的容器（状态为Exited），只征对某个项目。 用于拉取服务依赖的镜像 docker-compose pull [service_name] 用于重启某个服务中的所有容器 docker-compose restart [service_name] 只有正在运行的服务可以使用重启命令，停止的服务是不可以重启 删除停止的服务（服务里的容器） docker-compose rm [service_name] -f #强制删除 -v #删除与容器相关的卷（volumes） docker-compose run 用于在服务中运行一个一次性的命令。这个命令会新建一个容器，它的配置和srvice的配置相同。 但两者之间还是有两点不同之处 1、run指定的命令会直接覆盖掉service配置中指定的命令 2、run命令启动的容器不会创建在service配置中指定的端口，如果需要指定使用--service-ports指定 启动/停止某个服务的所有容器 docker-compose start/stop [service_name] docker-compose scale [SERVICE=NUM...] t, --timeout TIMEOUT (default: 10s) 指定某个服务启动的容器个数 docker-compose scale web=2 worker=3 配置文件实例Compose file 参考 实现wordpress新建一个compose工作目录 mkdir compose/wordpress -p cd compose/wordpress vim docker-compose.yml version:&apos;3&apos; #compose配置文件的版本。（注意不是docker的版本，也不是compose程序的版本） services: #定义服务（每一个子项就是一种服务，每种服务可以生成多个容器） wordpress: #服务的名字叫wordpress depends_on: #wordpress 依赖的服务 - db image: wordpress:latest #使用的镜像文件是wordpress:latest volumes: #定义存储卷 - wordpress_files:/var/www/html #卷挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式（HOST:CONTAINER:ro） ports: #端口映射 - &quot;8080:80&quot; #将宿主机的8080映射到容器的80 restart: always environment: #wordpress服务启动时，需要传递的参数 WORDPRESS_DB_HOST: db:3306 #指明数据库主机地址和端口 WORDPRESS_DB_NAME: wpdb #数据库中使用的数据库名为wpdb WORDPRESS_DB_USER: wpuser #能够使用wpdb数据库的用户名 WORDPRESS_DB_PASSWORD: wppass #wpuser用户的密码 db: #第二个服务的名字叫做db image: mysql:5.7 #使用的镜像文件是mysql:5.7 volumes: - db_data:/var/lib/mysql #使用的存储卷 restart: always #重启设置，有问题就重启 environment: #启动db服务时传递的参数 MYSQL_ROOT_PASSWORD: magedu #数据库使用的密码magedu MYSQL_DATABASE: wpdb #启动容器时创建wpdb数据库 MYSQL_USER: wpuser #创建wpuser用户 MYSQL_PASSWORD: wppass #为wpuser用户设定的密码 volumes: #宿主机对应的卷 wordpress_files: #没有值，默认会创建，也可以指定 db_data: 测试 php连接数据库宿主机IP为 192.168.80.17 新建一个compose工作目录 mkdir compose/php cd compose/php 创建yml文件 vim docker.yml version: &quot;3&quot; services: web: container_name: web image: php:7.2-apache environment: - ALLOW_OVERRIDE=true ports: - &quot;80:80&quot; links: - db volumes: - ./app:/var/www/html/ db: image: mariadb container_name: mariadb restart: always volumes: - ./mysql:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: root MYSQL_USER: admin MYSQL_PASSWORD: test MYSQL_DATABASE: database ports: - &quot;3306:3306&quot; 在宿主机创建测试页， cat app/index.php &lt;?php echo &apos;&lt;h1&gt;Yeah, it works!&lt;h1&gt;&apos;; phpinfo(); ?&gt; 宿主机目录列表 [root@test php]# tree . ├── docker-compose.yml ├── mysql └── app └── index.php 启动容器 docker-compose -f docker.yml up -d 使用Docker-Compose部署nginx代理Tomcat集群,实现负载均衡大体步骤分为以下四步 1、下载所需的文件tomcat,jdk 2、编写dockerfile来布署tomcat与java环境，生成镜像文件 3、编写docker-compose.yml配置文件，启动所有容器服务 4、测试负载均衡]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker常用操作]]></title>
    <url>%2F2019%2F02%2Fdocker%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[基础命令操作命令参考参考手册 docker --help 查看帮助 1.查看docker版本 docker info docker version 2.搜索官方仓库镜像 docker search mariadb 3.根据镜像名称（tag指定版本）拉取镜像 docker image pull mariadb:latest [-limit 10 ]（展示前10条） 不指定tag时，default tag: latest alpine 版本：构建容器小镜像的发行版本 4.查看当前主机镜像列表 docker image ls 5.导出镜像 docker image save busybox &gt; docker-busybox.tar.gz docker image save -o /mnt/busybox_nginx.tar.gz busybox -o：指定导出镜像的位置； 可以同时导出多个镜像；为一个文件； 指定.tar.gz 可以导出并压缩。 6.删除镜像 docker image rm busybox 7.导入镜像 docker load -i ss.tar.gz 8.启动容器 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] options 常用命令选项 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 -i：交互式访问 --name CT_NAME --rm：容器运行终止即自行删除 --network BRIDGE：让容器加入的网络； 默认为docker0(nat)； -d：后台运行容器，并返回容器ID -p：端口映射，将容器内服务的端口映射在宿主机的指定端口 -h &quot;mars&quot;: 指定容器的hostname -e username=&quot;ritchie&quot;: 设置环境变量； --env-file=[]: 从指定文件读入环境变量； --cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定CPU运行； -m :设置容器使用内存最大值； --net=&quot;bridge&quot;: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link=[]: 添加链接到另一个容器； --expose=[]: 开放一个端口或一组端口； docker run --name c1 -it busybox /bin/sh 在运行容器时，交互式进入容器 9.查询容器运行状态命令 docker ps [-a] docker container ls [-a] -a：查询所有的容器 两个命令是一样的效果 注：容器内的第一个进程必须一直处于运行的状态，否则这个容器，就会处于退出状态！ 10.停止运行的容器 docker stop 关闭运行的容器 类似kill -15 docker kill 杀死运行的容器 类似kill -9 11. 启动的容器 docker start /restart 12暂停容器中的所有进程， docker pause &lt;container-id&gt; docker unpause为逆过程即恢复所有进程。比较少使用。 13.查看容器的详细信息 docker inspect c1 14.删除容器 先关闭容器，再删除容器 docker rm web1 docker rm -f `docker ps -a -q` 删除所有容器，-f 强制删除 15.连接到运行容器 attach：附加至某运行状态的容器的终端设备； docker attach c1 这样就能进入容器了，但是要注意，用这个方法发退出容器的时候，容器会停止，所以退出时要选择Ctrl+p,Ctrl+q退出容器 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] 让运行中的容器运行一个额外的程序 options 选项 -d：在后台运行命令 -e：设置环境变量 -i：交互式 -t：打开一个终端 -u：用户名或UID docker run --name c1 -d nginx:1.14-alpine docker exec -it c1 /bin/sh 这个方法退出容器，容器是不会停止的 16.查询容器内部日志 docker logs web1 17 docker commit &lt;container-id&gt; 把容器的可读写层转化成只读层，即从容器状态【可读写文件系统】变为镜像状态【只读文件系统】，可理解为【固化】 docker build 一般作用在dockerfile文件上。 18 Docker Hub： 登陆https://hub.docker.com docker login docker logout 而后可以推送docker镜像 docker push docker pull 19 显示image历史 docker image history --help 20.docker ps 命令： docker ps [OPTIONS] -a :显示所有的容器，包括未运行的。 -l :显示最近创建的容器。 -n :列出最近创建的n个容器。 --no-trunc :不截断输出。 -q :静默模式，只显示容器编号。 -s :显示总的文件大小。 -f过滤器：过滤标志(-f或–filter)格式是key=value。如果超过一个过滤，就传递多个标志(如–filter “foo=bar” –filter “bif=baz”) 目前支持的过滤有如下这些: id(容器id) label(label=或label=&gt;) name(容器名称) exited(整数 – 容器退出码。只在使用–all才有用) status (created restarting running paused exited dead) ancestor([:], or ) – 过滤从指定镜像创建的容器。 before (容器的名称或id) – 过滤在给定id或名称之前创建的容器。 since (容器的名称或id) – 过滤在给定id或名称之后创建的容器。 isolation (default process hyperv) (Windows daemon only) volume (数据卷名称或挂载点) – 过滤挂载有指定数据卷的容器。 network (网络id或名称) – 过滤连接到指定网络的容器。 例： docker ps -f network=docker0 --format为格式化输出。格式化选项(–format)使用Go模板来美化打印容器输出。 Go模板有效的占位符如下： .ID 容器ID .Image 镜像ID .Command Quoted command .CreatedAt 创建容器的时间点. .RunningFor 从容器创建到现在过去的时间. .Ports 暴露的端口. .Status 容器状态. .Size 容器占用硬盘大小. .Names 容器名称. .Labels 容器所有的标签. .Label 指定label的值 例如&apos;{{.Label “com.docker.swarm.cpu”}}’ .Mounts 挂载到这个容器的数据卷名称 docker ps --format &quot;{{.ID}}: {{.Command}}&quot; docker state 动态方式显示容器的资源占用状态： docker top CONTAINER：Display the running processes of a container docker查看单个容器的网络ip docker inspect -f &apos;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}&apos; container_name_or_id 显示所有容器IP地址： docker inspect --format=&apos;{{.Name}} - {{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&apos; $(docker ps -aq)]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker之image]]></title>
    <url>%2F2019%2F02%2Fdocker%E4%B9%8Bimage%2F</url>
    <content type="text"><![CDATA[Docker 镜像镜像是构建Docker的基石，用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分 Docker镜像含有启动容器所需要的文件系统及其内容，因此其用于创建并启动docker容器 1.docker镜像包含了启动容器/虚拟机所依赖的所有文件、文件系统 包括程序文件，库文件，配置文件,数据目录等等 2.采用分层构建机制，最底层为bootfs，其之为rootfs bootfs： 在所创建的容器中是看不到的，用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以节约内存资源；把对应的对容器的管理委托给宿主机的内核 rootfs： 位于bootfs之上，表现为docker容器的根文件系统; 传统模式中，系统启动之时，内核挂载rotfs时会首先将其挂载为“只读”模式，完整性自检完成后将其重新挂载为读写模式 docker中，rootfs由内核挂载为“只读”模式，容器启动完成rootfs也不会以读写方式重新挂载 docker容器的用户空间和根文件系统一直都是只读的 docker中，rootfs由内核挂载为“只读”模式，而后通过“联合挂载(AUFS)”技术额外挂载一个“可写”层 注意：当删除容器时，这个容器自有的“可写”层会一起被删除 镜像层级位于下层的镜像称为父镜像（parent image），最底层的称为基础镜像（base image） 最上层为“可读写层”，其下的均为“只读”层； a.完整的docker镜像包括bootfs,rootfs b.而rootfs又包括Base Image+自定义的镜像层+可写层writable 除了writable是可写层，其他都是只读层 c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加一个可写层，这个可写层writable是属于容器的 d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的 e.可写层是可以自定义修改，把可写层保存为镜像，再和原始镜像进行叠加成一个自定义的镜像,可以作为基础镜像使用了，一般不这么做，而是通过dockerfile自定义镜像 AUFSAdvanced multi-layered unification filessystem：高级多层统一文件系统 Docker最初使用aufs作为容器文件系统层，它目前仍作为存储后端之一来支持； aufs竞争产品是overlayfs2，后者自从3.18版本开始被合并到Linux内核； aufs是一种支持联合挂载的文件系统，支持不同目录挂载到同一个目录，挂载对用户来说是透明的。 Docker的graph driver主要用于管理和维护镜像，包括把镜像从仓库下载下来，到运行时把镜像挂载起来可以被容器访问等，都是graph driver做的 镜像原理ext4和xfs默认是不支持联合挂载和写时复制机制的 写时复制 可以在多个容器之间共享镜像，每个容器启动时不需要单独复制一份镜像文件 将所有镜像层以只读方式挂载到一个挂载点，在上面覆盖一个可读写的容器层。 写时复制配合分层机制减少了镜像对磁盘空间的占用和容器启动时间 文件操作 读 从最顶层的读写层开始向下寻找，本层没有则根据层与层之间的关系到下一层找 写 如果文件不存在则在读写层新建一个，否则向上面一样从顶层开始查找，找到后复制到读写层进行修改 删 如果文件仅仅在读写层则直接删除；否则需要删除读写层的备份，而不会真正删除底层文件 增 在容器中创建文件时，新文件被添加到容器层中。 只有运行中文件系统发生变化，才会把变化的内容写到读写层，并隐藏只读层中的老版本文件 Docker提供了各种基于不同文件系统实现的存储驱动来管理实际的镜像文件 默认在/var/lib/docker/image/overlay2/ 镜像在设计上将元数据和文件存储完全隔离。 Docker管理元数据采用的也正是从上至下repository、image、layer是3个层次。 所以repository与image两个元数据并无物理上的镜像文件与之对应， layer则存在物理上的镜像文件与之对应。 仓库元数据 文件中存储了所有版本镜像的名字和tag以及对应的镜像ID（image/aufs） 镜像元数据 文件中存储了镜像架构、操作系统、默认配置、该镜像的容器ID和配置，构建镜像的历史信息以及rootfs组成（image/aufs/imagedb/content/sha256） 分层元数据 镜像层 描述不可改变的镜像层（image/aufs/layerdb/sha256） 容器层 描述可读写的容器层（image/aufs/layerdb/mounts/），读写层的ID也对应容器的ID 管理命令docker image 相关命令 docker imges:镜像的管理命令 ls： 查看本地所有的镜像列表 build: 新建 import: 从归档文件中创建镜像 export :将文件系统作为一个tar归档文件导出到STDOUT inspect: 查看下载/创建的镜像详细信息 可以查看下载的某个镜像的具体信息 如：CMD:镜像启动默认运行的命令 Volume: network: 下文中构建docker file时这些都可以自定义 load: 从tar文件导入镜像 prune: 删除未使用的镜像 pull：从远程仓库拉取镜像到本地 push: 把本地镜像推到远程的Registry rm: docker image rm = docker rmi 删除镜像 tag: 给镜像打标签 save: 镜像文件导出为tar文件 镜像制作：基于容器制作 在容器中完成操作后制作； 基于镜像制作 编辑一个Dockerfile，而后根据此文件制作； 基于容器制作： docker commit docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] -author, -a 指定作者 --pause, -p 暂停运行容器，保持数据一致 --change, -c 镜像内部默认运行的命名 docker commit -a &quot;liu&lt;8@qq.com&gt;&quot; -c &apos;CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/html&quot;]&apos; -p b1 liu/httpd:v0.2 上传docker hub docker login 登录到docker hub 输入账号密码，正常登录后 push镜像 docker image push liu/httpd:v0.2 正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层 这种方式适用于测试环境： 将镜像文件导出为tar文件: docker save Save one or more images to a tar archive (streamed to STDOUT by default) docker save [OPTIONS] IMAGE [IMAGE...] docker save -o myimag.gz liu/httpd:v0.1 从tar文件导入镜像 ： docker load Load an image from a tar archive or STDIN docker load [OPTIONS] --input, -i Read from tar archive file, instead of STDIN --quiet, -q false Suppress the load output docker load -i myimag.gz]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker基础]]></title>
    <url>%2F2019%2F01%2Fdocker%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[基本概念容器官方文档 容器(Linux Containers) 是一个存放东西的地方，容器存放的东西可能更偏向于应用比如网站、程序甚至是系统环境。比如nginx，mysql，或者其他的服务器 是独立运行的一个（或一组）应用，以及它们必需的运行环境 是将软件打包成标准化单元，以用于开发、交付和部署 直接运行在操作系统内核之上的用户空间 容器技术可以让多个独立的用户空间运行在同一台宿主机上 可以运行在物理机也可以运行在虚拟机上，当然也可以运行在公有云主机上。 如果这个进程想要的话，我们就把这个容器启动起来，我们这个进程想把这个容器删掉 容器与虚拟化的区别? 虚拟化使得多个操作系统可同时运行在单个系统上 容器则可共享同一个操作系统的内核，将应用程序与系统其它部分隔离开 Docker官方文档docker中文社区 Docker是指容器化技术，是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机)、 bare metal、OpenStack 集群和其他的基础应用平台 Docker通常用于如下场景： web应用的自动化打包和发布； 自动化测试和持续集成、发布； 在服务型环境中部署和调整数据库或其他的后台应用； 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境 特点 Docker容器后台运行,就必须有一个前台进程 一个容器中只运行一个进程；镜像构建：分层构建，联合挂载 每个进程之间是隔离的 进程终止容器也可删除，容器有生命周期。与宿主机没有密切关联关系 Docker底层依赖的核心技术主要包括Linux操作系统的命名空间（Namespace）、控制组（Control Group）、联合文件系统（Union File System）和Linux网络虚拟化支持 命名空间 每个容器都可以拥有自己单独的命名空间 host主机的UTS、IPC、Network可以与容器可以进行共享 控制组(cgroup)控制组主要用来对共享资源进行隔离、限制、审计等，只有能控制分配到容器的资源，才能避免多个容器同时运行时对宿主机系统的资源竞争 cgroup blkio 这个子系统设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。 cpu 这个子系统使用调度程序为cgroup任务提供cpu的访问。 cpuacct 产生cgroup任务的cpu资源报告。 cpuset 如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。 devices 允许或拒绝cgroup任务对设备的访问。 freezer 暂停和恢复cgroup任务。 memory 设置每个cgroup的内存限制以及产生内存资源报告。 net_cls 标记每个网络包以供cgroup方便使用。 ns 名称空间子系统。 perf_event 对cgroup中的任务进行统一性能测试 如：可以在/sys/fs/cgroup/cpu/docker/目录下看到对Docker组应用的各种限制值 联合文件系统(unionFS)是一种轻量级的高性能分层文件系统，它支持将文件系统中的修改信息作为一次提交，并层层叠加，同时可以将不同目录挂载到同一个虚拟文件系统下，应用看到的是挂载的最终结果。 网络每一个使用 docker run 启动的容器其实都具有单独的网络命名空间，Docker为我们提供了四种不同的网络模式，Host、Container、None 和 Bridge 模式。 架构程序自身使用c/s架构，客户端向服务器发送请求，服务器负责构建、运行和分发容器。客户端和服务器可以运行在同一个Host上，使用远程API来管理和创建Docker容器与远程的服务器通信 Client &lt;--&gt; Daemon &lt;--&gt; Registry Server Docker 容器：通过 Docker 镜像来创建，是 Docker 镜像的运行实例 DOCKER_HOST：真正运行容器的主机 Containers：容器，独立运行的一个或一组应用 Images：镜像，用于创建 Docker 容器的模板 Registry：镜像仓库 镜像image与容器Container区别： 镜像是静态的，不会运行 容器则是动态的，有生命周期 容器构建示例 运行容器一个实例： docker run -it --rm --name c1 busybox:latest /bin/sh 当运行这条指令后的执行流程步骤： 1.检查本地是否存在指定的镜像，不存在则从registry下载； 2.利用镜像启动容器 3.分配一个文件系统，并且在只读的镜像层之外挂载一个可读写层； 4.从宿主机配置的网桥接口桥接一个虚拟接口给此容器； 5.从地址池中分配一个地址给容器； 6.执行用户指定的应用程序； 7.程序执行完成后，容器即终止 注意：容器是为任务而生，任务完成即销毁，释放资源。为单一任务（进程）设计 运行的容器内部必须有一个工作前台的运行的进程； docker的容器的通常也是仅为运行一个程序； 要想在容器内运行多个程序，一般需要提供一个管控程序，例如supervised 创建容器： 基于“镜像文件”， 镜像文件有默认要运行的程序； 安装dockerDocker 提供了两个版本：社区版 (CE) 和企业版 (EE)。 Docker社区版(CE)是开发人员和小型团队开始使用Docker并尝试使用基于容器的应用的理想之选。 DockerCE 有两个更新渠道，即 stable 和 edge Stable 每个季度为您提供可靠更新 Edge 每个月为您提供新功能 依赖的基础环境 64 bits cpu linux kernel 3.10+ linux kernel cgroups and namespaces docker程序环境： 环境配置文件： /etc/sysconfig/docker-network /etc/sysconfig/docker-storage /etc/sysconfig/docker Unit File： /usr/lib/systemd/system/docker.service Docker Registry配置文件： /etc/containers/registries.conf docker-ce: 配置文件：/etc/docker/daemon.json INSTALL 1.首先配置repo wget -P /etc/yum.repos.d/ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 2.镜像加速地址 多种加速方式 docker cn 阿里云加速器 中国科技大学 注册阿里云账号,专用加速器地址获得路径： https://cr.console.aliyun.com/#/accelerator 由于国外网速较慢，下载镜像不方便 https://cr.console.aliyun.com/cn-hangzhou/mirrors mkdir /etc/docker tee /etc/docker/daemon.json &lt;&lt;EOF { &quot;registry-mirrors&quot;: [&quot;https://5k0xky51.mirror.aliyuncs.com&quot;,&quot;https://registry.docker-cn.com&quot;] } EOF 3.安装 yum install docker-ce -y systemctl daemon-reload systemctl restart docker systemctl enable docker.service 在安装docker的时候可能会遇到如下的问题 报错 Error: Package: 3:docker-ce-18.09.0-3.el7.x86_64 (docker-ce-stable) Requires: container-selinux &gt;= 2.9 原因：安装时依赖container-selinux安装包 解决办法：在yum仓库设置正确的 extra 源]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat部署与发布]]></title>
    <url>%2F2019%2F01%2Ftomcat%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[安装jdkOpenJDK 开源，在linux中内置 java-VERSION-openjdk： The OpenJDK runtime environment. java-VERSION-openjdk-headless： The OpenJDK runtime environment without audio and video support. java-VERSION-openjdk-devel： The OpenJDK development tools. CentOS 7： VERSION：1.6.0, 1.7.0, 1.8.0 注意：多版本并存时，可使用 alternatives命令设定默认使用的版本； [oracle jdk](https://www.oracle.com/technetwork/java/javase/downloads/index.html) 安装相应版本的rpm包； jdk-VERSION-OS-ARCH.rpm 例如:jdk-8u191-linux-x64.rpm 注意：安装完成后，要配置JAVA_HOME环境变量，指向java的安装路径； rpm -ivh jdk-8u191-linux-x64.rpm 配置环境变量 vim /etc/profile.d/java.sh export JAVA_HONE=/usr/java/default export PATH=$JAVA_HOME/bin:$PATH . /etc/profile.d/java.sh 了解当前的java环境： java -version 安装tomcat1.yum安装（Base Repo） yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp systemctl start tomcat systemctl enable tomcat 2.二进制安装 tomcat包下载 在生产环境中我们需要将tomcat配置成以daemon守护进程来运行，主要有以下几个原因： 以daemon方式运行tomcat可使tomcat不受终端影响，不会因为退出终端而停止运行。 可以让tomcat以普通用户身份运行 可以让tomcat在系统启动时自动运行 useradd tomcat -s /sbin/nologin tar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/ /usr/local/ ln -sv apache-tomcat-8.5.37 tomcat chown -R tomcat:tomcat apache-tomcat-8.5.37/ 配置环境变量 vim /etc/profile.d/tomcat.sh export CATALINA_BASE=/usr/local/tomcat export PATH=CATALINA_BASE/bin:$PATH 启动 /usr/local/tomcat/bin/catalina.sh start 部署webapp的方法deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载至JVM； 部署有两种方式： 自动部署：auto deploy 手动部署: 冷部署：把webapp复制到指定的位置，而后才启动tomcat； 热部署：在不停止tomcat的前提下进行部署； 部署工具：manager、ant脚本、tcd(tomcat client deployer)等； undeploy：反部署，停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署； tomcat的两个管理应用: manager：管理webapps应用程序 host-manager：管理虚拟主机 测试类应用，并冷部署直接将程序目录放在webapps目录下面（不推荐） 1.创建一个webapp组织结构，必须在ROOT目录 mkdir -pv /data/webapps/ROOT/{lib,classes,WEB-INF,META-INF} 2.新建一个index.jsp vim /data/webapps/ROOT/index.jsp 1234567891011&lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello world"); %&gt; &lt;/body&gt;&lt;/html&gt; 3.修改配置文件servel.xml 4.访问网页test/index.jsp 可以在host主机定义context上下文 mkdir /app/tset-v1 创建软连接，方便替换新文件，此时自定义的应用访问 ln -sv /app/tset-v1 /app/test /usr/local/tomcat/bin/catalina.sh stop &amp;&amp; /usr/local/tomcat/bin/catalina.sh start tomcat管理工具1.manager app：webapp管理工具，部署之后，重启服务，仍然有效 2. 打开http://IP:8080就可出现如下 自动部署发工具将程序打包成war包，然后上传到webapps目录下面 站点主动解压部署 浏览器访问： http://192.168.80.37:8080/jenkins-2.138.3]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker资源限制]]></title>
    <url>%2F2019%2F01%2Fdocker%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[资源控制默认情况，在Docker容器中没有任何资源限制 可以从名称空间(namespace)和控制组(cgroups)两个维度来定义 Cgroup是Control group的简写，是Linux内核提供的一种限制所使用物理资源的机制，这些资源主要包括CPU、内存、blkio Cgroup配置文件为/sys/fs/cgroup/ memoryOOME：如果Linux内核探测到当前宿主机已经没有足够内存可用，用于实现执行某些重要的系统功能，它会抛出一个异常，并且开始启动去killing某些进程来释放内存 一旦发生OOME，任何进程都有可能被杀死，包括docker daemon在内 使用docker run -m 命令来限制单个容器内存使用量 内存限制配置文件 memory.limit_in_bytes echo 512M &gt; memory.limit_in_bytes 注意： 1.一旦容器Cgroup使用超过内存限制的容量，Linux内核将会尝试收回这些内存， 2.但进程不会被kill掉，因为内核会尝试将物理内存中的数据移动到swap空间中，从而让内存分配成功 3.设置的limit过小，或者swap空间不足，进程就会被杀死 触发控制 配置文件 memory.oom_control 当物理内存达到上限后，系统的默认行为是kill掉cgroup中继续申请内存的进程 如果写1到这个文件，表示不启动OOM-killer，当内核无法给进程分配足够的内存时，将会暂停该进程直到有空余的内存之后再继续运行；同时，memory.oom_control还包含一个只读的under_oom字段，用来表示当前是否已经进入oom状态，也即是否有进程被暂停了。 https://segmentfault.com/a/1190000008125359 CPU默认设置每个容器可以使用宿主机的所有CPU资源 --cpu cpu数量 --cpuset-cpus选项来世某个程序独享CPU内核以便提高处理速度， --cpu-share选项设置CPU按比例共享CPU资源权重 ,默认值为 1024 --cpu-quota选项来限制CPU使用速率，CPU的百分比是以1000为单位 对应的Cgroup配置文件为/sys/fs/cgroup/cpuset/docker 容器编号cpuset.cpus。选项后面直接跟参数0，1，2...表示第一个内核，第二个内核，第三个内核 如果服务器有16个核心，那么CPU编号为0~15，是容器绑定1~4个内核使用 docker run -d --cpuset-cpus 0,1,2,3 容器名 注意： cgroup 只能限制 CPU 的使用，而不能保证CPU的使用。 cpuset-cpus，可以让容器在指定的CPU或者核上运行，但是不能确保它独占这些CPU； cpu-shares 是个相对值，只有在CPU不够用的时候才其作用。， 当CPU够用的时候，每个容器会分到足够的CPU；不够用的时候，会按照指定的比重在多个容器之间分配CPU。 blkio一台服务器上进行容器的混合部署，那么会出现有几个程序写入磁盘数据的情况 Block IO：指的是磁盘的读写，docker可以通过设置权重，限制bps和iops的方式控制容器读写磁盘的带宽 --blkio-weight，改变容器的优先级,weight的权重值在 10~1000之间 在资源紧张的情况下才会起到权重的作用，正常情况下，都是平等的 --device-write-iops：来限制写入iops， --device-write-bps ： 限制写入某个设备的bps(数据量) --device-write-iops ：限制写入某个设备的iops(次数) --device-read-bps：可以限制读取iops。 但是这种方法只能针对blkio限制的设备，而不是分区。 Cgroup写配置文件/sys/fs/cgroup/blkio/docker/容器ID/blkio.write_iops_device 例如限制容器的/dev/sda1的写入iops为1MB docker run --device-write-bps /dev/sda1:2mb 容器名 相关命令Docker run --help docker stats [container_name]显示容器使用的系统资源 只返回当前的状态 --no-stream 不想持续的监控容器使用资源的情况， docker stats --no-stream [container_name] 显示运行容器 docker stats $(docker ps --format={{.Names}}) 定义输出的内容和格式 docker stats --format &quot;table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}&quot; 占位符： .Container 根据用户指定的名称显示容器的名称或 ID。 .Name 容器名称。 .ID 容器 ID。 .CPUPerc CPU 使用率。 .MemUsage 内存使用量。 .NetIO 网络 I/O。 .BlockIO 磁盘 I/O。 .MemPerc 内存使用率。 .PIDs PID 号。 format 选项输出 json 格式的结果 docker stats --no-stream --format \ &quot;{\&quot;container\&quot;:\&quot;{{ .Container }}\&quot;,\&quot;memory\&quot;:{\&quot;raw\&quot;:\&quot;{{ .MemUsage }}\&quot;,\&quot;percent\&quot;:\&quot;{{ .MemPerc }}\&quot;},\&quot;cpu\&quot;:\&quot;{{ .CPUPerc }}\&quot;}&quot; docker topdocker top [OPTIONS] CONTAINER [ps OPTIONS] 查看容器中运行的进程信息 查看所有运行容器的进程信息 for i in `docker ps |grep Up|awk &apos;{print $1}&apos;`;do echo \ &amp;&amp;docker top $i; done]]></content>
  </entry>
  <entry>
    <title><![CDATA[LVS实战]]></title>
    <url>%2F2019%2F01%2FLVS%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[RS的预配置脚本： 1234567891011121314151617181920212223242526272829#!/bin/bash#vip=10.1.0.5mask='255.255.255.255'case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig lo:0 $vip netmask $mask broadcast $vip up route add -host $vip dev lo:0 ;;stop) ifconfig lo:0 down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esac VS的配置脚本： 1234567891011121314151617181920212223242526272829#!/bin/bash#vip='10.1.0.5'iface='eno16777736:0'mask='255.255.255.255'port='80'rs1='10.1.0.7'rs2='10.1.0.8'scheduler='wrr'type='-g'case $1 instart) ifconfig $iface $vip netmask $mask broadcast $vip up iptables -F ipvsadm -A -t $&#123;vip&#125;:$&#123;port&#125; -s $scheduler ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs1&#125; $type -w 1 ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs2&#125; $type -w 1 ;;stop) ipvsadm -C ifconfig $iface down ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esac ###]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat负载均衡]]></title>
    <url>%2F2019%2F01%2Ftomcat%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[httpd proxy 进入tomcat的请求可分为两类： (1) standalone : 请求来自于客户端浏览器； (2) 由其它的web server反代：来自前端的反代服务器； nginx --&gt; http connector --&gt; tomcat httpd(proxy_http_module) --&gt; http connector --&gt; tomcat httpd(proxy_ajp_module) --&gt; ajp connector --&gt; tomcat httpd(mod_jk) --&gt; ajp connector --&gt; tomcat Tomcat集群(1) httpd + tomcat cluster httpd: mod_proxy, mod_proxy_http, mod_proxy_balancer tomcat cluster：http connector (2) httpd + tomcat cluster httpd: mod_proxy, mod_proxy_ajp, mod_proxy_balancer tomcat cluster：ajp connector (3) httpd + tomcat cluster httpd: mod_jk tomcat cluster：ajp connector (4) nginx + tomcat cluster 基于nginx反向代理后端tomcat负载均衡编辑nginx.conf http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; upstream web { server 192.168.0.10:8080; server 192.168.0.20:8080; } server { listen 80; server_name localhost; location / { root html; index index.jsp index.htm; } location ~* \.(jsp|do)$ { proxy_pass http://web; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 基于http的httpd + tomcat cluster实现httpd的代理模块： proxy_module proxy_http_module：适配http协议客户端； proxy_ajp_module：适配ajp协议客户端； 官方文档 httpd反向代理，配置在server或虚拟主机内 ProxyRequests off &lt;LocationMatch &quot;\.(jsp|do)$&quot;&gt; ProxyPass http://127.0.0.1:8080/ &lt;/LocationMatch&gt; mod_proxy文档 反向代理及后端负载均衡配置示例： 安装httpd并在/etc/httpd/conf.d/目录下新建tomcat-httpd.conf &lt;proxy balancer://tcsrvs&gt; BalancerMember http://172.18.100.67:8080 BalancerMember http://172.18.100.68:8080 ProxySet lbmethod=byrequests &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName www.a.com ProxyRequests Off ProxyVia On ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / http://tcsrvs:8080/ ProxyPassReverse / http://tcsrvs:8080/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; 配置参数详解： ProxySet lbmethod byrequests 进行加权请求计数 bytraffic 执行基于权重的流量计数调度，bybusyness通过考量每个后端服务器的当前负载进行调度 maxattempts 放弃请求之前实现故障转移的次数，默认为1，其最大值不应该大于总的节点数 nofailover 取值为On或Off，设置为On时表示后端服务器故障时，用户的session将损坏 在后端服务器不支持session复制时可将其设置为On。 stickysession 调度器的stickysession的名字，根据web程序语言的不同，其值为JSESSIONID或PHPSESSIONID ProxyRequests 不开启正向代理 ProxyVia {On|Off|Full|Block} 用于控制在http首部是否使用Via:主要用于在多级代理中控制代理请求的流向。 默认为Off，即不启用此功能； On表示每个请求和响应报文均添加Via:； Full表示每个Via:行都会添加当前apache服务器的版本号信息； Block表示每个代理请求报文中的Via：都会被移除。 ProxyPreserveHos {On|Off} 代理会将用户请求报文中的Host:行发送给后端的服务器，而不再使用ProxyPass指定的服务器地址。如果想在反向代理中支持虚拟主机，则需要开启此项 proxy_ajp反向代理proxy_ajp_module 安装httpd并在/etc/httpd/conf.d/目录下新建tomcat-ajp.conf apache:mod_jk反向代理配置过程： Tomcat端配置使用之前的配置，无需修改 Httpd端配置 1).vim /etc/httpd/conf.d/mod_jk.conf LoadModule jk_module modules/mod_jk.so JkWorkersFile /etc/httpd/conf.d/workers.properies JkLogFile logs/mod_jk.log JkLogLevel notice JkMount /* testsrvs JkMount /jk_status Status 2)./etc/httpd/conf.d/workers.properies worker.list=testsrvs,Status,srv_A,srv_B worker.srv_A.host=192.168.1.102 worker.srv_A.port=8009 worker.srv_A.lbfactor=1 worker.srv_A.type=ajp13 worker.srv_B.host=192.168.1.103 worker.srv_B.port=8009 worker.srv_B.lbfactor=2 worker.srv_B.type=ajp13 worker.testsrvs.type=lb worker.testsrvs.balance_workers=srv_A,srv_B worker.testsrvs.sticky_session=0 //{0|1}关闭/开启session sticky worker.Status.type=status mod_proxy和mod_jkmod_proxy 优势: 不需要编译和维护一个对立的模块。mod_proxy,mod_proxy_http,mod_proxy_ajp,mod_proxy_balancer已经是apache 2.2+的标准集成部分； 可以使用http、https和AJP协议，即便是在同一个balancer中。 劣势: mod_proxy_ajp不支持大于8k的数据包； 只有最基本的负载均衡器； 不支持域模型集群（domain model clustering） mod_jk是ASF的一个项目，是一个工作于apache端基于AJP协议与Tomcat通信的连接器，它是apache的一个模块，是AJP协议的客户端（服务端是Tomcat的AJP连接器 优势: 先进的负载均衡器； 先进的节点失败侦察功能； 支持大型AJP 数据包 劣势: 需要单独维护一个独立的模块]]></content>
  </entry>
  <entry>
    <title><![CDATA[LVS基础]]></title>
    <url>%2F2019%2F01%2FLVS%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[LVS官网 LVS是Linux Virtual Server的简称，也就是Linux虚拟服务器。 是国人章文嵩博士发起的一个开源项目，它是一款四层负载均衡软件 从 Linux2.4内核以后，已经完全内置了LVS的各个功能模块，无需给内核打任何补丁，可以直接使用 LVS 提供的各种功能。 体系架构 工作组成及原理LVS由两部分组成，包括ipvs和ipvsadm ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及相关的RealServer ipvs：工作于内核空间的netfilter的INPUT钩子之上的框架 工作原理： 根据请求报文的目标IP和目标协议及端口将其调度转发至某RealServer，根据调度算法来挑选RS； LVS是工作在linux内核空间的tcp/ip栈的应用程序，其程序名称为ipvs， ipvs会监听input链上的请求，一旦请求的是集群服务的话，ipvs钩子函数会将请求拉出并进行报文修改，强制转发到postrouting处理 在客户端看来 负载层的LVS就是一个真实的应用服务器，客户端向LVS发送请求信息，LVS接收数据报文至内核空间， 工作在input链上的ipvs模块会判断用户请求是不是定义的后端服务器， 如果用户请求的就是定义的后端集群服务，数据报文传送到input链上时，input链会强行将数据报文转发给postrouting， postrouting将数据报文传送给后端真实服务器 调度算法ipvs scheduler:根据其调度时是否考虑各RS当前的负载状态 静态方法：仅根据算法本身进行调度； RR：roundrobin，轮询； 它将请求依次分配给不同的节点，各个节点均摊分配。这种算法简单，但只适合各个节点处理性能差不多的情况 WRR：Weighted RR，加权轮询； 它将依据不同节点的权值分配任务。权值较高的节点将优先获得任务，并且分配到的连接数将比权值低的节点更多。相同权值的节点得到相同数目的连接数 SH：Source Hashing，实现session sticky， 源IP地址hash；将来自于同一个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定； DH：Destination Hashing；目标地址哈希， 将发往同一个目标地址的请求始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡； 动态方法：主要根据每RS当前的负载状态及调度算法进行调度,Overhead=value较小的RS将被调度 LC 最小连接调度：least connections Overhead=activeconns*256+inactiveconns IPVS表存储了所有活动的连接。Lvs服务器会比较将连接请求发送到当前连接最少的节点。 WLC 加权最小连接调度：Weighted LC ,默认调度方法 Overhead=(activeconns*256+inactiveconns)/weight 在节点性能差异较大的时候，可以为节点自动调整权重，权重较高的节点承担更大比例的连接。 SED 最短预期延时调度：Shortest Expection Delay Overhead=(activeconns+1)*256/weight NQ 不排队调度：Never Queue LBLC 基于局部性的最少连接调度：Locality-Based LC，动态的DH算法； 调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。 该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器， 若该服务器 是可用的且没有超载，将请求发送到该服务器； 若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用”最少链接”的原则选出一个可用的服务 器，将请求发送到该服务器 LBLCR 带复制的基于局部性的最少连接调度 ：LBLC with Replication，带复制功能的LBLC； 维护从一个 目标IP地址到一组服务器的映射 根据请求的目标IP地址找出该目标IP地址对应的服务器组，按”最小连接”原则从服务器组中选出一台服务器 若服务器没有超载，将请求发送到该服务器，若服务器超载； 则按”最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。 同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度 工作模式lvs-nat：多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发； 1.RIP和DIP必须在同一个IP网络，且应该使用私网地址；RS的网关要指向DIP； 2.请求报文和响应报文都必须经由Director转发；Director易于成为系统瓶颈； 3.支持端口映射，可修改请求报文的目标PORT； 4.vs必须是Linux系统，rs可以是任意系统； 1)当用户请求到达DS，此时请求的数据报文会先到内核空间的PREROUTING链。此时报文的源IP为CIP，目标IP为VIP 。 2) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链。 3) IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP 4) POSTROUTING链通过选路，将数据包发送给RS。 5) RS比对发现目标为自己的IP，开始构建响应报文发回给DS。此时报文的源IP为RIP，目标IP为CIP 。 6) DS在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。此时报文的源IP为VIP，目标IP为CIP lvs-nat设计要点： (1)RIP与DIP在同一IP网络, RIP的网关要指向DIP (2)支持端口映射 (3)Director要打开核心转发功能 lvs-dr：Direct Routing，直接路由；操纵封装新的MAC地址 通过为请求报文重新封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变； Director和各RS都得配置使用VIP； 1.确保前端路由器将目标IP为VIP的请求报文发往Director： 主机上均需要配置VIP，解决地址冲突的方式有三种 (1) 在前端网关做静态绑定； (2) 在各RS使用arptables； arptables -A IN -d $VIP -j DROP arptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP (3) 在各RS修改内核参数，来限制arp响应和通告的级别； /proc/sys/net/ipv4/conf/all/ /proc/sys/net/ipv4/conf/lo/ 限制响应级别：arp_ignore 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应； 1: 仅在请求的目标IP配置在本地主机的接收到请求报文接口上时，才给予响应； 限制通告级别：arp_announce 0：默认值，把本机上的所有接口的所有信息向每个接口上的网络进行通告 1：尽量避免向非直接连接网络进行通告； 2：必须避免向非本网络通告 2.RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director； 3.RS跟Director要在同一个物理网络； 4.请求报文要经由Director，但响应不能经由Director，而是由RS直接发往Client； 5.不支持端口映射,不支持地址转换 1)当用户请求到达DS，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 2) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 3) IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址 4) 由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至RS。 5)client的请求被Director转发并经过链路层寻址到达RS后，由于RS的lo接口配置了VIP(请求中的目标IP正是VIP)，所以接收请求并处理。处理完成之后， 将响应报文通过lo接口传送给eth0网卡（这个网卡一般指和调度器在一个网段的网卡）然后向外发出。此时的源IP地址为VIP，目标IP为CIP 为什么要抑制ARP请求? 1.由于后端RS要将VIP绑定到lo网卡上,这就出现了一个问题,客户端请求到达LVS前端路由器的时候,前端路由器会发送一个{目标地址为VIP}的请求报文,所以需要抑制RS的ARP,保证让DS收到这个报文,而不是RS收到这个报文 2.抑制RS原因:保证前端路由将目标地址为VIP的报文发给DS,而不是RS lvs-tun：转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而是在原IP报文之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP）； 1.DIP, VIP, RIP都应该是公网地址； 2.RS的网关不能，也不可能指向DIP； 3.请求报文要经由Director，但响应不能经由Director； 4.不支持端口映射； 5.RS的OS得支持隧道功能； 1).客户端将请求发往DS，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 2)PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 3)负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将在客户端请求报文的首部再封装一层IP报文,将源地址改为DIP，目标地址改为RIP,并将此包发送给RS。 4)RS收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层IP首部的目标地址是自己lo接口上的VIP，所以会处理次请求报文， 并将响应报文通过lo接口送给eth0网卡（这个网卡一般指和调度器在一个网段的网卡）直接发送给客户端。此时的源IP地址为VIP，目标IP为CIP 注意：需要设置lo接口的VIP不能在共网上出现。 lvs-fullnat：通过同时修改请求报文的源IP地址和目标IP地址进行转发； CIP &lt;--&gt; DIP VIP &lt;--&gt; RIP 1.VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP； 2.RS收到的请求报文源地址是DIP，因此，只能响应给DIP；但Director还要将其发往Client 3.请求和响应报文都经由Director； 4.支持端口映射； 注意：此类型默认不支持；需要打补丁 区别 lvs-nat, lvs-fullnat：请求和响应报文都经由Director； lvs-nat：RIP的网关要指向DIP； lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信； lvs-dr, lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client； lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发； lvs-tun：通过在原IP报文之外封装新的IP首部实现转发，支持远距离通信； ipvsadmipvsadm/ipvs： 集群和集群之上的各RS是分开管理的； 集群服务定义 服务上的RS定义 ipvs： grep -i -C 10 &quot;ipvs&quot; /boot/config-VERSION-RELEASE.x86_64 支持的协议：TCP， UDP， AH， ESP， AH_ESP, SCTP； ipvsadm 命令用于管理集群服务 LVS ipvsadm： 程序包：ipvsadm Unit File: ipvsadm.service 主程序：/usr/sbin/ipvsadm 规则保存工具：/usr/sbin/ipvsadm-save 规则重载工具：/usr/sbin/ipvsadm-restore 配置文件：/etc/sysconfig/ipvsadm-config ipvsadm命令： 核心功能： 集群服务管理：增、删、改 集群服务的RS管理：增、删、改 查看 管理集群服务： 增、改： ipvsadm -A|E -t|u|f vip_addr:port [-s scheduler] [-p [timeout]] 删： ipvsadm -D -t|u|f vip_addr:port 管理集群上的RS： 增、改： ipvsadm -a|e -t|u|f vip_addr:port -r rip[:port] [-g|i|m] [-w weight] 删： ipvsadm -d -t|u|f vip_addr:port -r rip[:port] 查看： ipvsadm -L|l [options] --numeric, -n：以数字形式显示IP端口 --exact：expand numbers (display exact values) --connection， -c：显示ipvs中目前存在的连接，也可以用于分析调度情况 --stats：显示历史转发消息统计（累加值） --rate ：显示转发速率信息（瞬时值） --timeout ：显示配置的tcp/tcpfin/udp超时时间 -s:指定集群的调度算法，默认为wlc -A:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 ,是一个数字 -D:删除虚拟服务器记录 -E:修改虚拟服务器记录 -C:清空所有记录 -L:查看 -a:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 -r:指定后端realserver的IP -g:DR模式 -i:TUN模式 -m:NAT模式 -w:指定权重 -d:删除realserver记录 -e:修改realserver记录 -l:查看 保存：可以保存至 /etc/sysconfig/ipvsadm ipvsadm -S = ipvsadm-save systemctl stop ipvsadm.service ipvsadm -S &gt; 规则文件路径 重载保存的规则 ipvsadm -R &lt; /PATH/FILE ipvsadm-restore &lt; /PATH/FILE systemctl restart ipvsadm.service FireWall MarkFWM：FireWall Mark 一个集群服务(lvs-dr调度web server)可以将两个服务(如80/443/22等)绑定在一起调度 MARK target 可用于给特定的报文打标记 --set-mark value 其中：value 可为0xffff格式，表示十六进制数字 借助于防火墙标记来分类报文，而后基于标记定义集群服务；可将多个不同的应用使用同一个集群服务进行调度 实现方法： 1.在Director主机打标记： iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport -dports $port1,$port2,… -j MARK --set-mark NUMBER $vip是LVS的VIP地址，$dport是要访问本地的端口，$num是防火墙标记位。如果想让2个不同的端口当做同一个集群服务的话，这里的$num的值要一样。 2.在Director主机基于标记定义集群服务： ipvsadm -A -f NUMBER [options] 例： iptables -t mangle -A PREROUTING -d 10.1.0.5 -p tcp -m multiport --dports 80,443 -j MARK --set-mark 11 ipvsadm -A -f 11 -s rr ipvsadm -a -t 192.168.80.100 -r 192.168.80.194 -g -w 1 ipvsadm -a -t 192.168.80.100 -r 192.168.80.220 -g -w 1 持久连接session 绑定：对共享同一组RS的多个集群服务，需要统一进行绑定，lvs sh算法无法实现 持久连接（lvs persistence）模板：实现无论使用任何调度算法，在一段时间内（默认360s），能够实现将来自同一个地址的请求始终发往同一个RS 持久连接实现方式 : 1.每端口持久（PPC）：每个端口定义为一个集群服务，每集群服务单独调度 ipvsadm -E -t 192.168.7.250:80 -s rr -p 60 2.每防火墙标记持久（PFWMC）：基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity ipvsadm -A -f 10 -s wrr -p 3.每客户端持久（PCC）：基于0端口（表示所有服务）定义集群服务，即将客户端对所有应用的请求都调度至后端主机，必须定义为持久模式 ipvsadm -E -t 192.168.7.250:0 -s rr -p 60 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] LVS高可用ldirectord下载 用于监视和管理负载平衡虚拟服务器LVS集群中的RealServer服务器。 ldirectord通过定期请求一个已知的URL并检查响应是否包含预期的响应来监视RealServer服务器的健康状况。如果RealServer发生故障，则将此RS删除，一旦它恢复正常，它将被重新激活。 ldirectord配置文件 /etc/ha.d/ldirectord.cf 主配置文件 /usr/share/doc/ldirectord-3.9.6/ldirectord.cf 配置模版 /usr/lib/systemd/system/ldirectord.service 服务 /usr/sbin/ldirectord 主程序 /var/log/ldirectord.log 日志 /var/run/ldirectord.ldirectord.pid pid 文件 配置示例： checktimeout=3 #检查超时(秒) checkinterval=1 #检查间隔(秒) fallback=127.0.0.1:80 autoreload=yes logfile=&quot;/var/log/ldirectord.log&quot; quiescent=no #down时yes权重为0，no为删除 virtual=5 #指定VS的FWM或IP：port real=172.16.0.7:80 gate 2 #RealServer,gate表示DR模型，后面为权重 real=172.16.0.8:80 gate 1 fallback=127.0.0.1:80 gate #sorry server,集群不可用时，指向备用服务器 service=http # 集群类型 scheduler=wrr # 调度算法 checktype=negotiate # 健康度检查方法，ping, checkport=80 request=&quot;index.html&quot; # 检测的页面文件 receive=&quot;CentOS&quot; # 检查的页面字符 启动ldirectord 启动会自动创建集群规则，先把之前的规则清空 检测Mysql的范例 #Sample configuration for a MySQL virtual service. virtual = 192.168.10.74:3306 real=sql01-&gt;sql03:3306 gate 10 fallback=127.0.0.1:3306 service=mysql scheduler=wrr #persistent=600 #netmask=255.255.255.255 protocol=tcp checktype=negotiate login=&quot;readuser&quot; passwd=&quot;genericpassword&quot; database=&quot;portal&quot; request=&quot;SELECT * FROM link&quot;]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx自动安装脚本]]></title>
    <url>%2F2019%2F01%2Fnginx%E8%87%AA%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[nginx官方仓库中的nginx的unit file： [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/run/nginx.pid ExecStartPre=/usr/sbin/nginx -t -c /etc/nginx/nginx.conf ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target epel仓库中的Nginx的unit file文件： [Unit] Description=The nginx HTTP and reverse proxy server After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/run/nginx.pid # Nginx will fail to start if /run/nginx.pid already exists but has the wrong # SELinux context. This might happen when running `nginx -t` from the cmdline. # https://bugzilla.redhat.com/show_bug.cgi?id=1268621 ExecStartPre=/usr/bin/rm -f /run/nginx.pid ExecStartPre=/usr/sbin/nginx -t ExecStart=/usr/sbin/nginx ExecReload=/bin/kill -s HUP $MAINPID KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process PrivateTmp=true [Install] WantedBy=multi-user.target]]></content>
  </entry>
  <entry>
    <title><![CDATA[集群与分布式]]></title>
    <url>%2F2019%2F01%2F%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[系统扩展方式： Scale UP：向上扩展,增强 Scale Out：向外扩展,增加设备，调度分配问题，Cluster 目前关于网站架构一般比较合理流行的架构方案 Web 前端采用 Nginx/HAProxy+Keepalived 作负载均衡器； 后端采用 MySQ L数据库一主多从和读写分离，采用 LVS+Keepalived 的架构 集群介绍集群,为解决某个特定问题将多台计算机组合起来形成的单个系统，这些单个的计算机系统就是集群的节点（node） 特点： 1.可扩展性。集群的性能不限于单一的服务实体，新的服务实体可以动态的加入到集群，从而增强集群的性能。 2.高可用性。当发生单节点服务故障时，单台服务器上所运行的应用程序将在另一节点服务器上被自动接管。消除单点故障对于增强数据可用性、可达性和可靠性是非常重要的。 3.负载均衡。负载均衡能把任务比较均匀的分布到集群环境下的计算和网络资源，以便提高数据吞吐量。 4.错误恢复。如果集群中的某一台服务器由于故障或者维护需要而无法使用，资源和应用程序将转移到可用的集群节点上。 类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） HPC：High-performance computing，高性能计算系统 LB通过不同的调度机制将用户的请求分派到后端不同的服务器。缓解服务器的请求压力 负载均衡（Load Balance，缩写LB）是一种网络技术，它在多个备选资源中做资源分配 参考OSI模型用四层负载均衡、七层负载均衡进行分类 四层负载均衡 1.工作在OSI的四层 2.不管数据包是什么，只是通过修改IP头部或者以太网头部的地址实现负载均衡 通过修改网络数据包“中转”请求；一般工作在操作系统的内核空间（kernel space），比如通过Linux的netfilter定义的hook改变数据包 七层负载均衡 1.工作在OSI的七层，支持应用层协议 2。一般会把数据包内容解析出来后通过一定算法找到合适的服务器转发请求。它是针对某个特定协议所以不通用。比如Nginx只能用于HTTP而不适用于Mysql。 3.必须解析出数据包的内容，根据内容来做相关的转发（比如做Mysql的读写分离），一般工作在用户空间（user space），比如通过Nginx、Mysql Proxy、Apache它们都是实现某个具体协议，也叫做代理(Proxy) 实现方式： 硬件 F5 Big-IP Citrix Netscaler A10 软件 lvs：Linux Virtual Server ，工作在网络4层 nginx：支持TCP（四层）和HTTP（七层）调度，阿里七层SLB使用Tengine haproxy：支持七层(mode http) 四层(mode tcp) ats：apache traffic server，yahoo捐助 perlbal：Perl 编写 pound 基于工作的协议层次划分： 传输层（通用）：DPORT LVS： nginx：stream haproxy：mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http：nginx, httpd, haproxy(mode http), ... fastcgi：nginx, httpd, ... mysql：mysql-proxy, ... 会话保持：负载均衡 (1) session sticky：同一用户调度固定服务器 Source IP：LVS sh算法（对某一特定服务而言） Cookie (2) session replication：每台服务器拥有全部session session multicast cluster (3) session server：专门的session服务器 Memcached，Redis 负载均衡集群设计时要注意的问题： (1) 是否需要会话保持； (2) 是否需要共享存储； 共享存储：NAS， SAN， DS（分布式存储） LVS、Nginx、HAProxy对比HA高可用集群是用于单点故障，能够自动将资源、服务进行切换另一个节点能够自动且立即向外提供服务，这样可以保证服务一直在线。在这个过程中，对于客户端来说是透明的。 用平均无故障时间（MTTF）来衡量系统的可靠性，用平均维护时间（MTTR）来衡量系统的可维护性 定义： MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 HA=MTBF/（MTBF+MTTR） 99%：表示 一年宕机时间不超过4天 99.9% ：表示一年宕机时间不超过10小时 99.99%： 表示一年宕机时间不超过1小时 99.999% ：表示一年宕机时间不超过6分钟 实现高可用集群有三种方式 1.主从方式（非对称） 包含2个节点和一个或多个服务器，一台作为主节点（active），另一台作为备份节点（standy）。备份节点随时都在检测主节点的健康状况，当主节点发生故障时，服务会自动切换到备份节点上以保证服务正常运行 2.对称方式 包含2个节点和一个或多个服务，其中每一个节点都运行着不同的服务且相互作为备份，两个节点互相检测对方的健康状况，这样当其中一个节点发生故障时，该节点上的服务会自动切换到另一个节点上去。 3.多机方式 包含多个节点和多个服务。每一个节点都可能运行和不运行服务，每台服务器都监视着几个指定的服务，当其中的一个节点发生故障时，会自动切换到这组服务器中的一个节点上去 实现高可用集群需要用到的组件： HPC分布式分布式结构就是将一个完整的系统，按照业务功能，拆分成一个个独立的子系统，在分布式结构中，每个子系统就被称为“服务”。 分布式存储：云盘 分布式计算：hadoop，Spark 集群与分布式对比集群：同一个业务，部署在多个服务器上 。 分布式：一个业务拆分为多个子业务，部署在多个服务器上 联系与区别： 1.分布式是指将不同的业务分布在不同的地方 2.集群可能运行着一个或多个分布式系统，也可能根本没有运行分布式系统 3.将一套系统拆分成不同子系统部署在不同服务器上（这叫分布式），然后部署多个相同的子系统在不同的服务器上（这叫集群），部署在不同服务器上的同一个子系统应做负载均衡 4.集群是个物理形态: 逻辑上处理同一任务的机器集合，可以属于同一机房，也可分属不同的机房: 分布式是个工作方式: 可以运行在某个集群里面，某个集群也可作为分布式概念的一个节点,而集群并不一定就是分布式的 集群类型： LB集群：负载均衡集群 四层 lvs，nginx(stream)，haproxy(mode tcp) 七层 nginx，haproxy(mode http)，varnish(diectors modules) HA集群：高可用性集群 SPoF: Single Point of Failure 核心特性：通过冗余方式，为活动设备提供备用设备，在活动设备出现故障时，备用设备能够上线并取代活动设备成为新的活动设备，即组合多台主机完成一个核心目标所构建出来的集群 HP集群：高性能计算集群 综合多台计算机的能力，解决复杂问题 系统可用性的公式：A=MTBF/（MTBF+MTTR） MTBF(Mean Time Between Failure)：平均无故障时间 MTTR(Mean Time To Restoration)：平均修复(故障)时间 (0,1), 95% 几个9（指标）: 99%, ..., 99.999%，99.9999%； 系统故障： 硬件故障：设计缺陷、wear out（损耗）、自然灾害…… 软件故障：设计缺陷 提升系统高用性的解决方案： 提升MTBF 平均无故障时间增大，即硬件设备故障率降低 与设备厂商有关，x86服务器故障率较高 降低MTTR 平均修复(故障)时间降低 提供备用服务器，其配置和主服务器相同，使用应用程序监控设备是否出现故障，一旦出现故障，就自动使用备用服务器替换主服务器 手段：设备冗余redundant active/passive 主备 active/active 双主 active --&gt; HEARTBEAT --&gt; passive active &lt;--&gt; HEARTBEAT &lt;--&gt; active 注意：活动主机为active，备用主机为passive 活动主机通过单播，多播或组播方式向其他主机发送心跳信息，如果其他主机在一定周期内没有收到活动主机的心跳信息，就认为活动主机出现故障，备用主机就取代活动主机成为活动主机 高可用的是“服务”： HA nginx service： vip/nginx process[/shared storage] 资源：组成一个高可用服务的“组件” (1) passive node的数量 (2) 资源切换 提供(构建高可用)服务的关键因素: ip地址：进入服务器的接口。 如果使用固定ip地址提供服务，那么备用主机则必须能够拿到该固定ip才能够在活动主机故障后成为活动主机 process：用户空间的进程对客户端提供服务 相对于ipvs来说，没有进程的说法，仅是内核空间的规则 storage：数据同步问题 对于mysql数据库来说，主备只能解决设备问题，备用服务器无法获取数据库中的数据，因此需要解决数据同步的问题 数据同步： 主从复制：使用软件或某个服务脱离于系统本身，对数据进行数据主从复制完成数据同步 rsync_inotify 文件级同步 drbd kernel2.6.33 分布式复制块设备 在不安装第三方软件，基于内核模块的情况下，把两个主机之上的两个磁盘或磁盘分区做成跨主机的镜像设备， 当在其中一块磁盘写入数据时，会同步到另外一块镜像磁盘上，实现数据同步的功能，系统可用性最高达到99.5% 提供(构建高可用)服务的关键因素: ip地址：进入服务器的接口。 如果使用固定ip地址提供服务，那么备用主机则必须能够拿到该固定ip才能够在活动主机故障后成为活动主机 process：用户空间的进程对客户端提供服务 相对于ipvs来说，没有进程的说法，仅是内核空间的规则 storage：数据同步问题 对于mysql数据库来说，主备只能解决设备问题，备用服务器无法获取数据库中的数据，因此需要解决数据同步的问题 数据同步： 主从复制：使用软件或某个服务脱离于系统本身，对数据进行数据主从复制完成数据同步 rsync_inotify 文件级同步 drbd kernel2.6.33 分布式复制块设备 在不安装第三方软件，基于内核模块的情况下，把两个主机之上的两个磁盘或磁盘分区做成跨主机的镜像设备， 当在其中一块磁盘写入数据时，会同步到另外一块镜像磁盘上，实现数据同步的功能，系统可用性最高达到99.5% shared storage： NAS：文件共享服务器； SAN：存储区域网络，块级别的共享 注意：NAS和SAN二者要求不同，NAS属于文件级别的存储设备，SAN属于块级别存储设备，二者的区别在于后端主机之上是否有操作系统，是否能够对多个节点同时对同一个文件施加读写操作时，自动维持文件锁。 另外，块设备后端服务器无法维持文件锁，需要前端调用者来维持，如果两个节点写同一个文件，会导致文件系统崩溃 Network partition：网络分区 网络分区：由于硬件设备故障而导致节点之间无法连接，出现网络不同的区域。 一旦出现网络分区，能够代表集群继续工作的网络分区小群体中的节点成员数量必须大于原集群成员节点的一半，在大于半数的网络分区中选举主节点和备用节点 quorum：法定人数 with quorum： &gt; total/2 without quorum: &lt;= total/2 隔离设备： fence node：STONITH = Shooting The Other Node In The Head，断电重启 资源：断开存储的连接 TWO nodes Cluster 辅助设备：ping node, quorum disk Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作 Failback：故障移回，即某资源的主节点故障后重新修改上线后，将之前已转移至其它节点的资源重新切回的过程 HA Cluster实现方案: ais：应用接口规范 完备复杂的HA集群 RHCS：Red Hat Cluster Suite红帽集群套件 heartbeat corosync vrrp协议实现：虚拟路由冗余协议 keepalived]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat之session保持]]></title>
    <url>%2F2019%2F01%2Ftomcat%E4%B9%8Bsession%E4%BF%9D%E6%8C%81%2F</url>
    <content type="text"><![CDATA[会话保持的重要性在生成环境中，我们的Tomcat服务器肯定要做冗余或者高可用，如果没有做session保持，那么用户访问页面时只要状态丢失，那么是会造成cookie丢失这种情况的， 会话保持Session sticky会话粘性：通过在前端调度器的配置中实现统一session发送至同一后发端服务器 缺点：某台后端服务器down，其上面的会话会丢失 nginx 的ip_hash算法，haproxy的url_param算法 source_ip nginx: ip_hash haproxy: source lvs: sh cookie： nginx：hash haproxy: cookie Session cluster会话集群：通过配置Tomcat保持所有Tomcat的session的信息一致。 通过多播通信的信道，把session信息传递给同一集群的其他主机 在大规模集群中，多播信道会充满多播信息，形成拥塞，造成延迟 Session server 会话服务：将所有的session交给专门的session服务管理。 redis(store), memcached(cache) 存储设备具有主从复制机制 依靠前端进行备份，在主备server上写两份session信息 双写 double write 对数据进行周期性备份 Session sticky官方文档 基于BalancerMember的会话粘性实现(http协议) httpd配置文件，在conf.d/http-tomcat.conf ,新建虚拟主机 Header add Set-Cookie &quot;ROUTEID=.%{BALANCER_WORKER_ROUTE}e; path=/&quot; env=BALANCER_ROUTE_CHANGED &lt;proxy balancer://tcsrvs&gt; BalancerMember http://192.168.80.37:8080 route=TomcatA loadfactor=1 BalancerMember http://192.168.80.47:8080 route=TomcatB loadfactor=2 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName lb.a.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location /balancer-manager&gt; 启用管理接口 SetHandler balancer-manager ProxyPass ! Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; 基于BalancerMember的会话粘性实现(ajp协议)httpd配置文件，在conf.d/http-tomcat.conf ,新建虚拟主机 Header add Set-Cookie &quot;ROUTEID=.%{BALANCER_WORKER_ROUTE}e;path=/&quot; env=BALANCER_ROUTE_CHANGED &lt;proxy balancer://tcsrvs&gt; BalancerMember ajp://192.168.80.37:8009 route=TomcatA loadfactor=1 BalancerMember ajp://192.168.80.47:8009 route=TomcatB loadfactor=2 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName lb.a.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location /balancer-manager&gt; SetHandler balancer-manager ProxyPass ! Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; 保持会话的方式参考前一种方式。 示例程序：在tomcat上编辑server.xml,在&lt;Engine&gt;之间 1.在TomcatA上某根目录中index.jsp，提供如下页面 123456789101112131415161718&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.a.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 2.在TomcatB上某context中index.jsp，提供如下页面 123456789101112131415161718&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatB.a.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 3.测试，提前配置hosts或dns服务器 Session cluster官方文档示例 tomcat的集群session共享方案只适合在小规模集群中(6台左右)使用，当集群节点数量过多时，节点间session复制会产生网络带宽的瓶颈，会产生session复制延迟 1.启用tomcat集群，添加如下定义到&lt; Engine &gt; 或 &lt; Host &gt; 标签中 &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; 使用上述配置将使用DeltaManager to replicate session deltas 启用所有会话复制。通过all-to-all，意味着会话被复制到集群中的所有其他节点。这适用于较小的集群 但不建议将其用于较大的集群（很多Tomcat节点）。此外，在使用增量管理器时，它将复制到所有节点，甚至是未部署应用程序的节点。这种方式并不可靠。默认不会启用这功能 要解决此问题，您将需要使用BackupManager。此管理器仅将会话数据复制到一个备份节点，并且仅复制到已部署应用程序的节点 2.以下是一些启用tomcat集群重要的默认值 多播地址为228.0.0.4 多播端口为45564 ： 用于集群成员关系判断，该端口监地址不能是127.0.0.1 会话复制端口使用范围 ： 4000-4100，默认从4000依次开始 监听器已配置 ClusterSessionListener 两个监听器TcpFailureDetector和MessageDispatch15Interceptor 注意： 时间必须同步 如果使用的是mod_jk，确保在引擎上设置&lt; Engine name=&quot;Catalina&quot; jvmRou te=&quot;标识&quot; &gt; mod_jk简称JK，是Apache服务器的一个可插入模块，用以为Apache或IIS服务器提供处理JSP/Servlet的能力 mod_jk实质上是Apache与Tomcat的连接器，并藉此附带提供集群和负载均衡的功能 确保要在web.xml中进行会话复制的应用程序定义&lt;distributable/&gt;元素，不加不会生效 确保会话不丢失，最好做会话绑定 示例：1.此处定义index.jsp的页面为&lt;host&gt;的&lt;Context&gt;中,内容如上面 每个tomcat中jvmRoute不一样，修改server.xml配置文件 1&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tcA"&gt; 2.配置在server.xml中&lt;Host&gt;标签 12345678910111213141516171819202122232425262728293031323334&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;&lt;/Cluster&gt; 配置文件介绍123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960classname配置tomcat集群在进行信息传递时互相使用什么类来进行传递；channelsendoptions可以设置为2,4,8.10； 2表示确认发送 Channel.SEND_OPTIONS_USE_ACK 4表示同步发送Channel.SEND_OPTIONS_SYNCHRONIZED_ACK 8表示你异步发送Channel.SEND_OPTIONS_ASYNCHRONOUS 10表示 在异步模式下，可以通过加上确认发送(Acknowledge)来提高可靠性manager决定如何管理集群的session信息，className－指定实现org.apache.catalina.ha.ClusterManager接口的类,信息之间的管理.expireSessionsOnShutdown－设置为true时，一个节点关闭，将导致集群下的所有Session失效notifyListenersOnReplication－集群下节点间的Session复制、删除操作，是否通知session listenersmaxInactiveInterval－集群下Session的有效时间(单位:s)。maxInactiveInterval内未活动的Session，将被Tomcat回收。默认值为1800s &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt;Channel是Tomcat节点之间进行通讯的工具。Channel包括5个组件：Membership、Receiver、Sender、Transport、Interceptor &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt;Membership维护集群的可用节点列表。它可以检查到新增的节点，也可以检查到没有心跳的节点 &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" 组播地址 port="45564" 组播端口 frequency="500" 发送心跳(向组播地址发送UDP数据包)的时间间隔(单位:ms)。默认值为500 dropTime="3000"/&gt; Membership在dropTime(单位:ms)内未收到某一节点的心跳，则将该节点从可用节点列表删除。默认值为3000 Receiver : 接收器，负责接收消息BioReceiver(阻塞式)、NioReceiver(非阻塞式)&lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="192.168.99.240" 接收消息的地址（默认是自动，但是最好手动更改为本地网卡对外ip,不能是127.0.0.1） port="4000" 接收消息的端口 autoBind="100" 端口的变化区间,在4000-4099间取一个端口 selectorTimeout="5000" NioReceiver内轮询的超时时间.s maxThreads="6"/&gt; 线程池的最大线程数sender：发送器负责发送消息 sender内嵌了transport组件，transport组件是负责真正传送消息&lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt;Transport分为两种：bio.PooledMultiSender(阻塞式)、nio.PooledParallelSender(非阻塞式) &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt;&lt;/Sender&gt;MessageDispatch15Interceptor查看Cluster组件发送消息的方式是否设置为Channel.SEND_OPTIONS_ASYNCHRONOUS(Cluster标签下的channelSendOptions为8时)。当设置为Channel.SEND_OPTIONS_ASYNCHRONOUS时，MessageDispatch15Interceptor先将等待发送的消息进行排队，然后将排好队的消息转给Sender&lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt;&lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt;&lt;/Channel&gt;Valve :可以作为过滤器，ReplicationValve－在处理请求前后打日志；过滤不涉及Session变化的请求。 vmRouteBinderValve－Apache的mod_jk发生错误时，保证同一客户端的请求发送到集群的同一个节点&lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt;&lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt;Deployer：同步集群下的所有节点的一致性 &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt;ClusterListener : 监听器，监听Cluster组件接收的消息，使用DeltaManager时，Cluster接收的信息通过ClusterSessionListener传递给DeltaManager &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; 3.配置应用程序的web.xml，使其能够被tomcat delta manager管理 默认站点目录没有web.xml文件,可以复制tomcat的全局web.xml值站点目录WEB-INF下， web.xml在安装目录下是对所有站点程序生效，是全局配置，通常每个站点程序都会有单独的web.xml cp /usr/local/tomcat/conf/web.xml /usr/local/tomcat/webapps/ROOT/WEB-INF 4.在&lt;web-app&gt;&lt;/web-app&gt;的范围内加入&lt;distributable/&gt;标签即可 vim web.xml 注意：前端调度器的配置中不能开启session sticky功能 5.]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置进阶]]></title>
    <url>%2F2019%2F01%2Ftomcat%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[日志配置文档 在server.xml里的&lt;host&gt;标签下加上 存储为json格式 Tomcat日志切割配置logrotate对catalina.out日志切割 12345678910vim /etc/logrotate.d/tomcat /usr/local/tomcat/logs/catalina.out &#123; daily rotate 5 missingok dateext compress notifempty copytruncate &#125; daily 指定转储周期为每天,其它可用值为‘monthly’，‘weekly’或者‘yearly’ rotate 30 指定日志文件删除之前转储的次数,一次将存储30个归档日志。对于第31个归档，时间最久的归档将被删除,0指没有备份 missingok 如果日志不存在则忽略该警告信息 dateext 文件后缀是日期格式,也就是切割后文件是:xxx.log-20150828.gz compress 通过gzip压缩转储以后的日志（gzip -d xxx.gz解压） notifempty 如果是空文件的话，不转储 copytruncate 用于还在打开中的日志文件，把当前日志备份并截断 Tomcat的manager页面 1.manager-gui：允许通过web的方式登录查看服务器信息 2.manager-script: 允许以纯文本的方式访问 3.manager-jmx: 允许jmx的代理访问 4.manager-status: 允许以只读状态访问 5.admin-gui: 允许访问HTML GUI 6.admin-script: 允许访问文本接口 开启权限，需要进行修改 vim /usr/local/tomcat/conf/tomcat-users.xml #去掉注释&lt;!-- --&gt; 修改为如下 123&lt;role rolename="manager-gui"/&gt;&lt;role rolename="admin-gui"/&gt;&lt;user username="admin" password="admin" roles="manager-gui,admin-gui"/&gt; 访问出现403或404版本:Tomcat 8 问题：访问tomcat的Server Status、Manager App、HostManager三个页面均显示403，conf/tomcat-users.xml里已添加配置： 重启之后，还是403，甚至在尝试使用多种解决方法的时候还出现过404 解决办法: 打开webapps下的host-manager和manager，都有一个共同的文件夹META-INF，里面都有context.xml，这个文件的内容是： 1234&lt;Context antiResourceLocking="false" privileged="true" &gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="127.d+.d+.d+|::1|0:0:0:0:0:0:0:1" /&gt;&lt;/Context&gt; 这段代码的作用是限制来访IP的，127.d+.d+.d+|::1|0:0:0:0:0:0:0:1，是正则表达式，表示IPv4和IPv6的本机环回地址 比如我们只允许内网网段访问管理页面，那么改成这样就可以： 1234&lt;Context antiResourceLocking="false" privileged="true" &gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="192.168.80.*" /&gt;&lt;/Context&gt; 重启后重新打开tomcat Tomcat多实例配置多虚拟主机：nginx 多个Server标签（域名，ip，端口） 进程数量固定 master+worker 多实例（多进程）：同一个程序启动多次，分为两种情况: 第一种：一台机器跑多个站点； 第二种：一个机器跑一个站点多个实例，配合负载均衡 1.复制程序文件 tar xf apache-tomcat-8.0.27.tar.gz cp -a apache-tomcat-8.0.27 /usr/local/tomcat8_1 cp -a apache-tomcat-8.0.27 /usr/local/tomcat8_2 2.修改端口，以启动多实例。多实例之间端口不能一致 sed -i &apos;s#8005#8011#;s#8080#8081#&apos; /usr/local/tomcat8_1/conf/server.xml sed -i &apos;s#8005#8012#;s#8080#8082#&apos; /usr/local/tomcat8_2/conf/server.xml 3.将配置好的tomcat程序打包，以备之后使用 4.启动tomcat多实例 /usr/local/tomcat8_1/bin/cantina.sh start]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat基本配置]]></title>
    <url>%2F2019%2F01%2Ftomcat%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[tomcat配置rpm包安装的程序环境： 配置文件目录：/etc/tomcat 主配置文件：server.xml 工作目录：/usr/share/tomcat/ webapps存放位置：/var/lib/tomcat/webapps/ ROOT：/(根目录) index.jsp：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； META-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类； lib/：类文件，当前webapp所提供的类，被打包为jar格式 docs examples host-manager manager Unit File：tomcat.service 环境配置文件：/etc/sysconfig/tomcat webapp归档格式： .war：webapp .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp； 二进制tomcat的目录结构 tomcat的配置文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略 catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； log4j tomcat的两个管理应用: manager：管理webapps应用程序 host-manager：管理虚拟主机 tomcat的常用组件配置Tomcat的核心组件：server.xml 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型： 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, ... 集群类组件：listener, cluster, ... server.xml文件的结构服务类组件配置信息 1234567891011121314151617181920212223242526&lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" 所在监听端口，以及协议版本号 connectionTimeout="20000" 连接超时时间，单位毫秒 redirectPort="8443" /&gt; 必要的时候可以做重定向，定义在8443 &lt;Connector port="8443"protocol="HTTP/1.1" SSLEnabled="true" 端口监听在8443，协议http1.1 maxThreads="150" scheme="https" secure="true" 最大线程，协议版本，安全的 clientAuth="false" sslProtocol="TLS" /&gt; 不验证客户端 ssl协议用的是tls &lt;Connector port="8009" protocol="AJP/1.3"redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; 引擎，名为catalina &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" 应用程序存放的位置，相对路径 unpackWARs="true" autoDeploy="true"&gt; 定义阀门，java中类的记录方式，当前所处域名反过来写的记录方式 &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" 日志的命名 pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; 访问日志的格式 &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; &lt;Server&gt;:代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口； &lt;Service&gt;:用于实现将一个或多个connector组件关联至一个engine组件； &lt;Connector&gt;:负责接收请求，常见的有三类连接器http/https/ajp； 定义连接器时可以配置的属性非常多，但通常定义HTTP连接器时必须定义的属性只有“port”，定义AJP连接器时必须定义的属性只有&quot;protocol&quot;，因为默认的协议为HTTP 常用属性： address：监听的IP地址；默认为本机所有可用地址；即0.0.0.0； maxThreads：最大并发连接数，默认为200； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； enableLookups：是否通过request.getRemoteHost()进行DNS查询以获取客户端的主机名；默认为true redirectPort：如果某连接器支持的协议是HTTP，当接收客户端发来的HTTPS请求时，则转发至此属性定义的端口 secure： sslProtocol： port： connectionTimeout：等待客户端发送请求的超时时间，单位为毫秒，默认为60000 &lt;Engine&gt;:Servlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过defaultHost属性来定义默认的虚拟主机； &lt;Host&gt;:位于engine内部,接收请求并处理相应请求的主机一般都是基于主机名，可以有多个主机 属性： (1) appBase：此Host的webapps的默认存放目录，指存放非归档的web应用程序的目录或归档的WAR文件目录路径； 可以使用基于$CATALINA_BASE变量所定义的路径的相对路径； (2) autoDeploy：在Tomcat处于运行状态时，将某webapp放置于appBase所定义的目录中时，是否自动将其部署至tomcat； (3) unpackWARs=&quot;true&quot; 自动展开war文件 &lt;Context path=&quot;/PATH&quot; docBase=&quot;/PATH/TO/SOMEDIR&quot; reloadable=&quot;&quot;/&gt; docBase的路径相对于appBase的路径 &lt;Valve&gt;存在多种类型： 定义访问日志：[org.apache.catalina.valves.AccessLogValve](https://tomcat.apache.org/tomcat-7.0-doc/api/org/apache/catalina/valves/AccessLogValve.html) 定义访问控制：org.apache.catalina.valves.RemoteAddrValve 示例： 12345 &lt;Host name="www.a.com" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" deny="172\.16\.100\.67"/&gt;&lt;/Host&gt; 综合示例： 自定义默认网站目录 123456789&lt;Host name="www.a.com" appBase="/web/apps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="node1_access" suffix=".log" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;Context path="/test" docBase="test" reloadable=""&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="node1_test_access_" suffix=".log" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Context&gt;&lt;/Host&gt; 修改配置文件后，要重启服务]]></content>
  </entry>
  <entry>
    <title><![CDATA[tomcat基础]]></title>
    <url>%2F2019%2F01%2Ftomcat%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[java 基础概念程序：指令+数据 过程式编程：以指令为中心，数据服务于代码； 对象式编程：以数据为中心，指令服务于数据； Java 是由Sun 推出的高级程序设计语言 Java是面向对象的，PHP还是采用面向过程的开发方法，Java的性能也优于PHP JAVA运行原理 ： Java具有跨平台的优点，在Java中引入了虚拟机制概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器。这台虚拟的机器在任何平台上都提供给编译程序一个共同的接口 Java技术为三个方向： J2SE：Standard Edition J2EE：Enterprise Edition J2ME：Mobile Edition java总体来说就是java语言、java API、jvm等构成。 1.jvm：java虚拟机，java的代码都是运行在jvm上，这是java语言跨平台的保证，针对不同的系统jvm也不同，这就实现了同一份代码，通过不同jvm的运行可以让对应的操作系统识别。 2.JRE（java running environment）：就是提供给java代码一个运行环境，java代码运行在jvm上，但是开发程序的时候往往除本身代码外会有引入的api，当程序运行时，jvm会加载相关的类，所以一个能保证代码能正常运行的环境是jvm+api（java se api）。 3.JDK（java development kit）：java开发环境，JDK=java语言+开发相关的API+JRE。开发环境除了要正常运行程序外（JRE环境），还需要进行开发相关的操作如打包、编译等这类工具。 JVM 内存结构 java中通过多线程机制使得多个任务同时执行处理，所有的线程共享JVM内存区域main memory，而每个线程又单独的有自己的工作内存，当线程与内存区域进行交互时，数据从主存拷贝到工作内存，进而交由线程处理 方法区：线程共享； 用于存储被JVM加载的class信息、常量、静态变量、方法等； 堆：是jvm所管理的内存中占用空间最大的一部分；也是GC管理的主要区域；存储对象； Java栈：线程私有，存储 线程自己的局部变量； PC寄存器：线程私有的内存空间，程序的指令指针； java文件执行过程 jsp--&gt;jasper--&gt;java--&gt;Javac--.class--&gt;Servlet 第一次执行被jsp类库组件jasper加载，jasper组件预处理jsp文件，将里面自身不是代码的内容转换为jar语句,输出结果变成一个纯java文件，包括了响应cgi程序调用，经由javac编译器编译为.class文件，交由servlet去调用jvm运行 tomcat官网 Tomcat 类似与一个apache的扩展型，属于apache软件基金会的核心项目，属于开源的轻量级Web应用服务器，是一个优秀的完全由Java语言编写的Servlet容器 JSP:Java Server Page 动态网页技术，出现在Servlet技术之后的,它和servle技术一样，都是SUN公司定义的一种用于开发动态web资源的技术。 JSP技术的最大的特点在于，写jsp就像在写html，但它相比html而言，html只能为用户提供静态数据，而Jsp技术允许在页面中嵌套java代码，为用户提供动态数据。 Jsp页必须转换成Servlet，才能对请求进行服务，因此Jsp的底层完全是Servlet JSP工作原理 客户端浏览器向服务器端发出request请求，服务端接受请求之后会先检查此JSP文件是否存在 1).若不存在，则直接报错； 2).若存在，则接着检查所请求的这个JSP文件内容(代码)是否已经被更新，或者是否是JSP文件创建后的第一次被访问 ■如果是，那么这个JSP文件将会在服务器端的JSP引擎下转换成一个Servlet的java源文件；接着这个Servlet类会在java编译器的作用下被编译成字节码文件，并装载到JVM中去执行。 ■如果不是，则直接由服务器端检索出它对应的Servlet实例来处理。 注意： JSP 文件不是在服务器启动的时候转换成 Servlet类的。 而是在被客户端访问的时候才可能发生转换的(如JSP文件内容没有被更新等，就不再发生Servlet转换)。 Servlet: Servlet是JavaWeb的三大组件之一，它属于动态资源 Servlet完全运行在服务器端，因此它不依赖于浏览器。不管浏览器是否支持Java语言，都能请求访问服务器端的Servlet CGI:Common Gateway Interface 外部应用用程序与HTTP服务器之间的接口协议 与CGI程序相比，Servlet具有以下优点： Servlet是单实例多线程的运行方式，每个请求在一个独立的线程中运行，而提供服务的Servlet实例只有一个。 Servlet具有可升级性，能响应更多的请求，因为Servlet容器使用一个线程而不是操作系统进程，而线程仅占用有限的系统资源。 Servlet使用标准的API，被更多的Web服务器所支持。 Servlet使用Java语言编写，因此拥有Java程序语言的所有优点，包括容易开发和平台独立性。 Servlet可以访问Java平台丰富的类库，使得各种应用的开发更为容易。 Servlet容器给Servlet提供额外的功能，如错误处理和安全。 没有权限使用1024以内的端口 使用http或https协议 8080 常见的网页类型： HTML&amp;HTM：HyperText Markup Language 超文本连接标示语言 .html .html ASP：Active Server Page 动态服务器页面（微软开发） .asp ASP.net：ASP的下一个版本，也是建立在通用语言上的程序架构，网页后缀如aspx PHP：Hypertext Preprocessor 超级本本预处理语言 .php .php5 .phps JSP：JAVA Server Pages Sun Microsystems公司倡导，有点类似ASP技术 .jsp Tomcat组成 Tomcat作为servlet容器,Servlet运行在Tomcat容器当中(如docker镜像运行在docker容器当中) catalina 就是Tomcat服务器使用的 Apache实现的servlet容器的名字 Server：指的就是整个Tomcat服务器,包含多组服务,负责管理和启动各个Service，同时监听8005端口发过来的shutdown命令，用于关闭整个容器 Service：Tomcat封装的、对外提 供完整的、基于组件的web服务，包含Connectors、Container两个核心组件，以及多个功能组件，各个Service之间是独立的，但是共享同一JVM的资源 Connector：Tomcat与外部世界的连接器，监听固定端口接收外部请求，传递给Container,并将Container处理的结果返回给外部 Container：Catalina，Servlet容器，内部有多层容器组成，用于管理Servlet生命周期，调用servlet相关方法。 Loader：封装了 Java ClassLoader，用于Container加载类文件； Realm：Tomcat中为web应用程序提供访问认证和角色管理的机制； JMX：Java SE中定义技术规范，是一个为应用程序、设备、系统等植入管理功能的框架，通过 JMX 可以远程监控 Tomcat 的运行状态； Jasper：Tomcat 的 Jsp 解析引擎，用于将Jsp转换成Java文件，并编译成class文件。 Session：负责管理和创建session，以及Session的持久化(可自定义)，支持session的集群。 Pipeline：在容器中充当管道的作用，管道中可以设置各种 valve(阀门)，请求和响应在经由管 道中各个阀门处理，提供了一种灵活可配置的处理请求和响应的机制。 Container组成 Engine：Servlet 的顶层容器,包含一个或多个Host子容器； Host：虚拟主机，负责web应用的部署和Context的创建； Context：Web应用上下文，包含多个Wrapper，负责web配置的解析、管理所有的Web资源； Wrapper：最底层的容器，是对Servlet的封装，负责Servlet实例的创 建、执行和销毁。 Service对外提供Web应用服务，而Service核心组件Container的灵魂便是Servlet容器。 而真正管理Servlet的是Context容器。 Context容器直接管理Servlet在容器中的包装类Wrapper，一个Web应用对应一个Context容器。 添加一个Web应用就会创建一个Context容器，并将这个Context容器加入到父容器Host中。 Tomcat的工作模式运行模式1.工作模式 Tomcat作为servlet容器，有三种工作模式： 1、独立的servlet容器 servlet容器是web服务器的一部分；然而大多数的Web服务器并非基于Java，因此，就有了下面两种Servlet容器的工作模式 2、进程内的servlet容器 servlet容器是作为web服务器的插件和java容器的实现，web服务器插件在内部地址空间打开一个jvm,使得Java容器可以在此JVM中加载并运行Servlet。 反应速度快但伸缩性不足； 3、进程外的servlet容器 servlet容器运行于web服务器之外的地址空间，并作为web服务器的插件和java容器实现的结合。Web服务器插件和Java容器（在外部JVM中运行）使用IPC机制（通常是TCP/IP）进行通信 反应时间不如进程内但伸缩性和稳定性比进程内优； 进入Tomcat的请求可以根据Tomcat的工作模式分为如下两类： Tomcat作为应用程序服务器：请求来自于前端的web服务器，这可能是Apache, IIS, Nginx等； Tomcat作为独立服务器：请求来自于web浏览器； Tomcat的运行模式Tomcat Connector(连接器)有三种运行模式： bio(blocking I/O) 即阻塞式I/O操作，表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包) 一个线程处理一个请求 Tomcat7以下版本默认 缺点：并发量高时，线程数较多，浪费资源。三种模式中性能也最低 nio(new I/O) Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。 它拥有比传统I/O操作(bio)更好的并发运行性能。 利用Java 的异步请求 IO 处理，可以通过少量的线程处理大量的请求。 tomcat 8版本及以上默认就是在NIO模式下允许 apr(Apache Portable Runtime/Apache可移植运行时) Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式 Tomcat7或Tomcat8在Win7或以上的系统中启动默认使用这种方式。 Linux如果安装了apr和native，Tomcat直接启动就支持apr 生命周期就是类的产生到销毁的过程。 servlet的生命周期： 加载并实例化 –&gt; 初始化 –&gt; 应用阶段（请求处理） –&gt; 销毁 1.创建 Servlet 实例。 2.Web 容器调用 Servlet 的 init() 方法，对Servlet 进行初始化。 3.Servlet初始化后，将一直存在于容器中，用于响应客户端请求。根据客户端的请求方式通过 Servlet 中service() 方法去相应的 goGet(),或 doPost() 方法； 4.Web 容器销毁Servlet时，调用Servlet的destroy()方法，通常在关闭Web容器之时销毁Servlet。 扩展： 管理的servlet，商品管理的servlet等，servlet体系结构是建立在java多线程机制之上的，servlet容器会自动使用线程池等技术来支持系统的运行。 当servlet被部署在应用服务器中（应用服务器中用于管理Java组件的部分被抽象成为容器）以后，由容器控制servlet的生命周期。 除非特殊制定，否则在容器启动的时候，servlet是不会被加载的，servlet只会在第一次请求的时候被加载和实例化。 servlet一旦被加载，一般不会从容器中删除，直至应用服务器关闭或重新启动。但当容器做内存回收动作时，servlet有可能被删除。也正是因为这个原因，第一次访问servlet所用的时间要大大多于以后访问所用的时间 jsp的生命周期： 转换，编译，加载并实例化，初始化（_jspInit），请求处理（_jspService()调用），销毁（_jspDestory()）。 转换：就是web容器将JSP文件转换成一个包含了Servlet类定义的java源文件。 编译：把在转换阶段创建的java源文件变异成类文件。 JSP生命周期其他的四个阶段跟Servlet生命周期相同 注意： 在正常情况下，Servlet只会初始化一次，而处理服务会调用多次，销毁也只会调用一次 但是如果一个Servlet长时间不使用的话，也会被容器自动销毁，而如果需要再次使用时会重新进行初始化的操作，即在特殊情况下初始化可能会进行多次，销毁也可能进行多次 jsp servlet的区别和联系JSP在本质上就是SERVLET,但是两者的创建方式不一样. Servlet完全是JAVA程序代码构成，擅长于流程控制和事务处理，通过Servlet来生成动态网页很不直观. JSP由HTML代码和JSP标签构成，可以方便地编写动态网页. 因此在实际应用中采用Servlet来控制业务流程，而采用JSP来生成动态网页. JSP是Servlet技术的扩展，本质上就是Servlet的简易方式。 JSP编译后是“类servlet”。 Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML里分离开来。而JSP是Java和HTML组合成一个扩展名为.jsp的文件。 JSP侧重于视图，Servlet主要用于控制逻辑]]></content>
  </entry>
  <entry>
    <title><![CDATA[发布环境介绍]]></title>
    <url>%2F2018%2F12%2F%E5%8F%91%E5%B8%83%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[发布环境蓝绿发布（Blue/Green Deployment）定义：蓝绿部署是不停老版本，部署新版本然后进行测试。确认OK后将流量切到新版本，然 后老版本同时也升级到新版本。 特点：蓝绿部署无需停机，并且风险较小。 部署过程： 主：活动环境：负责对外提供服务，版本：v1.0 所有外部请求的流量都打到这个版本上。 备：非活动环境：版本：v2.0 版本2的代码与版本1不同(新功能、Bug修复等)。 将环境从版本1切换到版本2。 如版本2测试正常，就删除版本1正在使用的资源（例如实例），从此正式用版本2。 注意事项： 1.需要提前考虑数据库与应用部署同步迁移/回滚的问题 2.蓝绿部署需要有基础设施支持 3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境 和绿色环境有被摧毁的风险. 优势与不足： 优势：升级切换和回退速度非常快 不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响 灰度发布/金丝雀发布灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式， 让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范 围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可 以发现、调整问题，以保证其影响度，而我们平常所说的金丝雀部署也就是灰度发布的一种方式 而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径 发布步骤： 1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。 2.从负载均衡列表中移除掉「金丝雀」服务器。 3.升级「金丝雀」应用（排掉原有流量并进行部署）。 4.对应用进行自动化测试。 5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。 6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。 A/B Testing A/B 测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/ B测试通常用在应用的前端上，不过当然需要后端来支持。 A/B 测试与蓝绿部署的区别在于， A/B 测试目的在于通过科学的实验设计、采样样本代表性、流量分割与小流量测试等方式来获得具有代表性的实验结论，并确信该结论在推广到全部流量可信；蓝绿部署的目的是安全稳定地发布新版本应用，并在必要时回滚。 优势和不足 优势：用户体验影响小，灰度发布过程出现问题只影响少量用户。 不足：发布自动化程度不够，发布期间可引发服务中断。 预发布验证： 新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器 灰度发布： 可以基于主机，用户或者业务，又细分为地区，VIP和普通用户 滚动发布在金丝雀发布基础上的进一步优化改进，是一种自动化程度较高的发布方式，用户体验比较平 滑，是目前成熟型技术组织所采用的主流发布方式 滚动发布：一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复 始，直到集群中所有的实例都更新成新版本。 特点 1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数。我们可以部分部署，例如每次只取出集群的 20% 进行升级。 部署过程 滚动式发布一般先发1台，或者一个小比例，如2%服务器，主要做流量验证用，类似金丝雀 (Canary) 测试。 滚动式发布需要比较复杂的发布工具和智能 LB，支持平滑的版本替换和流量拉入拉出。 每次发布时，先将老版本 V1 流量从LB上摘除，然后清除老版本，发新版本V2，再将LB流 量接入新版本。这样可以尽量保证用户体验不受影响。 一次滚动式发布一般由若干个发布批次组成，每批的数量一般是可以配置的（可以通过发 布模板定义）。例如第一批 1 台（金丝雀），第二批 10%，第三批 50%，第四批 100%。 每个批次之间留观察间隔，通过手工验证或监控反馈确保没有问题再发下一批次，所以总 体上滚动式发布过程是比较缓慢的 (其中金丝雀的时间一般会比后续批次更长，比如金丝雀 10 分钟，后续间隔 2 分钟)。 回退是发布的逆过程，将新版本流量从 LB 上摘除，清除新版本，发老版本，再将LB流量 接入老版本。和发布过程一样，回退过程一般也比较慢的。 优势和不足 优势：用户体验影响小，体验较平滑。 不足：发布和回退时间比较缓慢。 发布工具比较复杂，LB 需要平滑的流量摘除和拉入能力]]></content>
  </entry>
  <entry>
    <title><![CDATA[kvm之qemu-kvm命令]]></title>
    <url>%2F2018%2F12%2Fkvm%E4%B9%8Bqemu-kvm%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[qemu-kvm 管理kvmqemu-kvm [options] [disk_image] 选项有很多类别： 标准选项、块设备相关选项、显示选项、网络选项、... 标准选项： -machine [type=]name：-machine help来获取列表，用于指定模拟的主机类型； -cpu cpu：-cpu help来获取列表；用于指定要模拟的CPU型号； -smp n[,maxcpus=cpus][,cores=cores][,threads=threads][,sockets=sockets]：指明虚拟机上vcpu的数量及拓扑； -boot [order=drives][,once=drives][,menu=on|off] [,splash=sp_name][,splash-time=sp_time][,reboot-timeout=rb_time][,strict=on|off] order：各设备的引导次序：c表示第一块硬盘，d表示第一个光驱设备；-boot order=dc,once=d -m megs：虚拟机的内存大小； -name NAME：当前虚拟机的名称，要惟一； 块设备相关的选项： -hda/-hdb file：指明IDE总线类型的磁盘映射文件路径；第0和第1个； -hdc/-hdd file：第2和第3个； -cdrom file：指定要使用光盘映像文件； -drive [file=file][,if=type][,media=d][,index=i] [,cache=writethrough|writeback|none|directsync|unsafe][,format=f]： file=/PATH/TO/SOME_IMAGE_FILE：映像文件路径； if=TYPE：块设备总线类型，ide, scsi, sd, floppy, virtio,... media=TYPE：介质类型，cdrom和disk； index=：设定同一类型设备多个设备的编号； cache=writethrough|writeback|none|directsync|unsafe：缓存方式； format= 指定映像文件的格式，具体格式可参见qemu-img命令 CentOS磁盘镜像文件下载： https://cloud.centos.org/centos/7/images/ 显示选项： -display type：显示的类型，sdl, curses, none, spice和vnc； -nographic：不使用图形接口； -vga [std|cirrus|vmware|qxl|xenfb|none]：模拟出的显卡的型号； -vnc display[,option[,option[,...]]]]：启动一个vnc server来显示虚拟机接口； 让qemu进程监听一个vnc接口； display： (1) HOST:N 在HOST主机的第N个桌面号输出vnc； 5900+N (2) unix:/PATH/TO/SOCK_FILE (3) none options： password：连接此服务所需要的密码； -monitor stdio：在标准输出上显示monitor界面； Ctrl-a, c：在console和monitor之间切换； Ctrl-a, h 网络选项： -net nic[,vlan=n][,macaddr=mac][,model=type][,name=str][,addr=str][,vectors=v] 为虚拟机创建一个网络接口，并将其添加至指定的VLAN； model=type：指明模拟出的网卡的型号，ne2k_pci,i82551,i82557b,i82559er,rtl8139,e1000,pcnet,virtio； macaddr=mac：指明mac地址；52:54:00: -net tap[,vlan=n][,name=str][,fd=h][,fds=x:y:...:z][,ifname=name][,script=file][,downscript=dfile]: 通过物理的TAP网络接口连接至vlan n； script=file：启动虚拟机时要执行的脚本，默认为/etc/qemu-ifup downscript=dfile：关闭虚拟机时要执行的脚本，/etc/qemu-ifdown ifname=NAME：自定义接口名称； 通过脚本实现启动和停止系统时桥接网络和删除桥接的自动执行操作 /etc/qemu-ifup 1234567891011#!/bin/bashbridge=br0if [ -n "$1" ];then ip link set $1 up sleep 1 brctl addif $bridge $1 [ $? -eq 0 ] &amp;&amp; exit 0 || exit 1else echo "Error: no interface specified." exit 2fi cat/etc/qemu-ifdown 1234567891011#!/bin/bash#bridge=br0if [ -n "$1" ];then brctl delif $bridge $1 ip link set $1 down exit 0else echo "Error: no interfacespecified." exit 1fi 其它选项： -daemonize：以守护进程运行； 示例1： qemu-kvm -name c2 -smp 2,maxcpus=4,sockets=2,cores=2 -m 128 -drive file=/images/kvm/cos-i386.qcow2,if=virtio -vnc :1 -daemonize -net nic,model=e1000,macaddr=52:54:00:00:00:11 -net tap,script=/etc/qemu-ifup 示例2： qemu-kvm -name winxp -smp 1,maxcpus=2,sockets=1,cores=2 -m 1024 -drive file=/data/vms/winxp.qcow2,media=disk,cache=writeback,format=qcow2 file=/tmp/winxp.iso,media=cdrom -boot order=dc,once=d -vnc :1 -net nic,model=rtl8139,macaddr=52:54:00:00:aa:11 -net tap,ifname=tap1,script=/etc/qemu-ifup -daemonize 启动完成后，通过 vncviewer 连接我们启动的虚拟机]]></content>
  </entry>
  <entry>
    <title><![CDATA[kvm批量启动vm脚本]]></title>
    <url>%2F2018%2F12%2Fkvm%E6%89%B9%E9%87%8F%E5%90%AF%E5%8A%A8vm%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[获取到所有的虚拟机名称，保存到文件 virsh list --all | awk &apos;{print $2}&apos; | sed -n &apos;3,$p&apos; | grep -v &apos;^$&apos; &gt; list.txt 批量启动、关闭cat start.sh 12345678910#! /bin/bash### start all vmfile=/root/VM/list.txtcat $file | while read linedo /usr/bin/virsh start $line sleep 2done echo 'vm all started' cat shutdown.sh 12345678910#! /bin/bash### shutdown all vmfile=/root/VM/list.txtcat $file | while read linedo /usr/bin/virsh shutdown $line sleep 2done echo 'vm all shutdown']]></content>
  </entry>
  <entry>
    <title><![CDATA[kvm之virsh常用命令]]></title>
    <url>%2F2018%2F12%2Fkvm%E4%B9%8Bvirsh%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[virsh管理kvmvirsh的详细命令解析 常用命令 domain virsh start 启动一个虚拟机 virsh suspend 暂停 virsh resume 恢复 virsh save 将虚拟机的当前运行状态保存到宿主机磁盘 virsh restore 恢复虚拟机的状态 virsh destory 删除虚拟机运行状态 virsh shutdown 关闭虚拟机 virsh undefined 取消一个域 virsh autostart 随着宿主机启动而启动 virsh attach-disk &lt;domain&gt; PATH/IMG_FILE &lt;target&gt; 向一个域添加一个虚拟磁盘 virsh detach-disk &lt;domain&gt; &lt;target&gt; 移除一个域中的虚拟硬盘 dumpxml XML 中的域信息 monitor virsh domblklist 显示域的虚拟磁盘设备 virsh domiflist 显示域的虚拟网卡 virsh domblkinfo &lt;domain&gt; &lt;device&gt; 显示域的虚拟磁盘设备的详细信息 virsh domblkstat &lt;domain&gt; &lt;device&gt; 显示域的虚拟磁盘设备的状态 virsh domifstat &lt;domain&gt; &lt;interface&gt; 显示域的虚拟网卡的状态 Network virsh net-list 显示虚拟网络的列表 virsh net-dumpxml 显示虚拟网络的xml文件 virsh net-create file.xml 从file.xml创建一个网络 virsh net-autostart net_NAME 自动启动net_Name网络 virsh net-start 开始一个(以前定义的)不活跃的网络 示例： 1,查看运行的虚拟机 virsh list 2,查看所有的虚拟机（关闭和运行的虚拟机） virsh list –all 3,连接虚拟机 virsh console +域名（虚拟机的名称） 4，退出虚拟机 ctrl+] 5,关闭虚拟机 virsh shutdown +域名 virsh destroy +域名 这种方式的关闭，是一种删除的方式，只是在virsh list中删除了该虚拟机。 6，挂起虚拟机 virsh suspend +域名 7，恢复被挂起的虚拟机 virsh resume +域名 8，子机随宿主主机（母机）启动而启动 virsh autostart + 域名 9，取消自动启动 virsh auotstart –disable +域名 10，彻底删除虚拟机 删除虚拟机 virsh destroy +域名 解除标记 virsh undefine +域名 删除虚拟机文件 11,启动虚拟机并进入该虚拟机 virsh start 域名 –console 12.查看虚拟机信息 virsh dominfo 域名 重启 virsh reboot 域名 查看虚拟机信息 virsh dominfo 域名 查看虚拟机磁盘 virsh domblklist 域名 查看虚拟网卡 virsh domiflist 域名 更改虚拟机配置,libvirt使用xml文件来定义虚拟机配置 virsh edit 域名]]></content>
  </entry>
  <entry>
    <title><![CDATA[kvm虚拟机网卡与磁盘管理]]></title>
    <url>%2F2018%2F12%2Fkvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[使用到的指令集： qemu-img virt-sysprep virsh dnsmasq 网络配置[官方文档](https://wiki.libvirt.org/page/VirtualNetworking) brctl命令使用需要安装brctl-utils brctl show：查看现有的虚拟桥设备 brctl addbr BR_NAME：添加虚拟网桥设备 brctl stp BRIDGE_NAME on：打开stp协议 brctl addif BRIDGE_NAME IFNAME：将虚拟网卡加入虚拟桥设备 1. 添加一对虚拟网卡 ip link add brin type veth peer name brout 2. 启动添加的网卡 ip link set brin up ip link set brout up 以上方式是在命令行上配置的，是临时存在的，只要重启网络服务可能配置就不存在的 netns：网络名称空间netns 可以创建一个完全隔离的新网络环境，这个环境包括一个独立的网卡空间，路由表，ARP表，ip地址表，iptables等。总之，与网络有关的组件都是独立的 Usage: ip netns list 查看当前宿主机的所有名称空间 ip netns add NAME 添加一个网络名称空间 示例：ip netns add r1 ip netns delete NAME 删除一个网络名称空间 示例：ip netns delete r1 ip netns exec NAME cmd ... 执行网络名称空间的命令 示例：ip netns exec r1 ifconfig -a ip link set VETH netns NETNS_NAME 将虚拟网卡VETH加入网络名称空间NETNS_NAME ip link set dev net-out name eth0 netns ns1 ip link add type veth peer name net1-out 删除虚拟网络空间模式，所有和虚拟网络空间有关的虚拟网卡都会被删除。 示例：两个隔离环境虚拟机需要通信 yum install bridge-utils libvirt libvirt-client virt-install virt-viewer net-tools -y 1.创建网桥，并激活 brctl addbr r1 brctl addbr r2 ip link set up r1 ip link set up r2 2.创建虚拟机并连接网桥 virt-install --name vm1 --ram 512 --vcpus=1 --disk /root/VM/cirros-0.3.0-x86_64-disk-1.img --network bridge=r1,model=virtio --force --import --nographics --serial=pty --console=pty virt-install --name vm2 --ram 512 --vcpus=1 --disk /root/VM/cirros-0.3.0-x86_64-disk-2.img --network bridge=r2,model=virtio --force --import --nographics --serial=pty --console=pty 3.创建虚拟网络空间 ip netns add route 4.创建一张虚拟网卡，虚拟网卡分为前半段和后半段，分别添加到网桥与虚拟网络空间 ip link add net-1 type veth peer name net-2 ip link add net-4 type veth peer name net-3 brctl addif r1 net-1 brctl addif r2 net-4 ip link set net-2 netns route ip link set net-3 netns route ip link set net-1 up&amp;&amp;ip link set net-4 up&amp;&amp;ip netns exec route ifconfig net-3 up&amp;&amp;ip netns exec route ifconfig net-4 up 5.配置vm1、vm2、net-2、net-3 ip地址 virsh console vm2 (vm1类似) # ip addr add 192.168.20.2/24 dev eth0 # ip route add defaulit via 192.168.20.1 ip netns exec route ip addr add 192.168.10.1/24 dev net-2 ip netns exec route ip addr add 192.168.20.1/24 dev net-3 6.宿主机开启路由转发 sysctl -w net.ipv4.ip_forward=1 7.测试， 四种网络模型1.桥接网络 1)CentOS 7创建物理桥，使用内核自带的桥接模块实现： 桥接口配置文件保留地址信息；复制物理网卡配置文件 TYPE=Bridge Device=BRIDGE_NAME 物理网卡配置文件： 删除地址、掩码和网关等相关的配置，添加 BRIDGE=BRIDGE_NAME 重启网络服务即可： 2)创建xml文件 br.xml 12345&lt;network&gt; &lt;name&gt;br&lt;/name&gt; //kvm &lt;forward mode='bridge'/&gt; &lt;bridge name='br0'/&gt;&lt;/network&gt; 2.nat网络 nat.xml 12345678910&lt;network&gt; &lt;name&gt;nat&lt;/name&gt; &lt;forward mode='nat'/&gt; &lt;bridge name='virbr0' stp='on' delay='0'/&gt; &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt; &lt;dhcp&gt; &lt;range start='192.168.122.2' end='192.168.122.254'/&gt; &lt;/dhcp&gt; &lt;/ip&gt;&lt;/network&gt; 3.route route.xml 12345678910&lt;network&gt; &lt;name&gt;route&lt;/name&gt; &lt;forward mode='route'/&gt; &lt;bridge name='virbr2' stp='on' delay='0'/&gt; &lt;ip address='192.168.200.1' netmask='255.255.255.0'&gt; &lt;dhcp&gt; &lt;range start='192.168.200.2' end='192.168.200.254'/&gt; &lt;/dhcp&gt; &lt;/ip&gt;&lt;/network&gt; 4.isolate 隔离网络 isolate.xml 1234&lt;network&gt; &lt;name&gt;isolate&lt;/name&gt; &lt;bridge name='virbr1' stp='on' delay='0'/&gt;&lt;/network&gt; 注意：网卡mac地址不能冲突 定义网络： virsh define nat.xml virsh start nat dnsmasq是一款小巧且方便地用于配置DNS服务器和DHCP服务器的工具，适用于小型网络，它提供了DNS解析功能和可选择的DHCP功能 dnsmasq listen-address=192.168.1.132,127.0.0.1 dhcp-range=192.168.1.50,192.168.1.150,48h dhcp-option=3,192.168.0.1 磁盘管理映像文件的实现三种方式; raw cow qcow2 qemu-img command [command options] command create 创建一个磁盘映像 -f [disk_format] [disk_format]：qcow,qcow2,raw,host_device,host_cdrom,vmdk,vhdx,dmg... [-o otions] # qemu-img create -f qcow2 -o ? /VM/temp.qcow size： preallocation (off,metadata,falloc,full) 预分配模式,metadata：只写入磁盘元数据到磁盘，空间动态增长；full全量划分，空间全部占用 info 查看磁盘映像格式的信息 convert 磁盘映像的格式装换成其它格式 resize 改变磁盘映像的大小 check 检查磁盘映像文件的错误 示例： 转换磁盘格式 qemu-img convert -f raw -O qcow2 test01.img test01.qcow2 快照管理virsh snapshot-create &lt;domain&gt; 1 创建快照： virsh snapshot-create redis-1 virsh snapshot-create-as docker test 2 查看快照 #virsh snapshot-list redis-1 Name Creation Time State ------------------------------------------------------------ 1546507229 2019-01-03 17:20:29 +0800 running tst 2019-01-03 18:19:01 +0800 shutoff ls /var/lib/libvirt/qemu/snapshot/redis-1/ virsh list --all 3 销毁关闭虚拟机 virsh shtudown docker virsh detstroy docker 4 恢复虚拟机快照 virsh snapshot-revert redis-1 test virsh snapshot-current &lt;domain&gt; [--name] [--security-info] [--snapshotname &lt;string&gt;] 恢复到最近一次快照 virsh snapshot-current redis-1 --snapshotname 1546507229 5 删除虚拟机快照 virsh snapshot-delete redis-1 tst save和restore可以在虚机开机状态下（内存）保存当前的虚机状态为一个文件 不推荐使用save和restore到生产中 在测试场景中，我们经常需要不断的将vm还原到某个起点，然后重新开始部署和测试。每次都删除/创建vm仍然很慢。 这个时候，可以使用save/restore方法。 virsh save --bypass-cache vm2 /opt/vm2_save --running 上面这个命令将vm2的当前状态保存到/opt/ --running参数表示下次restore回来的时候能够自动启动vm2,这个命令会导致vm2被关闭。 --bypass-cache加载时避免文件系统缓存 在save之前可以做一些基础工作。 还原： virsh destroy vm2 virsh restore /opt/vm2_save --bypass-cache --running 必须先关闭虚拟机 磁盘热插拔扩展qcow2格式的磁盘可以动态增加，创建的镜像类型后缀可以是qcow2，或者可以是img 虚拟机必须 running 1.创建一块磁盘 qemu-img create -f qcow2 -o preallocation=metadata /VM/vdb.img 1G 将空盘添加到虚拟机 virsh attach-disk redis-1 /root/VM/vdb.img vbd --cache none 查看虚拟机的磁盘列表 查看vm3的磁盘列表 2.拔掉磁盘 注意：使用virsh指令删除磁盘会直接强制将虚拟机中磁盘删除，如果磁盘已经挂载使用，要停止该磁盘的写操作，否则会造成数据丢失，拔掉的磁盘存储在kvm宿主机的vm实例的镜像目录中，需要使用可以再挂载使用 virsh detach-disk redis-1 vdb 在虚拟机中会自动识别其名称，命令是按字母顺序来的 网卡热插拔虚拟机redis-1添加一个网卡到物理桥br0上 virsh attach-interface redis-1 bridge br0 注意： 撤销网卡，撤销网卡前先关闭网卡 撤销某一块网卡要指定该网卡的MAC，要不会撤销该网卡所在网桥上所有的网卡 查看虚拟机网卡 virsh domiflist redis-1 Interface Type Source Model MAC --------------------------------------------------- vnet0 bridge br virtio 52:54:00:47:70:89 vnet1 bridge br0 rtl8139 52:54:00:fd:cd:cb 撤销网卡 virsh detach-interface vm4 bridge --mac 52:54:00:fd:cd:cb]]></content>
  </entry>
  <entry>
    <title><![CDATA[虚拟化技术基础]]></title>
    <url>%2F2018%2F12%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[虚拟化虚拟化（Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源 可以实现IT资源的动态分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需 虚拟化和云计算的关系虚拟化重点对资源的虚拟，比如把一台大型的服务器虚拟成多台小定的服务器。一个侧重虚拟的这种技术。 云计算的重点是对资源池（可以是经过虚拟化之后）进行统一的管理和调度。一种侧重对虚拟化之后的资源进行管理和调度。 虚拟化架构 虚拟化技术有很多，但是虚拟化架构主要有两种形式：裸金属架构和宿主架构： Type-I:虚拟机直接运行在系统硬件上，创建硬件全仿真实例，被称为“裸机”,也称为裸金属架构。 xen,vmware ESX/ESXi Type-II:虚拟机运行在传统操作系统上，同样创建的是硬件全仿真实例，被称为“托管”hypervisor。也称为宿主架构 kvm,vmware workstation,virtualbox 几个重要的概念： A.宿主机：Host ，即物理服务器 B.虚拟机：Guest ，也称客户机、虚机 C.VMM（virtual Machine Monitor）：即Hypervisors，它是一种运行在基础物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享硬件。Hypervisors是一种在虚拟环境中的“元”操作系统。他们可以访问服务器上包括磁盘和内存在内的所有物理设备。Hypervisor不但协调着这些硬件资源的访问，也同时在各个虚拟机之间施加防护。当服务器启动并执行Hypervisor时，它会加载所有虚拟机客户端的操作系统同时会分配给每一台虚拟机适量的内存、CPU、网络和磁盘。 cpu虚拟化CPU的运行级别，Ring 0也称为核心态，操作系统需要直接访问硬件和内存，使用特权指令，控制中断、修改页表、访问设备，因此它的代码需要运行在最高运行级别。Ring 3也称为用户态，需要访问磁盘、写文件时，则需要调用系统函数，这样的操作称为用户态到核心态。 Ring 是指 CPU 的运行级别，Ring 0是最高级别，Ring1次之，Ring2更次之 因为宿主操作系统是工作在 ring0 的，客户操作系统就不能也在 ring0 了，但是它不知道这一点，以前执行什么指令，现在还是执行什么指令，但是没有执行权限是会出错的。所以这时候虚拟机管理程序（VMM）需要避免这件事情发生。 虚机怎么通过 VMM 实现 Guest CPU 对硬件的访问，根据其原理不同有三种实现技术： 1. 全虚拟化 2. 半虚拟化 3. 硬件辅助的虚拟化 上层架构和底层要保持一致 模拟：Emulation上层的虚拟机架构和底层可以不一样，性能比较差 著名的模拟器 PearPC,Bochs,QEMU 完全虚拟化（Full Virtualization)宿主机完全虚拟出一个完整的平台，guest不需要任何修改,guest不清楚自己运行在虚拟环境中； 只需要模拟环0，假设各guest的内核运行在环1（实际上不可能运行在环1，因为环1没有特权指令） 软件模拟特权指令：例如VMM捕获关机指令，关闭虚拟机程，而非物理机 Hypervisor(VMM)在guest操作系统和裸硬件之间用于工作协调 BT：二进制翻译（软件） VMware Workstation,VMware Server,VirtuaBox，Parallels Desktop 半虚拟化Para Virtualization）操作系统辅助的虚拟化，也即半虚拟化(paravirtualization)或准虚拟化 它使用Hypervisor分享存取底层的硬件，但是它的guest操作系统集成了虚拟化方面的代码，guest OS能配合Hypervisor来协作实现虚拟化。（guest操作系统意识到自己是处于虚拟化环境）（Xen） 优点：与全虚拟化相比，架构更精简，整体速度会有一定优势。 缺点：要修改包含该API的操作系统，但是对于某些不含该API的操作系统（主要是windows）来说，就不行能用这种方法 Xen 硬件辅助的全虚拟化 (Hardware Assisted Virtualization)HVM：硬件辅助的虚拟化（硬件），模拟出环-1，host的内核运行在环-1，guest内核运行在环0上，此时环0上没有特权指令，guest运行特权时指令cpu会被触发，这个过程不需要hyper进行监控，提高性能 CPU厂商Intel 和 AMD 开始支持虚拟化了。 CPU: ring -1 Intel：intel vt-x AMD:amd-v Intel-VT （Virtualization Technology）技术。 这种 CPU，这种 CPU，有 VMX root operation 和 VMX non-root operation两种模式，两种模式都支持Ring 0 ~ Ring 3 共 4 个运行级别。这样，VMM 可以运行在 VMX root operation模式下，客户 OS 运行在VMX non-root operation模式下。 内存虚拟化进程视角看内存：线性地址空间 虚拟地址 内核视角看内存：物理地址空间 MMU将线性地址转化为物理地址 1.MMU：memory management unit，称为内存管理单元，或者是存储器管理单元， MMU是硬件设备,MMU的主要作用是负责从CPU内核发出的虚拟地址到物理地址的映射，并提供硬件机制的内存访问权限检查 2.TLB:Translation Lookaside Buffer 可以把它理解成页表缓冲。里面存放的是一些页表文件（虚拟地址到物理地址的转换表） TLB就是负责将虚拟内存地址翻译成实际的物理内存地址，而CPU寻址时会优先在TLB中进行寻址。处理器的性能就和寻址的命中率有很大的关系 在有两个虚机的情况下，情形是这样的 KVM为了在一台机器上运行多个虚拟机，需要增加一个新的内存虚拟化层，也就是说，必须虚拟MMU 来支持客户操作系统，来实现VA-&gt;PA-&gt;MA的翻译。客户操作系统继续控制虚拟地址到客户内存物理地址的映射 （VA -&gt; PA），但是客户操作系统不能直接访问实际机器内存，因此VMM需要负责映射客户物理内存到实际机器内存（PA -&gt; MA） VMM 内存虚拟化的实现方式： 软件方式：通过软件实现内存地址的翻译，比如 Shadow page table （影子页表）技术 硬件实现：基于 CPU 的辅助虚拟化功能，比如 AMD的NPT和Intel的EPT技术 KVM中，虚机的物理内存即为qemu-kvm进程所占用的内存空间。KVM使用CPU辅助的内存虚拟化方式。在 Intel 和 AMD 平台，其内存虚拟化的实现方式分别为： EPT和 NPT采用类似的原理，都是作为CPU中新的一层，用来将客户机的物理地址翻译为主机的物理地址 Intel和AMD分别通过EPT(Extended Page Tables)和NPT(Nested Page Tables)为虚拟化应用提升影子MMU的性能，并通过标记(tagged)TLB来 避免虚拟机切换时频繁清写(flush)TLB以提高TLB缓存的命中率 I/0虚拟化I/0: 外存： 硬盘、光盘、u盘 网络设备： 网卡 显示设备： VGA：frame buffer机制， 键盘鼠标： ps/2,usb：完全模拟实现，当前焦点捕获，将虚拟设备和物理设备建立关联关系 I/O虚拟化的方式： 模拟：完全使用软件来模拟真实硬件 半虚拟化：KVM中，要想提高IO虚拟化的效率，就要使用半虚拟化的方式：virtio。 IO-through：IO透传，让虚拟机直接使用物理设备，几乎接近于硬件性能，硬件必须要 支持透传技术： Intel:VT-d 基于北桥的硬件辅助的虚拟化技术 虚拟和模拟： 虚拟：要求guest.kernel和host.kernel一致，用以提高性能 只需要捕获特权指令，其他非特权指令，直接在CPU上运行即可 模拟：可以不一致，需要进行翻译 需要捕获所有指令，翻译执行 虚拟化技术分类：虚拟化技术的分类： (1) 模拟：Emulation Qemu, PearPC, Bochs, ... (2) 完全虚拟化：Full Virtualization，Native Virtualization BT/hvm VMWare Workstation, VirtualBox, VMWare Server, Parallels Desktop, KVM(hvm), XEN(hvm) (3) 半虚拟化：Para-Virutalization 特点：GuestOS明确知道自己运行虚拟机之上； xen, UML(user-mode linux) (4) 容器级虚拟化： LXC, OpenVZ, libcontainer, runC, rkt, Linux V Servers, Virtuozzo, ... (5) 库级别虚拟化： wine (6) 程序级虚拟化 jvm, pvm, ...]]></content>
  </entry>
  <entry>
    <title><![CDATA[kvm]]></title>
    <url>%2F2018%2F12%2Fkvm%2F</url>
    <content type="text"><![CDATA[KVMKVM 全称是 基于内核的虚拟机（Kernel-based Virtual Machine），它是一个内核模块，内核2.6.20后包含在内核中，该内核模块使得Linux变成了一个Hypervisor, 它由 Quramnet 开发，该公司于 2008年被 Red Hat 收购。 它支持 x86 (32 and 64 位), s390, Powerpc 等 CPU。 它是完全开源的。 是x86架构且硬件支持虚拟化技术（如intel VT或AMD-V）的Linux全虚拟化解决方案 需要经过修改的QEMU软件（qemu-kvm），作为虚拟机上层控制和界面 能在不改变linux或windows镜像的情况下同时运行多个虚拟机， kvm原理Qemu-KVM:纯软件实现的虚拟化系统,主要用于实现IO虚拟化 qemu-kvm是qemu项目的一个分支，专用于管理kvm，到1.3.0合并到了qemu上 qemu是支持xen和kvm的，但是qemu-kvm是仅仅支持kvm的 虚拟机的每一个cpu[vcpu],使用一个线程模拟 ☉依赖于HVM（要求cpu必须支持硬件虚拟化） Intel：VT-x（表现为vmx） ADM： ADM-V (表现为svm) ☉内核模块（整体表现为一个内核模块）： kvm：核心模块 kvm-intel（专用于intel的模块）；kvm-amd（专用于amd的模块） ★KVM模块载入后的系统的运行模式： 内核模式：GuestOS(虚拟机操作系统)执行I/O类操作，或其它的特殊指令的操作；称作“来宾-内核”模式； 用户模式：代表GuestOS请求I/O类操作； 来宾模式：GuestOS的非I/O类操作；事实上，它被称作“来宾-用户”模式； kvm hypervisor：host上的内核 ★kvm组件 /dev/kvm： 工作于hypervisor，在用户空间可通过ioctl()系统调用来完成VM创建、启动等管理功能；它是一个字符设备 功能：创建VM、为VM分配内存、读写VCPU的寄存器、向VCPU注入中断、运行VCPU等等； ☉qemu进程： 工作于用户空间，主要用于实现模拟PC机的IO设备； KVM和qemuQEMU:主要提供了以下几个组件： 处理器模拟器： 仿真IO设备 关联模拟设备到真实设备 提供调试器 提供与模拟器交互的接口 VM 运行期间，QEMU会通过KVM模块提供的系统调用进入内核，由KVM负责将虚拟机置于处理的特殊模式运行。当虚机进行 I/O 操作时，KVM 会从上次系统调用出口处返回 QEMU，由 QEMU 来负责解析和模拟这些设备。 除此以外，虚机的配置和创建、虚机运行所依赖的虚拟设备、虚机运行时的用户环境和交互，以及一些虚机的特定技术比如动态迁移，都是 QEMU 自己实现的。 KVM模块按需加载到kernel中，KVM 本身不执行任何设备模拟，需要 QEMU 通过 /dev/kvm 接口设置一个 GUEST OS 的地址空间，向它提供模拟的 I/O 设备，并将它的视频显示映射回宿主机的显示屏 KVM模块加载过程： 1.首先初始化内部的数据结构； 2.做好准备后，KVM 模块检测当前的 CPU，然后打开CPU虚拟化模式开关，并通过执行指令将宿主操作系统置于虚拟化模式的根模式； 3.最后，KVM 模块创建特殊设备文件 /dev/kvm 并等待来自用户空间的指令。 后面需要KVM和QEMU交互完成，两者的通信接口是/dev/kvm的IOCTL调用， 在非根模式下，所有敏感的二进制指令都被CPU捕捉到，CPU在保存现场之后自动切换到根模式，由 KVM 决定如何处理。 CPU 中的内存管理单元MMU是通过页表的形式将程序运行的虚拟地址转换成实际物理地址。在虚拟机模式下，MMU 的页表则必须在一次查询的时候完成两次地址转换。因为除了将客户机程序的虚拟地址转换了客户机的物理地址外，还要将客户机物理地址转化成真实物理地址。 网络虚拟化模型1）bridge 桥接 把物理机上的网卡当作交换机， 在桥接方式下，模拟一个虚拟的网卡给客户系统，主系统对于客户系统来说相当于是一个桥接器。客户系统好像是有自己的网卡一样，自己直接连上网络，也就是说客户系统对于外部直接可见。 2）route 路由 相当于虚拟机连接到一台路由器上，由路由器(物理网卡),统一转发，但是不会改变源地址。 该模式网桥要作为路由器对虚拟机地址进行转发，路由模式是无法修改源地址ip，因此虚拟机可能会成功的将报文发送给目标地址ip，而目标地址ip无法将报文回传给源地址ip 3）NAT 源地址转换为路由器(物理网卡)地址，但是其他主机的报文无法到达虚拟机，在docker环境中经常被使用。 4）isolation 隔离 各虚拟机虚拟网卡连在虚拟交换机上，虚拟机之间能互相通信，但虚拟机与主机和internet不能通信 VirtIOKVM是一个混合类型的VMM，它能够以模拟方式支持硬件的完全虚拟化，也能够在GuestOS中安装驱动程序进而支持部分硬件的半虚拟化对网络设备和块设备来讲，半虚拟化方式能够极大地提升设备性能 KVM 功能与特性：支持CPU 和 memory 超分（Overcommit） 支持半虚拟化I/O （virtio） 支持热插拔 （cpu，块设备、网络设备等） 支持对称多处理（Symmetric Multi-Processing，缩写为 SMP ） 支持实时迁移（Live Migration） 支持 PCI 设备直接分配和 单根I/O 虚拟化 （SR-IOV） 支持 内核同页合并 （KSM ） 支持 NUMA （Non-Uniform Memory Access，非一致存储访问结构 ） KVM 工具集合libvirt：操作和管理KVM虚机的虚拟化 API，使用 C 语言编写，可以由 Python,Ruby, Perl, PHP, Java 等语言调用。可以操作包括 KVM，vmware，XEN，Hyper-v, LXC等Hypervisor。 kvm的管理工具栈： qemu： qemu-kvm qemu-img qemu-io 在Guest上运行qumu进程 基于libvirt API管理工具主要有VMM和virsh： GUI： virt-manager：通过libvirt管理虚拟机的图形化工具， virtinst：构建及安装虚拟的工具组件，包括virt-install（创建及安装虚拟机）、virt-clone（虚 拟机克隆）、virt-convert（虚拟机格式转换）和virt-image（基于xml格式的镜像描述文件创 建虚拟机）等； virt-viewer：连接虚拟机的图形化客户端； CLI：virsh, virt-install virsh：管理虚拟机的交互式shell，可用于创建、暂停、停止域等，也可实现虚拟 设备的管理，是用于管理VKM虚拟机的最常用工具之一 libvirt远程管理虚拟机要用libvirt连接到超级管理程序，我们需要一个URI，这个URI配合virsh和virt-viewer命令使用，后面可以跟一些可选项，virt-viewer可以调用一些链接参数， 例如：virsh -c qemu:///system 当链接到远程机器时，可以定义几种使用的协议：ssh，tcp，tls。 当链接到远程机器时，需要使用远程主机的用户和主机名进行链接，如果没有定义链接用户，则会使用本机环境的$USER的用户进行链接， 当连接到qemu hypervisor时，接受两种链接类型：system可以有所有的访问权限，session有限制的访问。 例如： 使用full access链接至本机的qemuhypervisor，前面的-c是为了执行后面的list命令(--connect) virsh -c qemu:///system list 使用full access链接至远程主机的qemu hypervisor，每次都要输入ssh密码，改成ssh无密码登陆就不需要输入密码了，直接显示结果。 virsh -c qemu+ssh://tux@mercur/system 直接进入交互virsh模式 virsh -c qemu+ssh://10.1.1.8/system list 直接显示list后的结果 其余连接格式如下： qemu:///session (local access to per-user instance) qemu+unix:///session (local access to per-user instance) qemu:///system (local access to system instance) qemu+unix:///system (local access to system instance) qemu://example.com/system (remote access, TLS/x509) qemu+tcp://example.com/system (remote access, SASl/Kerberos) qemu+ssh:///system (remote access, SSH tunnelled) 实时迁移实时迁移的需求： •GuestOS映像文件放轩在共享存储上，如iSCSI、NFS或GFS2等； •目标物理主机的KVM要能够兼容源物理主机的KVM及其准备迁移的GuestOS； •在两台主机上，共​享​存​储​必​须​挂​载​在​同​一​位​置​，且​挂​载​的​目​录​名​必​须​一​致​； •两台物理主机的CPU需要具有相同类型的特性； •虚拟机没使用透传I/O； •两台物理主机的时间要同步； •两​台物理主机必​须​有​一​致​的​网​络​配​置​，且​所​有​桥​接​和​网​络​配​置​必​须​完​全​一​致 https://docs.openstack.org/install-guide/_image/openstack-arch-kilo-logical-v1.png]]></content>
  </entry>
  <entry>
    <title><![CDATA[KVM安装]]></title>
    <url>%2F2018%2F12%2FKVM%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装1）确保CPU支持HVM grep -E --color=auto &quot;(vmx|svm)&quot; /proc/cpuinfo 2）装载模块 modprobe kvm 3）验正： 存在/dev/kvm 或者 lsmod |grep kvm 4)安装kvm yum install libvirt virt-manager libvirt-daemon-kvm qemu-kvm libguestfs-tools 注意yum网络源与系统版本不一致，导致libvirtd服务无法启动 5)启动服务 systemctl start libvirtd 使用wok kimchi插件管理kvmWok基于cherrypy的web框架，可以通过一些插件来进行扩展，例如：虚拟化管理、主机管理、系统管理。它可以在任何支持HTML5的网页浏览器中运行。 Kimchi是一个基于HTML5的KVM管理工具，是Wok的一个插件（使用Kimchi前一定要先安装了wok），通过Kimchi可以更方便的管理KVM。 [github地](https://github.com/kimchi-project) 1、安装epel源 yum install epel-release 2、安装wok yum安装wok 与kimchi 编译安装 3.启动wokd服务（启动wokd时，nginx也会同时启动） systemctl start wokd 5、此时访问https://IP:8001即可看到登录页面，此登录的帐号密码为当前系统的帐号密码 注意：新建kvm网络接口后，如果页面不显示Virtualization选项 修改/etc/kimchi/template.conf network = 接口类型 #默认是default(此为nat网卡类型的名称) listen = 监听接口 安装虚拟机使用qemu-kvm安装kvm之qemu-kvm命令 使用virt-manager图形安装virt-manager 使用virsh命令利用xml安装virsh dumpxml redis-1 &gt; vm1.xml 使用virt-install安装virt-install是一个安装虚拟机的工具， 支持KVM,Xen和使用&quot;libvirt&quot;hypervisor来管理的虚拟机容器。 支持通过VNC、SPICE图形界面和文本模式安装虚拟机。 支持通过本地镜像文件或者远程NFS,HTTP,FTP或者PXE来安装虚拟机。 选项大体可分为下面几大类，同时对每类中的常用选项也做出简单说明： ◇一般选项：指定虚拟机的名称、内存大小、VCPU个数及特性等； -n NAME, --name=NAME：虚拟机名称，需全局惟一； -r MEMORY, --ram=MEMORY：虚拟机内在大小，单位为MB； --vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]：VCPU个数及相关配置； --cpu=CPU：CPU模式及特性，如coreduo等； 可以使用qemu-kvm -cpu ?来获取支持的CPU模式； ◇安装方法：指定安装方法、GuestOS类型等； -c CDROM, --cdrom=CDROM：光盘安装介质； -l LOCATION, --location=LOCATION：安装源URL，支持FTP、HTTP及NFS等， 如ftp://172.16.0.1/pub； --pxe：基于PXE完成安装； --livecd: 把光盘当作LiveCD； --os-type=DISTRO_TYPE：操作系统类型，如linux、unix或windows等； --os-variant=DISTRO_VARIANT：某类型操作系统的变体，如rhel5、fedora8等； -x EXTRA, --extra-args=EXTRA：根据--location指定的方式安装GuestOS时，用于传递给内核的额外选项， 例如指定kickstart文件的位置，--extra-args &quot;ks=http://172.16.0.1/class.cfg&quot; --boot=BOOTOPTS：指定安装过程完成后的配置选项，如指定引导设备次序、使用指定的而非安装的kernel/initrd来引导系统启动等 ； 例如： --boot cdrom,hd,network：指定引导次序； --boot kernel=KERNEL,initrd=INITRD,kernel_args=”console=/dev/ttyS0”：指定启动系统的内核及initrd文件； ◇存储配置：指定存储类型、位置及属性等； --disk=DISKOPTS：指定存储设备及其属性；格式为--disk /some/storage/path,opt1=val1，opt2=val2等； 常用的选项有： device：设备类型，如cdrom、disk或floppy等，默认为disk； bus：磁盘总结类型，其值可以为ide、scsi、usb、virtio或xen； perms：访问权限，如rw、ro或sh（共享的可读写），默认为rw； size：新建磁盘映像的大小，单位为GB； cache：缓存模型，其值有none、writethrouth（缓存读）及writeback（缓存读写）； format：磁盘映像格式，如raw、qcow2、vmdk等； sparse：磁盘映像使用稀疏格式，即不立即分配指定大小的空间； --nodisks：不使用本地磁盘，在LiveCD模式中常用； ◇网络配置：指定网络接口的网络类型及接口属性如MAC地址、驱动模式等； -w NETWORK, --network=NETWORK,opt1=val1,opt2=val2：将虚拟机连入宿主机的网络中，其中NETWORK可以为： bridge=BRIDGE：连接至名为“BRIDEG”的桥设备； network=NAME：连接至名为“NAME”的网络； 其它常用的选项还有： model：GuestOS中看到的网络设备型号，如e1000、rtl8139或virtio等； mac：固定的MAC地址；省略此选项时将使用随机地址，但无论何种方式，对于KVM来说，其前三段必须为52:54:00； --nonetworks：虚拟机不使用网络功能； ◇图形配置：定义虚拟机显示功能相关的配置，如VNC相关配置； --graphics TYPE,opt1=val1,opt2=val2：指定图形显示相关的配置，此选项不会配置任何显示硬件（如显卡），而是仅指定虚拟机启动后对其进行访问的接口； TYPE：指定显示类型，可以为vnc、sdl、spice或none等，默认为vnc； port：TYPE为vnc或spice时其监听的端口； listen：TYPE为vnc或spice时所监听的IP地址，默认为127.0.0.1，可以通过修改/etc/libvirt/qemu.conf定义新的默认值； password：TYPE为vnc或spice时，为远程访问监听的服务进指定认证密码； --noautoconsole：禁止自动连接至虚拟机的控制台； ◇设备选项：指定文本控制台、声音设备、串行接口、并行接口、显示接口等； --serial=CHAROPTS：附加一个串行设备至当前虚拟机，根据设备类型的不同，可以使用不同的选项，格式为“--serial type,opt1=val1,opt2=val2,...”， 例如： --serial pty：创建伪终端； --serial dev,path=HOSTPATH：附加主机设备至此虚拟机； --video=VIDEO：指定显卡设备模型，可用取值为cirrus、vga、qxl或vmvga； ◇虚拟化平台：虚拟化模型（hvm或paravirt）、模拟的CPU平台类型、模拟的主机类型、hypervisor类型（如kvm、xen或qemu等）以及当前虚拟机的UUID等； -v, --hvm：当物理机同时支持完全虚拟化和半虚拟化时，指定使用完全虚拟化； -p, --paravirt：指定使用半虚拟化； --virt-type：使用的hypervisor，如kvm、qemu、xen等；所有可用值可以使用’virsh capabilities’命令获取； ◇其它： --autostart：指定虚拟机是否在物理启动后自动启动； --print-xml：如果虚拟机不需要安装过程(--import、--boot)，则显示生成的XML而不是创建此虚拟机；默认情况下，此选项仍会创建磁盘映像； --force：禁止命令进入交互式模式，如果有需要回答yes或no选项，则自动回答为yes --dry-run：执行创建虚拟机的整个过程，但不真正创建虚拟机、改变主机上的设备配置信息及将其创建的需求通知给libvirt； -d, --debug：显示debug信息； 实际使用中，其必须提供的选项仅包括--name、--ram、--disk（也可是--nodisks）及安装过程相关的选项。此外，有时还需要使用括--connect=CONNCT选项来指定连接至一个非默认的hypervisor。 例： 创建一个名为vm2的虚拟机，内存大小为512MB，使用制作的映像文件/root/VM/cirros-0.3.0-x86_64-disk-2.img virt-install --name vm2 --ram 512 --vcpus=1 --disk /root/VM/cirros-0.3.0-x86_64-disk-2.img --network bridge=r2,model=virtio --force --import --nographics --serial=pty --console=pty 制作镜像文件yum install libguestfs libguestfs-tools virt-sysprep [--options] -d domain_name --remove-user-accounts：移除用户 --root-password：设定root密码 --intsall：指定封装安装的程序包 --operation：执行要清理的操作列表，使用--list-operations列出所有的操作 --network：指定封装的使用的网络 domain必须是shut off状态 virt-sysprep -d redis-1]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx代理与缓存]]></title>
    <url>%2F2018%2F12%2Fnginx%E4%BB%A3%E7%90%86%E4%B8%8E%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[四层调度：nginx(stream module) 七层调度：nginx(http_upstream module), haproxy(mode http), httpd, ngx_http_proxy_module1、proxy_pass URL; 上下文:location, if in location, limit_except 假如访问index.html 注意:proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； server { ... server_name HOSTNAME; location /uri/ { proxy_pass http://host[:port]; } ... } http://HOSTNAME/uri/index.html --&gt; http://host/uri/index.html 注意:proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri； server { ... server_name HOSTNAME; location /uri/ { proxy_pass http://host/aaa/; } ... } http://HOSTNAME/uri/index.html --&gt; http://host/aaa/index.html 注意:如果location定义其uri时使用了正则表达式的模式,或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri;用户请求时传递的uri将直接附加代理到的服务的之后； server { ... server_name HOSTNAME; location ~|~* /uri/ { proxy_pass http://host; } ... } http://HOSTNAME/uri/index.html --&gt; http://host/uri/index.html； 注意：proxy_pass后面的路径带uri但没有/时，其会将location的uri的后端部分追加给后端主机 server { ... server_name HOSTNAME; location /uri/ { proxy_pass http://host/aaa; } ... } http://HOSTNAME/uri/index.html --&gt; http://host/aaaindex.html 2、proxy_set_header field value; 上下文:http, server, location 设定发往后端主机的请求报文的请求首部的值,如请求服务器的主机名,请求服务器名称与代理服务器的端口,真实ip，以及代理者的ip 例： proxy_set_header Host $host; proxy_set_header Host $host:$proxy_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 3、proxy_cache_path 上下文: http 定义可用于proxy功能的缓存 proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; levels 指定该缓存空间有两层hash目录，第一层目录为1个字母，第二层为2个字母,levels最多三层，每层最多两个字符，这是为了加快访问文件的速度；最后使用代理url的哈希值作为关键字与文件名 keys_zone 设置这个缓存区的名称和内存缓存空间大小 inactive 设置数据多长时间没有被访问将删除 max_size 设置硬盘缓存空间大小 use_temp_path 如果为off，则nginx会将缓存文件直接写入指定的cache文件中，而不是使用temp_path存储，official建议为off，避免文件在不同文件系统中不必要的拷贝 例： proxy_cache_path /usr/local/nginx/proxy_cache levels=1:2 keys_zone=cache_one:100m inactive=1d max_size=1g; 4、proxy_cache zone | off 上下文:http, server, location 配置一块公用的内存区域名称，该区域可以存放缓存的索引数据 指明要调用的缓存，或关闭缓存机制 5、 proxy_cache_key string; 上下文:http, server, location 缓存中用于“键”的内容； 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 6、proxy_cache_valid [code ...] time; 上下文:http, server, location 定义对特定响应码的响应内容的缓存时长； 定义在http{...}中； proxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=pxycache:20m max_size=1g; 定义在需要调用缓存功能的配置段，例如server{...}； proxy_cache pxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; 7、proxy_cache_use_stale 上下文:http, server, location 确定在与后端服务器出现状况时，可以在哪些情况下使用过时的缓存响应 proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off error 如果无法选择代理服务器来处理请求，则 该参数还允许使用陈旧的缓存响应。 updating 如果当前正在更新，该参数允许使用过时的缓存响应。这允许在更新缓存数据时最小化对代理服务器的访问次数。 例子： location / { ... proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504 } 8、proxy_cache_methods GET | HEAD | POST ...; 上下文:http, server, location 指定客户端那些方法被缓存，默认为GET|HEAD 9、proxy_hide_header field; 上下文:http，server，location 默认情况下，nginx不会从代理服务器对客户端的响应中传递标题字段“Date”，“Server”，“X-Pad”和“X-Accel -...”。该proxy_hide_header指令设置了不会传递的其他字段 10、proxy_connect_timeout time; 表示与后端服务器连接的超时时间，既发起握手等候相应的超时时间 默认为60s；最长为75s； 11、proxy_read_timeout time; 上下文:http，server，location 代理服务器向后端服务器请求响应的超时。仅在两个连续的读操作之间设置超时，而不是为整个响应的传输。如果代理服务器在此时间内未传输任何内容，则关闭连接。 12、proxy_send_timeout time; 上下文:http，server，location 表示 设置后端服务器传输到代理服务器的超时。仅在两次连续写入操作之间设置超时，而不是为整个请求的传输。如果代理服务器在此时间内未收到任何内容，则关闭连接 Real-IP 和 X-Forwarded-For1.通过“proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for” 把从真实客户端IP和反向代理IP通过逗号分隔，添加到请求头中； 2.可以在第一个反向代理上配置“proxy_set_header X-Real-IP $remote_addr” 获取真实客户端IP； 3.配合realip模块从X-Forwarded-For也可以获取到真实客户端IP。 在整个反向代理链条的第一个反向代理可以不配置“proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for”， 否则客户端可以伪造X-Forwarded-For从而伪造客户端真实IP 如果服务端使用X-Forwarded-For第一个IP作为真实客户端IP，则就出问题了。 如果通过配置X-Real-IP请求头或者配合realip模块也不会出现该问题。 如果自己解析X-Forwarded-For的话，记得使用realip算法解析，而不是取第一个。 当我们进行限流时一定注意限制的是真实客户端IP，而不是反向代理IP ngx_http_upstream_modulenginx负载均衡是ngx_http_upstream_module模块的功能，需要在配置文件http块上下文中定义upstream块，指定一组负载均衡的后端服务器，然后在上面讲到的proxy_pass中引用，就可以反向代理时实现负载均衡了 (1) upstream name { ... } 定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中； 默认的调度方法是wrr； 1) server address [parameters]; 定义服务器地址和相关的参数； 地址格式： IP[:PORT] HOSTNAME[:PORT] unix:/PATH/TO/SOME_SOCK_FILE 参数： weight=number 权重，默认为1； max_fails=number 失败尝试的最大次数； fail_timeout=time 设置服务器为不可用状态的超时时长； backup 把服务器标记为“备用”状态； down 手动标记其为不可用； 2) least_conn; 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； 3)ip_hash; 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； 4) hash key [consistent]; 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； consistent：参数，指定使用一致性hash算法； 示例： hash $request_uri consistent hash $remote_addr hash $cookie_name 5) keepalive connections; 可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量； ####hash和一致性hash的区别 1.hash nginx的负载均衡时有一个hash $request_uri的选项，这个是类似于LVS的dh。是针对客户端访问的uri来做的绑定。这样客户端访问同一个uri的时候，会被分配到同一个服务器上去。这样提高了缓存的命中率。 过程：每个uri进行hash计算得到一个数值，这个数值除以整个节点数量取余数。（取模算法） 缺点：如果一个节点挂了，那么整个全局都会乱掉。因为整个的节点数变了，因为除数变了。 2.一致性hash 一致性hash的采用的是除数特别大，假设有一个hash环。是个闭环。 把32位二进制的整数转换为十进制后均匀分布在整个环上。hash结果是除以2的32次方-1（hash是除以） 那么结果一定是落在环上的。那么，这个点靠近谁，就缓存在谁那里 假设a节点坏了。那么下一次的计算结果就是旁边的邻居。但是邻居的缓存不会受到影响。 只是坏掉的A节点会从新去缓存。 tengine一致性hash介绍 如果后端主机宕机，请求会移动到其他的节点上去 ngx_http_headers_module上下文: http, server, location, if in location 向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值； 1、add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; #代理服务器的地址 add_header X-Accel $server_name; 2、expires [modified] time; expires epoch | max | off; 用于定义Expire或Cache-Control首部的值；用来对浏览器本地缓存的控制 在对响应代码头部中是否开启对“Expires”和“Cache-Control”的增加和修改操作。 可以指定一个正或负的时间值，Expires头中的时间根据目前时间和指令中指定的时间的和来获得。 epoch表示自1970年一月一日00:00:01 GMT的绝对时间 max指定Expires的值为2037年12月31日23:59:59，Cache-Control的值为10 years。 Cache-Control头的内容随预设的时间标识指定： ·设置为负数的时间值:Cache-Control: no-cache。 ·设置为正数或0的时间值：Cache-Control: max-age =#，这里#的单位为秒，在指令中指定。 参数off禁止修改应答头中的&quot;Expires&quot;和&quot;Cache-Control&quot;。 ngx_http_fastcgi_module1、fastcgi_pass address 上下文：location, if in location address为fastcgi server的地址； ； 2、fastcgi_index name; 上下文http, server, location fastcgi默认的主页资源; 3、fastcgi_param parameter value [if_not_empty]; 设置传递给FastCGI服务器的参数值，可以是文本，变量或组合 上下文：http, server, location 4、fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 上下文：http 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义 levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 5、fastcgi_cache zone | off; 上下文：http, server, location 调用指定的缓存空间来缓存数据； 6、fastcgi_cache_key string; 上下文：http, server, location 定义用作缓存项的key的字符串； 7、fastcgi_cache_methods GET | HEAD | POST ...; 上下文：http, server, location 为哪些请求方法使用缓存； 8、fastcgi_cache_min_uses number; 上下文：http, server, location 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9、fastcgi_cache_valid [code ...] time; 上下文：http, server, location 不同的响应码各自的缓存时长； 10、fastcgi_keep_conn on | off; 上下文：http, server, location 不同的响应码各自的缓存时长 11.fastcgi_connect_timeout 60; 设定Nginx服务器和后端FastCGI服务器连接的超时时间 11.fastcgi_send_timeout 60; 上下文：http, server, location 设定Nginx允许FastCGI服务端返回数据的超时时间 12.fastcgi_read_timeout 60; 上下文：http, server, location 设定Nginx从FastCGI服务端读取响应信息的超时时间 13.fastcgi_buffer_size 64k; 上下文：http, server, location 设定用来读取从FastCGI服务端收到的第一部分响应信息的缓冲区大小 14.fastcgi_buffers 4 64k; 上下文：http, server, location 设定用来读取从FastCGI服务端收到的响应信息的缓冲区大小以及缓冲区数量 15.fastcgi_busy_buffers_size 128k; 上下文：http, server, location 设定系统很忙时可以使用的fastcgi_buffers大小，推荐大小为fastcgi_buffers *2 16.fastcgi_temp_file_write_size 128k; 上下文：http, server, location fastcti临时文件的大小，可设置128-256K fastcgi配置nginx代理通过ngx_http_fastcgi_module这个模块，将收到php程序的请求后就转发到后台FastCGI服务器处理，这里nginx可以把php-fpm服务运行在同一机器上，也可以将nginx和php-fpm分离在两台机器上。但是，nginx不支持php模块方式,只能是php-fpm模式。 httpd 使用php_module prefork模型 php_module worker、event zts_module httpd (proxy、proxy_fcgi模块)--&gt;fcgi协议--&gt;php fpm:fastcgi process manager 配置示例1： 前提：配置好fpm server和mariadb-server服务； location ~* \.php$ { root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html$fastcgi_script_name; include fastcgi_params; #fastcgi_params 文件中含有各个nginx常量的定义 } 配置示例2：通过/pm_status和/ping来获取fpm server状态信息； 在/etc/php-fpm.d/www.conf 开启， pm.status_path = /status #默认情况下为/status ping.path = /ping nginx配置 在默认主机里面加上location或者你希望能访问到的主机里面 location ~* ^/(pm_status|ping)$ { include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; #脚本文件 } php-fpm状态页可以通过带参数实现个性化，可以带参数json、xml、html、full做一个组合。 curl http://127.0.0.1/status?json curl http://127.0.0.1/status?xml curl http://127.0.0.1/status?html curl http://127.0.0.1/status?full php-fpm状态页非常使用，使用zabbix或者nagios监控可以考虑使用xml或者默认方式。用web的话，推荐使用html，表格会比较清晰 七层反向代理 接受Internet上的连接请求,然后将请求转发给内部网络中的上游服务器，并将从上游服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外的表现就是一个Web服务器 允许传送请求到其它服务器，也就是做反向代理 例： 1.反向代理，后端服务器负载均衡 http { .... upstream dynamic { server backend1.example.com weight=5; server backend2.example.com:8080 max_fails=3; fail_timeout=5s ; server 192.0.2.1 max_fails=3; server backup1.example.com:8080 backup; server backup2.example.com:8080 backup; } server { ... location / { proxy_pass http://dynamic; proxy_redirect default; proxy_set_header Host $host; #表明请求的服务器主机名 proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 2; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 5; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 5; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 256k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 128k; #proxy_buffers缓冲区 proxy_busy_buffers_size 256k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 } } } 2.动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来 动静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问 //动态资源 location /bbs/\.(jsp|jspx|do|action)(\/.*)?$ { proxy_set_header real_ip $remote_addr; //real_ip设置变量名，可以通过web端获取 proxy_pass http://172.18.0.2; } //静态资源 location ~ .*\.(js|css|htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ { proxy_pass http://172.18.0.2; expires 30d； 缓存过期时间 } 四层反向代理ginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议的转发、代理或者负载均衡等。 基于ip+port,不会对IP做多余的修改，转发到后端，类似DNAT ngx_stream_core_module(1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 监听的端口； 默认为tcp协议； udp: 监听udp协议的端口； listen 127.0.0.1:12345; listen *:12345; listen 12345; # same as *:12345 listen localhost:12345; ngx_stream_proxy_module1.proxy_pass address; 设置代理服务器的地址。地址可以指定为域名或IP地址，以及端口 proxy_pass localhost：12345 proxy_pass unix：/tmp/stream.socket; proxy_pass $ upstream; 2.proxy_timeout timeout; 默认为10m; 3.proxy_connect_timeout time; 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 示例：http上下文外 stream { upstream sshsrvs { server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; } server { listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; } } 缓存 Nginx对客户已经访问过的内容在Nginx服务器本地建立副本，这样在一段时间内再次访问该数据，就不需要通过Ｎginx服务器再次向后端服务器发出请求，所以能够减少Ｎginx服务器与后端服务器之间的网络流量，减轻网络拥塞，同时还能减小数据传输延迟，提高用户访问速度。 同时，当后端服务器宕机时，Nginx服务器上的副本资源还能够回应相关的用户请求 proxyBuffer开启后才能使用proxy_cachhe。将已有的数据在内存中建立缓存数据，缓存过期不销毁硬盘的数据，nginx接受到被代理服务器的数据后，通过proxybuffer机制将数据传递给客户端，通过proxycache将数据缓存到本地硬盘 定义缓存： proxy_cache_path fastcgi_cache_path 调用缓存 proxy_cache fastcgi_cache proxy_cache例： 1.proxy_cache的最基本的配置 proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off; server { ... add_header Magedu-Cache &quot;$upstream_cache_status form $server_addr&quot;;#给请求响应增加一个头部信息，表示从服务器上返回的cache状态怎么样（有没有命中） upstream web { server backend1.example.com; server backend2.example.com; } } location / { proxy_pass http://web; #引用上面定义的upstream负载均衡组 proxy_cache my_cache; #引用上面定义上的缓存空间，同一缓存空间可以在几个地方使用 proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; #对代码200和302的响应设置10分钟的缓存，对代码404的响应设置为1分钟: } } 2.多磁盘分割缓存 使用NGINX，不需要建立一个RAID（磁盘阵列）。如果有多个硬盘，NGINX可以用来在多个硬盘之间分割缓存。 proxy_cache_path /path/to/hdd1 levels=1:2 keys_zone=my_cache_hdd1:10m max_size=10g inactive=60m use_temp_path=off; proxy_cache_path /path/to/hdd2 levels=1:2 keys_zone=my_cache_hdd2:10m max_size=10g inactive=60m use_temp_path=off; split_clients $request_uri $my_cache { 50% &quot;my_cache_hdd1&quot;; 50% &quot;my_cache_hdd2&quot;; } server { ... location / { proxy_cache $my_cache; proxy_pass http://my_upstream; } } split_clients配置部分指定了请求结果的一半在my_cache_hdd1中缓存，另一半在my_cache_hdd2中缓存。 基于$request_uri（请求URI）变量的哈希值决定了每一个请求使用哪一个缓存，对于指定URI的请求结果通常会被缓存在同一个缓存中。 fastcgi_cache配置fastcgi_cache是一个nginx的插件，用于缓存fastcgi接口的执行结果，例如缓存php的执行结果。特别是php网站的首页与一些非交互页面，利用fastcgi_cache可以大幅度提升访问速度，并且降低php的执行压力 1. 在nginx的主配置文件 在主配置文件(nginx.conf) fastcgi_cache_path /dev/shm/nginx-cache levels=1:2 keys_zone=cgi_wpcache:200m inactive=1d; fastcgi_cache_path:缓存文件的路径，/dev/shm/为tmfs缓存文件系统， 实际储存在内存中，所以读写IO性能更高。 levels:缓存目录的结构层次，例如1:2，缓存文件会就生成在指定目录的再下两层目录中。 keys_zone:缓存域名称，在vhost内进行缓存时需要调用。 inactive:缓存不活动时间，若缓存内容在指定时间内未被访问将会被清理出缓存域。 2. 站点配置 location / { fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME /data/webroot/$fastcgi_script_name; include fastcgi_params; fastcgi_cache cgi_wpcache; fastcgi_cache_methods GET HEAD; fastcgi_cache_key $request_method$host$request_uri; fastcgi_cache_valid 200 2d; fastcgi_ignore_headers Cache-Control Expires Set-Cookie; add_header X-Cache “$upstream_cache_status”; } fastcgi_cache:指定缓存域 fastcgi_cache_methods：指定缓存的请求方式 fastcgi_cache_key：指定缓存文件的标识，这个标识会MD5转码存储在缓存域的目录下 fastcgi_cache_valid：指定缓存状态，例如上文中只缓存响应状态码为200的请求所产生的返回页面两天 fastcgi_ignore_headers：默认情况下fastcgi_cache会忽略有特殊header的请求，并不进行缓存，官网说明。但当我们添加这个参数后，这些限制将不在存在。 add_header 将会在返回请求的response的header中添加一个X-Cache字段表示是否进行了缓存。如果需要也可以在nginx日志中通过log_format添加$upstream_cache_status字段 ·MISS 未命中，请求被传送到后端 ·HIT 缓存命中 ·EXPIRED 缓存已经过期请求被传送到后端 ·UPDATING 正在更新缓存，将使用旧的应答 ·STALE 后端将得到过期的应答 压力测试 ab -n 1000 -c 50 http://172.20.102.61/info.php]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx日志配置]]></title>
    <url>%2F2018%2F12%2Fnginx%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[ngx_http_log_module是用来定义请求日志格式的 日志对于统计排错来说非常有利的 1.access_log指令 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 默认值：access_log logs/access.log combined; 上下文：http,server,location,if in location, limit_except gzip压缩等级 buffer设置内存缓冲区大小 flush保存在缓冲区中的最长时间 不记录日志：access_log off #好像没作用 2.log_format指令 log_format name string ...... 上下文：http name 表示格式名称，string表示定义的格式 log_format combined &apos;$remote_addr - $remote_user [$time_local]&apos; &apos;&quot;$request&quot; $status $body_tytes_sent&apos; &apos; $http_referer &quot;$http_user_agent&quot;&apos; 例： log_format proxy &apos;$http_x_forwarded_for - $remote_user [$time_local]&apos; &apos;&quot;$request&quot; $status $body_bytes_sent&apos; &apos; &quot;$http_referer &quot; &quot; $http_user_agent&quot;&apos;; 3.日志格式允许包含的变量： $remote_addr, 记录客户端IP地址 $http_x_forwarded_for 记录转发代理服务器的ip $remote_user 记录客户端名称 $request 记录请求的URL和HTTP协议 $status 记录请求状态 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 $bytes_sent 发送给客户端的总字节数 $connection 链接的序列号 $connection_requests 当前通过一个链接获得的请求数量 $msec 日志写入时间，单位为秒，精确是毫秒 $pipe 如果请求时通过http流水线发送，pipe值为p，否则为. $http_referer 记录从那个页面链接访问过来的 $http_user_agent 记录客户端浏览器相关信息 $request_length 请求的长度 $request_time 请求处理时间，单位为秒，精确度毫秒 $time_iso8601 标准格式下的本地时间 $time_local 通用日志格式下的本地时间 $upstream_addr 记录分发的后端节点IP $upstream_status 记录后端节点返回的状态码 $upstream_cache_status 记录缓存的命中情况 4.open_log_file_cache指令 open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time] 默认值：open_log_file_cache off; 上下文：http,server,location max：最大文件描述符数量 inactive：存货时间，默认10s min_uses:设置在inactive时间段中，日志文件最少使用多少次，该日志文件描述符记入缓存中，默认1次 valid：设置检查频率，默认60s off：禁用 例： open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2; 5、error_log file [level]; 上下文:main,http,server,location 错误日志文件及其级别；出于调试需要，可设定为debug； 但debug仅在编译时使用了“--with-debug”选项时才有效 方式：file /path/logfile; stderr:发送到标准错误 syslog:server-address[,parameter=values]: 发送到syslog memory:size 内存 level:debug|info|notice|warn|error|crit|alter|emerg 日志级别 6.log_not_found 默认值：log_not_found on; 上下文：http,server,location 是否在error_log中记录不存在的错误，默认on 7.log_subequest指令 log_subrequest on | off; 默认值：log_subrequest off; 上下文：http,server,location 是否在access_log中记录子请求的访问日志，默认off 8. rewrite_log指令 由ngx_http_rewrite_module模块提供的。用来记录重写日志的。对于调试重写规则建议开启。 Nginx重写规则指南 语法: rewrite_log on | off; 默认值: rewrite_log off; 上下文: http, server, location, if 启用时将在error log中记录notice级别的重写日志。 nginx 访问日志切割mv access.log $(date +%F -d &quot;-1day&quot;)_access.log /app/nginx/sbin/nginx -s reload 重新启动就会重新生成access_www.log文件，然后写定时任务。 crontab -l12 */5 * * * * /usr/sbin/ntpdate ntp1.aliyun.com &gt;/dev/null 2&gt;&amp;1 00 00 * * * /bin/sh /server/scripts/cut_log.sh &gt;/dev/null 2&gt;&amp;1 cat cut_log.sh 123cd /app/nginx/logs &amp;&amp;\mv access.log $(date +%F -d "-1day")_access.log/app/nginx/sbin/nginx -s reload Nginx常用日志收集及分析工具有rsyslog、awstats、flume、ELK(Elasticsearch logstash Kibana)、storm等。]]></content>
  </entry>
  <entry>
    <title><![CDATA[lamp]]></title>
    <url>%2F2018%2F12%2Flamp%2F</url>
    <content type="text"><![CDATA[LAMPCGI：Common Gateway Interface 可以让一个客户端，从网页浏览器通过http服务器向执行在网络服务器上的程序传输数据；CGI描述了客户端和服务器程序之间传输的一种标准 请求流程： Client -- (httpd) --&gt; httpd -- (cgi) --&gt; application server (program file) -- (mysql) --&gt; mysql php: 脚本编程语言、嵌入到html中的嵌入式web程序语言基于zend编译成opcode（二进制格式的字节码，重复运行，可省略编译环境） PHP 配置文件：/etc/php.ini, /etc/php.d/*.ini 配置文件在php解释器启动时被读取 对配置文件的修改生效方法 Modules：重启httpd服务 FastCGI：重启php-fpm服务 /etc/php.ini配置文件格式： [foo]：Section Header directive = value 注释符：较新的版本中，已经完全使用;进行注释 #：纯粹的注释信息 ;用于注释可启用的directive php.ini的核心配置选项文档： http://php.net/manual/zh/ini.core.php php.ini配置选项列表： http://php.net/manual/zh/ini.list.php php的加速器 XCache 收录EPEL源 项目地址http://xcache.lighttpd.net/ 使用mysql扩展连接数据库的测试代码 &lt;?php $conn = mysql_connect(‘mysqlserver&apos;,&apos;username&apos;,&apos;password&apos;); if ($conn) echo &quot;OK&quot;; else echo &quot;Failure&quot;; #echo mysql_error(); mysql_close(); ?&gt; Php使用mysqli扩展连接数据库的测试代码 &lt;?php $mysqli=new mysqli(&quot;mysqlserver&quot;,“username&quot;,“password&quot;); if(mysqli_connect_errno()){ echo &quot;Failure&quot;; $mysqli=null; exit; } echo “OK&quot;; $mysqli-&gt;close(); ?&gt; php7以上使用pdo扩展连接数据库的测试代码 &lt;?php $dsn=&apos;mysql:host=mysqlhost;dbname=test&apos;; $username=‘root&apos;; $passwd=‘magedu&apos;; $dbh=new PDO($dsn,$username,$passwd); var_dump($dbh); ?&gt; CentOS 7, lamp (php-fpm)实验环境：主机用于搭建wordpress 主机 系统 ip地址 部署服务 a CentOS 7 192.168.80.10 apache2.4 b CentOS 7 192.168.80.20 php-fpm php-mysql c CentOS 7 192.168.80.30 mariadb 一、主机a上部署apache 1.在主机a上安装httpd服务 yum install httpd -y 2.检查fcgi模块是否加载 httpd -M | grep fcgi cat /etc/httpd/conf.modules.d/00-proxy.conf 3.fastcgi配置 vim /etc/httpd/conf/httpd.conf 加二行 &lt;IfModule mime_module&gt; AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ....... 定位至DirectoryIndex index.html,修改为 &lt;IfModule dir_module&gt; DirectoryIndex index.php index.html &lt;/IfModule&gt; 3.创建虚拟主机配置文件 vim /etc/httpd/conf.d/vhosts.conf &lt;VirtualHost 192.168.80.10:80&gt; DocumentRoot /data/www1/wordpress ServerName www.a.com ProxyRequests off ProxyPassMatch ^/(.*\.php)$ fcgi://192.168.80.20:9000/data/www1/wordpress/$1 &lt;/VirtualHost&gt; &lt;Directory /data/www1/wordpress&gt; Options none AllowOverRide none Require all granted &lt;/Directory&gt; 4.启动httpd服务 systemctl start httpd systemctl enable httpd 二、在主机b上部署 1.安装php-fpm php-mysql php-mbstring yum install php-fpm php-mysql php-mbstring -y 2.修改php-fpm配置文件 vim /etc/php-fpm.d/www.conf listen = 192.168.80.20:9000 listen.allowed_clients = 192.168.80.10 3.创建/var/lib/php/session目录 mkdir -pv /var/lib/php/session #默认/var/lib/php/session目录不存在,所以我们要创建此目录 chown apache:apache /var/lib/php/session #修改属主属组为apache 4.启动php-fpm systemctl start php-fpm systemctl enable php-fpm 三、在主机c上部署mariadb 1.安装mariadb-server yum install mariadb-server -y 2.启动mariadb systemctl start mariadb systemctl enable mariadb 3.对mariadb执行安全环境部署 mysql_secure_installation 4.创建wordpress所需的用户及数据库 mysql -uroot -p MariaDB [(none)]&gt; CREATE DATABASE wpdb; MariaDB [(none)]&gt; USE wpdb MariaDB [wpdb]&gt; GRANT ALL ON wpdb to &apos;wpuser&apos;@&apos;192.168.80.%&apos; IDENTIFIED BY &apos;wpuser&apos;; 四、安装部署应用 因为此次试验是将apache和php-fpm 分开部署的, 用户访问的动态资源请求会直接转到 [192.168.80.20 php-fpm]主机上,因此我们的网站目录也需要部署到192.168.80.20主机上,两主机彼此各有一份 1.在主机a上创建网站目录 mkdir -pv /data/www1/ 2.在主机b上创建网站目录 mkdir -pv /data/www1/ 3.安装wordpress 1).解压wordpress wget https://wordpress.org/latest.tar.gz tar -xf latest.tar.gz 2)将文件复制到网站目录下 cp -a wordpress /data/www1/ 3)修改配置文件 cd /data/www1/wordpress cp wp-config-sample.php wp-config.php vim wp-config.php define(&apos;DB_NAME&apos;, &apos;wpdb&apos;); define(&apos;DB_USER&apos;, &apos;wpuser&apos;); define(&apos;DB_PASSWORD&apos;, &apos;wpuser&apos;); define(&apos;DB_HOST&apos;, &apos;192.168.80.30&apos;); 4.将主机a上/data/www1目录推送至主机b上 scp -rp /data/www1/wordpress root@192.168.80.20:/data/www1 5.连接wordpress 6.在b主机安装xcache [官网]http://xcache.lighttpd.net/wiki/ReleaseArchive rpm包：来自epel源 php-xcache 编译安装 yum -y install php-devel 下载并解压缩xcache-3.2.0.tar.bz2 phpize 生成编译环境 cd xcache-3.2.0 ./configure --enable-xcache --with-php-config=/usr/bin/php-config make &amp;&amp; make install cp xcache.ini /etc/php.d/ systemctl restart httpd.service php-fpm CentOS 7, lamp (php模块) 主机 系统 ip地址 部署服务 a CentOS 7 192.168.80.10 apache php php-mysql c CentOS 7 192.168.80.30 mariadb 1.在主机a上安装httpd服务 yum install httpd php php-mysql 1)建立测试页面 vim /var/www/html/index.php &lt;?php phpinfo(); ?&gt; vim /var/www/html/test.php &lt;?php try { $user=&apos;test&apos;; $pass=&apos;123456&apos;; $dbh = new PDO(&apos;mysql:host=192.168.80.30;dbname=mysql&apos;, $user, $pass); foreach($dbh-&gt;query(&apos;SELECT user,host,password from user&apos;) as $row) { print_r($row); } $dbh = null; } catch (PDOException $e) { print &quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;; die(); } ?&gt; 2)部署phpmyadmin phpMyAdmin 解压缩phpmyadmin 3)在a主机安装phpmyadmin缺少的包，php-mbstring、php-mcrypt 4）拷贝示例文件并编辑 cd /var/www/html/pma cp config.sample.inc.php config.inc.php vim config.inc.php 2.在c主机 yum install mariadb-server 3.测试php的连接 4.授权一个测试用户，并测试mariadb的连接 MariaDB [wpdb]&gt; GRANT select ON *.* to &apos;test&apos;@&apos;192.168.80.%&apos; IDENTIFIED BY &apos;123456&apos;; 5测试phpmyadmin的可用性 centos7上编译安装LAMP 准备编译环境1.新建src目录 mkdir /src 编译apacheyum groupinstall &quot;Development tools&quot; yum install pcre-devel openssl-devel expat-devel gcc -y apr和apr-util是httpd2.4以后的版本所需要的插件 http-2.4aprapr-util 1 准备apache useradd -r -s /sbin/nologin apache 2.编译,在src目录下 cd /src tar xf httpd-2.4.37.tar.bz2 tar xf apr-1.6.5.tar.bz2 tar xf apr-util-1.6.1.tar.bz 将插件放入httpd目录下 mv apr-1.6.5 httpd-2.4.37/srclib/apr mv apr-util-1.6.1 httpd-2.4.37/srclib/apr-util 3.配置 cd httpd-2.4.37/ ./configure \ --prefix=/usr/local/httpd \ --enable-so \ --enable-ssl \ --enable-cgi \ --enable-rewrite \ --with-zlib \ --with-pcre \ --with-included-apr \ --enable-modules=most \ --enable-mpms-shared=all \ --with-mpm=prefork make -j 2 &amp;&amp; make install #-j指定cpu线程数量 4.将httpd服务添加到系统服务 vim /usr/local/httpd/conf/httpd.conf 修改 User apache Group apache cp /usr/local/httpd/bin/apachectl /etc/init.d/httpd vi /etc/init.d/httpd 添加以下两行（注意，“#”不能省略）： #chkconfig: 35 85 21 #运行级别 启动优先级 关闭优先级 #description: Apache server 5. 导出环境变量 echo &apos;PATH=/usr/local/httpd/bin:$PATH&apos; &gt; /etc/profile.d/httpd.sh . /etc/profile.d/httpd.sh 6.加入服务管理，并启动 chkconfig --add httpd service httpd start | systemctl start httpd ss -tnl | grep 80 7.编辑虚拟主机 vim /usr/local/httpd/conf/extra/httpd-vhosts.conf &lt;VirtualHost *:80&gt; DirectoryIndex index.php ServerName wp.test.com DocumentRoot &quot;/usr/local/httpd/htdocs/wp&quot; ErrorLog &quot;logs/wp.test.com-error_log&quot; CustomLog &quot;logs/wp.test.com-access_log&quot; combined ProxyRequests Off ProxyPassMatch ^/(.*\.php(/.*)?)$ unix:/usr/local/php/fpm.sock|fcgi://127.0.0.1:9000/usr/local/httpd/htdocs/wp/ &lt;/VirtualHost&gt; &lt;Directory &apos;/usr/local/httpd/htdocs/wp&apos;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt; 编译php基于php模块方式libxml2-devel bzip2-devel libmcrypt-devel (epel) 1编译，（不同版本） php-5.6 1）.编译安装php-5.6 (与mariadb不在同一主机需安装 mysql-libs mysql-devel) cd php-5.6.37 ./configure --prefix=/usr/local/php --with-mysql --with-openssl --with-mysqli --enable-mbstring --with-png-dir --with-jpeg-dir --with-freetype-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --with-apxs2=/usr/local/httpd/bin/apxs --with-mcrypt --with-config-file-path=/usr/local/php --with-config-file-scan-dir=/usr/local/php.d --with-bz2 make &amp;&amp; make install 2）.编译安装php-7.1.7 ./configure --prefix=/usr/local/php --enable-mysqlnd --with-mysqli=mysqlnd --with-openssl --with-pdo-mysql=mysqlnd --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --with-apxs2=/usr/local/httpd/bin/apxs --with-config-file-path=/usr/local/php --with-config-file-scan-dir=/usr/local/php/php.d --enable-maintainer-zts --disable-fileinfo 注意：php-7.0以上版本使用--enable-mysqlnd --with-mysqli=mysqlnd，原--with-mysql不再支持 make &amp;&amp; make install 2.为php提供配置文件 cp /src/php-7.1.18/php.ini-production /usr/local/php/etc/php.ini 3.编辑apache配置文件httpd.conf，以使apache支持php vim /usr/local/httpd/conf/httpd.conf 1).加二行 &lt;IfModule mime_module&gt; AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps 2). 定位至DirectoryIndex index.html 修改为 &lt;IfModule dir_module&gt; DirectoryIndex index.php index.html &lt;/IfModule&gt; 4. apachectl restart 基于php-fpmPHP源码包 1.安装编译php-fpm必要的安装包 yum install freetype-devel libmcrypt-devel libxml2-devel libpng-devel libjpeg-devel useradd -r -s /sbin/nologin apache 2.解压编译 tar xvf php-7.1.7.tar.bz2 cd php-7.1.7/ ./configure --prefix=/usr/local/php --enable-mysqlnd --with-mysqli=mysqlnd --with-openssl --with-pdo-mysql=mysqlnd --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --enable-fpm --with-config-file-path=/usr/local/php --with-config-file-scan-dir=/usr/local/php/php.d --enable-maintainer-zts --disable-fileinfo 3. make &amp;&amp; make install 4.配置文件 cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf cp /src/php-7.1.18/php.ini-production /usr/local/php/etc/php.ini 5.编辑/usr/local/php/etc/php-fpm.d/www.conf vim /usr/local/php/etc/php-fpm.d/www.conf [www] listen.backlog = 511 listen.owner = apache listen.group = apache listen.mode = 0660 user = apache group = apache listen.allowed_clients = 127.0.0.1,192.168.80.10 listen = 9000 6.复制启动脚本文件至/etc/rc.d/init.d cp /src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm vim /etc/init.d/php-fpm 添加 #！/bin/bash #chkconfig: 35 86 22 #description: php-fpm ..... 7. 编辑apache配置文件httpd.conf，以使apache支持php vim /usr/local/httpd/conf/httpd.conf 取消下面两行的注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 加二行 &lt;IfModule mime_module&gt; AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps 修改下面行 &lt;IfModule dir_module&gt; DirectoryIndex index.php index.html &lt;/IfModule&gt; apachectl restart 7.启动 systemctl start php-fpm mariadb二进制10.2.19 1. 准备用户 groupadd -r -g 306 mysql useradd -r -g 306 -u 306 –s /sbin/nologin mysql 2.解压二进制 3.准备数据目录，建议使用逻辑卷 install -d /data/ll -o mysql -g mysql 4.创建mysql的软链接 ln -sv mariadb-VERSION mysql chown -R root:mysql /usr/local/mysql/ 5. 准备配置文件 cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf vim /ect/my.cnf [mysqld]中添加三个选项： datadir = /data/mysql innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 6.添加环境变量 echo &apos;PATH=/usr/local/mysql/bin/:$PATH&apos;&gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 7.初始化数据库文件 scripts/mysql_install_db --datadir=/data/mysql --user=mysql 8.准备服务脚本，并启动 cp support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start 9.安全初始化 /user/local/mysql/bin/mysql_secure_installation 安装成功信息 [root@server ~]#mysqladmin --version mysqladmin Ver 9.1 Distrib 10.2.19-MariaDB, for Linux on x86_64 拷贝示例文件并编辑部署wordpress (1). 解压缩wordpress （2）拷贝示例文件并编辑 cd wp cp wp-config.sample.php wp-config.php vim wp-config.php (3)在mariadb上面创建wordprss数据库及账户 CREATE DATABASE wordprss CHARACT SET=utf8 COLLATE=utf8_general_ci; grant all on wordpress.* to &apos;wpuer&apos;@&apos;192.168.80.%&apos; identified by &apos;123456&apos;; (4). 测试wordpress的可用]]></content>
  </entry>
  <entry>
    <title><![CDATA[http配置]]></title>
    <url>%2F2018%2F12%2Fhttp%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[httpd简介httpd是apache基金会（ASF：apache foundation）维护，其官网为httpd.apache.org,其基金会下有众多的著名软件。 ！ http的版本 httpd 2.2 (Centos 6平台的默认版本，其event模型仍为测试模型) httpd 2.4(Centos 7平台的默认版本，目前最新稳定版本，对event可用于生产环境中) 特性： 高度模块化：core + modules DSO: Dynamic Shared Object 动态加/卸载 MPM：multi-processing module多路处理模块 HTTP的MPM工作模型1. prefork：多进程I/O模型， 每个进程响应一个请求，一个主进程，用来生成和回收n个子进程，创建套接字，不响应请求，多个子进程，在服务启动时，预先生成多个空闲进程，等待请求，但最多不能超过1024个 pefork的配置： StartServers 8：启动时最多启动多少个进程 MinSpareServers 5：最小空闲进程 MaxSpareServers 20：最大空闲进程 ServerLimit 256：服务器最多生成多少个个进程，最大为20000 MaxRequestsPerChild 4000：每个子进程最多响应多少个请求 2. worker：复用多进程I/O模型， 一个主进程生成m个子进程，每个进程生成n个线程，每个线程响应一个请求，可并发响应m*n个请求 缺点是当一个线程受影响时，该子进程的所有线程都会受到影响 worker的配置 StartServers 4：启动时启动多个子进程 MaxClinets 300：最多启动多少个线程 MinSpareThreads 25：最小空闲线程 MaxSpareThreads 75：最大空闲线程 ThreadsPerChild 25：每个进程最多可以启动多少个线程 MaxRequestsPerChild 0：每个线程最多可以响应多少个请求，0表示不做限制 3. event：事件驱动模型， 一个主进程生成m个子进程，每个进程直接响应n个请求，且有专门负责管理keepalive类型的线程，当有真是请求到达时，将请求传递给服务线程，执行完毕后，又允许释放 httpd的功能特性httpd的常见特性： 1、CGI（Common Gateway Interface） 2、虚拟主机 3、支持反向代理 4、负载均衡 5、路径别名 6、丰富的用户认证机制 7、支持第三方模块 18.支持https协议，由mod_ssl模块提供 Httpd2.4新特性 MPM支持运行为DSO机制；以模块形式按需加载 在centos7上的httpd2.4上只有一个二进制程序 /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可 但是在centos6上的httpd2.2版本： 每个MPM模式都有各自对应的二进制程序 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker 如果更改MPM的模式，是需要改对应的二进制程序的 event MPM生产环境可用 异步读写机制 支持每模块及每目录的单独日志级别定义 每请求相关的专用配置 增强版的表达式分析式 毫秒级持久连接时长定义：httpd2.2只能精确到秒级别 上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的，所以在http中是可以定义连接时长(时长和传输请求两种方式)的 基于FQDN的虚拟主机不需要NameVirutalHost指令 httpd2.2创建虚拟主机时还需要NameVirutalHost指令 httpd2.4就不需要了 新指令，AllowOverrideList 支持用户自定义变量 更低的内存消耗 httpd配置文件配置文件： /etc/httpd/httpd.conf /etc/sysconfig/httpd 配置文件路径： /etc/httpd/conf.d/*.conf /etc/httpd/conf.modules.d/00-mpm.conf(修改httpd MPM的工作模式配置文件) 动态模块的路径： /etc/httpd/modules /usr/lib64/httpd/modules 检查配置语法： httpd –t 主程序文件： /usr/sbin/httpd 主进程文件： /etc/httpd/run/httpd.pid 日志文件目录： /var/log/httpd access_log: 访问日志 error_log：错误日志 帮助文档包： httpd-manual Httpd常见配置常见配置一般都在/etc/httpd/conf/httpd.conf的文件中，没有的配置选项可以加在httpd.conf文件最后，也可以放在/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf [http2.4官网文档]http://httpd.apache.org/docs/2.4/ 1.显示服务器版本信息 ServerTokens Prod[：Server: Apache ServerTokens Major: Server: Apache/2 ServerTokens Minor: Server: Apache/2.0 ServerTokens Min: Server: Apache/2.0.41 ServerTokens OS: Server: Apache/2.0.41 (Unix) ServerTokens Full : Server: Apache/2.0.41 (Unix) 打开f12调试模式，可以看到回应头的信息中带有apache的版本信息 也可以通过curl -I http://ip来显示头信息 建议使用：ServerTokens Prod 2.修改监听的IP和Port Listen [IP:]PORT (1) 省略IP表示为本机所有IP (2) Listen监听端口至少一个，可以有多个端口 (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口 3.持久连接：默认KeepAlive是开启的 TCP连接建立后，每个资源获取完成后，不会断开连接，而是继续等待其它资源请求的进行，默认关闭持久连接 断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4 支持毫秒级 副作用：对并发访问量大的服务器，持久连接会使有些请求得不到响应折衷：使用较短的持久连接时间 设置： KeepAlive On|Off KeepAliveTimeout 15 测试：telnet WEB_SERVER_IP PORT GET /URL HTTP/1.1 Host: WEB_SERVER_IP 4.MPM（ Multi-Processing Module）多路处理模块： prefork,worker,event 默认是prefork，因为后续的很多模块都依赖于prefork模块的 查看静态编译的模块 httpd -l 查看当前系统中httpd的静态编译及动态装载的加载的模块 httpd –M 动态模块加载：不需重启即生效 动态模块路径 /usr/lib64/httpd/modules/ 切换使用的MPM模块 /etc/httpd/conf.modules.d/00-mpm.conf 选择要启用的MPM相关的LoadModule指令即可 prefork的配置： StartServers 8 MinSpareServers 5 保留5个空闲子进程处理新的请求 MaxSpareServers 20 允许的最大空闲进程数 ServerLimit 256 最多进程数,最大20000，并发量建议最多10000 MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理 MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进程占用的内存就会释放(为0时永远不释放） worker和prefork配置类似，只不过会有线程数量的限制 5.DSO： Dynamic Shared Object 加载动态模块配置 /etc/httpd/conf/httpd.conf Include conf.modules.d/*.conf 配置指定实现模块加载格式： LoadModule &lt;mod_name&gt; &lt;mod_path&gt; 模块文件路径可使用相对路径： 相对于ServerRoot（默认/etc/httpd） 示例： LoadModule auth_basic_module modules/mod_auth_basic.so 6.定义’Main’ server的文档页面路径：存放页面的主目录 主目录是由DocumentRoot指令来设置的 网页文件默认是存在/var/www/html/下的，此处可以自定义 在/etc/httpd/conf/httpd.conf中 DocumentRoot默认网站的根目录的路径，默认值为/var/www/html，更改路径目录后，httpd2.4版本默认拒绝修改后的路径的访问，可使用以下字段开启访问 &lt;Directory &quot;PATH&quot;&gt; AllowOverride None Require all granted Options None &lt;/Directory&gt; DirectoryIndex，网站默认主页的名称，默认值为index.html ServerSignature On|Off|Email：默认访问不存在页面，产生错误文档，会暴露服务器的版本号等，默认为Off 注意：SELinux和iptables的状态 httpd访问控制（1）&lt;Directory&gt;中“基于源地址”实现访问控制 Options {None|FollowSymlinks|Indexes|All} 在选项前的+，- 表示增加或删除指定选项 Indexes：默认URL下不存在主页文件时，就会将该网站的文件列表显示出来，通常下载网站使用该选项 注意：存放页面的主目录下没有index.html文件，但是此时即使加上options Indexes选项，页面也不会列出主目录下的所有文件，需把welcome.html文件改名或删除 FollowSymlinks：显示该网站的软链接指向的路径 None：全部禁用 All：全部允许 AllowOverride {None|All}，该指令只在&lt;Directory&gt;中有效，与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName指定）文件中，覆盖之前的配置 All：.htaccess文有效 None：.htaccess中所有指令都无效 示例： &lt;directory &quot;/data/www&quot;&gt; AllowOverride None options Indexes FollowSymLinks Require all granted &lt;/directory&gt; (2).基于IP的访问控制 Reqired all granted，允许所有IP的访问 Require all denied ,拒绝所有主机访问 默认需在&lt;RequireAll&gt;&lt;/RequireAll&gt; &lt;RequireAll&gt; Required all granted Required ip IPADDR 授权指定来源的IP访问 Require not ip IPADDR 拒绝特定的IP访问 &lt;/RequireAll&gt; 控制特定的主机访问： &lt;RequireAll&gt; Require host HOSTNAME：授权特定主机访问 Require not host HOSTNAME：拒绝 &lt;/RequireAll&gt; 不能有失败，至少有一个成功匹配才成功，即失败优先 &lt;RequireAll&gt; Require all granted Require not ip 172.16.1.1 拒绝特定IP &lt;/RequireAll&gt; 多个语句有一个成功，则成功，即成功优先 &lt;RequireAny&gt; Require all denied require ip 172.16.1.1 允许特定IP &lt;/RequireAny&gt; 示例： 拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表 &lt;directory /data/www&gt; options indexes &lt;RequireAll&gt; Require all granted Require not ip 192.168.34.107 &lt;/RequireAll&gt; &lt;/directory&gt; 查看http运行状态 &lt;Location /server-status&gt; AllowOverride None SetHandler server-status require local &lt;/location&gt; (3).基于用户的访问控制 basic：明文 1. 生成明文验证的虚拟账号 htpasswd -c /PATH/FILE USER -c：创建文件，第一次创建时账号时使用 -s：sha加密算法 -D：删除指定用户 -p 明文密码 -d CRYPT格式加密，默认 -m md5格式加密 2. 修改配置 &lt;Directory &quot;PATH&quot;&gt; Options None AllowOverride None AuthName &quot;STRING&quot; AutyType Basic AuthUserFile &quot;PATH/USER_FILE&quot; AuthGroupFile &quot;Path/GROUP_FILE&quot;：基于组的验证 Require user USER...| Require valid-user Require group GROUP：基于组的验证 &lt;/Diectory&gt; digets：消息摘要 日志设定format官方说明文档http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats 日志类型：访问日志(access_log)和错误日志(error_log) 日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式 /etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义 LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined --&gt;由Logformat指令定义完起一个combined名 CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式 ErrorLog &quot;logs/error_log&quot; 定义的格式各个项说明 %h 客户端IP地址 %l 远程用户,启用mod_ident才有效，通常为减号“-” %u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-” %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”， “URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页 是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源， 所以网站要加防盗链 %{User-Agent}i 请求报文中首部“User-Agent”的值；即发出请求的应用程序 httpd实现用户家目录共享1.查看是否启用了user_dir.so模块 /etc/httpd/conf.modules.d/00-base.conf 2.配置 vim /etc/httd/conf.d/userdir.conf &lt;IfModule mod_userdir&gt; #UserDir diabled UserDir public_html &lt;IfMoudle&gt; &lt;Directory &quot;/home/USER/public_html&quot;&gt; AuthType Basic AuthUserFile=&quot;/etc/httd/conf/httpasswd&quot; Require user USER &lt;/Directory&gt; 3.创建目录 cd ~user mkdir public_html echo test &gt; public_html/index.html setfacl -m u:apache:x /home/用户家目录 4. 使用http://IP:PORT/~USER/index.html httpd status页面是否加载了mod_status.so &lt;Location &quot;/status&quot;&gt; AutType Basic AuthUserFile &quot;/etc/httpd/conf/httpasswd&quot; AuthName &quot;http status&quot; Require user USER SetHandler server-status &lt;/Location&gt; httpd别名Alias /URL/ &quot;/PATH&quot; 示例： Alias /data/ /data/web，当访问/test资源时，实际上对应磁盘上的/data/web目录下的资源 httpd虚拟主机建立配置基于IP的配置文件 /etc/httpd/conf.d/vhosts.conf &lt;VirtualHost 172.16.100.6:80&gt; DocumentRoot &quot;/www/a.com/htdocs&quot; &lt;/VirtualHost&gt; &lt;VirtualHost 172.16.100.7:80&gt; DocumentRoot &quot;/www/b.net/htdocs&quot; &lt;/VirtualHost&gt; 基于端口的虚拟主机： 可和基于IP的虚拟主机混和使用 /etc/httpd/conf.d/vhosts.conf listen 808 listen 8080 &lt;VirtualHost 172.16.100.6:80&gt; DocumentRoot &quot;/www/a.com/htdocs&quot; &lt;/VirtualHost&gt; &lt;VirtualHost 172.16.100.6:808&gt; DocumentRoot &quot;/www/b.net/htdocs&quot; &lt;/VirtualHost&gt; 基于FQDN虚拟主机 基于FQDN的虚拟主机不再需要NameVirutalHost指令 &lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot &quot;/apps/b.net/htdocs&quot; &lt;/VirtualHost&gt; httpd的模块mod_deflate，压缩页面优化传输速度，但只压缩适合压缩的资源如文本文件等 1. 启用模块mod_delate.so 2. 添加如下内容 AddOutputFilterByType DEFLATE text/plain AddOutputFilterByType DEFLATE text/html AddOutputFilterByType DEFLATE text/xml mod_ssl，加密httpd ssl会话简单流程： 1. 客户端发送一个加密方式，并向服务器请求证书 2. 服务器发送证书，并以该选定的加密方式给客户端 3. 客户端取得证书并验证该证书 1. 验证证书的来源合法性 2. 验证证书的完整性 3. 检查证书的有效期限 4. 检查证书是否在吊销列表中 5. 证书拥有者的名字，是否与访问的目标一致 4. 如果以上验证一致，则客户端生成临时会话密钥，并使用服务器的公钥加密此数据发送个服务器完成密钥交换 5. 服务器用此密钥加密用户请求资源，响应客户端的请求 注意：SSL是基于IP地址实现,单IP的主机仅可以使用一个https虚拟主机 使用yum install mod_ssl安装 (1) 为服务器申请数字证书 示例：通过私建CA发证书 (a) 创建私有CA (b) 在服务器创建证书签署请求 (c) CA签证 配置文件在/etc/httpd/conf.d/ssl.conf配置如下字段 SSLCertificateFile PATH/FILE.crt SSLCertificateKeyFile PATH/FILE.key SSLCACertificateFile PATH/CA_FILE.crt SSLCertificateChianFile PATH/CA_CHAIN.crt httpd重定向Redirect [status] old-url new-url 1. 临时重定向，Temp，返回状态码302 2. 永久重定向，Permanent，返回状态码301 示例： Redirect temp / https://www.magedu.com/ HSTS HSTS:HTTP Strict Transport Security 服务器端配置支持HSTS后，会在给浏览器返回的HTTP首部中携带HSTS字段。浏览器获取到该信息后，会将所有HTTP访问请求在内部做307跳转到HTTPS。 而无需任何网络过程 HSTS preload list 是Chrome浏览器中的HSTS预载入列表，在该列表中的网站，使用Chrome浏览器访问时，会自动转换成HTTPS。Firefox、Safari、Edge浏览器也会采用这 个列表 实现HSTS示例： vim /etc/httpd/conf/httpd.conf Header always set Strict-Transport-Security &quot;max-age=31536000&quot; RewriteEngine on RewriteRule ^(/.*)$ https://%{HTTP_HOST}$1 [redirect=302] httpd代理 正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见； 反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见,如负载均衡等功能 启用反向代理 ProxyPass &quot;/&quot; &quot;http://www.example.com/&quot; ProxyPassReverse &quot;/&quot; &quot;http://www.example.com/&quot; 特定URL反向代理 ProxyPass &quot;/images&quot; &quot;http://www.example.com/&quot; ProxyPassReverse &quot;/images&quot; http://www.example.com/ 示例： &lt;VirtualHost *&gt; ServerName www.magedu.com ProxyPass / http://localhost:8080/ ProxyPassReverse / http://localhost:8080/ &lt;/VirtualHost&gt; sendfile机制：提高网络传输的速度1.在不使用sendfile机制，网络应用先通过读硬盘里的数据至kernel buffer中，期间需要从user mode切换至kernel mode 2.之后又需要将此数据从kernel buffer拷贝至user buffer中，期间必不可少需要从kernel mode切换至user mode， 3.然后将user buffer的数据拷贝至kernel socket buffer，此时也必须从user mode切换至kernel mode， 4.从kernel socket buffer拷贝此数据协议栈，此时也必须从kernel mode切换至user mode。完成网络传输。 因此sendfile机制就是用来简化上述步骤中4次模式切换和4次拷贝。 在使用sendfile机制时，网络应用调用该机制将数据拷贝至kernel buffer 2.然后该数据被直接拷贝至另外一个与socket相关的kernel buffer中， 3.直接将该数据从kernel socket buffer直接拷贝给协议栈，完成网络传输，此间不需要模式的切换，因为数据始终在kernel中 curl是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在&quot;标准输出&quot;（stdout）上面 curl [option] [url] -A 指定用户代理 -I 只显示头部信息 -i 显示页面内容，包括报文头部 -L 如有3XX响应码，重新发请求至新位置 -e/--referer 来源网址 -D/--dump-header &lt;file&gt; 把header信息写入到该文件中 -o &lt;file&gt; 将网路文件保存为指定文件中 --cacert &lt;file&gt; 指定CA证书 -H &lt;line&gt; 自定义首部信息传递给服务器 --basic 使用HTTP基本认证 --limit-rate &lt;rate&gt; 设置传输速度 -f/--fail 连接失败时不显示http错误 -T/--upload-file &lt;file&gt; 上传文件 -u/--user &lt;user[:password]&gt; 设置服务器的用户和密码 -O 使用URL中默认的文件名保存文件到本地 -s/--silent 静音模式。不输出任何东西 -C 选项可对文件使用断点续传功能 -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中 -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址 -X/--request GET|POST 向服务器发送指定请求方法 -#/--progress-bar 进度条显示当前的传送状态 -v 显示一次http通信的整个过程，包括端口连接和http request头信息。 --trace-ascii file 保存一次通信过程到文件 例： 查看网页源码 curl www.sina.com 自动跳转 curl -L www.sina.com 显示头信息 curl -I www.sina.com 显示一次http通信的整个过程， curl -v www.sina.com curl --trace-ascii output.txt www.sina.com 更详细 发送表单信息 GET curl example.com/form.cgi?data=xxx POST curl -X POST --data &quot;data=xxx&quot; example.com/form.cgi Referer字段 ,表示从哪里跳转过来。 curl -e http://www.example.com http://www.example.com 模拟User Agent ，设备信息，服务器会根据字段，针对不同设备，返回不同格式的网页 curl --user-agent &quot;[User Agent]&quot; [URL] HTTP认证 curl -u name:password example.com httpd自带的工具程序httpd自带的工具程序 htpasswd：basic认证基于文件实现时，用到的账号密码文件生成工具 apachectl：httpd自带的服务控制脚本，支持start和stop rotatelogs：日志滚动工具 access.log --&gt; access.log, access.1.log --&gt; access.log, acccess.1.log, access.2.log httpd的压力测试工具ab, webbench, http_load, seige Jmeter 开源 Loadrunner 商业，有相关认证 tcpcopy：网易，复制生产环境中的真实请求，并将之保存 ab [OPTIONS] URL 来自httpd-tools包 -n：总请求数 -c：模拟的并行数 -k：以持久连接模式测试 ulimit –n # 调整能打开的文件数]]></content>
  </entry>
  <entry>
    <title><![CDATA[http协议]]></title>
    <url>%2F2018%2F12%2Fhttp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[HTTP协议HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传送协议。 HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。http是无状态的。 使用html（Hyper text mark language）编程语言编写，被称为文本标记语言 1234567891011&lt;html&gt; &lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;/h1&gt; &lt;h2&gt;&lt;/h2&gt; &lt;p&gt;正文&lt;a href="www.magedu.com/download.html"&gt;正文&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;&lt;/h2&gt; &lt;/body&gt;&lt;/html&gt; http协议版本http0.9、http1.0、http1.1和http2.0的版本区别 http 0.9 : 功能简陋，只有一个GET命令，只能支持html http 1.0 1.支持cache, MIME(支持各种资源类型), method 2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低 3.引入了POST命令和HEAD命令，头部信息和 4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用 http 1.1 ：是目前被广泛使用的标准 1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性 2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个 请求，进一步改进了HTTP协议的效率 3.新增方法：PUT、PATCH、OPTIONS、DELETE 缺点 4.同一个TCP连接里，所有的数据通信是按次序进行的。服务器只能顺序处理回应，前面的回应慢，会有许多请求排队，造成&quot;队头堵塞&quot;（Head-of-line blocking） 为避免上述问题，两种方法： 一是减少请求数，二是同时多开持久连接。 网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等 5.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的， 浪费带宽，影响速度 http/2.0 ：解决 HTTP/1.1 效率不高问题 1.头信息和数据体都是二进制，称为头信息帧和数据帧 2.和http1.1区别：请求不需要排队，提高效率 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing） 3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度 4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息) Cookie的追踪用户的原理 http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点 第一次方访问服务时,服务器发送一个cookie的小数据(随机数,用来标识客户端身份),客户端会将其保存下来,随后 , 访问同一个站点时,会把应用于此站点的cookie提交给服务器,从而服务器就能识别客户端身份。 胖Cookie的实现原理 将用户会话及状态信息都保存至客户端本地,在请求数据时,将状态信息回传至服务器 瘦cookie + session的实现原理 将用户的状态信息都保存至服务器端,并与相应客户端的cookie令牌相对应,请求数据的时候,只是需向告诉服务器自己的cookie信息. HTTP工作机制工作机制： http请求：http request http响应：http response 一次http事务：请求&lt;--&gt;响应 Web资源：web resource 1.一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源的集合 2.静态文件：无需服务端做出额外处理; 服务器端是什么样传到客户端就是什么样，比如下面这些 比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi 只不过浏览器有时会解析出来以好看的页面展示给用户 3.动态文件：服务端执行程序，返回执行的结果 服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果 文件后缀：.php, .jsp ,.asp,.sh等 将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户 提高HTTP连接性能 并行连接：通过开多个TCP连接发起并发的HTTP请求 持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接 管道化连接：通过共享TCP连接发起并发的HTTP请求 复用的连接：交替传送请求和响应报文（实验阶段） URLURI: Uniform Resource Identifier 统一资源标识，分为URL和URN 一般把URI认为是URL URN: Uniform Resource Naming，统一资源命名 不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名 示例： P2P下载使用的磁力链接是URN的一种实现, magnet:?xt=urn:btih:66034d7A6890EF8 URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 示例 www.baidu.com 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成 &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等 user:用户，某些方案访问资源时需要的用户名 password:密码，用户对应的密码，中间用：分隔 Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析 port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080 /path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔 params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对 query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能 frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 URL示例 http://www.magedu.com:8080/images/logo.jpg ftp://mage:password@172.16.0.1/pub/linux.ppt rtsp://videoserver/video_demo/ Real Time Streaming Protocol 网站访问量1.IP(独立IP)：即Internet Protocol,指独立IP数 一个局域网内通过一个公网IP出去，则局域网内IP数只算一个 2.PV(访问量)： 即Page View, 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是页面的来访者数量，而是网站被访问的页面数量 3.UV(独立访客)：即Unique Visitor, 访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。网站判断来访电脑的身份是通过来访电脑的cookies实现的。如果更换了IP后但不清除 cookies，再访问相同网站，该网站的统计中UV数是不变的 网站统计http://www.alexa.cn/rank/ 一次完整的http请求处理过程 1、建立连接：接收或拒绝连接请求 2、接收请求：接收客户端请求报文中对某资源的一次请求的过程 Web访问响应模型（Web I/O） 单进程I/O模型：访问量不大 启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应 会造成请求排队现象，只适用于访问并发不大的情况 多进程I/O模型： 系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求 如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点 而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的 复用I/O结构： 开启多个进程进程，而一个进程又同时监控N个连接请求 只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗 实现方法：多线程模型和事件驱动 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 事件驱动：一个进程处理N个请求 复用的多进程I/O模型： 启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求 充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求 1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程 2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应 避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费 同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题 3、处理请求：对请求报文进行解析，并获取请求的资源及请求发放等相关信息 元数据：请求报文首部 &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt; HEADERS格式name:value &lt;request body&gt; 示例： Host: www.chuyuni.cn 请求的主机名称 Server: Apache/2.4.7 HTTP常用请求方式,method(请求的方法） GET：从服务器获取一个资源 HEAD:只从服务器获取文档的响应首部 POST：向服务器发送要处理的数据 PUT：将请求主体部分存储在服务器上，向服务器上传文件 DELETE：请求删除服务器上指定的文档 TRACE：追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 4. 访问资源 获取请求报文中的请求资源 web服务器，存放了web资源的服务器，负责向请求者提供对方请求的静态资源或者动态资源，这些资源放置于本地文件系统某路径下 web服务器资源路径映射方式 1. documentroot 2. alias 3. 虚拟主机documentroot 4. 用户家目录documentroot 5.构建响应报文： 一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体 1）响应实体 描述了响应主体MIME类型的Content-Type首部 描述了响应主体长度的Content-Length 2）URL重定向 web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径 3）MIME类型 多媒体的邮件扩展 当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文 将构建完的响应报文发送给用户 将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户 用户再层层解封装获得index.html的内容 7.记录日志 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务 通过在/var/log/httpd/acess_log日志中记录http的响应记录数 方便分析排错使用,日志统计该网站的IP，PV量等信息 http事务：请求：request 响应：response 报文语法格式： request报文 &lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;CRLF&gt; &lt;headers&gt;&lt;CRLF&gt; &lt;entity-body&gt;&lt;CRLF&gt; repsonse报文 &lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;CRLF&gt; &lt;headers&gt;&lt;CRLF&gt; &lt;entity-body&gt;&lt;CRLF&gt; method：请求方法，标明客户端希望服务器对资源执行的动作 GET、HEAD、POST version HTTP/&lt;major&gt;.&lt;minor&gt; status: 三位数字，如200，301，302，404，502；标记请求处理过程中发生的情况 reason-phrase： 状态码所标记的状态的用户可理解的简要描述 headers: 每个请求或响应报文可包含任意个首部，每个首部都有首部名称，后面跟一个冒号，而后跟上一个可选空格，接着是一个值 entity-body：请求时附加的数据或响应时附加数据 常用状态码：status： 1xx：100-101，信息提示 2xx：200-206，成功 3xx：300-305，重定向 4xx：400-415，错误类信息，客户端错误 5xx：500-505，错误类信息，服务器端错误 200：成功，请求的所有数据通过响应报文的entity-body部分发送：OK 301：请求的URL指向的资源已经被删除，但在响应报文中通过首部Location指明了资源现在所处的新位置，Moved Permanently 302：与301相似，但在响应报文中通过Location指明资源现在所处的临时新位置，Found 304：客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端，Not Modified 401：需要输入账号和密码认证方能访问资源，Unauthorized 403：请求被禁止，Forbidden 404：服务器无法找到客户端请求的资源，Not found 500：服务器内部错误，Internal Server Error 502：代理服务器从后端服务器收到一条伪响应，Bad Gateway 常见错误： nginx 反向代理报400错误与Host关系 如果后端真是的服务器设置有类似防盗链或者根据http请求头中的host字段来进行路由或判断功能的话，如果反向代理层的nginx不重写请求头中的host字段，将会导致请求失败，报400错误 解决办法： location中设置 proxy_set_header Host $http_host; 将头信息返回服务器 首部的分类：1. 通用首部 Date：报文的创建时间 Connection：连接状态，如keep-alive，close Via：显示报文经过的中间节点 Cache-Control：控制缓存 2. 请求首部 Accept：通知服务器自己可接受的媒体类型 Accept-Charset：客户端可接受的字符集 Accept-Encoding：接受编码格式，如gzip Accept-Language：接受的语言 Client-IP 请求的客户端I Host：请求的服务器名称和端口号 Referer：包含当前正在请求的资源的上一级资源 User-Agent：客户端代理 条件式请求首部： Expect：允许客户端列出某请求所要求的服务器行为 IF-Modified-Since：自从指定的时间之后，请求的资源十分发生过修改 If-Unmodified-Since If-None-Match：本地缓存中存储中文档的ETag标签是否与服务器文档的Etag不匹配 If-Match:与上面相反 安全请求首部： Authorization：向服务器发送认证信息，如账号密码 Cookie：客户端向服务器发送cookie Cookie2： 代理请求首部： Proxy-Authorization：向代理服务器认证 3. 响应首部 信息性 Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多重表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其它首部列表 安全响应首部： Set-Cookie：向客户端设置cookie Set-Cookie2： WWW-Autheticate：来自服务器对客户端的质询认证表单 4. 实体首部 Allow：列出对此实体可使用的请求方法 Location：告诉客户端真正的实体位于何处 Content-Encoding:对主体执行的编码 Content-Language:理解主体时最适合的语言 Content-Length：主体的长度 Content-Location：实体真正所处位置 Content-Type：主体的对象类型 缓存相关： ETag：实体的扩张标签 Expire：实体的过期时间 Last-Modified：最后一次修改时间 5. 扩展首部 协议查看或分析的工具：tcpdump, wireshark,tshark]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql复制加密、读写分离]]></title>
    <url>%2F2018%2F12%2Fmysql%E5%A4%8D%E5%88%B6%E5%8A%A0%E5%AF%86%E3%80%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[复制加密基于SSL的加密 在默认的主从复制过程或远程连接到MySQL/MariaDB所有的链接通信中的数据都是明文的，外网里访问数据或则复制，存在安全隐患。通过SSL/TLS加密的方式进行复制的方法，来进一步提高数据的安全性 [参考]https://mariadb.com/kb/en/library/replication-with-secureconnections/ 实现过程： 主服务器开启SSL：[mysqld] 加一行ssl 主服务器配置证书和私钥；并且创建一个要求必须使用SSL连接的复制账号 从服务器使用CHANGER MASTER TO 命令时指明ssl相关选项 1. 生成加密证书 生成私钥 (umask 066;openssl genrsa 2048 &gt; cakey.pem) 生成ca证书 openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 生成私钥并生成证书 openssl req -newkey rsa:2048 -days 365 -nodes -keyout master.key &gt; master.csr openssl req -newkey rsa:2048 -days 365 -nodes -keyout slave.key &gt; slave.csr openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 &gt; master.crt openssl x509 -req -in slave.csr -CA cacert.pem -CAkey cakey.pem -set_serial 02 &gt; slave.crt openssl x509 -in master.crt -noout -text 2. 在主服务器添加如下字段 [mysqld] log_bin server_id=1 ssl ssl_ca=/etc/my.cnf.d/ssl/cacert.pem ssl_cert=/etc/my.cnf.d/ssl/master.crt ssl_key=/etc/my.cnf.d/ssl/master.key 3. 在主服务器授权一个支持SSL的用户 GRANT REPLCATION SLAVE ON *.* TO &apos;USER&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;PASSWORD&apos; REQUIRE SSL; 4. 从服务器启动复制进程 mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;192.168.80.3&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;centos&apos;, MASTER_LOG_FILE=&apos;mariadb-bin.000001&apos;, MASTER_LOG_POS=245, MASTER_PORT=3306, MASTER_SSL=1, MASTER_SSL_CA = &apos;/etc/my.cnf.d/ssl/cacert.pem&apos;, MASTER_SSL_CERT = &apos;/etc/my.cnf.d/ssl/slave.crt&apos;, MASTER_SSL_KEY = &apos;/etc/my.cnf.d/ssl/slave.key&apos;; 可以将其写在配置文件 复制的监控和维护(1) 清理日志 PURGE { BINARY | MASTER } LOGS { TO &apos;log_name&apos; | BEFORE datetime_expr } RESET MASTER RESET SLAVE 例： purge master logs to &apos;mariadb-bin.000006&apos; 删除6之前的日志 (2) 复制监控 SHOW MASTER STATUS SHOW BINLOG EVENTS SHOW BINARY LOGS SHOW SLAVE STATUS SHOW PROCESSLIST (3) 从服务器是否落后于主服务 Seconds_Behind_Master: 0 (4) 如何确定主从节点数据是否一致 percona-tools (5) 数据不一致如何修复 删除从数据库，重新复制 MySQL读写分离mysql-proxy:OracleAtlas：Qihoodbproxy：美团Cetus：网易乐AmoebaCobar：阿里巴巴，Amoeba的升级版 Mycat：基于CobarProxySQL ProxySQL： MySQL中间件，两个版本：官方版和percona版，percona版是基于官方版基础上修改，C++语言开发，轻量级但性能优异(支持处理千亿级数 据)，具有中间件所需的绝大多数功能，包括： 多种方式的的读/写分离 定制基于用户、基于schema、基于语句的规则对SQL语句进行路由 缓存查询结果 后端节点监控 官方手册官方站点 ProxySQL： 主配置文件：/etc/proxysql.cnf 服务脚本：/etc/init.d/proxysql 主程序：/usr/bin/proxysql 默认监听 6032/tcp(ProxySQL的管理端口) 6033/tcp(ProxySQL对外提供服务的端口) 1. 安装配置 基于YUM仓库安装 cat &lt;&lt;EOF | tee /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl=http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key EOF 使用yum install proxysql安装 基于RPM下载安装 https://github.com/sysown/proxysql/releases 2.准备：实现读写分离前，先实现主从复制 注意：slave节点需要设置read_only=ON 3.启动ProxySQL： service proxysql start 3. 使用mysql客户端连接proxysql的6032端口，默认的管理员密码是admin mysql -uadmin -padmin -P6032 -h127.0.0.1 4. 向proxysql添加MySQL节点，以下操作不需要use main也可成功 mysql&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port)VALUES(10,&apos;192.168.80.20&apos;,3306); mysql&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port)VALUES(10,&apos;192.168.80.30&apos;,3306); mysql&gt; load mysql servers to runtime; mysql&gt; save mysql servers to disk; 5.添加监控后端节点的用户。ProxySQL通过每个节点的read_only值来自动调整它们是属于读组还是写组 在主节点授权一个用户 mysql&gt; GRANT REPLICATION CLIENT ON *.* TO &apos;monitor&apos;@&apos;192.168.80.%&apos; IDENTIFIED BY &apos;monitor&apos;; 6. 在proxysql节点上配置监控，并加载保存至磁盘 mysql&gt; set mysql-monitor_username=&apos;monitor&apos;; mysql&gt; set mysql-monitor_password=&apos;monitor&apos;; mysql&gt; load mysql variables to runtime; mysql&gt; save mysql variables to disk; 7.在proxysql节点上配置分组信息 需要修改的是main库中的mysql_replication_hostgroups表 该表有3个字段： writer_hostgroup，reader_hostgroup，comment,指定写组的id为10，读组的id为20 mysql&gt; insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); mysql&gt; load admin variables to runtime; mysql&gt; save admin variables to disk; 8.查看状态 Monitor模块监控后端的read_only值，按照read_only的值将节点自动移动到读/写组 SELECT hostgroup_id,hostname,port,status,weight FROM mysql_servers; | hostgroup_id | hostname | port | status | weight || 10 | 192.168.80.20 | 3306 | ONLINE | 1 || 20 | 192.168.80.30| 3306 | ONLINE | 1 | 监控模块的指标保存在monitor库的log表中 查看监控连接是否正常的 (对connect指标的监控)：(如果connect_error的结果 为NULL则表示正常) mysql&gt; select * from mysql_server_connect_log; 查看监控心跳信息 (对ping指标的监控)： mysql&gt; select * from mysql_server_ping_log; 查看read_only和replication_lag的监控日志 mysql&gt; select * from mysql_server_read_only_log; mysql&gt; select * from mysql_server_replication_lag_log; 9.在主服务器节点授权一个配置发送SQL语句的用户 GRANT ALL ON *.* TO &apos;sqluser&apos;@&apos;192.168.80.%&apos; IDENTIFIED BY &apos;123456&apos;; 10.在proxysql节点上，将sqluser用户添加到mysql_user表中，default_hostgroup默认组设置为写组10,当读写分离的路由规则不符合时，会访问默认组的数据库 mysql&gt; insert into mysql_users(username,password,default_hostgroup) values(&apos;sqluser&apos;,&apos;123456&apos;,10); mysql&gt; load mysql users to runtime; mysql&gt; save mysql users to disk; 11.使用sqluser用户测试是否能路由到默认的10写组实现读、写数据 mysql -usqluser -p123456 -P6033 -h127.0.0.1 -e &apos;select @@server_id&apos; mysql -usqluser -p123456 -P6033 -h127.0.0.1 -e &apos;create database testdb 12. 在proxysql节点上，配置路由规则，实现读写分离 与规则有关的表：mysql_query_rules和mysql_query_rules_fast_routing，后者是前者的扩展表，1.4.7之后支持 插入路由规则：将select语句分离到20的读组，select语句中有一个特殊语句SELECT...FOR UPDATE它会申请写锁，应路由到10的写组 mysql&gt; insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); mysql&gt; load mysql query rules to runtime; mysql&gt; save mysql query rules to disk; 注意：因ProxySQL根据rule_id顺序进行规则匹配，select ... for update规则的 rule_id必须要小于普通的select规则的rule_id 13.测试读操作是否路由给20的读组 mysql -usqluser -p123456 -P6033 -h127.0.0.1 -e &apos;select @@server_id&apos; 路由的信息：查询stats库中的stats_mysql_query_digest表 SELECT hostgroup hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; 路由规则 select rule_id,active,match_digest,destination_hostgroup,apply from mysql_query_rules;]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx常用模块]]></title>
    <url>%2F2018%2F12%2Fnginx%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[参考文档 ngx_http_access_module上下文：http, server, location, limit_except 实现基于ip的访问控制功能 1、allow address | CIDR | unix: | all; 2、deny address | CIDR | unix: | all; 自上而下检查，一旦匹配，将生效，条件严格的置前 示例： location / { deny 192.168.1.1; allow 192.168.1.0/24; deny all; } ngx_http_auth_basic_module模块上下文：http, server, location, limit_except 实现基于用户的访问控制，使用basic机制进行用户认证； 1、auth_basic string | off; 2、auth_basic_user_file file; location /admin/ { alias /webapps/app1/data/; auth_basic &quot;Admin Area&quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; } 注意：口令文件 1、明文文本：格式name:password:comment 2、加密文本：由htpasswd命令实现,htpasswd命令由httpd-tools所提供； ngx_http_stub_status_module模块上下文:server, location 用于输出nginx的基本状态信息； 示例: Active connections: 291 server accepts handled requests 16630948 16630948 31070465 Reading: 6 Writing: 179 Waiting: 106 Active connections: 活动状态的连接数； accepts：已经接受的客户端请求的总数； handled：已经处理完成的客户端请求的总数； requests：客户端发来的总的请求数； Reading：处于读取客户端请求报文首部的连接的连接数； Writing：处于向客户端发送响应报文过程中的连接数； Waiting：处于等待客户端发出请求的空闲连接数； stub_status; 配置示例： location /basic_status { stub_status; access_log off; #关闭记录日志,因为反向代理如果并发大，会导致IO吃紧 } ngx_http_gzip_module上下文:http，server，location 在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用 启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景； 1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用 对服务器的压力就会更大 2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源 3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本 再定义压缩规则 1、gzip on | off; 启用或禁用压缩 上下文:http，server，location，if in location 2、gzip_comp_level level; gzip压缩级别，范围为1到9，值越大，压缩效率越高，消耗cpu资源越大 3、gzip_disable regex ...; 对具有与任何指定正则表达式匹配的“User-Agent”标头字段的请求禁用gzipping响应 4、gzip_min_length length; 启用压缩功能的响应报文大小阈值； 5、gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小； 默认情况下，缓冲区大小等于一个内存页面 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； 7、gzip_types mime-type ...; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能； 8.gzip_http_version ... 压缩版本用于设置识别HTTP协议版本,默认1.1 示例： gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/plain application/x-javascript text/css application/xml; ngx_http_ssl_module上下文:http, server 代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现 面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器 如果是四层调度，https访问必须是客户端与后端服务器之间建立； 如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器CPU资源消耗不是很大 1.ssl on | off; 2、ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3、ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4、ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5、ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； [shared:name:size]：在各worker之间使用一个共享的缓存； 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 7.ssl_ciphers ciphers 加密算法 8. ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3]; 启用指定的协议 配置示例： 生成私钥和证书： openssl genrsa -out nginx.key 2048 openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.a.com&quot; 配置主体： server { listen 443 ssl; server_name www.a.com; root /vhosts/ssl/htdocs; ssl on; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; } 为减少处理器负载，建议使用： 设置worker processes等于处理器数， 启用 keep-alive连接， 启用 shared 会话缓存， 禁用builtin会话缓存， 并可能增加session_timeout（默认为5分钟）： ngx_http_rewrite_module将用户请求的URI基于regex所描述的模式进行检查，而后完成替换 url重写: 1.客户端访问URL被重写到另外一个路径了 http://www.a.com/a/1.jpg ---&gt; http://images.a.com/1.jpg 2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上 http://www.a.com/images/1.jpg---&gt;https://www.a.com/1.jpg rewirte的处理逻辑： 1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement) 2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入 了last和break的两个机制 3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的 rewrite了这样就避免了死循环 1、rewrite regex replacement [flag] 上下文:server, location, if 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI； 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端； 301：permanent,永久重定向； 302：redirect,临时重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；浏览器的URL地址显示跳转后的地址 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；浏览器的URL地址显示跳转后的地址 例： rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 rewrite ^/bbs/(.*)$ http://www.magedu.com http://192.168.80.27/bbs/ --&gt; http://www.magedu.com/ redirect和permanent区别 2、return 上下文:server, location, if 停止处理并将指定的内容返回code给客户端 return code [text]; return code URL; return URL; 3、rewrite_log on | off; 上下文:http,server,location, if 是否开启重写日志； 4、if (condition) { ... } 上下文:server, location 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 例： if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) { set $id $1; } if ($request_method = POST) { return 405; } 5、set $variable value; 上下文:server, location, if 用户自定义变量 ； 例： location /download/ { if ($forbidden) { return 403; } if ($slow) { limit_rate 10k; } rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; } ngx_http_referer_module上下文:server, location 1、valid_referers none | blocked | server_names | string ...; 定义referer首部的合法可用值；用于防盗链 none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regulare xpression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*\.images\.com； 配置示例： 先定义valid_referers的允许连接网站，再通过if判断如果不是在valid_referers中定义的网站，就返回一张图片或者文字说明 valid_referers none block server_names 172.18.0.2 *.a.com *.ma.com ma.* ~\.mage\.; if($invalid_referer) { return http://www.ma.com/invalid.jpg; }]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql高可用]]></title>
    <url>%2F2018%2F12%2Fmysql%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[MySQL高可用解决方案MMM: Multi-Master Replication Manager for MySQL，Mysql主主复制管理器是一套灵活的脚本程序，基于perl实现，用来对mysql replication进行监控和故障迁移，并 能管理mysql Master-Master复制的配置(同一时间只有一个节点是可写的) [官网]http://www.mysql-mmm.orghttps://code.google.com/archive/p/mysql-master-master/downloads MHA： Master High Availability，对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现，目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，出于机器成本的考虑，淘宝进行了改造，目前淘宝TMHA已经支持一主一从 [官网]https://code.google.com/archive/p/mysql-master-ha/ Galera Cluster： wsrep(MySQL extended with the Write Set Replication)通过wsrep协议在全局实现复制；任何一节点都可读写，不需要主从复制，实现多主读写 GR（Group Replication） MySQL官方提供的组复制技术(MySQL 5.7.17引入的技术)， 基于原生复制技术Paxos算法 MHA实现MHA的过程 MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。 MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。 整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。 例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。 使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。 MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 MHA服务有两种角色，MHA Manager(管理节点）和MHA Node(数据节点）： MHA Manager:通常单独部署在一台独立机器上管理多个master/slave集群，每个master/slave集群称作一个application; MHA node:运行在每台MYSQL服务器上（master/slave/manager),它通过监控具备解析和清理logs功能的脚本来加快故障转移 MHA组件常见工具 Manager节点： masterha_check_ssh :MHA依赖的ssh环境监测工具 masterha_check_repl: MYSQL复制环境检测工具； masterga_manager: MHA 服务主程序 masterha_check_status: MHA 运行状态探测工具； masterha_master_monitor:MYSQL master节点可用性监测工具； masterha_master_swith:master节点切换工具； masterha_conf_host:添加或删除配置的节点； masterha_stop:关闭MHA服务的工具。 Node节点： save_binary_logs:保存和复制master的二进制日志； apply_diff_relay_logs:识别差异的中继日志事件并应用于其他slave； filter_mysqlbinlog:去除不必要的ROLLBACK事件（MHA已不再使用这个工具 purge_relay_logs:清除中继日志（不会阻塞SQL线程） 自定义扩展： secondary_check_script:通过多条网络路由检测master的可用性； master_ip_failover_script:更新application使用的masterip； report_script:发送报告 init_conf_load_script:加载初始配置参数； master_ip_online_change_script:更新master节点ip地址； 实现MHA的过程前提条件 1.各主机基于ssh-key验证 2.各主机的时间需要同步 主节点 [mysqld] server-id=1 log-bin=/PATH/LOG_BIN_FILENAME skip_name_resolve=ON innodb_file_per_table = ON 1. 授权MHA账号以实现控制服务器 mysql&gt; GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO &apos;repluser&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;replpass&apos; 在所有MYSQL节点授权拥有管理权限的用户可在本地网络中有其他节点上远程访问。当然，此时仅需要且只能在master节点运行类似如下。 mysql&gt; GRANT ALL ON *.* TO ‘mhaadmin’@’172.16.252.%’ IDENTIFIED BY ‘mhapass’; MariaDB [(none)]&gt;SHOW MASTER STATUS 从节点配置 [mysqld] server-id = 2 #复制集群中的各节点的id均必须唯一； relay-log = relay-log log-bin read_only = ON relay_log_purge = 0 skip_name_resolve = ON innodb_file_per_table = ON MariaDB [(none)]&gt;CHANGE MASTER TO MASTER_HOST=’master ip′,MASTER_USER=’repluser’,MASTER_PASSWORD=’replpass’,MASTER_LOG_FILE=’master-log.000003′,MASTER_LOG_POS=498; MariaDB [(none)]&gt; START SLAVE; MariaDB [(none)]&gt; SHOW SLAVE STATUS\G 安装配置MHA Manager 节点需要为每个监控的master/slave集群提供一个专用的配置文件，而所有的master/slave集群也可共享全局配置。全局配置文件默认为/etc/masterha_default.cnf，其为可选配置。如果仅监控一组master/slave集群，也可直接通过application的配置来提供各服务器的默认配置信息。而每个application的配置文件路径为自定义。 a、准备基于SSH互信通信环境： b、安装MHA 除了源码包，MHA官方也提供了rpm格式的程序包 vim /etc/mastermha/app1.cnf [server default] user=mhauser password=magedu manager_workdir=/data/mastermha/app1/ manager_log=/data/mastermha/app1/manager.log remote_workdir=/data/mastermha/app1/ ssh_user=root repl_user=repluser repl_password=magedu ping_interval=1 [server1] hostname=192.168.8.17 candidate_master=1 [server2] hostname=192.168.8.27 candidate_master=1 [server3] hostname=192.168.8.37 测试启动 检测各节点间ssh互信通信配置是否Ok masterha_check_ssh --conf=/etc/mha/mysqlcluster1.cnf 检查管理的MySQL复制集群的连接配置参数是否OK masterha_check_repl --conf=/etc/mha/mysqlcluster1.cnf 启动 masterha_manager --conf=/etc/mha/mysqlcluster1.cnf 测试故障转移 (1)在master节点关闭mariadb服务,模拟主节点数据崩溃 #killall -9 mysqld mysqld_safe #rm -rf /var/lib/mysql/* (2)在manager节点查看日志： /data/mastermha/app1/manager.log 注意，故障转移完成后，manager将会自动停止，此时使用masterha_check_status命令检测将会遇到错误提示，如下所示： #masterha_check_status –conf=/etc/masterha/app1.cnf XXX is stopped(:NOT_RINNING). Galera Cluster特点 多主架构：真正的多点读写的集群，在任何时候读写数据，都是最新的 同步复制：集群不同节点之间数据同步，没有延迟，在数据库挂掉之后，数据不会丢失 并发复制：从节点APPLY数据时，支持并行执行，更好的性能 故障切换：在出现数据库故障时，因支持多点写入，切换容易 热插拔：在服务期间，如果数据库挂了，只要监控程序发现的够快，不可服务时间就会非常少。在节点故障期间，节点本身对集群的影响非常小 自动节点克隆：在新增节点，或者停机维护时，增量数据或者基础数据不需要人工手动备份提供，Galera Cluster会自动拉取在线节点数据，最终集群会变为一致 对应用透明：集群的维护，对应用程序是透明的 工作工程 Galera Cluster官方文档： http://galeracluster.com/documentation-webpages/galera-documentation.pdf http://galeracluster.com/documentation-webpages/index.html https://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/ Galera Cluster包括两个组件 Galera replication library (galera-3) WSREP：MySQL extended with the Write Set Replication WSREP复制实现： PXC：Percona XtraDB Cluster，是Percona对Galera的实现 MariaDB Galera Cluster 参考仓库： https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.59/yum/centos7-amd64/ 注意：都至少需要三个节点，不能安装mariadb-server 1. 配置repo源 cat &gt; /etc/yum.repos.d/galera-cluster &lt;&lt;EOF [galera] name=&quot;galera-cluster&quot; baseurl=https://mirrors.tuna.tsinghua.edu.cn/mariadb//mariadb-10.0.37/yum/centos74-amd64/ enable=1 gpgcheck=0 EOF 2. 使用yum install MariaDB-Galera-server安装 3. 在各节点配置vim /etc/my.cnf.d/server.cnf [galera] wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=&quot;gcomm://192.168.56.81,192.168.56.82,192.168.56.83&quot; binlog_format=row default_storage_engine=InnoDB innodb_autoinc_lock_mode=2 bind-address=0.0.0.0 4. 首次启动，需初始胡集群，在其中一个节点执行以下命令 /etc/init.d/mysql start --wsrep-new-cluster 5. 正常启动其它节点 service mysql start 查看集群中相关系统变量和状态变量 SHOW VARIABLES LIKE &apos;wsrep_%‘; SHOW STATUS LIKE &apos;wsrep_%‘; SHOW STATUS LIKE &apos;wsrep_cluster_size‘;]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx安装和基础配置]]></title>
    <url>%2F2018%2F12%2Fnginx%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装官方的预制包 1.yum安装 ，需要epel yum install nginx -y 2.编译安装 yum groupinstall &quot;Development Tools&quot; &quot;Server Platform Development&quot; yum install pcre-devel openssl-devel zlib-devel useradd -r nginx ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aio make &amp;&amp; make install ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx 服务管理 可以添加到/etc/init.d或者/usr/lib/systemd/system/下 启动，不需要通过systemd nginx 可以不重启服务加载配置文件 nginx -s reload 需要退出时，可以自动等待请求处理结束后 nginx -s quit 显示nginx的使用帮助 nginx -h 显示nginx编译时的选项 nginx -V 编译安装nginx选项：--prefix=/etc/nginx 安装路径 --sbin-path=/usr/sbin/nginx 指明nginx程序文件安装路径 --conf-path=/etc/nginx/nginx.conf 主配置文件安装位置 --error-log-path=/var/log/nginx/error.log 错误日志文件安装位置 --http-log-path=/var/log/nginx/access.log 访问日志文件安装位置 --pid-path=/var/run/nginx.pid 指明pid文件安装位置 --lock-path=/var/run/nginx.lock 锁文件安装位置 --http-client-body-temp-path=/var/cache/nginx/client_temp 客户端body部分的临时文件存放路径，服务器允许客户端使用put方法提交大数据时，临时存放的磁盘路径 --http-proxy-temp-path=/var/cache/nginx/proxy_temp 作为代理服务器，服务器响应报文的临时文件存放路径 --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp 作为fastcgi代理服务器，服务器响应报文的临时文件存放路径 --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp 作为uwsgi代理服务器，服务器响应报文的临时文件存放路径 --http-scgi-temp-path=/var/cache/nginx/scgi_temp 作为scgi反代服务器，服务器响应报文的临时文件存放路径 --user=nginx 指明以那个身份运行worker进程，主控master进程一般由root运行 --group=nginx --with-http_ssl_module 表示把指定模块编译进来 程序环境配置文件的组成部分： 主配置文件：nginx.conf include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主程序文件：/usr/sbin/nginx Unit File：nginx.service 配置主配置文件的配置指令： directive value [value2 ...]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name 主配置文件结构： main block：主配置段，也即全局配置段； event { ... }：事件驱动相关的配置； http { ... }：http/https 协议相关的配置段； mail { ... } stream { ... } http协议相关的配置结构 http { ...：各server的公共配置 server { ... }：每个server用于定义一个虚拟主机； server ... listen server_name root alias location [OPERATOR] URL { ... if CONDITION { ... } } } } 配置指令main配置段常见的配置指令： 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置：1、user Syntax: user user [group]; Default: user nobody nobody; Context: main 定义工作进程使用的用户和组凭据。如果省略group，则使用名称等于user的组 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置：1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; nginx进程的CPU亲缘性；程序就会一直在指定的cpu运行，防止进程在多cpu环境切换，从而避免因切换带来的CPU的L1/L2 cache失效 CPU MASK：bit mask 00000000： 0000 0001：0号CPU 0000 0010：1号CPU ... ... 0000 0011：0和1号CPU； 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,20] 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限；socket文件数，进程的并发连接数 每一个连接都需要打开一个套接字，每一个套接字的维持都需要一个文件描述符 默认情况下linux限制每个用户最多同时打开1024个文件 对高并发服务器来说都需要修改ulimit数量(ulmit -a/-n number) 调试、定位问题：1、daemon on|off; 是否以守护进程方式运行Nignx；前台、后台 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on；是否开启子进程 3.nginx日志 事件驱动相关的配置:events { ... } 1、worker_connections number; 每个worker进程所能够打开的最大并发连接数数量； worker_processes * worker_connections 2、use method; 指明并发连接请求的处理方法； use epoll; 3、accept_mutex on | off; 处理新的连接请求的方法；on意味着由各worker轮流处理新请求，Off意味着每个新请求的到达都会通知所有的worker进程； 与套接字相关的配置：配置一个虚拟主机； server { listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; 。。。。 } 1、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] default_server：设定为默认虚拟主机，建议旨在一个server上 ssl：限制仅能够通过ssl连接提供服务； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小； 注意： 1) 基于port； listen PORT; 指令监听在不同的端口 2) 基于ip的虚拟主机 listen IP:PORT; IP 地址不同 3) 基于hostname server_name fqdn; 指令指向不同的主机名 2、server_name name ...; 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串； 支持*通配任意长度的任意字符；server_name *.magedu.com www.magedu.* 支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.magedu\.com$ 匹配机制： 1) 首先是字符串精确匹配; 2) 左侧*通配符； 3) 右侧*通配符； 4) 正则表达式；一般不要使用，高并发请求时，会降低服务器性能 3.server_tokens on | off | build | string (上下文：http, server, location) 是否在响应报文的Server首部显示nginx版本 4、 tcp_nodelay on | off; (上下文：http, server, location) 在keepalived模式下的连接是否启用TCP_NODELAY选项； off，延迟发送，多个请求合并后发送 on，不延迟发送 tcp_nopush on|off; (上下文：http, server, location) 在sendfile模式下，是否启用TCP_CORK选项； sendfile on | off; (上下文：http, server, location) 是否启用sendfile功能；在内核中封装报文直接发送，默认off Nagle算法：如果包的大小满足MSS，那么可以立即发送，否则数据会被放到缓冲区，等到已经发送的包被确认了之后才能继续发送 设置套接字的TCP_NODELAY选项来完成，这样就禁用了Nagle 算法 当使用sendfile函数时，tcp_nopush才起作用，它和指令tcp_nodelay是互斥的。 在tcp交互的过程中，当应用程序接收到数据包后马上传送出去，不等待，而tcp_cork选项是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞，已经是默认了。 也就是说tcp_nopush = on 会设置调用tcp_cork方法，这个也是默认的，结果就是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞。 定义路径相关的配置：1、root path; (上下文：http,server,location,if in location） 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； 注意：匹配顺序：location下的root--&gt;server下的root--&gt;http下的root 2、location [ = | ~ | ~* | ^~ ] uri { ... }. 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； =：对URI做精确匹配； ~：对URI做正则表达式模式匹配，区分字符大小写； ~*：对URI做正则表达式模式匹配，不区分字符大小写； ^~：对URI的左半部分做匹配检查，不区分字符大小写； 不带符号：以URI为前缀的所有uri； 匹配优先级：=, ^~, ～/～*，不带符号； 例： location = / { [ configuration A ] } location / { [ configuration B ] } location /documents/ { [ configuration C ] } location ^~ /images/ { [ configuration D ] } location ~* \.(gif|jpg|jpeg)$ { [ configuration E ] } “ /”请求将匹配配置A，“ /index.html”请求将匹配配置B，“ /documents/document.html”请求将匹配配置C， “ /images/1.gif”请求将匹配配置D，“ /documents/1.jpg”请求将匹配配置E 3、alias path; （上下文：location） 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧/； (b) alias，给定的路径对应于location中的/uri/右侧/； 注意： 如果location后面的URI有/，则alias后面的路径也得有/ 使用alias标签的目录块中不能使用rewrite的break 4、index file ...; (上下文；http, server, location) 指定默认网页文件 5、error_page code ... [=[response]] uri; (上下文：http,server,location, if in location) 定义错误页 error_page 404 /404.html; location = /404.html { root &quot;/www/error_pages&quot;; } 6、try_files file ... uri; (上下文：server, location) 按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。 只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。 最后一个参数是回退URI且必须存在，否则会出现内部500错误 location /images/ { try_files $uri /images/default.gif; } location / { try_files $uri $uri/index.html $uri.html =404; } 定义客户端请求的相关配置 (上下文:http,server,location)1、keepalive_timeout timeout [header_timeout] 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 2、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 3、keepalive_disable none | browser ...; 对哪种浏览器禁用长连接； 4、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 5、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 6、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置：1、limit_rate rate; (上下文:http,server,location,if in location) 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 2、limit_except method .. { ... } （上下文:location) 限制对指定的请求方法之外的其它方法的使用客户端； limit_except GET { allow 192.168.1.0/24; deny all; } 文件操作优化的配置 (上下文：http，server，location)1、aio on | off | threads[=pool]; 是否启用aio功能；aio：异步IO 2、directio size | off; 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m; 3、open_file_cache off; 禁用缓存 open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息： (1) 文件的描述符、文件大小和最近一次的修改时间； (2) 打开的目录结构； (3) 没有找到的或者没有权限访问的文件的相关信息； max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现缓存管理； inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项； 4、open_file_cache_valid time; 缓存项有效性的检查频率；默认为60s; 5、open_file_cache_min_uses number; 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项； 6、open_file_cache_errors on | off; 是否缓存查找时发生错误的文件一类的信息；]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx基础]]></title>
    <url>%2F2018%2F12%2Fnginx%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[基础知识1.一个Web请求的处理过程 用户请求--&gt;送达到用户空间--&gt;系统调用--&gt;内核空间--&gt;内核到磁盘上读取网页资源-&gt;返回到用户空间-&gt;响应给用户 客户端向Web服务请求过程，在这个过程中，有两个I/O过程，一个就是客户端请求的网络I/O，另一个就是Web服务器请求页面的磁盘I/O 2.I/O模型： 阻塞型、非阻塞型、复用型、信号驱动型、异步 3.web请求处理机制 1).在网络通信中同步和异步是描述通信模式的概念，关注消息通知机制 同步：发送方发送完请求后，需要等待接收到接收方发回的响应，才能发送下一个请求 异步：发送方发出一个请求后，不等接收方响应这个请求，就继续发送下一个请求，被调用者通过状态、通知或回调机制通知调用者被调用者的运行状态； 2).网络通信中主要指套接字socket的阻塞和非阻塞，而socket的实质就是IO操作。关注调用者在等待结果返回之前所处的状态； 阻塞：blocking，调用结果返回之前，调用者被挂起；等到调用结果返回之后才进入就绪状态，获取CPU后继续执行 非阻塞：nonblocking，调用结果返回之前，调用者不会被挂起,立即返回执行下一个调用 一次文件IO请求，都会由两阶段组成： 第一步：等待数据，即数据从磁盘到内核内存； 第二步：复制数据，即数据内核内存到进程内存 3.资源类型： 静态:一般客户端发送请求到web服务器，web服务器从内存在取到相应的文件，返回给客户端，客户端解析并渲染显示出来。 css,js,jpg.text... 动态：一般客户端请求的动态资源，先将请求交于web容器，web容器连接数据库，数据库处理数据之后，将内容交给web服务器，web服务器返回给客户端解析渲染处理。 php,jsp 4.数据类型 结构化数据：mysql 半结构化数据：json,xml 非结构化数据:分布式存储（SDS） 5.httpd MPM：multi-processing module多路处理模块 prefork：进程模型，两级结构，主进程master负责生成子进程，每个子进程负责响应一个请求；默认模型 worker：线程模型，三级结构，主进程master负责生成子进程，每个子进程负责生成多个线程，每个线程响应一个请求； event：事件驱动模型,基于异步I/O模型主进程master负责生成子进程，每个子进程响应多个请求； Nginx官网 Nginx启动特别容易,并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动. 你还能够不间断服务的情况下进行软件版本的升级 Nginx是一款优秀的web服务器和反向代理服务器，基于nginx我们可以搭建一个强大的web服务器，也可以把nginx作为反向代理服务器而实现负载均衡、动静分离等功能 Nginx因具有高并发（特别是静态资源）占用系统资源少等特性 nginx的功用： 静态的web资源服务器；(图片服务器，或js/css/html/txt等静态资源服务器) 结合FastCGI/uwSGI/SCGI等协议反代动态资源请求； http/https协议的反向代理； imap/pop3协议的反向代理； tcp/udp协议的请求转发； nginx与apache比较nginx的基本特性 对静态资源高速高并发访问及缓存 支持FastCGI、Uwsgi、SCGI、Memcache Server的加速和缓存 支持SSL、TLS、SNI 具有模块化的架构：过滤器包括gzip压缩、rangs支持、chunked响应、XSLT、SSI及图像缩放等功能。在SSI过滤中，一个包含多个SSI的页面，如果经由FastCGI或反向代理，可被并行处理。 支持邮件服务代理 资源消耗少：在3万并发连接下，开启10个nginx线程消耗的内存不到200MB 可以做HTTP反向代理及加速缓存，即负载均衡功能，内置对RS节点服务器健康检查功能，这相当于专业的Haproxy软件或LVS的功能 具备Squid等专业缓存软件等的缓存功能 支持异步网络I/O时间模型epoll apache软件的特点 Apache2.2版本非常稳定强大，性能好。 prefork模式取消了进程开销 处理动态业务数据时，因关联到后端的引擎和数据库，瓶颈不在Apache上 高并发时消耗资源相对多一些 基于传统的select模型，高并发能力有限 支持扩展库，可以通过DSO、apxs方法编译安装额外的插件功能，不需要重新编译Apache 功能多，更稳定，更安全，插件也多 市场份额逐渐递减 Apache使用的是传统的select模型 静态业务： 若是高并发场景，尽量采用nginx或Lighttpd，首选nginx 动态业务： 理论上采用nginx和Apache均可，为了避免相同业务服务软件多样化，增加维护成本 既有动态又有静态： 选用nginx Nginx程序架构：master/worker 一个master进程： 负载加载和分析配置文件、管理worker进程、平滑升级 一个或多个worker进程 不应不大于cpu核心数 单进程处理并响应用户多请求 主要通过“共享内存”的机制实现进程间通信 一个进程响应一个任务，都是串行模式 缓存相关的进程： cache loader：载入缓存对象 cache manager：管理缓存对象 特性：异步、事件驱动和非阻塞 并发请求处理：通过epoll/select 文件IO：高级IO sendfile，异步，mmap 模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件，升级版本，更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 Nginx的模块化 nginx模块：高度模块化，但其模块早期不支持DSO机制；近期版本支持动态装载和卸载； 模块分类： 核心模块：core module 标准模块： HTTP modules： Standard HTTP modules Optional HTTP modules Mail modules Stream modules： 传输层代理 第三方模块 party modules 一般以Ngx_作为前缀，——module作为后缀，中间使用一个或者多个英文单词描述模块的工能，例如Ngx_core_module表示该模块提供Nginx的核心功能等 参考文档 Nginx模块组织工作图 web请求处理机制1、多进程方式：服务器没接受到一个客户端请求就有服务器的主进程生成一个子进程响应客户端，直到用户关闭连接，这样的优势是处理速度快，子进程之间相互独立，但是如果访问过大会导致服务器资源耗尽而无法提供请求。 2、多线程方式：与多进程方式类似，但是每收到一个客户端请求会有服务进程派生出一个线程来个客户方进行交互，一个线程的开销远远小于一个进程，因此多线程方式在很大程度减轻了web服务器对系统资源的要求，但是多线程也有自己的缺点，即当多个线程位于同一个进程内工作的时候，可以相互访问同样的内存地址空间，所以他们相互影响，一旦主进程挂掉则所有子线程都不能工作了，IIS服务器使用了多线程的方式，需要间隔一段时间就重启一次才能稳定。 Nginx服务器的一个显著的优势就是能够同时处理大量的并发请求。它结合多进程机制和异步机制。异步机制使用的是异步非阻塞方式。（Master-Worker)。 每个工作进程使用异步非阻塞方式，可以处理多个客户端请求。当某个工作进程接收到客户端的请求以后，调用IO进行处理，如果不能立即得到结果，就去处理其他的请求； 而客户端在此期间也无需等待响应，可以去处理其他事情； 当IO返回时，就会通知此工作进程；该进程得到通知，暂时挂起当前处理的失误去响应客户端请求。 异步可以理解为循环处理多个准备好的事件，不会导致无谓的资源浪费，当有更多的并发数只会占用更多的内存而已 事件驱动模型Nginx服务器的工作进程调用IO后，就取进行其他工作了；当IO调用返回后，会通知工作进程。 但IO调用时如何把自己的状态通知给工作进程的呢？ 1.让工作进程在进行其他工作的过程中间隔一段时间就去检查一下IO的状态，如果完成就响应客户端，如果未完成，继续工作 2.IO调用在完成后能主动通知工作进程 他们提供了一种机制就只让进程同时处理多个并发请求，不用关心IO调用的具体状态。IO调用完全由事件驱动模型来管理 Nginx采用事件驱动处理库（多路IO复用），最常用的就是select模型，poll模型，epoll模型 复用型IO（多路IO） 1.用户请求与内核处理之间有一个内核中的select()，poll() 3.相当于在内核中加了一个助理，能把请求分发给内核中不同的功能去处理，但是实际也是阻塞的，阻塞在select上，并没阻塞在用户进程上，所以还可以进行别的IO请求 4.当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 5.所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符fd（套接字描述符）其中的任意一个进入读就绪状态，通知应用程序进程 nginx使用最新的epoll和异步网络I/O模型，，能够处理大量连续的读写请求 架构简介 1.Nginx启动后，会产生一个主进程，主进程执行一系列的工作后会产生一个或者多个工作进程 2.在客户端请求动态站点的过程中，Nginx服务器还涉及和后端服务器的通信。Nginx将接收到的Web请求通过代理转发到后端服务器，由后端服务器进行数据处理和组织； 3.Nginx为了提高对请求的响应效率，降低网络压力，采用了缓存机制，将历史应答数据缓存到本地。保障对缓存文件的快速访问 工作进程 工作进程的主要工作有以下几项： 接收客户端请求； 将请求一次送入各个功能模块进行过滤处理； IO调用，获取响应数据； 与后端服务器通信，接收后端服务器处理结果； 数据缓存 响应客户端请求； 进程交互 Nginx服务器在使用Master-Worker模型时，会涉及到主进程和工作进程的交互和工作进程之间的交互。这两类交互都依赖于管道机制。 1.Master-Worker交互 这条管道与普通的管道不同，它是由主进程指向工作进程的单向管道，包含主进程向工作进程发出的指令，工作进程ID等；同时主进程与外界通过信号通信； 2.worker-worker交互 这种交互是和Master-Worker交互是基本一致的。但是会通过主进程。工作进程之间是相互隔离的 Nginx 进程的功能和进程间的通信1、主进程(woker process)的功能： 读取Nginx 配置文件并验证其有效性和正确性 建立、绑定和关闭socket连接 按照配置生成、管理和结束工作进程 接受外界指令，比如重启、升级及退出服务器等指令 不中断服务，实现平滑升级，重启服务并应用新的配置 开启日志文件，获取文件描述符 不中断服务，实现平滑升级，升级失败进行回滚处理 编译和处理perl脚本 2、工作进程（woker process）的功能 接受处理客户的请求 将请求以此送入各个功能模块进行处理 IO调用，获取响应数据 与后端服务器通信，接收后端服务器的处理结果 缓存数据，访问缓存索引，查询和调用缓存数据 发送请求结果，响应客户的请求 接收主程序指令，比如重启、升级和退出等 Ninx进程间的通信1.主进程和工作进程之间的通信： (1)工作进程是有主进程生成的，主进程使用fork()函数，在Nginx服务器启动过程中主进程根据配置文件决定启动工作进程的数量，然后建立一张全局的工作表用于存放当前未退出的所有的工作进程，主进程生成工作进程后会将新生成的工作进程加入到工作进程表中，并建立一个单向的管道并将其传递给工作进程，该管道与普通的管道不同，它是由主进程指向工作进程的单项通道，包含了主进程想工作进程发出的指令、工作进程ID、工作进程在工作进程表中的索引和必要的文件描述符等信息。 (2)主进程与外界通过信号机制进行通信，当接收到需要处理的信号时，它通过管道向相关的工作进程发送正确的指令，每个工作进程都有能力捕获管道中的可读事件，当管道中有可读事件的时候，工作进程就会从管道中读取并解析指令，然后采取相应的执行动作，这样就完成了主进程与工作进程的交互。 2.工作进程与工作进程之间的通信 (1)工作进程之间的通信原理基本上和主进程与工作进程之间的通信是一样的，只要工作进程之间能够取得彼此的信息，建立管道即可通信，但是由于工作进程之间是完全隔离的，因此一个进程想要直到另外一个进程的状态信息就只能通过主进程来设置了。 (2)为了实现工作进程之间的交互，主进程在生成工作进程只之后，在工作进程表中进行遍历，将该新进程的ID以及针对该进程建立的管道句柄传递给工作进程中的其他进程，为工作进程之间的通信做准备，当工作进程1向工作进程2发送指令的时候，首先在主进程给它的其他工作进程工作信息中找到2的进程ID，然后将正确的指令写入指向进程2的管道，工作进程2捕获到管道中的事件后，解析指令并进行相关操作，这样就完成了工作进程之间的通信。 配置更新和NGINX升级仅包含少量工作进程的NGINX进程架构，使得配置、甚至是二进制文件本身的更新都非常高效 更新NGINX的配置，是一个非常简单的、轻量级的、可靠的操作。运行nginx –s reload命令即可，该命令会检查磁盘上的配置，并给主进程发送一个SIGHUP信号 当主进程接收到SIGHUP信号后，会做两件事： 1. 重新加载配置，fork一套新的工作进程。这些新的工作进程会立即开始接受连接和处理流量（traffic）（使用新的配置）。 2. 发出信号，通知旧的工作进程安静地退出。这些旧进程不会再接受新的连接了。只要它们处理的HTTP请求结束了，它们就会干净地关闭连接。一旦所有的连接都被关闭，工作进程也就退出了。 这个过程会导致CPU占用率和内存使用的一个小高峰，但相比于从活动连接中加载资源，这个小高峰可忽略不计。你可以在一秒内重新加载配置多次。极少情况下，一代又一代工作进程等待连接关闭时会出现问题，但即便出现问题，它们也会被立即解决掉。 NGINX的二进制升级过程更加神奇——你可以飞速地升级NGINX本身，服务器不会有任何的丢连接、宕机、或服务中断等情况。 二进制升级过程与配置更新相似。新的NGINX主进程与原来的主进程并行，它们共享监听套接字。两个进程都是活跃的（active），它们各自的工作进程处理各自的流量（traffic）。然后，你可以通知旧的主进程与其工作进程完美退出]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql其他实践]]></title>
    <url>%2F2018%2F11%2Fmysql%E5%85%B6%E4%BB%96%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[复制的问题和解决方案1. 数据损坏或丢失 Master： MHA + semi repl Slave： 重新复制 2. 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 3. 不惟一的server id 重新复制 4. 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制 MYSQL压力测试数据库服务衡量指标： qps: query per second tps: transaction per second 1. mysqlslap 来自于mariadb包，测试的过程默认生成一个mysqlslap的schema,生成测试表t1，查询和插入测试数据，mysqlslap库自动生成，如果已经存在则先删除。用--only-print来打印实际的测试过程，整个测试完成后不会 在数据库中留下痕迹 mysqlslap [options] [options] --auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力 --auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认) -engines engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：-engines=myisam,innodb --concurrency=N, -c N 表示并发量 --commint=N 2. Sysbench：功能强大 https://github.com/akopytov/sysbench 3. pcc-mysql 4. MySQL Benchmark Suite 5. MySQL super-smack 6. MyBench my.cnf企业级配置参数介绍[mysqld] //服务器端配置 datadir=/data/mysql //数据目录 socket=/var/lib/mysql/mysql.sock //socket通信设置 user=mysql //使用mysql用户启动； symbolic-links=0 //是否支持快捷方式； log-bin=mysql-bin //开启bin-log日志； server-id = 1 //mysql服务的ID； auto_increment_offset=1 //自增长字段从固定数开始； auto_increment_increment=2 //自增长字段每次递增的量； socket = /tmp/mysql.sock //为MySQL客户程序与服务器之间的本地通信套接字文件； port = 3306 //指定MsSQL监听的端口； key_buffer = 384M //key_buffer是用于索引块的缓冲区大小； table_cache = 512 //为所有线程打开表的数量； sort_buffer_size = 2M //每个需要进行排序的线程分配该大小的一个缓冲区； read_buffer_size = 2M //读查询操作所能使用的缓冲区大小。 query_cache_size = 32M //指定MySQL查询结果缓冲区的大小 read_rnd_buffer_size = 8M //改参数在使用行指针排序之后，随机读； myisam_sort_buffer_size = 64M //MyISAM表发生变化时重新排序所需的缓冲； thread_concurrency = 8 //最大并发线程数，取值为服务器逻辑CPU数量×2； thread_cache = 8 //缓存可重用的线程数； skip-locking //避免MySQL的外部锁定，减少出错几率增强稳定性。 default-storage-engine=INNODB //设置mysql默认引擎为Innodb； [mysqld_safe] //mysql服务安全启动配置； log-error=/var/log/mysqld.log //mysql错误日志路径； pid-file=/var/run/mysqld/mysqld.pid //mysql PID进程文件； key_buffer_size = 2048MB //MyISAM表索引缓冲区的大小； max_connections = 3000 //mysql最大连接数； innodb_buffer_pool_size = 2048MB //InnoDB内存缓冲数据和索引大小； basedir = /usr/local/mysql55/ //数据库安装路径； [mysqldump] //数据库导出段配置； max_allowed_packet =16M //服务器和客户端发送的最大数据包； MYSQL配置最佳实践高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能” 参考： 阿里巴巴Java开发手册 https://blog.csdn.net/jiankunking/article/details/56279259 58到家数据库30条军规解读 http://zhuanlan.51cto.com/art/201702/531364.htm]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql备份与还原（二）]]></title>
    <url>%2F2018%2F11%2Fmysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[xtrabackupPercona [官网]&lt;www.percona.com&gt; percona-server InnoDB --&gt; XtraDB Xtrabackup percona提供的mysql数据库备份工具，惟一开源的能够对innodb和xtradb数据库进行热备的工具 支持对innodb进行热备、增量备份、差量备份。 支持对myisam进行温备，因为在备份myisam表时，会对myisam表添加读锁，而且不能对myisam表进行增量备份，每次备份myisam数据都是全量，即使名义上是增量，但是实际上仍然是全量 是一种客户端工具，通过mysql协议连接mysql服务器 数据库中既有myisam表又有innodb表时，xtrabackup在备份时，会先备份inndb数据，备份完innodb数据后，再备份非innodb数据，当我们需要将备份的数据prepare时，只操作innodb数据即可，非innodb数据不用动，prepare完成后，innodb的一致性时间点与非innodb数据的一致性时间点是相同的 [手册]https://www.percona.com/doc/percona-xtrabackup/LATEST/index.html 特点： 备份还原过程快速、可靠 备份过程不会打断正在执行的事务 能够基于压缩等功能节约磁盘空间和流量 自动实现备份检验 开源，免费 安装xtrabackup 1. yum install percona-xtrabackup 在EPEL源中 2. 通过官网网站下载安装，需要解决依赖包 https://www.percona.com/downloads/XtraBackup/LATEST/ 安装2.3版本之前的XtraBackup后，我们会有两个主要的备份工具：xtrabackup与innobackupex innobackupex: Perl 脚本，它对xtrabackup这个C程序进行了封装，在备份innodb表时，此脚本会调用xtrabackup这个C程序 xtrabackup: C/C++ 编译的二进制，是专门用来备份InnoDB表的，和mysqlserver没有交互 xbcrypt 加密解密备份工具 xbstream 流传打包传输工具，类似tar 使用innobackupex进行备份，则可以备份innodb或xtradb的表，同时也能够备份myisam表 centos7默认2.4版本 xtrabackup版本升级到2.4后，相比之前的2.1有了比较大的变化： innobackupex 功能全部集成到xtrabackup里面，只有一个binary程序，另外为了兼容考虑，innobackupex作为xtrabackup的软链接，即xtrabackup现在支持非Innodb表备份，并且 Innobackupex 在下一版本中移除，建议通过xtrabackup替换innobackupex 常用选项 xtrabackup [option] PATH [选项说明]https://www.percona.com/doc/percona-xtrabackup/LATEST/genindex.html --user，用户 --password，密码 --host，备份数据库地址 --databases，数据库名，如有多个数据库，彼此需要以空格隔开 --incremental，创建一个增量备份，需要指定--incremental-basedir --increment-basedir，指定为前一次全备份或增量备份的目录 --incremental-dir：还原时增量备份的目录 --include=name，包含的表名 格式：databasename.tablename --target-dir，指定备份的路径 备份过程： 1. 整理数据库Prepare xtrabackup --prepare [options] BACKUP-PATH(新版本) innobackupex --apply-log [options] BACKUP-PATH(旧版本) --apply-log，备份完成后，无法确定备份的数据的是否包含未提交的事务或已经提交但尚未同步至数据文件的事务，此选项作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态 --use-memory，和--apply-log一起使用，指定整理数据库时的使用内存的大小,单位字节，也可1MB,1M,1G,1GB等 --redo-only，--apply-log-only(新版本)，此选项在prepare base full backup，往其中合并增量备份时候使用，但不包括对最后一个增量备份的合并 --export：表示开启可导出单独的表之后再导入其他Mysql 2. 复制数据库 xtrabackup --copy-back [options] --target-dir BACKUP-PATH(新版本) innobackupex --move-back [options] BACKUP-PATH(旧版本) --copy-back：做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir --move-back：这个选项与--copy-back相似，唯一的区别是它不拷贝文件，而是移动文件到目的地。这个选项移除backup文件，用时候必须小心。 使用场景：没有足够的磁盘空间同事保留数据文件和Backup副本 还原注意事项： 1.datadir 目录必须为空。除非指定innobackupex --force-non-emptydirectorires选项指定，否则--copy-backup选项不会覆盖 2.在restore之前,必须shutdown MySQL实例，不能将一个运行中的实例 restore到datadir目录中 3.由于文件属性会被保留，大部分情况下需要在启动实例之前将文件的属主改为mysql，这些文件将属于创建备份的用户 chown -R mysql:mysql /data/mysql 以上需要在用户调用innobackupex之前完成 --force-non-empty-directories：指定该参数时候，使得innobackupex -copy-back或--move-back选项转移文件到非空目录，已存在的文件不会被覆盖。如果--copy-back和--move-back文件需要从备份目录拷贝一个在 datadir已经存在的文件，会报错失败 生成相关文件 使用innobackupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关 于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关 文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以 时间命名的目录中,在备份时，innobackupex还会在备份目录中创建如下文件： (1)xtrabackup_info：innobackupex工具执行时的相关信息，包括版本，备份选项，备份时长，备份LSN(log sequence number日志序列号)，BINLOG的位置 (2)xtrabackup_checkpoints：备份类型（如完全或增量）、备份状态（如是否已经为 prepared状态）和LSN范围信息,每个InnoDB页(通常为16k大小)都会包含一个日志序列号LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面 最近是如何发生改变的 (3)xtrabackup_binlog_info：MySQL服务器当前正在使用的二进制日志文件及至备份 这一刻为止二进制日志事件的位置，可利用实现基于binlog的恢复 (4)backup-my.cnf：备份命令用到的配置选项信息 (5)xtrabackup_logfile：备份生成的日志文件 示例：新版xtrabackupxtrabackup完全备份及还原 1 在原主机做完全备份到/backups xtrabackup --backup --target-dir=/backups/ scp -rp /backups/ 目标主机:/backups 2 在目标主机上 1）预准备：确保数据一致，提交完成的事务，回滚未完成的事务 xtrabackup --prepare --target-dir=/backups/ 2) 停止目标主机mysql服务，并清空数据库目录 systemctl stop mariadb rm /var/lib/mysql/* -rf 3）复制到数据库目录 注意：数据库目录必须为空，MySQL服务不能启动 xtrabackup --copy-back --target-dir=/backups/ 4）还原属性 chown -R mysql:mysql /var/lib/mysql 5）启动服务 systemctl start mariadb xtrabackup完全，增量备份及还原 备份过程 1）完全备份： xtrabackup --backup --target-dir=/backups/base 2）第一次修改数据 3）第一次增量备份 xtrabackup --backup --target-dir=/backups/inc1 --incrementalbasedir=/backups/base 4）第二次修改数据 5）第二次增量 xtrabackup --backup --target-dir=/backups/inc2 --incrementalbasedir=/backups/inc1 6）备份过程目标主机生成三个备份目录 /backups/{base，inc1，inc2} scp -rp /backups/ 目标主机:/backups/ 还原过程 ：在目标主机 1）预准备完成备份，此选项--apply-log-only 阻止回滚未完成的事务 xtrabackup --prepare --apply-log-only --target-dir=/backups/base 2）合并第1次增量备份到完全备份， xtrabackup --prepare --apply-log-only --target-dir=/backups/base --incremental-dir=/backups/inc1 3）合并第2次增量备份到完全备份：最后一次还原不需要加选项--apply-log-only xtrabackup --prepare --target-dir=/backups/base --incremental-dir=/backups/inc2 4）复制到数据库目录，注意数据库目录必须为空，MySQL服务不能启动 xtrabackup --copy-back --target-dir=/backups/base 5）还原属性： chown -R mysql:mysql /var/lib/mysql 6）启动服务： systemctl start mariadb 旧版xtrabackupxtrabackup完全备份及还原 1 在原主机 innobackupex /backups scp -rp /backups/ 目标主机:/backups 2 在目标主机 1）整理数据 innobackupex --apply-log /backups/2018-02-23_11-55-57 2）停止MySQL服务，并清空MySQL数据目录 systemctl stop mariadb rm -rf /var/lib/mysql/* 3）复制数据库目录 innobackupex --copy-back /backups/2018-02-23_11-55-57 4）更改属性，并重启服务 chown -R mysql.mysql /var/lib/mysql/ systemctl start mariadb xtrabackup完全，增量备份及还原 备份过程 1 在原主机 innobackupex /backups mkdir /backups/inc{1,2} 修改数据库内容 innobackupex --incremental /backups/inc1 --incremental-basedir=/backups/2018-02-23_11-55-57（完全备份生成的路径） 再次修改数据库内容后执行 innobackupex --incremental /backups/inc2 --incremental-basedir=/backups/inc1/2018-12-11_06-02-51/（上次增量备份生成的路径） 拷贝到目标主机 scp -rp /backups/ 目标主机:/backups 还原过程 2 在目标主机 不启动mariadb rm -rf /var/lib/mysql/* 预准备完成备份 innobackupex --apply-log --redo-only /data/2018-02-23_14-21-42/ 合并第1次增量备份到完全备份 innobackupex --apply-log --redo-only /data/2018-02-23_14-21-42/ --incremental-dir=/data/inc1/2018-02-23_14-26-17 合并第2次增量备份到完全备份 innobackupex --apply-log /data/2018-02-23_14-21-42/ --incrementaldir=/data/inc2/2018-02-23_14-28-29/ 复制到数据库目录，注意数据库目录必须为空，MySQL服务不能启动 innobackupex --copy-back /data/2018-02-23_14-21-42/ 更改属性 chown -R mysql.mysql /var/lib/mysql/ systemctl start mariadb]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql备份与还原（一）]]></title>
    <url>%2F2018%2F11%2Fmysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[备份注意备份后，需要还原测试 备份类型： 完全备份，备份整个数据集 部分备份，只备份数据子集，如部分库或表 差异备份 仅备份最近一次完全备份以来变化的数据， 备份较慢，还原简单 增量备份，：仅备份最近一次完全备份或增量备份（如果存在增量）以来变化的数据,备份较快，还原复杂 注意：二进制日志文件不应该与数据文件放在同一磁盘 备份类型 冷备：读写操作均不可进行 1.停止数据库服务 2.拷贝数据文件、二进制日志等重要数据 scp -pr /data/mysql sys2:/data/mysql scp -pr /data/log sys2:/data/log 3.检查文件夹权限 chown -R mysql.mysql /var/lib/mysql 4.启动mysql 温备：读操作可执行；但写操作不可执行 热备：读写操作均可执行 MyISAM：温备，不支持热备 InnoDB：都支持 物理和逻辑备份 物理备份：直接复制数据文件进行备份，与存储引擎有关，占用较多的空间， 速度快 逻辑备份：从数据库中“导出”数据另存而进行的备份，与存储引擎无关，占用空间少，速度慢,可能丢失精度 备份时需要考虑的因素温备的持锁多久 备份产生的负载 备份过程的时长 恢复过程的时长 备份内容数据 二进制日志、InnoDB的事务日志 程序代码（存储过程、函数、触发器、事件调度器） 服务器的配置文件 备份工具cp, tar等复制归档工具：物理备份工具，适用所有存储引擎；只支持冷备；完全和部分备份 LVM的快照：先加锁，做快照后解锁，几乎热备；借助文件系统工具进行备份 mysqldump：逻辑备份工具，适用所有存储引擎，温备；支持完全或部分备份；对InnoDB存储引擎支持热备，结合binlog的增量备份 xtrabackup：由Percona提供支持对InnoDB做热备(物理备份)的工具，支持完全备份、增量备份 MariaDB Backup：从MariaDB 10.1.26开始集成，基于Percona XtraBackup 2.3.8实现 mysqlbackup：热备份， MySQL Enterprise Edition组件 mysqlhotcopy：PERL 语言实现，几乎冷备，仅适用于MyISAM存储引擎，使用LOCK TABLES、FLUSH TABLES和cp或scp来快速备份数据库 基于LVM的备份LVM快照，先加锁，做快照后解锁，几乎热备 1. 数据库文件，二进制日志文件需在lvm卷中 2. 加锁 FLUSH TABLES WITH READ LOCK; 3. 记录二进制日志文件及位置 FLUSH LOGS; SHOW MASTER STATUS; mysql -e &apos;SHOW MASTER STATUS&apos; &gt; /PATH 4. 创建快照 lvcreate -L SIZE -s -p -r -n NAME /DEV/VG_NAME/LV_NAME 例： lvcreate -L 200M -s -p r -n mysql_snap /dev/centos/mysql 5. 释放锁 UNLOCK TABLES 6. 挂载快照卷，执行数据备份 mount -o nouuid norecovery /DEV/VG_NAME/LV_SNATSHOT /MOUNTPIONT tar jcf mysqlbackup.tar.gz MOUNTPIONT/ 7. 删除快照卷 lvremove /DEV/VG_NAME/LV_SHATSHOT 8. 通过原卷备份二进制日志 set sql_log_bin=off cat /PATH 查看记录点 mysqlbinlog LOG_BIN_FILE --start-position=POSITION &gt; increment.sql mysqldump备份逻辑备份工具：mysqldump, mydumper, phpMyAdmin [mysqldump参考]https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html mysqldump 客户端命令，通过mysql协议连接至mysql服务器进行备份 mysqldump [options] database [tables] mysqldump [options] -B DB1 [DB2 DB2]... mysqldump [options] -A [OPTIONS] [options] -A，--all-databases 备份所有数据库，及存储过程和自定义函数 -B，--databases 备份指定的数据库，不含存储过程和自定义函数 -E，--events 备份相关所有的event scheduler -R, --routines：备份所有存储过程和自定义函数 --triggers：备份表相关触发器，默认启用,用--skip-triggers，不备份触发器 --default-character-set=utf8，指定备份的字符集 备份前查看数据库字符集，mysqldump --help defaults-prints查看mysqdump默认字符集 --master-data[=#]，需要启用二进制日志 1：适用于主从复制，告诉从库从哪个位置开始同步，所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1 2：记录为注释的CHANGE MASTER TO语句，只是单纯记录二进制文件位置 此选项会自动关闭--lock-tables功能，自动打开-x |--lock-all-tables功能（除 非开启--single-transaction） -F, --flush-logs：备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的 二进制日志文件，配合-A 或 -B选项时，会导致刷新多次数据库。建议在同一时刻执行转储和日志刷新，可通过和--single-transaction或-x，--master-data一起使用实现，此时只刷新一次日志 --compact 去掉注释，适合调试，生产不使用 -d, --no-data 只备份表结构 -t, --no-create-info 只备份数据,不备份create table -n,--no-create-db 不备份create database，可被-A或-B覆盖 --flush-privileges 备份mysql或相关时需要使用 -f, --force 忽略SQL错误，继续执行 --hex-blob 使用十六进制符号转储二进制列，当有包括BINARY，VARBINARY，BLOB，BIT的数据类型的列时使用，避免乱码 -q, --quick 不缓存查询，直接输出，加快备份速度 示例： mysqldump hellodb &gt;bak.sql 此条语法不会备份数据库结构 mysqldump -B hellodb &gt; bak.sql mysqldump -A &gt; all_bak.sql mysqldump -uroot --single-transaction --database hellodb &gt; bak4.sql mysqldump -A --master-data=1 &gt; bak3.sql ！ MyISAM备份选项： 支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作 锁定方法如下： -x,--lock-all-tables：加全局读锁，锁定所有库的所有表，同时加--single-transaction或--lock-tables选项会关闭此选项功能 注意：数据量大时，可能会导致长时间无法并发访问数据库 -l,--lock-tables：对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,--skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能 会造成数据不一致 注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用 建议备份策略 mysqldump -uroot -A -F -x --master-data=1 --default-character-set=utf8 --hex-blob &gt;PATH InnoDB备份选项： 支持热备，可用温备但不建议用 --single-transaction 此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执 行START TRANSACTION指令开启事务 此选项通过在单个事务中转储所有表来创建一致的快照。仅适用于存储在支持多版本控制的存储引擎中的表（目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。在进行单事务转储时，要确保有效的转储文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE， DROP TABLE，RENAME TABLE，TRUNCATE TABLE 此选项和--lock-tables（此选项隐含提交挂起的事务）选项是相互排斥备份大型表时,建议将--single-transaction选项和--quick结合一起使用 建议备份策略 mysqldump -uroot -A -F --single-transaction --flush-privileges --default-character-set=utf8 --master-data=2 --hex-blob &gt;PATH 分库备份脚本12345#!/bin/bashfor db in `mysql -e 'show databases' |grep -Ev '^(Database|information_schema|performance_schema)$'`do mysqldump -B $db|gzip &gt; $db`date +%F`.sql.gzdone 1mysql -e 'show databases' |grep -Ev '^(Database|information_schema|performance_schema)$'|sed -r 's/(.*)/mysqldump -B \1 |gzip &gt; \/data\/\1.sql.gz/' |bash 1mysqldump –uroot –A –F --single-transaction --master-data=2 --default-character-set=utf8 --hex-blob &gt;$BACKUP/fullbak_$BACKUP_TIME.sql 使用mysqldump备份恢复1.使用策略禁止用户访问，防止用户读取或写入错误数据 2，恢复数据会产生大量的insert语句，没有必要记录到二进制日志中，需要关闭当前二进制日志记录 mysql &gt; set sql_log_bin=off 使用完全备份进行恢复 mysql &gt; source /root/bak5.sql 3. 新开终端查看备份的位置 cat /root/bak5.sql |less --CHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000007&apos;, MASTER_LOG_POS=245; cat /root/bak5.sql |less 5 在新终端，通过上个备份时间点，进行时间点恢复，备份时间点后的数据的二进制日志将其备份到文件，进行还原， 例如：备份文件为bak6.sql，某人误操作drop数据库，所以备份结束位置应该是drop语句的位置，不要将drop语句提取出来 6 返回旧终端 mysql&gt;source bak6.sql 7.开启二进制 set sql_log_bin=on; 8 检查无误后，恢复用户访问]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql多实例]]></title>
    <url>%2F2018%2F11%2Fmysql%E5%A4%9A%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[mariadb 多实例1.创建目录并修改权限 mkdir /mysql/{3306,3307,3308}/{etc,socket,pid,log,data} -pv chown -R mysql.mysql /mysql/ 2.创建数据库信息 cd /usr/local/mysql #mysql存放位置 scripts/mysql_install_db --datadir=/mysql/3306/data --user=mysql scripts/mysql_install_db --datadir=/mysql/3307/data --user=mysql scripts/mysql_install_db --datadir=/mysql/3308/data --user=mysql 3.修改配置文件 cp /etc/my.cnf /mysql/3306/etc/ #修改以下信息 vim /mysql/3306/etc/my.cnf [mysqld] port=3306 datadir=/mysql/3306/data socket=/mysql/3306/socket/mysql.sock [mysqld_safe] log-error=/mysql/3306/log/mariadb.log pid-file=/mysql/3306/pid/mariadb.pid #!includedir /etc/my.cnf.d 4.启动脚本mysqld 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/bin/bash#chkconfig: 345 80 2port=3306mysql_user="root"mysql_pwd=""cmd_path="/usr/local/mysql/bin"mysql_basedir="/mysql"mysql_sock="$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting MySQL...\n" $&#123;cmd_path&#125;/mysqld_safe --defaults-file=$&#123;mysql_basedir&#125;/$&#123;port&#125;/etc/my.cnf &amp;&gt; /dev/null &amp; else printf "MySQL is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "MySQL is stopped...\n" exit else printf "Stoping MySQL...\n" $&#123;cmd_path&#125;/mysqladmin -u $&#123;mysql_user&#125; -p$&#123;mysql_pwd&#125; -S $&#123;mysql_sock&#125; shutdown fi&#125;function_restart_mysql()&#123; printf "Restarting MySQL...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf "Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n"esac 拷贝到对应目录 cp mysqld /mysql/3306/ cp mysqld /mysql/3307/ cp mysqld /mysql/3308/ 修改权限 chmod +x /mysql/3306/mysqld chmod +x /mysql/3307/mysqld chmod +x /mysql/3308/mysqld 启动服务 /mysql/3306/mysqld start /mysql/3307/mysqld start /mysql/3308/mysqld start 安全加固 /usr/local/mysql/bin/mysql_secure_installation -S /mysql/3308/socket/mysql.sock 添加启动服务 cp /mysql/3308/mysqld /etc/init.d/mysql3308 chkconfig --list chkconfig --add mysqld3308 连接数据库 mysql -uroot -S /mysql/3307/socket/mysql.sock 或 mysql -uroot -h 127.0.0.1 -P 3307 #在mariadb内输入 show variables like &apos;%port%&apos;;]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从复制]]></title>
    <url>%2F2018%2F11%2Fmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL扩展方式1. 横向扩展 2. 纵向扩展 MySQL扩展 1. 读写分离，分开读服务器和写服务器 2. 复制:每个节点都有相同的数据集 向外扩展 二进制日志 单向 复制的功用： 数据分布 负载均衡读 备份 高可用和故障切换 MySQL升级测试 复制的架构1. 一主一从 2. 一主多从 3. 一主一从，此从还有从服务器 4. 主主 5. 多主一从 6. 环状复制 主从复制原理 1. 主服务器收到用户的写数据库的操作，产生数据更新 2. 将更新操作写入bin log二进制日志中 3. 主服务器使用dump tread读出二进制日志的更新操作 4. 通过网络传输到从服务器， 5. 从服务器接收到后，从服务通过I/O thread将此更新的操作写入relay log中 6. 从服务器写入日志后，通过sql thread更新本机的数据库文件，完成数据主从服务器的数据库的同步 主从复制特点 异步复制 主从数据不一致较常见 复制需要考虑二进制日志事件记录格式 STATEMENT（5.0之前） ROW（5.1之后，推荐） MIXED 主从复制线程： 主节点： dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events 从节点： I/O Thread：向Master请求二进制日志事件，并保存于中继日志中 SQL Thread：从中继日志中读取日志事件，在本地完成重放 跟复制功能相关的文件： master.info：用于保存slave连接至master时的相关信息，例如账号、密码、服务器地址等 relay-log.info：保存在当前slave节点上已经复制的当前二进制日志和本地replay log日志的对应关系 主从复制的实现过程[主从配置过程:官网]https://mariadb.com/kb/en/library/setting-up-replication/https://dev.mysql.com/doc/refman/5.5/en/replication-configuration.html 主服务器 1. 启动二进制日志 [mysqld] log-bin=/PATH/LOG_BIN_FILENAME server-id=1 2. 主服务器授权复制账号 GRANT REPLICATION SLAVE ON *.* TO &apos;repluser&apos;@&apos;192.168.80.%&apos; IDENTIFIED BY &apos;centos&apos;; 查看二进制文件及位置 show master logs; 从服务器 1. 启动中继日志 [mysqld] relay-log=/PATH 可选，relay log的文件路径，默认值hostname-relay-bin server-id=2 为当前节点设置一个全局惟的ID号 read_only=ON 设置数据库只读 relay_log_index=relay-log.index 可选，默认值hostname -relay-bin.index 2. 使用有复制权限的用户账号连接至主服务器， mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;master_host_name&apos;, MASTER_USER=&apos;replication_user_name&apos;, MASTER_PASSWORD=&apos;replication_password&apos;, MASTER_LOG_FILE=&apos;recorded_log_file_name&apos;, MASTER_LOG_POS=recorded_log_position; 3.启动复制线程，后续自动启动 mysql &gt; START SLAVE[I/O THERAD|SQL_THREAD]; 查看从服务器状态及进程 SHOW SLAVE STATUS \G show processlist\G 如果主服务器运行一段时间，产生了大量了数据，可通过以下方式配置并启动从服务器 1. 通过备份恢复数据至从服务器 mysqldump -A -F --single-transaction --master-data=1 &gt; /PATH/Filename 2. 将此备份的数据复制到从服务器,复制起始位置为备份时，二进制日志文件及其POS scp -p /PATH/FILENAME &apos;USER&apos;@&apos;SLAVE_HOST_IP&apos;:/PATH 3.更改my.cnf server-id=# 为当前节点设置一个全局惟的ID号 read_only=ON systemctl start mariadb.service mysql &lt; bak7.sql mysql &gt; START SLAVE 重置从服务器 RESET SLAVE，在从服务器清除master.info ，relay-log.info, relay log ，开始新的relay log，注意：需要先STOP SLAVE RESET SLAVE ALL，清除所有从服务器上设置的主服务器同步信息如：PORT, HOST, USER和 PASSWORD等 一个主，两个从，主down机，将一个从作为新主 主从级联复制master复制到slave，从在复制到另一个slave 如果要启用级联复制,需要在中间从服务器启用以下配置 [mysqld] server-id=2 read_only=ON log_bin log_slave_updates 复制架构中应该注意的问题 低版本到高版本可以，但是高版本不能往低版本同步 binlog记录模式，例如：row 模式就比默认的语句要好 1. 限制从服务器为只读 注意：此设置对super权限用户无效 2. 当发生复制错误时从服务器忽略几个主服务器的复制事件，是个global变量 stop slave； #临时停止同步开关 set global sql_slave_skip_counter =N； #将同步指针向下移动N个 start slave； 3. 主从复制事务的安全 []&lt;https://mariadb.com/kb/en/library/server-system-variables/ &gt; 在主服务器启用如下参数 sync_binlog=1 每次写后立即同步二进制日志到磁盘，性能差 如果用到的为InnoDB存储引擎: innodb_flush_log_at_trx_commit=1 每次事务提交立即同步日志写磁盘 innodb_support_xa=on 默认值，分布式事务MariaDB10.3.0废除 sync_master_info=# #次事件后master.info同步到磁盘 在slave节点启用服务器选项： skip_slave_start=ON 不自动启动slave 在slave节点启用参数： sync_relay_log=# #次写后同步relay log到磁盘 sync_relay_log_info=# #次事务后同步relay-log.info到磁盘 主主复制的实现过程互为主从 容易产生的问题：数据不一致；因此慎用 1. 主服务器启动二进制日志 [mysqld] log-bin=/PATH/LOG_BIN_FILENAME relay-log server-id=1 auto_increment_offset=1 //起始点 auto_increment_increment=2 //增长幅度 2. 主服务器创建授权账号 GRANT REPLCATION SLAVE ON *.* TO &apos;repluser&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;replpass&apos;; 3. 另外一台主服务器启动二进制日志 [mysqld] log-bin=/PATH/LOG_BIN_FILENAME relay-log server-id=2 auto_increment_offset=2 auto_increment_increment=2 4. 均把对方指定为主节点，并启动复制线程 另外一台主服务器启动复制进程 mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;HOST&apos; MASTER_USER=&apos;repluser&apos; MASTER_PASSWORD=&apos;replpass&apos; MASTER_LOG_FILE=&apos;MASTER_BIN&apos; MASTER_LOG_POS=#; mysql&gt; START SLAVE; 主服务器启动复制进程 MySQL&gt; CHANGE MASTER TO MASTER_HOST=&apos;HOST&apos; MASTER_USER=&apos;repluser&apos; MASTER_PASSWORD=&apos;replpass&apos; MASTER_LOG_FILE=&apos;MASTER_BIN&apos; MASTER_LOG_POS=#; mysql&gt; START SLAVE; 半同步复制默认情况下，MySQL的复制功能是异步的，异步复制可以提供最佳的性能，主库把binlog日志发送给从库即结束，并不验证从库是否接收完毕。这意味着当主服务器或从服务器端发生故障时，有可能从服务器没有接收到主服务器发送过来的binlog日志，这就会造成主服务器和从服务器的数据不一致，甚至在恢 复时造成数据的丢失 只要一个从服务器复制成功，就返回给客户端操作成功 类似主从配置方法，原基础增加如下 查看插件 show plugins 1. 主服务器配置启动半同步插件 mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME &apos;semisync_master.so&apos;; mysql&gt; SET GLOBAL rpl_semi_sync_master_enabled=1; 开启 mysql&gt; SET GLOBAL rpl_semi_sync_master_timeout=1000;超时时长1s [mysqld] server-id=1 log-bin=/PATH/LOG_BIN_FILENAME 2. 从服务器启动半同步插件 mysql&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME &apos;semisync_slave.so&apos;; mysql&gt; SET GLOBAL rpl_semi_sync_slave_enabled=1; [mysqld] server-id=2 read_only=ON 3. 在主服务器查看半同步的状态 mysql&gt; SHOW GLOBAL VARIABLE LIKE &apos;%semi%&apos;; mysql&gt; SHOW GLOBAL STATUS LIKE &apos;%semi%&apos;; 复制过滤器从节点只复制指定的数据库或数据表 实现方式 (1) 服务器选项：主服务器仅向二进制日志中记录与特定数据库相关的事件 注意：此项和binlog_format相关 [参看]https://mariadb.com/kb/en/library/mysqld-options/#-binlogignore-db binlog_do_db= //数据库白名单列表，多个数据库需多行实现 binlog_ignore_db= //数据库黑名单列表 注意：这样实现方式会导致二进制还原将无法实现 (2) 从服务器SQL_THREAD在replay中继日志中的事件时，仅读取与特定数据库(特定表)相关的事件并应用于本地 问题：会造成网络及磁盘IO浪费 2. 从服务器实现复制过滤器选项，仅读取与特定数据库(特定表)相关的事件并应用于本地 注意：这样实现方式会导致网络和磁盘IO的浪费 replicate_do_db= 指定复制库的白名单 replicate_ignore_db= 指定复制库黑名单 replicate_do_table= 指定复制表的白名单 replicate_ignore_table= 指定复制表的黑名单 replicate_wild_do_table= test%.stu% 支持通配符 replicate_wild_ignore_table=]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql事务及并发控制]]></title>
    <url>%2F2018%2F11%2Fmysql%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[事务事务Transactions：一组原子性的SQL语句，或一个独立工作单元。 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个 人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等， 这样，这些数据库操作语句就构成一个事务 事务日志：记录事务信息，实现undo,redo等故障恢复功能 ACID特性： A：atomicity原子性； 整个事务中的所有操作要么全部成功执行，要么全部失败后回滚，不可能停滞在中间某个环节。 C：consistency一致性； 数据库总是从一个一致性状态转换为另一个一致性状态 如果事务是并发多个，系统也必须如同串行事务一样操作。其主要特征是保护性和不变性(Preserving an Invariant) 假设有三个账户，每个账户余额是10元，那么三个账户总额是30元，如果在这个3个账户之间同时发生多个转账，无论并发多少个，比如在A与B账户之间转账5元，在b与c账户之间转账10元，三个账户总额也应该还是30元，这就是保护性和不变性 I：Isolation隔离性； 一个事务所做出的操作在提交之前，是不能为其它事务所见；隔离有多种隔离级别，实现并发。 如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。 D：durability持久性； 一旦事务提交，其所做的修改会永久保存于数据库中 事务控制语句：启动事务： BEGIN 或 START TRANSACTION 显式地开启一个事务 结束事务： COMMIT：提交 ROLLBACK: 回滚 注意：只有事务型存储引擎中的DML语句方能支持此类操作 自动提交：set autocommit={1|0} 默认为1，为0时设为非自动提交 建议：显式请求和提交事务，而不要使用“自动提交”功能 事务支持保存点：savepoint 需设置set autocommit=0 SAVEPOINT identifier #SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT ROLLBACK TO identifier 把事务回滚到标记点 RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常 实现MySQL事务处理：方法一：用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 方法二：直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=OFF 禁止自动提交 SET AUTOCOMMIT=ON 开启自动提交（系统默认项） 示例：事务测试 事务隔离级别事务并发问题： 1.脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。 3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表 在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。 在标准SQL规范中，定义了4个事务隔离级别，不同的隔离级别对事务的处理不同。 从上至下更加严格： READ UNCOMMITTED：可读取到未提交数据，产生脏读 READ COMMITTED：可读取到提交数据，但未提交数据不可读，产生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致 REPEATABLE READ 可重复读，多次读取数据都一致，产生幻读，即读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改前的旧数据。此为MySQL默认设置 SERIALIZABILE 可串行化，未提交的读事务阻塞修改事务，或者未提交的修改事务阻塞读事务。导致并发性能差 MVCC-多版本的并发控制协议MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC(Multi-VersionConcurrency Control)，它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能 管理事务隔离级别：查看事务隔离级别 show global variables like &quot;%isolation%&quot;; 服务器变量tx_isolation指定，默认为REPEATABLE-READ，可在GLOBAL和SESSION级进行设置 SET tx_isolation=” READ-UNCOMMITTED READ-COMMITTED REPEATABLE-READ SERIALIZABLE 服务器选项中指定 vim /etc/my.cnf [mysqld] transaction-isolation=SERIALIZABLE 并发控制锁粒度： 表级锁 行级锁 锁： 读锁：共享锁，只读不可写，多个读互不阻塞， 写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁 实现： 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 锁策略：在锁粒度及数据安全性寻求的平衡机制 显示使用锁 LOCK TABLES tbl_name [[AS] alias] lock_type lock_type: READ ， WRITE FLUSH TABLES [tbl_name] [WITH READ LOCK] 关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁 SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] 查询时加写或读锁 1. select *** for update 的使用场景 为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。 2. select *** lock in share mode 使用场景 为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。 查看当前有那些表是打开的 show open tables show OPEN TABLES where In_use &gt; 0; 这个语句记录当前锁表状态 显示哪些线程正在运行,以及被锁的表 SHOW PROCESSLIST\G show full processlist mysqladmin processlist 然后 kill id UNLOCK TABLES 解锁 读锁： 读锁也称为共享锁，读锁允许多个连接可以同一时刻并发的读取同一资源,互不干扰； 写锁： 写锁也称为排他锁，一个写锁会阻塞其他的写锁或读锁，保证同一时刻只有一个连接可以写入数据，同时防止其他用户对这个数据的读写。 死锁： 两个或多个事务在同一资源相互占用并请求锁定对方占用的资源的状态 如下所示： 事务1 事务2 update table1 update table2 update table2 update table1 产生死锁]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql查询缓存]]></title>
    <url>%2F2018%2F11%2Fmysql%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[mysql架构 查询执行路径 查询缓存（ Query Cache ）原理 缓存SELECT操作或预处理查询的结果集和SQL语句，当有新的SELECT语句或预处理查询语句请求，先去查询缓存，判断是否存在可用的记录集，判断标准：与缓存的SQL语句，是否完全一样，区分大小写 优缺点: 不需要对SQL语句做任何解析和执行，当然语法解析必须通过在先，直接从 Query Cache中获得查询结果，提高查询性能 查询缓存的判断规则，不够智能，也即提高了查询缓存的使用门槛，降低其效率； 查询缓存的使用，会增加检查和清理Query Cache中记录集的开销 哪些查询可能不会被缓存 查询语句中加了SQL_NO_CACHE参数 查询语句中含有获得值的函数，包含自定义函数， 如：NOW()、CURDATE()、GET_LOCK()、RAND()、CONVERT_TZ()等 对系统数据库的查询：mysql、information_schema 查询语句中使用SESSION级别变量或存储过程中的局部变量 查询语句中使用了LOCK IN SHARE MODE、FOR UPDATE的语句，查询语句中类似SELECT …INTO导出数据的语句 对临时表的查询操作；存在警告信息的查询语句；不涉及任何表或视图的查询语句；某用户只有列级别权限的查询语句 事务隔离级别为Serializable时，所有查询语句都不能缓存 查询缓存相关的服务器变量 query_cache_min_res_unit：查询缓存中内存块的最小分配单位，默认4k，较小值会减少浪费，但会导致更频繁的内存分配操作，较大值会带来浪费，会导致碎片过多，内存不足 query_cache_limit：单个查询结果能缓存的最大值，默认为1M，对于查询结果过大而无法缓存的语句，建议使用SQL_NO_CACHE query_cache_size：查询缓存总共可用的内存空间；单位字节，必须是1024的整数倍，最小值40KB，低于此值有警报 query_cache_wlock_invalidate：如果某表被其它的会话锁定，是否仍然可以从查询缓存中返回结果，默认值为OFF，表示可以在表被其它会话锁定的场景中继续从缓存返回数据；ON则表示不允许 query_cache_type：是否开启缓存功能，取值为ON, OFF, DEMAND SELECT语句的缓存控制 SQL_CACHE：显式指定存储查询结果于缓存之中 SQL_NO_CACHE：显式查询结果不予缓存 query_cache_type参数变量 query_cache_type的值为OFF或0时，查询缓存功能关闭 query_cache_type的值为ON或1时，查询缓存功能打开，SELECT的结果符合缓存条件即会缓存，否则，不予缓存，显式指定SQL_NO_CACHE，不予缓存，此为默认值 query_cache_type的值为DEMAND或2时，查询缓存功能按需进行，显式指定SQL_CACHE的SELECT语句才会缓存；其它均不予缓存 [参看]&lt;https://mariadb.com/kb/en/library/server-system-variables/#query_cache_type https://dev.mysql.com/doc/refman/5.7/en/query-cache-configuration.html&gt; 优化查询缓存 查询缓存相关的状态变量：SHOW GLOBAL STATUS LIKE ‘Qcache%&apos;; Qcache_free_blocks：处于空闲状态Query Cache中内存Block数 Qcache_total_blocks：Query Cache中总Block，当Qcache_free_blocks相对此值较大时，可能用内存碎片，执行FLUSH QUERY CACHE清理碎片 Qcache_free_memory：处于空闲状态的 Query Cache内存总量 Qcache_hits：Query Cache 命中次数 Qcache_inserts：向QueryCache中插入新的 Query Cache的次数，即没有命中的次数 Qcache_lowmem_prunes：记录因为内存不足而被移除出查询缓存的查询数 Qcache_not_cached：没有被Cache的SQL数，包括无法被Cache的SQL以及由于query_cache_type设置的不会被Cache的SQL语句 Qcache_queries_in_cache：在 Query Cache中的SQL数量 命中率和内存使用率估算 查询缓存中内存块的最小分配单位query_cache_min_res_unit：(query_cache_size - Qcache_free_memory) / Qcache_queries_in_cache 查询缓存命中率 ：Qcache_hits / ( Qcache_hits + Qcache_inserts ) * 100% 查询缓存内存使用率：(query_cache_size – qcache_free_memory) /query_cache_size * 100% InnoDB存储引擎的缓冲池: 通常InnoDB存储引擎缓冲池的命中不应该小于99% 查看相关状态变量： show global status like &apos;innodb%read%&apos;\G Innodb_buffer_pool_reads: 表示从物理磁盘读取页的次数 Innodb_buffer_pool_read_ahead: 预读的次数 Innodb_buffer_pool_read_ahead_evicted:预读页，但是没有读取就从缓冲池中被替换的页数量，一般用来判断预读的效率 Innodb_buffer_pool_read_requests: 从缓冲池中读取页次数 Innodb_data_read: 总共读入的字节数 Innodb_data_reads: 发起读取请求的次数，每次读取可能需要读取多个页 Innodb缓冲池命中率计算： 平均每次读取的字节数]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql日志]]></title>
    <url>%2F2018%2F11%2Fmysql%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[日志事务日志 transaction log 错误日志 error log 通用日志 general log 慢查询日志 slow query log 二进制日志 binary log 中继日志 reley log 事务日志事务日志默认为顺序地的追加进事务日志文件，ib_logfile0,ib_logfile1 查看事务日志变量 SHOW VARIABLES LIKE &apos;innodb_log&apos; innodb_log_file_size 默认为5M，每个日志文件大小 innodb_log_file_in_group 2，日志组成员 innodb_log_group_home_dir ./，事务日志文件路径 innodb_flush_log_at_trx_commit ，事务日志刷新到磁盘的定义，默认为1 innodb_flush_log_at_trx_commit 说明：设置为1，同时sync_binlog = 1表示最高级别的容错 innodb_use_global_flush_log_at_trx_commit的值确定是否可以使用SET语句 重置此变量 1默认情况下，日志缓冲区将写入日志文件，并在每次事务后执行刷新到磁盘。这是完全遵守ACID特性 0提交时没有任何操作; 而是每秒执行一次日志缓冲区写入和刷新。这样可以提供更好的性能，但服务器崩溃可以清除最后一秒的事务 2每次提交后都会写入日志缓冲区，但每秒都会进行一次刷新。性能比0略好一些，但操作系统或停电可能导致最后一秒的交易丢失 3模拟MariaDB 5.5组提交（每组提交3个同步），此项MariaDB 10.0支持 优化 错误日志错误日志 mysqld启动和关闭过程中输出的事件信息 mysqld运行中产生的错误信息 event scheduler运行一个event时产生的日志信息 在主从复制架构中的从服务器上启动从服务器线程时产生的信息 错误日志相关配置 SHOW GLOBAL VARIABLES LIKE &apos;log_error&apos; 错误文件路径 log_error=/PATH/TO/LOG_ERROR_FILE 是否记录警告信息至错误日志文件 log_warnings=1|0 默认值1 通用日志通用日志：记录对数据库的通用操作，包括错误的SQL语句 文件：file，默认值 表：table 通用日志相关设置 SHOW GLOBAL VARIABLES LIKE &apos;general%&apos;; SHOW GLOBAL VARIABLES LIKE &apos;log_out%&apos;; 相关设置 general_log=ON|OFF general_log_file=HOSTNAME.log log_output=TABLE|FILE|NONE TABLE：将语句操作记录在mysql.general_log表里 FILE： 将语句操作记录在数据目录下 慢查询日志记录执行查询时长超出指定时长的操作 show profiles //查看慢查询的所有编号 show profile for query 5 //查询指定慢查询编号的详细执行过程 SHOW GLBOAL VARIABLES LIKE &apos;show_query_log&apos; 相关的设置： slow_query_log=ON|OFF 开启或关闭慢查询 long_query_time=N 慢查询的阀值，单位秒 slow_query_log_file=HOSTNAME-slow.log 慢查询日志文件 log_show_filter=admin,filesort,filesort_on_disk,full_join,full_scan,query_cache,query_cache_miss,tmp_table,tmp_table_on_disk 上述查询类型且查询时长超过long_query_time，则记录日志 log_queries_not_using_indexes=ON 不使用索引或使用全索引扫描，不论是否达到慢查询阀值的语句是否记录日志，默认OFF，即不记录 log_slow_rate_limit = 1 多少次查询才记录，mariadb特有 log_slow_verbosity= Query_plan,explain 记录内容 二进制日志二进制日志 记录导致数据改变或潜在导致数据改变的SQL语句 记录已提交的日志 不依赖于存储引擎类型 功能：通过“重放”日志文件中的事件来生成数据副本 注意：建议二进制日志和数据文件分开存放 中继日志：relay log 主从复制架构中，从服务器用于保存从主服务器的二进制日志中读取的事件 二进制日志记录三种格式 基于“语句”记录：statement，记录语句，默认模式 基于“行”记录：row，记录数据，日志量较大 混合模式：mixed, 让系统自行判定该基于哪种方式进行 查看二进制日志记录格式 SHOW VARIABLES LIKE &apos;binlog_format&apos; 二进制日志文件的构成 有两类文件 日志文件：mysql|mariadb-bin.文件名后缀，二进制格式 如： mariadb-bin.000001 索引文件：mysql|mariadb-bin.index，文本格式 查看mariadb自行管理使用中的二进制日志文件列表，及大小 SHOW {BINARY | MASTER} LOGS 查看使用中的二进制日志文件 SHOW MASTER STATUS 查看二进制文件中的指定内容 SHOW BINLOG EVENTS [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] [row_count] show binlog events in ‘mysql-bin.000001&apos; from 6516 limit 2,3 手动刷新二进制日志,重新生成 FLUSH logs 相关的配置： sql_log_bin={on|off}，默认为ON log_bin=/PATH/LOG_BIN_FILENAME，默认为off，只有在配置文件中写入该选项才能启用二进制日志 binlog_format={statement|row|mixed} max_binlog_size=默认为1G，当日志文件到达其值时自动滚动 说明：文件达到上限时的大小未必为指定的精确值 sync_binlog={1|0}，二进制日志即时同步磁盘功能，默认为0，由操作系统负责同步日志到磁盘 expire_logs_days=N，二进制日志可以自动删除的天数。 默认为0，即不自动删除 mysqlbinlog 二进制日志的客户端命令工具 mysqlbinlog [option] LOG_BIN_FILE [option] -v，显示二进制日志文件命令的详细信息 --start-position，开始的位置 --stop-position，停止的位置 --start-datetime，开始的时间点，时间格式：YYYY-MM-DD hh:mm:ss --stop-datetime，停止的时间点 示例： mysqlbinlog /var/lib/mysql/bin.000003 -v mysqlbinlog --start-position=6787 --stop-position=7527 /var/lib/mysql/bin.000003 -v mysqlbinlog --start-datetime=&quot;2018-12-09 16:20:10&quot; --stop-datetime=&quot;2018-12-09 16:30:00&quot; bin.000009 -v 清除指定二进制日志 PURGE BINARY LOGS TO &apos;LOG_BIN_FILENAME&apos;; 示例： PRUGE BINARY LOGS TO &apos;mysql-bin.000002&apos; ;删除2之前的日志 PURGE BINARY LOGS BEFORE &apos;2017-01-23&apos;; PURGE BINARY LOGS BEFORE &apos;2017-03-22 09:25:30&apos;; 删除所有的日志 RESET MASTER [TO #]，文件名从#开始记数，默认从1开始，一般是master主机第一次启动时执行，MariaDB10.1.6开始支持TO #]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql数据类型]]></title>
    <url>%2F2018%2F11%2Fmysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[https://dev.mysql.com/doc/refman/5.5/en/data-types.html 选择正确的数据类型对于获得高性能至关重要，三大原则： 更小的通常更好，尽量使用可正确存储数据的最小数据类型 简单就好，简单数据类型的操作通常需要更少的CPU周期 尽量避免NULL，包含为NULL的列，对MySQL更难优化 mySQL中定义数据字段的类型对你数据库的优化是非常重要的。 MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型 数值类型1、整型 MySQL数据类型 含义（有符号） tinyint(m) 1个字节 范围(-128~127) smallint(m) 2个字节 范围(-32768~32767) mediumint(m) 3个字节 范围(-8388608~8388607) int(m) 4个字节 范围(-2147483648~2147483647) bigint(m) s 8个字节 范围(+-9.22*10的18次方) 取值范围如果加了unsigned，则最大值翻倍，如tinyint unsigned的取值范围为(0~255) int(m)里的m是表示SELECT查询结果集中的显示宽度，并不影响实际的取值范围，规定了MySQL的一些交互工具（例如MySQL命令行客户端）用来显示字符的个数。对于存储和计算来说，Int(1)和Int(20)是相同的 2、浮点型(float和double) MySQL数据类型 含义 float(m,d) 单精度浮点型 8位精度(4字节) m总个数，d小数位 double(m,d) 双精度浮点型 16位精度(8字节) m总个数，d小数位 设一个字段定义为float(6,3)，如果插入一个数123.4567,实际数据库里存的是123.456，但总个数还以实际为准，即6位 3、定点数 浮点型在数据库中存放的是近似值，而定点类型在数据库中存放的是精确值。在数据库中存放的是精确值,存为十进制 decimal(m,d) 参数m&lt;65 是总个数，d&lt;30且 d&lt;m 是小数位 MySQL5.0和更高版本将数字打包保存到一个二进制字符串中（每4个字节存9个数字）。例如，decimal(18,9)小数点两边将各存储9个数字，一共使用9个字节：小数点前的数字用4个字节，小数点后的数字用4个字节，小数点本身占1个字节 浮点类型在存储同样范围的值时，通常比decimal使用更少的空间。float使用4个字节存储。double占用8个字节 因为需要额外的空间和计算开销，所以应该尽量只在对小数进行精确计算时才使用decimal——例如存储财务数据。但在数据量比较大的时候，可以考虑使用bigint代替decimal 4、字符串(char,varchar,_text) MySQL数据类型 含义 char(n) 固定长度，最多255个字符 varchar(n) 可变长度，最多65535个字符 tinytext 可变长度，最多255个字符 text 可变长度，最多65535个字符 mediumtex 可变长度，最多2的24次方-1个字符 longtext 可变长度，最多2的32次方-1个字符 BINARY(M) 固定长度，可存二进制或字符，长度为0-M字节 char和varchar： 区别 值 CHAR(4) 存储需求 VARCHAR(4) 存储需求 ‘’ ‘ ‘ 4个字节 ‘’ 1个字节 ‘ab’ ‘ab ‘ 4个字节 ‘ab ‘ 3个字节 ‘abcd’ ‘abcd’ 4个字节 ‘abcd’ 5个字节 ‘abcdefgh’ ‘abcd’ 4个字节 ‘abcd’ 5个字节 请注意上表中最后一行的值只适用不使用严格模式时；如果MySQL运行在严格模式，超过列长度不的值不保存，并且会出现错误 1.char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉, 所以char类型存储的字符串末尾不能有空格，varchar不限于此 2.char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar是存入的实际字符数+1个字节（n&lt; n&gt;255)，所以varchar(4),存入3个字符将 占用4个字节 3.char类型的字符串检索速度要比varchar类型的快 varchar和text： 1.varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个字节（n&lt; n&gt;255)，text是实际字符数+2个字节。 2.text类型不能有默认值 3.varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速度快于text 5.二进制数据(_Blob) BLOB和text存储方式不同，TEXT以文本方式存储，英文存储区分大小写，而Blob是以二进制方式存储，不分大小写 BLOB存储的数据只能整体读出 TEXT可以指定字符集，BLOB不用指定字符集 6.日期时间类型 MySQL数据类型 含义 date 日期 ‘2008-12-2’ time 时间 ‘12:25:36’ datetime 日期时间 ‘2008-12-2 22:06:44’ timestamp 自动存储记录修改时间 YEAR(2), YEAR(4) 年份 timestamp字段里的时间数据会随其他字段修改的时候自动刷新，这个数据类型的字段可以存放这条记录最后被修改的时间]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql视图、函数、存储过程、触发器]]></title>
    <url>%2F2018%2F11%2Fmysql%E8%A7%86%E5%9B%BE%E3%80%81%E5%87%BD%E6%95%B0%E3%80%81%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E3%80%81%E8%A7%A6%E5%8F%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[视图视图：VIEW,虚表，保存有实表的查询结果 创建方法： CREATE VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION] 查看视图定义： SHOW CREATE VIEW view_name 删除视图： DROP VIEW [IF EXISTS] view_name [, view_name] ... [RESTRICT | CASCADE] 视图中的数据事实上存储于“基表”中，因此，其修改操作也会针对基表实现；其修改操作受基表限制 函数系统函数和自定义函数 [系统函数]https://dev.mysql.com/doc/refman/5.7/en/func-op-summaryref.html 自定义函数 (user-defined function UDF) 保存在mysql.proc表中 创建UDF CREATE [AGGREGATE] FUNCTION function_name(parameter_name type,[parameter_name type,...])RETURNS {STRING|INTEGER|REAL} runtime_body 说明： 参数可以有多个,也可以没有参数 必须有且只有一个返回值 参数可以有多个，也可以没有 示例无参数： create function hellofun() returns varchar(20) return &apos;hello word!&apos;; 示例有参数： DELIMITER // #避免遇到；就执行，让所有语句作为一个整体执行，用//代替；的含义 CREATE FUNCTION deleteById(uid SMALLINT UNSIGNED) RETURNS VARCHAR(20) BEGIN DELETE FROM students WHERE stuid = uid; RETURN (SELECT COUNT(stuid) FROM students); END // #到最后想执行就加上// DELIMITER ; #用于向 MySQL 提交查询语句 自定义函数中定义局部变量语法 DECLARE 变量1[,变量2,... ]变量类型 [DEFAULT 默认值] 说明：局部变量的作用范围是在BEGIN...END程序中,而且定义局部变量语句必须在BEGIN...END的第一行定义 示例： DELIMITER // CREATE FUNCTION addTwoNumber(x SMALLINT UNSIGNED, Y SMALLINT UNSIGNED) RETURNS SMALLINT BEGIN DECLARE a, b SMALLINT UNSIGNED; SET a = x, b = y; RETURN a+b; END// DELIMITER ; 为变量赋值语法 SET parameter_name = value[,parameter_name = value...] SELECT INTO parameter_name 示例: ... DECLARE x int; SELECT COUNT(id) FROM tdb_name INTO x; RETURN x; END// 查看函数列表： SHOW FUNCTION STATUS; 查看函数定义 SHOW CREATE FUNCTION function_name 删除UDF: DROP FUNCTION function_name 调用自定义函数语法: SELECT function_name(parameter_value,...) 存储过程存储过程优势 存储过程把经常使用的SQL语句或业务逻辑封装起来,预编译保存在数据库中,当需要时从数据库中直接调用,省去了编译的过程 提高了运行速度 同时降低网络数据传输量 存储过程与自定义函数的区别 存储过程实现的过程要复杂一些,而函数的针对性较强 存储过程可以有多个返回值,而自定义函数只有一个返回值 存储过程一般独立的来执行,而函数往往是作为其他SQL语句的一部分来使用 存储过程：存储过程保存在mysql.proc表中 创建存储过程 CREATE PROCEDURE sp_name ([ proc_parameter [,proc_parameter ...]]) routime_body proc_parameter : [IN|OUT|INOUT] parameter_name type 其中IN表示输入参数，OUT表示输出参数，INOUT表示既可以输入也可以输出； param_name表示参数名称；type表示参数的类型 查看存储过程列表 SHOW PROCEDURE STATUS; 查看存储过程定义 SHOW CREATE PROCEDURE sp_name 调用存储过程 CALL sp_name ([ proc_parameter [,proc_parameter ...]]) CALL sp_name 说明:当无参时,可以省略&quot;()&quot;,当有参数时,不可省略&quot;()” 存储过程修改 ALTER语句修改存储过程只能修改存储过程的注释等无关紧要的东西,不能修改存储过程体,所以要修改存储过程,方法就是删除重建 删除存储过程 DROP PROCEDURE [IF EXISTS] sp_name 创建无参存储过程 delimiter // CREATE PROCEDURE showTime() BEGIN SELECT now(); END// delimiter ; CALL showTime; 创建含参存储过程：只有一个IN参数 delimiter // CREATE PROCEDURE selectById(IN uid SMALLINT UNSIGNED) BEGIN SELECT * FROM students WHERE stuid = uid; END// delimiter ; call selectById(2); 示例： delimiter // CREATE PROCEDURE dorepeat(n INT) BEGIN SET @i = 0; SET @sum = 0; REPEAT SET @sum = @sum+@i; SET @i = @i + 1; UNTIL @i &gt; n END REPEAT; END// delimiter ; CALL dorepeat(100); SELECT @sum; 创建含参存储过程:包含IN参数和OUT参数 delimiter // CREATE PROCEDURE deleteById(IN uid SMALLINT UNSIGNED, OUT num SMALLINT UNSIGNED) BEGIN DELETE FROM students WHERE stuid = uid; SELECT row_count() into num; END// delimiter ; call deleteById(2,@Line); SELECT @Line; 说明:创建存储过程deleteById,包含一个IN参数和一个OUT参数.调用时,传入删除的ID和保存被修改的行数值的用户变量@Line,select @Line;输出被影响行数 存储过程和函数中可以使用流程控制来控制语句的执行 流程控制： IF：用来进行条件判断。根据是否满足条件，执行不同语句 CASE：用来进行条件判断，可实现比IF语句更复杂的条件判断 LOOP：重复执行特定的语句，实现一个简单的循环 LEAVE：用于跳出循环控制 ITERATE：跳出本次循环，然后直接进入下一次循环 REPEAT：有条件控制的循环语句。当满足特定条件时，就会跳出循环语句 WHILE：有条件控制的循环语句 触发器触发器的执行不是由程序调用，也不是由手工启动，而是由事件来触发、激活从而实现执行 创建触发器 CREATE [DEFINER = { user | CURRENT_USER }] RIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_body 说明： trigger_name：触发器的名称 trigger_time：{ BEFORE | AFTER }，表示在事件之前或之后触发 trigger_event:：{ INSERT |UPDATE | DELETE }，触发的具体事件 tbl_name：该触发器作用在表名 示例 ： CREATE TABLE student_info ( stu_id INT(11) NOT NULL AUTO_INCREMENT, stu_name VARCHAR(255) DEFAULT NULL, PRIMARY KEY (stu_id) ); CREATE TABLE student_count ( student_count INT(11) DEFAULT 0 ); INSERT INTO student_count VALUES(0); 示例：创建触发器，在向学生表INSERT数据时，学生数增加，DELETE学生时， 学生数减少 CREATE TRIGGER trigger_student_count_insert AFTER INSERT ON student_info FOR EACH ROW UPDATE student_count SET student_count=student_count+1; CREATE TRIGGER trigger_student_count_delete AFTER DELETE ON student_info FOR EACH ROW UPDATE student_count SET student_count=student_count-1; 查看触发器 SHOW TRIGGERS 查询系统表information_schema.triggers的方式指定查询条件，查看指定的触发器信息。 mysql&gt; USE information_schema; mysql&gt; SELECT * FROM triggers where trigger_name=&apos;trigger_student_count_insert&apos;; 删除触发器 DROP TRIGGER trigger_name;]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql变量]]></title>
    <url>%2F2018%2F11%2Fmysql%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[在MySQL/MariaDB中有好几种变量类型：用户自定义变量、系统变量、一般的临时变量(即本地变量，或称为局部变量)。 用户变量用户变量是基于会话的，也是基于用户的，所以我觉得称之为会话变量更合适，但会话变量一般用来表示系统会话变量(后面会说明)，所以还是称之为用户变量好了。 只有本用户才能引用自身的用户变量，其他用户无法引用，且当用户退出会话时，用户变量自动销毁。 用户变量使用&quot;@&quot;开头，用户变量可以直接赋值，无需事先声明。在引用未赋值的用户变量时，该变量值为null 有以下三种方式设置用户变量： 1.set语句，此时可以使用&quot;=&quot;或者&quot;:=&quot;操作符; 2.select语句，此时只能使用&quot;:=&quot;格式赋值，因为除了set语句中，&quot;=&quot;都会被视为比较操作符。; 3.select ... into var_name from TABLE语句，此时要求select语句只能返回标量值，即单行数据。因此为了保险，select into var_name的时候，应尽量结合limit语句限制输出。 set @a1=1,@a2=3,@a3:=2; select @a4:=@a1+@a3; select 33,&apos;abc&apos; into @a5,@a6 from dual; 在mariadb 10.2.6中，引入了一张系统架构表information_schema.USER_VARIABLES，该表中记录了当前用户当前会话定义的用户变量信息。该信息架构表在mysql中没有 SELECT * FROM information_schema.USER_VARIABLES; 系统变量在MySQL/mariadb中维护两种系统变量：全局系统变量和会话系统变量。系统变量是用来设置MySQL服务运行属性和状态的。 全局系统变量使用global或者&quot;@@global.&quot;关键字来设置。会话系统变量使用session或者&quot;@@session.&quot;关键字来设置，其中session可以替换为Local，它们是同义词。如果省略这些关键字，则默认为session系统变量。设置global系统变量要求具有super权限。 -- 设置全局系统变量 set global sort_buffer_size=32M; set @@global.sort_buffer_size=32M; -- 设置会话系统变量 set session sort_buffer_size=32M; set @@session.sort_buffer_size=32M; set sort_buffer_size=32M; -- 查看全局系统变量值 select @@global.sort_buffer_size; show global variables like &quot;sort_buffer%&quot;; -- 查看会话系统变量，不能使用select sort_buffer_size select @@session.sort_buffer_size; select @@sort_buffer_size; show [session] variables like &quot;sort_buffer%&quot;; -- 一次性设置多个变量，包括会话变量、全局变量以及用户变量 SET @x = 1, SESSION sql_mode = &apos;&apos;; SET GLOBAL sort_buffer_size = 1000000, SESSION sort_buffer_size = 1000000; SET @@global.sort_buffer_size = 1000000, @@local.sort_buffer_size = 1000000; SET GLOBAL max_connections = 1000, sort_buffer_size = 1000000; 全局系统变量对全局有效，当有新的会话打开时，新会话会继承全局系统变量的值，所以设置全局系统变量之后新打开的会话都会继承设置后的值。设置全局系统变量对已经打开的连接无效，但是其他已经打开的连接可以查看到设置后的全局系统变量值。 系统变量按照是否允许在运行时修改，还分为动态变量和静态变量。能在运行过程中修改的变量称为动态变量，只能在数据库实例关闭状态下修改的变量称为静态变量或只读变量。动态变量使用set修改。如果在数据库实例运行状态下修改静态变量，则会给出错误。如： set @@innodb_undo_tablespaces=3; ERROR 1238 (HY000): Variable &apos;innodb_undo_tablespaces&apos; is a read only variable 系统变量除了可以在运行中的环境下设置，还可以在配置文件中或者mysqld/mysqld_safe这样的命令行中设置，甚至mysql客户端命令行也可以传递。在配置文件中设置系统变量时，下划线或者短横线都允许，它们表示同一个意思。例如下面的两行配置是等价的： innodb_file_per_table=1 innodb-file-per-table=1 局部变量局部变量也称为本地变量，只能在begin...and语句块中生效。它不像用户变量，本地变量必须使用declare事先声明，所以declare也必须在begin...end中使用。 局部变量无论是声明还是调用的时候都不需要任何多余的符号(即不需要@符号)，直接使用其名称var_name即可。 使用declare声明变量，可以一次性声明多个同类型的变量，需要时可有直接为其指定默认值，不指定时默认为null。 decalre var_name,... type [default value]; 使用set为变量赋值。MySQL/mariadb中set支持一次性赋值多个变量。 在begin...end中的set是一般set语句的扩展版本，它既可以设置系统变量、用户变量，也可以设置此处的本地变量。 set var_name=expr,[var_name=expr1,...] 或者使用select...into语句从表中获取值来赋值给变量，但是这样的赋值行为要求表的返回结果必须是单列且单行的标量结果。例如下面的语句将col的列值赋值给var_name变量。 select col into var_name from table_name; 因为局部变量只能在begin...end中使用，所以此处使用存储过程的例子来演示。 DROP PROCEDURE IF EXISTS haha; DELIMITER $$ CREATE PROCEDURE haha() BEGIN DECLARE a INT; SET a=1; SET @i:=2; SELECT a,@i; END$$ DELIMITER ; CALL haha(); a @i ------ -------- 1 2 在MySQL中，begin...end只能定义在存储程序中，所以declare也只能定义在存储程序内。但在mariadb中，begin...end是允许定义在存储程序(存储函数，存储过程，触发器，事件)之外的，所以decalre也算是能够定义在存储程序之外吧。需要定义在存储程序之外时，使用 begin not atomic 关键字即可。例如： delimiter $$ begin not atomic declare a int; set a=3; select a; end$$]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql引擎]]></title>
    <url>%2F2018%2F11%2FMysql%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[mysql引擎[存储引擎比较]https://docs.oracle.com/cd/E17952_01/mysql-5.5-en/storage-engines.html Mysql在V5.5之前默认存储引擎是MyISAM；在此之后默认存储引擎是InnoDB MyISAM表 MyISAM是独立于操作系统的，这说明可以轻松地将其从Windows服务器移植到Linux服务器； MyISAM特点 不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5前默认的数据库引擎 MyISAM存储引擎特别适合以下几种情况下使用： 选择密集型表。MyISAM存储引擎在筛选大量数据时非常快，是它最突出的优点； 插入密集型表。MyISAM的并发插入特性允许同时选择、插入数据。 例如：MyISAM存储引擎非常适合管理邮件或Web服务器日志数据。 InnoDB表 特点： 行级锁 支持事务，适合处理大量短期事务 读写阻塞与事务隔离级别相关 可缓存数据和索引 支持聚簇索引 崩溃恢复性更好 支持MVCC高并发 从MySQL5.5后支持全文索引 从MySQL5.5.5开始为默认的数据库引擎 支持自动增加列AUTO_INCREMENT属性； 一般来说，如果需要事务支持，并且有较高的并发读取频率，InnoDB是很不错的选择。 其他存储引擎类型：CSV：将CSV文件（以逗号分隔字段的文本文件）作为MySQL表文件。 MRG_MYISAM：此引擎也被称为MERGE存储引擎，如果一些myisam表的表结构完全相同，可以将这些MyISAM表合并成的一张MRG_MYISAM虚拟表。 BLACKHOLE：类似于/dev/null，不真正存储数据。 MEMORY：内存存储引擎，速度快，但是一旦断电数据将会丢失，支持hash索引，支持表级锁，常用于临时表。 PERFORMANCE_SCHEMA：从mysql5.5之后，多出了PERFORMANCE_SCHEMA数据库，PERFORMANCE_SCHEMA数据库中的表的表类型均为PERFORMANCE_SCHEMA，此数据库用于存储与数据库的性能相关的信息，用户无法创建使用这种存储引擎的表，但是dba可以通过PERFORMANCE_SCHEMA数据库中的信息进行性能分析，PERFORMANCE_SCHEMA数据库服务启动后此库中将不断的收集数据，mysql停机后此库中的表将不存在数据，类似于linux中的/proc。 FEDERATED: 用于访问其它远程MySQL服务器上表的存储引擎接口。 ARCHIVE: 见名知义，创建此种表类型的表往往用于存储归档信息、安全审计信息、历史信息等，创建数据仓库时，可能会用到此种表类型，使用archive表类型的表只支持select和insert操作，不能更新和删除操作，支持行级锁。 FEDERATED：利用federated引擎可将本地数据表映射至远程 MySQL 数据表，从而就可以解决应用程序中繁多的跨机器连接数据库问题，其实federated相当于一个访问其他远程mysql server的代理接口，它通过创建一个到远程mysql server的客户端连接，通过FEDERATED引擎创建的表只是在本地有表定义文件，数据文件则存在于远程数据库中。 查看引擎，表类型show engines; 查看默认引擎 show variables like&apos;storage_engine&apos;; 查看数据库所有表类型 show table status\G; 查看单张表类型 show table status like &apos;to%&apos;\G; 查看创建表方法 修改存储引擎已经存在数据的情况下，不要随意修改存储引擎，可能会导致原有表的特性消失 修改命令： alter table ll engine=myisam; 修改默认存储引擎 首先停止mysql服务 修改my.cnf [mysqld] 添加default-storage-engine=innodb 重启mysql服务 引擎数据文件MyISAM 每当我们建立一个MyISAM引擎的表时，就会在本地磁盘上建立三个文件， tb_demo.frm存储表定义； tb_demo.MYD存储表数据； tb_demo.MYI存储表索引。 InnoDB 所有InnoDB表的数据和索引放置于同一个表空间中 表空间文件：datadir定义的目录下 数据文件：ibddata1, ibddata2, ... 每个表单独使用一个表空间存储表的数据和索引 启用：innodb_file_per_table=ON [参考]https://mariadb.com/kb/en/library/xtradbinnodb-serversystem-variables/#innodb_file_per_table ON (&gt;= MariaDB 5.5) 注意：如果在没有开启innodb_file_per_table前，并且已经存在某些使用innodb的表，那这些表，在开启后数据然在ibdta1中，新建的表才会单独使用以.ibd为后缀的表空间文件 本地磁盘上建立两个文件 ll.frm 表格式定义 ll.ibd 数据文件(存储数据和索引)]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql用户权限管理]]></title>
    <url>%2F2018%2F11%2Fmysql%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL用户账号用户账号有两部分组成： &apos;USERNAME&apos;@&apos;HOST&apos; HOST 支持通配符：%，表示授权所有主机 _匹配任意单个字符 用户管理查询用户 创建用户方法一：使用create user创建 方法二：直接在mysql.user表插入一条记录，这种方式很少用，在设置了严格的sql-mode（如TRADITIONAL），无法用 方法三：使用授权语句进行创建 grant all on *.* to tom@&apos;localhost&apos; identified by &apos;123456&apos;; 删除用户使用drop直接删除或者delete删除mysql.user表记录 但是drop删除更彻底 方法一：使用delete删除mysql.user表记录 注意：如果某些数据库授权给删除的用户，在mysql.db表用户对应的权限不会删除，再次创建此用户可能会报错 解决方法：1.删除mysql.db用户残留的权限后，使用flush privileges命令刷新 方法二：drop会删除mysql.user表与用户对应的权限 drop user tom@localhost; 重命名用户rename user OldName to NewName; 修改或设置密码1.管理员使用mysqladmin设置mysql用户密码 mysqladmin -u用户名 -p旧密码 password 新密码 示例: mysqladmin -uroot -p111111 password 123456 当mysql用户没有密码 -p可以不指定 mysqladmin -uroot password 123456 2.使用root登陆后，使用 set password设置用户密码 设置root密码 设置用户密码 MariaDB [(none)]&gt; set password for &apos;user&apos;@&apos;ip/host&apos;=password(&apos;password&apos;); 或 MariaDB [(none)]&gt; update mysql.user set password=passworD(&quot;New-password&quot;) where user=&apos;用户&apos;; MariaDB [(none)]&gt; flush privileges; //刷新数据库 3.忘记密码 前置条件：必须拥有服务器最高管理员（root）权限 1. systemctl stop mariadb /usr/local/mysql/bin/mysqld_safe --skip-grant-tables &amp; “&amp;” 表示在后台运行 然后修改密码 2.修改配置文件 修改my.cnf skip-grant-tables skip-networking #只允许本地连接 使用update命令修改管理员密码 关闭mysqld进程，移除上述两个选项，重启mysqld 授权管理[参考]https://dev.mysql.com/doc/refman/5.7/en/grant.html 授权语法grant 权限1,权限2,…权限n on 数据库名称.表名称 to 用户名@用户地址 identified by &quot;连接口令&quot;; 当权限1,权限2,…权限n被all privileges或者all代替，表示赋予用户全部权限。 当数据库名称.表名称被*.*代替，表示赋予用户操作服务器上所有数据库所有表的权限。 用户地址可以是localhost，也可以是ip地址、机器名字、域名。也可以用’%&apos;表示从任何地址连接。 ‘连接口令’不能为空，否则创建失败 示例： 1.给本地用户授权 grant all on mysql.* to tom@localhost identified by &apos;123456&apos;; localhost与127.0.0.1属于两个用户连接方式 2.给远程用户授权 grant all on mysql.* to tt@&apos;192.168.%.%&apos; identified by &apos;111111&apos;; 最后记得刷新权限,让其生效 flush privileges; 授权某个(多个)用户某个数据库某个(多个)权限 grant select on test.* to tom@&apos;192.168.%.%&apos;; grant insert,delete,update on test.* to tom@&apos;localhost&apos;; grant select on hellodb.* to tom@localhost,tt@localhost; 操作 MySQL 存储过程、函数 权限。 grant execute on testdb.* to developer@&apos;192.168.0.%&apos;; grant execute on function hellodb.test to tt@&apos;192.168.%.%&apos;; grant execute on procedure testdb.pr_add to &apos;tt&apos;@&apos;localhost&apos;; 更改或者删除存储函数或者存储过程的权限 grant create routine on testdb.* to tt@&apos;192.168.0.%&apos;; grant alter routine on testdb.* to tt@&apos;192.168.0.%&apos;; 作用在表中的列上： grant select(id, se, rank) on testdb.* to tt@localhost; 操作视图、查看视图源代码权限： grant create view on testdb.* to tt@&apos;192.168.0.%&apos;; grant show view on testdb.* to tt@&apos;192.168.0.%&apos;; 操作 MySQL 索引权限： grant index on testdb.* to tt@&apos;192.168.0.%; 创建、修改、删除 MySQL 数据表结构权限。 grant create on testdb.* to tt@&apos;192.168.0.%&apos;; grant alter on testdb.* to tt@&apos;192.168.0.%&apos;; grant drop on testdb.* to tt@&apos;192.168.0.%&apos;; 操作 MySQL 外键权限： grant references on testdb.* to tt@&apos;192.168.0.%&apos;; 操作 MySQL 临时表权限： grant create temporary tables on testdb.* to tt@&apos;192.168.0.%&apos;; 如果用户有可能会跨越不安全的网络连接到数据库，可以强制用户使用ssl建立会话 grant usage on *.* to &apos;tt&apos;@&apos;222.222.222.222&apos; require ssl; 取消上述的ssl连接限制，撤销强制使用ssl建立会话的限制 grant usage on *.* to &apos;tt&apos;@&apos;222.222.222&apos;require none; 用户有权将已拥有的权限授予其他用户 grant select on testdb.* to tt@&apos;192.168.%.%&apos; with grant option; 除了grant option，管理员还可以通过如下选项对用户进行一些其他的限制 MAX_QUERIES_PER_HOUR：限制用户每小时执行的查询语句数量； MAX_UPDATES_PER_HOUR：限制用户每小时执行的更新语句数量； MAX_CONNECTIONS_PER_HOUR：限制用户每小时连接数据库的次数； MAX_USER_CONNECTIONS：限制用户使用当前账号同时连接服务器的连接数量； 示例: grant select on *.* to tt@&apos;192.168.%.%&apos; identified by &apos;123456&apos; with max_queries_per_hour 20; grant select on *.* to tt@&apos;192.168.%.%&apos; identified by &apos;123456&apos; with max_updates_per_hour 10; grant select on *.* to tt@&apos;192.168.%.%&apos; identified by &apos;123456&apos; with max_connections_per_hour 15; grant select on *.* to tt@&apos;192.168.%.%&apos; identified by &apos;123456&apos; with max_user_connections 2; 如果将上述限制对应的数字改为0，则表示不限制。 查看授权SHOW GRANTS FOR CURRENT_USER\G; show grants for 用户名@主机； 查看数据库授权 select * from mysql.db where Db=&quot;你要查看的数据库&quot;\G; 撤销授权 revoke &quot;要移除的权限&quot; on 数据库.表 from 用户@host; revoke all on hellodb.* from tt@localhost; 注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存 (1) GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进程通常会自动重读授权表，使之生效 (2) 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程重读授权表 mariadb &gt; FLUSH PRIVILEGES;]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引与约束]]></title>
    <url>%2F2018%2F11%2Fmysql%E7%B4%A2%E5%BC%95%E4%B8%8E%E7%BA%A6%E6%9D%9F%2F</url>
    <content type="text"><![CDATA[索引索引：是特殊数据结构，定义在查找时作为查找条件的字段，在MySQL又称为键key，索引通过存储引擎实现 优点： 索引可以降低服务需要扫描的数据量，减少了IO次数 索引可以帮助服务器避免排序和使用临时表 索引可以帮助将随机I/O转为顺序I/O 缺点： 占用额外空间，影响插入速度 索引类型： B+TREE、HASH、R TREE 聚簇（集）索引；非聚簇索引：数据和索引是否存储在一起 主键索引、二级（辅助）索引 稠密索引、稀疏索引：是否索引了每一个数据项 简单索引、组合索引 左前缀索引：取前面的字符做索引 覆盖索引：从索引中即可取出要查询的数据，性能高 B+ Tree索引 B+ Tree索引顺序存储，每一个叶子节点到根结点的距离是相同的；左前缀索引，适合查询范围类的数据 可以使用B+Tree索引的查询类型： 全值匹配：精确所有索引列，如：姓wang，名xiaochun，年龄30 匹配最左前缀：即只使用索引的第一列，如：姓wang 匹配列前缀：只匹配一列值开头部分，如：姓以w开头的 匹配范围值：如：姓ma和姓wang之间 精确匹配某一列并范围匹配另一列：如：姓wang,名以x开头的 只访问索引的查询 B+Tree索引的限制： 如不从最左列开始，则无法使用索引，如：查找名为xiaochun，或姓为g结尾 不能跳过索引中的列：如：查找姓wang，年龄30的，只能使用索引第一列 如果查询中某个列是为范围查询，那么其右侧的列都无法再使用索引：如：姓wang,名x%,年龄30，只能利用姓和名上面的索引 特别提示： 索引列的顺序和查询语句的写法应相匹配，才能更好的利用索引 为优化性能，可能需要针对相同的列但顺序不同创建不同的索引来满足不同类型的查询需求 Hash索引Hash索引：基于哈希表实现，只有精确匹配索引中的所有列的查询才有效，索引自身只存储索引列对应的哈希值和数据指针，索引结构紧凑，查询性能好 Memory存储引擎支持显式hash索引，InnoDB和MyISAM存储引擎不支持 适用场景：只支持等值比较查询，包括=, &lt;=&gt;, IN() 不适合使用hash索引的场景 不适用于顺序查询：索引存储顺序的不是值的顺序 不支持模糊匹配 不支持范围查询 不支持部分索引列匹配查找：如A，B列索引，只查询A列索引无效 空间索引（R-Tree）：MyISAM支持空间索引，可以使用任意维度组合查询，使用特有的函数访问， 常用于做地理数据存储，使用不多 全文索引(FULLTEXT)在文本中查找关键词，而不是直接比较索引中的值，类似搜索引擎 InnoDB从MySQL 5.6之后也开始支持 聚簇索引与非聚簇索引聚簇索引: 顺序结构与数据存储物理结构一致的一种索引，并且一个表的聚簇 索引只能有唯一的一条。MyISAM不支持聚簇索引。 非聚簇索引 记录的物理顺序与逻辑顺序没有必然的联系，与数据的存储物理结构没有关系；一个表对应的非聚簇索引可以有多条，根据不同列的约束可以建立不同要求的非聚簇索引； 索引优化策略：独立地使用列：尽量避免其参与运算，独立的列指索引列不能是表达式的一部分，也不能是函数的参数，在where条件中，始终将索引列单独放在比较符号的一侧 左前缀索引：构建指定索引字段的左侧的字符数，要通过索引选择性来评估 索引选择性：不重复的索引值和数据表的记录总数的比值 多列索引：AND操作时更适合使用多列索引，而非为每个列创建单独的索引 选择合适的索引列顺序：无排序和分组时，将选择性最高放左侧 索引优化建议只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值，此列在使用时也不会使用索引 尽量使用短索引，如果可以，应该制定一个前缀长度 对于经常在where子句使用的列，最好设置索引 对于有多个列where或者order by子句，应该建立复合索引 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引 尽量不要在列上进行运算（函数操作和表达式操作） 尽量不要使用not in和&lt;&gt;操作 管理索引只是创建一个单纯的索引，那么它则只是一个&quot;索引&quot; 创建索引： create index index_name ON tbl_name ( index_col_name[(length)], ... ); 示例： create index index_name on test (id(2)); #取字段左边2个字节作为索引 create index index_name on test (id) 联合索引 create index index_name on testtb1 (id,name); 查看帮助 help create index; 修改索引 alter table ll add index index_name(name); 删除索引： drop index index_name ON tbl_name; alter table tbl_name drop index index_name; 查看索引： show index from tb_name; show index from testtb where key_name like &apos;ind%&apos;; 优化表空间： OPTIMIZE TABLE tb_name; 查看索引的使用 SET GLOBAL userstat=ON; SHOW index_STATISTICS; explain通过EXPLAIN来分析索引的有效性 EXPLAIN SELECT clause 获取查询执行计划信息，用来查看查询优化器如何执行查询 输出信息说明： [参考]https://dev.mysql.com/doc/refman/5.7/en/explain-output.html id: 当前查询语句中，每个SELECT语句的编号 复杂类型的查询有三种： 简单子查询 用于FROM中的子查询 联合查询：UNION 注意：UNION查询的分析结果会出现一个额外匿名临时表 select_type： 简单查询为SIMPLE 复杂查询： SUBQUERY 简单子查询 PRIMARY 最外面的SELECT DERIVED 用于FROM中的子查询 UNION UNION语句的第一个之后的SELECT语句 UNION RESULT 匿名临时表 table：SELECT语句关联到的表 type：关联类型或访问类型，即MySQL决定的如何去查询表中的行的方式，以下顺序，性能从低到高 ALL: 全表扫描 index：根据索引的次序进行全表扫描；如果在Extra列出现“Using index” 表示了使用覆盖索引，而非全表扫描 range：有范围限制的根据索引实现范围扫描；扫描位置始于索引中的某一点，结束于另一点 ref: 根据索引返回表中匹配某单个值的所有行 eq_ref：仅返回一个行，但与需要额外与某个参考值做比较 const, system: 直接返回单个行 possible_keys：查询可能会用到的索引 key: 查询中使用到的索引 key_len: 在索引使用的字节数 ref: 在利用key字段所表示的索引完成查询时所用的列或某常量值 rows：MySQL估计为找所有的目标行而需要读取的行数 Extra：额外信息 Using index：MySQL将会使用覆盖索引，以避免访问表 Using where：MySQL服务器将在存储引擎检索后，再进行一次过滤 Using temporary：MySQL对结果排序时会使用临时表 Using filesort：对结果使用一个外部索引排序 约束主键：primary key，表上一个或多个字段的组合，填入主键字段中的数据，必须不同于已经存在的其它行的相同字段上的数据，而且也不能为空；一个表只能存一个主键，一个主键可以由多个字段组成； 惟一键：unique key，表上一个或多个字段的组合，填入其中字段中的数据，必须不同于已经存在的其它行的相同字段上的数据，但可以为空；一个表可以有多个唯一键； 外键：foreign key，一个表中的外键字段中所能够插入的数据取值范围，取决于引用的另一个表上主键字段上的已经存在数据集合； 非空约束设置非空字段 alter table test modify 字段名 varchar(10) not null; 删除非空约束 alter table test modify 字段名 varchar(10) null; 自动增长为字段设置自动增长，同样既可以使用change，也可以使用modify alter table test modify 字段名 int auto_increment; alter table test change 字段名 字段名 int auto_increment; 删除自动增长 alter table test change 字段名 字段名 int; alter table test modify 字段名 int; 主键约束添加 alter table test add primary key(字段名); alter table test add constraint primary key(字段名); 删除：不能直接删除主键，需要先删除其关联自动增长或外键，然后再删除主键 alter table test drop primary key 唯一键约束添加 :唯一键的名称默认为字段名称 alter table test add unique key(字段名); alter table test add unique key uni_t(字段名); 指定名称为uni_t 删除 alter table testtb drop index uni_t 外键约束添加：在test1表中创建一个新的字段，tid，并且添加了一个外键，外键的名称叫test1_fk，外键中，test1表中的tid字段引用了表test2表中的id字段 alter table testtb add column tid int default 0 not null; alter table testtb add constraint test1_fk foreign key(tid) references test2(id); 删除：删除外键，必须先查询到对应外键的名称，根据外键名称删除即可。 alter table test4 drop foreign key test_fk 查看约束查看students表的外键（查看主外键对应关系） select TABLE_NAME,COLUMN_NAME,CONSTRAINT_NAME,REFERENCED_TABLE_NAME,REFERENCED_COLUMN_NAME from information_schema.KEY_COLUMN_USAGE where TABLE_NAME = &apos;students&apos; and REFERENCED_TABLE_NAME is not null; 查看students表的主键被那些表引用为外键 select TABLE_NAME,COLUMN_NAME,CONSTRAINT_NAME,REFERENCED_TABLE_NAME,REFERENCED_COLUMN_NAME from information_schema.KEY_COLUMN_USAGE where REFERENCED_TABLE_NAME=&apos;students&apos;; 查看主键，查看外键，查看唯一键 select * from information_schema.key_column_usage where table_name=&apos;students&apos;\G; 查看的主键 desc students;]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql服务器配置]]></title>
    <url>%2F2018%2F11%2Fmysql%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysqld选项，服务器系统变量和服务器状态变量 [mysql]https://dev.mysql.com/doc/refman/5.7/en/mysqld-option-tables.html [mariadb]https://mariadb.com/kb/en/library/system-variables/ 注意：其中有些参数支持运行时修改，会立即生效；有些参数不支持，且只能通过修改配置文件，并重启服务器程序生效；有些参数作用域是全局的，且不可改变；有些可以为每个用户提供单独（会话）的设置 获取mysqld的可用选项列表： mysqld --help --verbose mysqld --print-defaults 获取默认设置 服务器系统变量：分全局和会话两种 服务器状态变量：分全局和会话两种 获取运行中的mysql进程使用各服务器参数及其值 MariaDB &gt; show global variables\G; MariaDB &gt; show [SESSION] VARIABLES; 设置服务器选项方法： 在命令行中设置 shell&gt; ./mysqld_safe --skip-name-resolve=1 在配置文件my.cnf中设置 skip_name_resolve=1 修改服务器变量的值： MariaDB &gt;&gt; help SET 修改全局变量：仅对修改后新创建的会话有效；对已经建立的会话无效 MariaDB &gt; SET GLOBAL system_var_name=value; MariaDB &gt; SET @@global.system_var_name=value; 修改会话变量： MariaDB &gt; SET [SESSION] system_var_name=value; MariaDB &gt; SET @@[session.]system_var_name=value; 状态变量（只读）：用于保存mysqld运行中的统计数据的变量，不可更改 MariaDB &gt; SHOW GLOBAL STATUS; MariaDB &gt; SHOW [SESSION] STATUS; 服务器变量SQL_MODE SQL_MODE：对其设置可以完成一些约束检查的工作,可分别进行全局的设置或当前会话的设置 [参看]https://mariadb.com/kb/en/library/sql-mode/ 常见MODE: NO_AUTO_CREATE_USER 禁止GRANT创建密码为空的用户 NO_ZERO_DATE 在严格模式，不允许使用‘0000-00-00’的时间 ONLY_FULL_GROUP_BY 对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么将认为这个SQL是不合法的 NO_BACKSLASH_ESCAPES 反斜杠“\”作为普通字符而非转义字符 PIPES_AS_CONCAT 将&quot;||&quot;视为连接操作符而非“或运算符”]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql连接管理]]></title>
    <url>%2F2018%2F11%2Fmysql%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql管理1.MySQL是用RPM包安装的 启动服务 systemctl start mariadb 如果在启动状态， 需要重启服务， 可以用以下命令直接重启 ， 而不需要先关闭再启动 关闭服务 systemctl stop mariadb 重启服务 systemctl restart mariadb 2.不是rpm安装的,启动和关闭 MySQL 服务 启动服务 /usr/bin/mysqld_safe &amp; 直接运行mysqld程序来启动MySQL服务的方法很少见，mysqld_safe脚本会在启动MySQL服务器后继续监控其运行情况，并在其死机时重新启动它。 关闭服务 mysqladmin -uroot shutdown -p密码 mysql命令 mysql [option] [database] [option] -u：指定需要登录的用户 -h：指定需要登录的主机 -p：指定该登录用户的密码 -e：在不登陆服务器端时，执行操作并退出 示例： -u与root用户名之间的空格可省略，表示将会提示输入密码 mysql -uroot -p mysql -u root -p123123 使用-D指定数据库 mysql -u root -D test -p123123 mysql -u root test -p123123 通过-S指定套接字位置 mysql -u root -p [-S /var/lib/mysql/mysql.sock] 或者将socket文件路径写入配置文件/etc/my.cnf.d/client.cnf [client] socket=/data/mysql/mysql.sock 使用-h指定mysql主机，-P大写，指定mysql服务对应的端口，前提是已授权客户端的IP能连数据库 mysql -u root -p -h 192.168.1.103 -P 3306 执行-e选项后面跟随的sql语句 mysql -u root -p123123 -e &apos;use mysql; select * from use;&apos; 连接数据库的常用选项 --host=host_name, -h host_name：服务端地址； --user=user_name, -u user_name：用户名； --port=port_num, -P port_num：服务端端口； --socket=path, -S path --database=db_name, -D db_name： --compress, -C：数据压缩传输 --execute=statement, -e statement：非交互模式执行SQL语句； --vertical, -E：查询结果纵向显示； --protocol={TCP|SOCKET|PIPE|MEMORY}： mysqladmin [option] command [option] -u：指定需要登录的用户 -p：指定该登录用户的密码 -h：指定需要登录的主机 command create [DB_NAME] drop [DB_NAME] debug 打开调试日志并记录于error log中 status 输出服务器的基本状态信息 --sleep：status的子参数，多久刷新一次 --count：status的子参数，显示的批次 extended-status 显示扩展的状态信息，等于：SHOW GLOBAL STATUS; flush-hosts 清空主机相关的缓存，包括：DNS解析缓存、连接错误次数过多而被拒绝访问mysqld的主机等 flush-logs 关闭日志，打开新日志对二进制、中继日志进行滚动 flush-privileges 刷新配置 flush-status 重置状态变量 flush-tables 关闭当前打开的表文件句柄 flush-threads 清空线程缓存池 kill 杀死指定的线程 password 修改指定用户的密码 ping 探测服务器是否在线 processlist 显示mysql线程列表 reload 相当于flush-privileges refresh 相当于同时使用flush-logs和flush-hosts shutdown 关闭mysql服务 start-slave 启动从服务器线程 stop-slave 关闭从服务器线程 variables 输出mysqld的服务器变量 version 显示mysql服务器版本 数据库导出、导入导出mariadb数据库有多种解决方案，一般采用phpmyadmin或Navicat for MySQL等 分别是；-u用户、-p密码、数据库名、&gt; 导出路径。以.sql结尾。 /usr/local/mysql/bin/mysqldump -uroot -p renwole &gt; /home/renwole.sql 注意：如果只导出表结构，在-p后面加上-d即可。 导入数据库有2种解决方案。 方案一 MariaDB [(none)]&gt; create database renwole; //建立空数据库名 MariaDB [(none)]&gt; use renwole; //选择数据库 MariaDB [(none)]&gt; set names utf8; //设置数据库导入编码 MariaDB [(none)]&gt; source /home/renwole.sql; //导入数据（注意sql文件的路径） 方案二 mysql -uroot -p renwole &lt; /home/renwole.sql 建议使用第二种方案导入，简单快捷不用设置导入编码，不易出错。以上解决方案也适用于mysql&amp;mariadb任意版 MySQL CLI管理help帮助 system：在CLI接口下执行shell命令 显示当前数据库已存在的用户 查看系统里已经存在的数据库 12345678MariaDB [(none)]&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | +--------------------+ 查看字符集排序规则 123456MariaDB [(none)]&gt; show collation;+------------------------------+----------+------+---------+----------+----| Collation | Charset | Id | Default | Compiled |Sortlen |+------------------------------+----------+------+---------+----------+----| big5_chinese_ci | big5 | 1 | Yes | Yes || big5_bin | big5 | 84 | | Yes | 查看字符集 12345678MariaDB [(none)]&gt; show character set;+----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 | 查看引擎 导入数据库 查看已创建表的语句 SHOW CREATE TABLE student; 修改提示符： prompt临时修改， 永久修改则修改/etc/my.cnf添加[mysql]字段下 例：prompt=[\u@\d]--&gt; 12345MariaDB [(none)]&gt; promptReturning to default PROMPT of \N [\d]&gt; MariaDB [(none)]&gt; prompt \u@\d--&gt;PROMPT set to '\u@\d--&gt;'root@(none)--&gt; 查看当前使用的是哪个数据库 select database();]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql表管理语句]]></title>
    <url>%2F2018%2F11%2Fmysql%E8%A1%A8%E7%AE%A1%E7%90%86%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[查看帮助 MariaDB [(none)]&gt; help create table; 查看字符集 MariaDB [mysql]&gt; show character set; 查看表结构 desc table; 查看表创建的语句信息 show create table table_name; 查看当前数据库表的属性信息 show table status\G 查看当前数据库某张表的属性信息 show table status like &apos;toc&apos;\G 创建表 create table tab_name select ... 根据根据select的结果建新表 create [temporary] table [if not exists] tbl_name {like old_tbl_name | (like old_tbl_name)}; 参照已有表的定义，来定义新的表 create table [ if not exists ] `表名`（ `字段名` 数据类型 修饰符, `字段名` 数据类型 修饰符, ... `字段名` 数据类型 修饰符 (最后一个字段分隔符, 不能加) ）engine=数据库引擎 default charset=编码类型; create table是关键字，表示创建表， tbl_name为表名， [IF NOT EXISTS]为可选的，表示如果表不存在时才创建,加上此选项后如果创建的数据表已经存在，不会报错，只会出现警告信息 ()括号内容分为字段定义、表级别约束定义、索引定义 [数据类型]https://yhsam.github.io/2018/11/mysql数据类型 修饰也是可选字段，是对字段进行限制。 修饰符 | NULL | 数据列可包含NULL值 || NOT NULL | 数据列不允许包含NULL值 || DEFAULT | 默认值 || PRIMARY KEY | 主键 || UNIQUE KEY | 唯一键 || CHARACTER SET name | 指定一个字符集 || 数值型 | || AUTO_INCREMENT | 自动递增，适用于整数类型 || UNSIGNED | 无符号(非负限定 ,即不能取负值) | 示例 ： 单个字段的主键， 字段名语法规则： 数据类型 PRIMARY KEY create table students ( id int UNSIGNED NOT NULL PRIMARY KEY, name VARCHAR（20）NOT NULL, age tinyint UNSIGNED ); DESC students; 多个主键 语法规则：PRIMARY KEY(字段1,字段2,...字段n) create table students2 ( id int UNSIGNED NOT NULL , name VARCHAR(20) NOT NULL, age tinyint UNSIGNED, PRIMARY KEY(id,name) ); 字符集更改： alter database studentdb character set utf8; alter table student character set utf8; 一般不要对已有表进行修改 alter table student change name name varchar(20) character set utf8;]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql库管理语句]]></title>
    <url>%2F2018%2F10%2Fmysql%E5%BA%93%E7%AE%A1%E7%90%86%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[系统数据库mysql数据库 是mysql的核心数据库，类似于Sql Server中的master库，主要负责存储数据库的用户、权限设置、关键字等mysql自己需要使用的控制和管理信息 performance_schema数据库 MySQL5.5开始新增的数据库，主要用于收集数据库服务器性能参数,库里表的存储引擎均为PERFORMANCE_SCHEMA，用户不能创建存储引擎为PERFORMANCE_SCHEMA的表 information_schema数据库 MySQL 5.0之后产生的，一个虚拟数据库，物理上并不存在information_schema数据库类似与“数据字典”，提供了访问数据库元数据的方式，即数据的数据。比如数据库名或表名，列类型，访问权限（更加细化的 访问方式） 创建数据库 CREATE {DATABASE} db_name [IF NOT EXISTS] CHARACTER SET [=] charset_name COLLATE collate_name [IF NOT EXITSTS]，如果存在则不创建 CHARACTER SET 设定默认字符集 utf8 COLLATE 设定默认排序规则 utf8_general_ci 如果指明了排序规则，就不要指定字符集，每一个字符集都有默认排序规则 查看排序法方式 show collation; 查看数据库 show databases; 查看数据库对应sql语句 show create database testdb; 修改数据库 alter database db_name [default] character set [=] | [default] collate [=] collation_name 修改数据库字符集或者字符集排序规则 alter database testdb character set utf8; alter database testdb default character set utf8; 修改并设置为默认字符集，除了已存在的表外新建表会继承 删除数据库 drop database db_name]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql—select语句]]></title>
    <url>%2F2018%2F10%2Fmysql%E2%80%94select%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[查询单表： SELECT select_expr FROM tbl_name [WHERE where_condition] select_expr 字段可以使用别名，一旦定义了别名，引用时必须使用别名 示例： SELECT user as 用户名,password as 密码 FROM user WHERE user=&apos;root&apos;; where_condition between，查找值介于之间的字段 示例： SELECT name,age,address FROM student WHERE age between 20 AND 40 in，查找值在这个范围内的 SELECT name,age FROM students WHERE age in (20,30); is null，判断字段是否空 LIKE %，任意长度的任意字符 _，任意单个字符 算术操作符：+，-，%，/，* 比较操作符：==，!=，&lt;&gt;，&gt;，&gt;=，&lt;，&lt;= 示例： SELECT * FROM students WHERE gender &lt;&gt; &apos;m&apos; 逻辑操作符：NOT，AND，OR，XOR DISTINCT 去除重复列 示例： SELECT DISTINCT gender FROM students; group by 分组显示，SELECT后面只能是分组的字段或者聚合函数(count(),max(),avg(),min(),sum()) 分组后，要是使用过滤条件需使用having关键字 示例： SELECT gender,avg(age) FROM students group by gender having gender=&apos;m&apos;; 分组后，需要排序需使用ORDER BY关键字 ASC，升序 DESC，降序 SELCET * FROM student ORDER BY classid desc ORDER BY 如想排序时显示的null在最后显示只需在要排序的字段加- 示例: SELECT gender,count(*) FROM students group by gender; SELECT gender,avg(age) FROM students group by gender; SELECT classid,gender,max(age) FROM students group by classid; LIMIT [[offset,]row_count]：对查询的结果进行输出行数数量限制 多表查询： union，纵向多表连接，去除多表中重复的字段 示例： SELECT stuid,name,age,gender FROM students union SELECT * FROM teachers; corss join，横向多表连接 示例： SELECT * FROM students cross join teachers 子查询： 用where子句实现的子查询 多表的内连接 示例： SELECT * FROM students,teahcers wheres tudents.teacherid=teahcers.tid; SELECT * FROM students inner join teachers on students.teacherid=teachers.tid; 多表的左外连接 示例： SELECT * FROM students left outer join teachers on students.teacherid=teachers.tid; 多表的右外连接 示例： SELECT * FROM students right outer join teachers on students.teacherid=teachers.tid; 多表的左外连接的特殊情况 示例： SELECT * FROM students left outer join teachers on students.teacherid=teachers.tid where teachers.tid is null; 多表右外连接的特特殊情况 示例： SELECT * FROM students right outer join teachers on students.teacherid=teachers.tid where students.stuid is null; 多表的全连接 示例： SELECT * FROM students full outer join teacheers on students.teacherid=teachers.tid(mysql默认不支持) SELECT * FROM students left outer join teachers on students.teacherid=teachers.tid union SELECT * FROM students right outer join teachers ON students.teacherid=teachers.tid; 多表的完全连接 示例： SELECT * FROM (SELECT StuID,s.name as student_name FROM students as s ) as n; 自连接： 示例： SELECT a.name,b.name from emp as a inner join emp as b left outer join a.leaderid=b.id]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql—insert、update、delete语句]]></title>
    <url>%2F2018%2F10%2Fmysql%E2%80%94insert%E3%80%81update%E3%80%81delete%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[INSERT插入语句 一次插入一行或多行数据 INSERT INTO tablename(列名1,列名2…) VALUES(列值1，列值2...); INSERT INTO tablename SET column_name1 = value1, column_name2 = value2，…; INSERT [INTO] tbl_name SELECT ... 示例： INSERT INTO student (name,age,sex,phone,address)VALUES(&apos;wang&apos;,30,10000,&apos;Fujian&apos;); INSERT INTO custom SELECT * FROM student; DELETE删除表中的记录 DELETE FROM tbl_name [WHERE where_condition] [ORDER BY...] [LIMIT] 示例： DELETE FROM student WHERE name=&apos;wang&apos; truncate table table_name; 注意：删除表记录时一定要指定WHERE条件，如不加，默认删除该表的所有记录 UPDATE更新表中的记录 UPDATE tbl_name SET {col_name=new_value,...}[WHERE where_condition] 示例： UPDATE user SET password=PASSWORD(&apos;centos&apos;) WHERE user=&apos;root&apos; 注意：更新表记录时一定要指定WHERE条件，如不加，默认更新该表的所有记录 执行update和delete时，忘记了加where，可能会导致清空表的悲剧 当发出没有WHERE或LIMIT关键字的UPDATE或DELETE时，mysql程序就会拒绝执行 mysql -U 登陆 alias mysql=&apos;mysql -U&apos; mariadb &gt;set sql_safe_updates = 1 退出终端失效]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql语句类型]]></title>
    <url>%2F2018%2F10%2Fmysql%E8%AF%AD%E5%8F%A5%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[SQL语句种类：DDL（Data Definition Language，数据定义语言） 用来创建或者删除存储数据用的数据库以及数据库中的表等对象 CREATE ：创建数据库和表等对象 DROP ： 删除数据库和表等对象 ALTER ： 修改数据库和表等对象的结构 DML（Data Manipulation Language，数据操纵语言） 用来查询或者变更表中的记录 SELECT ：查询表中的数据（Oracle算在DML里面，MySQL算在DQL（Data Query Language）里面） INSERT ：向表中插入新数据 UPDATE ：更新表中的数据 DELETE ：删除表中的数据 DCL（Data Control Language，数据控制语言） 用来确认或者取消对数据库中的数据进行的变更。除此之外，还可以对 RDBMS的用户是否有权限 操作数据库中的对象（数据库表等）进行设定。 COMMIT ： 确认对数据库中的数据进行的变更 ROLLBACK ：取消对数据库中的数据进行的变更 GRANT ： 赋予用户操作权限 REVOKE ： 取消用户的操作权限 DDL和DCL是自带commit的，一旦使用，无法rollback。 实际使用的 SQL 语句当中有 90% 属于 DML。 SQL语句性能优化查询时，能不要*就不用*，尽量写全字段名 大部分情况连接效率远大于子查询 多表连接时，尽量小表驱动大表，即小表join大表 在有大量记录的表分页时使用limit 对于经常使用的查询，可以开启缓存 多使用explain和profile分析查询语句 查看慢查询日志，找出执行时间长的sql语句优化 注意：有时语句看似没毛病，报错的原因可能是中文的操作导致，类似中文空格]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql安装及配置]]></title>
    <url>%2F2018%2F10%2FMysql%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[数据库（database）：一个以某种有组织的方式存储的数据集合，保存有组织的数据的容器（通常是一个文件或一组文件 数据库管理系统（DBMS：database message system）：数据库是通过DBMS创建和操作的容器 [数据库排名]https://db-engines.com/en/ranking 比较流行的数据库分为以下几种： Relational DBMS：如Oracle，MySQL/MariaDB，SQL Server，DB2。 Document Store：如MongoDB，Amazon DynamoDB。 Key-Value Store：如Redis。 Search Engine：如Elasticsearch。 数据结构模型：层次模型 在层次模型中，每个结点表示一个记录类型，记录类型之间的联系用结点之间的连线表示，这种是1:n的联系 网状结构 用有向图表示实体和实体之间的联系的数据结构模型称为网状数据模型。是一种m:n的关系 关系模型 用二维表的形式表示实体和实体间联系的数据模型 关系型数据库关系：关系就是二维表 行：表中的每一行，称为记录 列：表中每一列，称为字段 主键：用于惟一确定一个记录的字段 域：属性的取值范围 实体（行）完整性 Entity integrity 域（列）完整性 Domain Integrity 参考完整性 Referential Integrity RDMBS设计范式基础概念 1NF：无重复的列，每一列都是不可分割的基本数据项，同一列中不能有多个值， 说明：第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库 2NF：属性完全依赖于主键，第二范式必须先满足第一范式，要求表中的每个行必须可以被唯一区分。通常为表加上一个列，以存储各个实例的唯一标识PK，非PK的字段需要与整个PK有直接相关性 3NF：属性不依赖于其它非主属性，满足第三范式必须先满足第二范式。第三范式要求一个数据库表中不包含已在其它表中已包含的非主关键字信息，非PK的字段间不能有从属关系 关系型数据库的常见组件：数据库：database 表：table 行：row 列：column 索引：index 视图：view 用户：user 权限：privilege 存储过程：procedure 存储函数：function 触发器：trigger 事件调度器：event scheduler SQL: Structure Query Language结构化查询语言 数据存储协议：应用层协议，C/S S：server, 监听于套拼字，接收并处理客户端的应用请求； C：Client 程序接口 CLI GUI 约束关系： 主键（Primary key）：一个或多个字段的组合，数据必须能在本表中唯一标识本行；不能为空，即NOT NULL; 一个表只能存在一个 惟一键（unique key）：一个或多个字段的组合，必须能在本表中唯一标识本行；允许为NULL；一个表可以存在多个 外键（FOREIGN KEY）：一个表中的某字段可填入数据取决于另一个表的主键已有的数据； 索引：将表中的一个或多个字段中的数据复制一份另存，并且此些需要按特定次序排序存储； 关系运算： 选择，挑选出符合条件的行 投影，挑选出需要的字段 连接，表间字段的关联 MySQL和MariaDB 官方网址： https://www.mysql.com/ http://mariadb.org/ 官方文档 https://dev.mysql.com/doc/ https://mariadb.com/kb/en/ 版本演变： MySQL：5.1 –&gt; 5.5 –&gt; 5.6 –&gt; 5.7 MariaDB：5.5 –&gt;10.0–&gt; 10.1 –&gt; 10.2 –&gt; 10.3 MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN,此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。 安装mariadbCentOS 7直接提供 1.源代码：编译安装 2.二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用 mariadb 3.程序包管理管理的程序包 MariaDB的特性： 插件式存储引擎：存储管理器有多种实现版本，功能和特性可能均略有差别；用户可根据需要灵活选择；Mysql5.5.5开始innoDB引擎是MYSQL默认引擎 存储引擎也称之为“表类型”； (1) 更多的存储的存储引擎 MyISAM --&gt; Aria, InnoDB --&gt; XtraDB (2) 诸多扩展和新特性 (3) 单进程，多线程 1234#centos 7 yum install mariadb-server -y#centos 6 yum install mysql-server -y 源码编译安装1. 安装编译需要的包 yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boostdevel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssldevel libevent-devel libaio-devel 2. 添加用户 useradd -r mysql -s /sbin/nologin -g mysql 3.创建数据库路径 mkdir -pv /data/mysql #建议在逻辑卷 chown mysql.mysql /data/mysql 4.解压缩源码包 tar xf mariadb-10.2.19.tar -C /usr/local 5.编译安装 编译选项https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html cd mariadb-10.2.19/ cmake. \ -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \ -DMYSQL_DATADIR=/data/mysql/ -DSYSCONFDIR=/etc \ -DMYSQL_USER=mysql \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_ARCHIVE_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITHOUT_MROONGA_STORAGE_ENGINE=1 \ -DWITH_DEBUG=0 \ -DWITH_READLINE=1 \ -DWITH_SSL=system \ -DWITH_ZLIB=system \ -DWITH_LIBWRAP=0 \ -DENABLED_LOCAL_INFILE=1 \ -DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \ -DDEFAULT_CHARSET=utf8 \ -DDEFAULT_COLLATION=utf8_general_ci make &amp; make install 6.添加环境变量 echo &apos;PATH=/usr/local/mysql/bin/:$PATH&apos;&gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 7，修改配置文件 cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf vim /ect/my.cnf [mysqld]中添加三个选项： datadir = /data/mysql innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 8.初始化数据库文件 scripts/mysql_install_db --datadir=/data/mysql --user=mysql 9.准备服务脚本，并启动 cp support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start 10.安全初始化 /user/local/mysql/bin/mysql_secure_installation 二进制安装二进制10.2.19 1. 准备用户 groupadd -r -g 306 mysql useradd -r -g 306 -u 306 –s /sbin/nologin mysql 2.解压二进制 3.准备数据目录，建议使用逻辑卷 install -d /data/ll -o mysql -g mysql 4.创建mysql的软链接 ln -sv mariadb-VERSION mysql chown -R root:mysql /usr/local/mysql/ 5. 准备配置文件 cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf vim /ect/my.cnf [mysqld]中添加三个选项： datadir = /data/mysql innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 6.添加环境变量 echo &apos;PATH=/usr/local/mysql/bin/:$PATH&apos;&gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 7.初始化数据库文件 scripts/mysql_install_db --datadir=/data/mysql --user=mysql 8.准备服务脚本，并启动 cp support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start 9.安全初始化 /user/local/mysql/bin/mysql_secure_installation 安装成功信息 [root@server ~]#mysqladmin --version mysqladmin Ver 9.1 Distrib 10.2.19-MariaDB, for Linux on x86_64 MySQL配置文件配置文件：/etc/my.cnf 默认数据库存放路径：/var/lib/mysql 默认启动程序管理器安装的mysql启动时会自动初始化数据库 配置文件采用类似ini风格 可包含以下字符 [mysqld] character_set_server=utf8mb4，更改服务器创建的数据库的字符集 innodb_file_per_table=on，将表存放的数据分开存放，在mysql 5.5版本中默认是不分开存放 [mysql] default_character_set=utf8mb4，更改客户端字符集 safe_updates，建议加入客户端选项可避免错误更新表记录 [client] [server] [mysql_safe] [mysqld_multi] 格式：parameter = value 说明：_和- 相同 1，ON，TRUE意义相同， 0，OFF，FALSE意义相同 后面覆盖前面的配置文件，顺序如下： /etc/my.cnf Global选项 /etc/mysql/my.cnf Global选项 SYSCONFDIR/my.cnf Global选项 $MYSQL_HOME/my.cnf Server-specific 选项 --defaults-extra-file= path ~/.my.cnf User-specific 选项 服务器监听的两种socket地址： ip socket: 监听在tcp的3306端口，支持远程通信； vim /etc/my.cnf [mysqld] skip-networking=1 关闭网络连接，只侦听本地客户端，所有和服务器的交互都通过一个socketh实现，socket的配置存放在/var/lib/mysql/mysql.sock） 可在/etc/my.cnf修改 unix sock: 监听在sock文件上(/tmp/mysql.sock, /var/lib/mysql/mysql.sock)仅支持本地通信； server: localhost, 127.0.0.1]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logrotate]]></title>
    <url>%2F2018%2F09%2Flogrotate%2F</url>
    <content type="text"><![CDATA[Logrotatelogrotate程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以节省磁盘空间,可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 logrotate工具对于防止因庞大的日志文件而耗尽存储空间是十分有用的。配置完毕后，进程是全自动的，可以长时间在不需要人为干预下运行 默认centos系统安装自带logrotate，安装方法如下 yum -y install logrotate crontabs 配置文件是/etc/logrotate.conf，通常不需要对它进行修改。 日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下。 logrotate.conf才主要的配置文件 logrotate.d是一个目录，该目录里的所有文件都会被主动的读入/etc/logrotate.conf中执行。 另外，如果 /etc/logrotate.d/ 里面的文件中没有设定一些细节，则会以/etc/logrotate.conf这个文件的设定来作为默认值。 切割介绍日志究竟轮换几次，这个是根据配置文件中的rotate参数来判定的 实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。 Logrotate的备份策略（以两个备份来说明，即rotate 2，文件error.log）： 原始文件error.log，经过一次转储，会生成error.log.1 第二次转储，生成error.log.2 第三次转储，error.log.n命名为error.log.n+1，同时生成新的error.log.1，删除error.log.n+1文件。 转储可以通过强制执行来观察工作过程 logrotate -vf /etc/logrotate.d/nginx。 可以在/etc/logrotate.d目录里放置自定义好的配置文件，用来覆盖Logrotate的缺省值 logrotate 默认自动切割时间日志轮转是系统自动完成的 默认的logrotate是一天运行一次,其脚本是/etc/cron.daily/logrotate 实际运行时，Logrotate会调用配置文件/etc/logrotate.conf Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件/etc/anacrontab（老版本的文件是/etc/crontab） 会发现logrotate自动切割日志文件的默认时间是凌晨3点多 取消自动切割1.可以移走/etc/anacrontab 2.crontab进行自定义的定时轮转操作 10 22 * * * /usr/sbin/logrotate -f /etc/logrotate.d/nginx &gt;/dev/null 2&gt;&amp;1 参数主要参数如下 ,man logrotate compress 通过gzip压缩转储以后的日志 nocompress 不压缩 copytruncate 用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据 nocopytruncate 备份日志文件但是不截断 create mode owner group 转储文件，使用指定的文件模式创建新的日志文件,如create 0744 nobody nobody nocreate 不建立新的日志文件 delaycompress 和compress一起使用时，转储的日志文件到下一次转储时才压缩 nodelaycompress 覆盖 delaycompress 选项，转储同时压缩。 errors address 专储时的错误信息发送到指定的Email 地址 ifempty 即使是空文件也转储，这个是 logrotate 的缺省选项。 notifempty 如果是空文件的话，不转储 mail address 把转储的日志文件发送到指定的E-mail 地址 nomail 转储时不发送日志文件 olddir directory 转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统 noolddir 转储后的日志文件和当前日志文件放在同一个目录下 prerotate/endscript 在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行 postrotate 在logrotate转储之后需要执行的指令，例如重新启动(kill -HUP)某个服务！必须独立成行 daily 指定转储周期为每天 weekly 指定转储周期为每周 monthly 指定转储周期为每月 missingok 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误 rotate count 指定日志文件删除之前转储的次数,一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除,0指没有备份，5指保留5个备份 dateformat .%s 配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数 size(或minsize) log-size 当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem). 当日志文件 &gt;= log-size的时候就转储。以下为合法格式：（其他格式的单位大小写没有试过） size = 5 或 size 5 （&gt;= 5 个字节就转储） size = 100k 或 size 100k size = 100M 或 size 100M 测试logrotate如何管理日志这里我们将创建一个10MB的日志文件/var/log/log-file。我们将展示怎样使用logrotate来管理该日志文件。 创建一个日志文件，然后在其中填入一个10MB的随机比特流数据文件。 touch /var/log/log-file head -c 10M &lt; /dev/urandom &gt; /var/log/log-file 由于现在日志文件已经准备好，我们将配置logrotate来轮循该日志文件。让我们为该文件创建一个配置文件。 vim /etc/logrotate.d/log-file /var/log/log-file { monthly rotate 5 compress delaycompress missingok notifempty create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript } 上面的模板是通用的，而配置参数则根据你的需求进行调整，不是所有的参数都是必要的 2.手动运行logrotate logrotate可以在任何时候从命令行手动调用。要调用为/etc/lograte.d/下配置的所有日志调用logrotate logrotate /etc/logrotate.conf 要为某个特定的配置调用logrotate,执行一次切割任务测试 ll /var/log/log-file -rw-r--r-- 1 root root 0 Jan 6 19:05 /var/log/log-file logrotate -vf /etc/logrotate.d/log-file ll /var/log/log-file* -rw-r--r-- 1 root root 0 Jan 6 19:05 /var/log/log-file -rw-r--r-- 1 root root 10485760 Jan 6 19:05 /var/log/log-file.1 即使轮循条件没有满足，我们也可以通过使用‘-f’选项来强制logrotate轮循日志文件，‘-v’参数提供了详细的输出。 Logrotate的记录日志logrotate自身的日志通常存放于/var/lib/logrotate/status目录。 如果处于排障目的，我们想要logrotate记录到任何指定的文件，我们可以指定像下面这样从命令行指定。 logrotate -vf -s /var/log/logrotate-status /etc/logrotate.d/log-file logrotate生产应用1.nginx设置日志切割,防止访问日志文件过大 12345678910111213cat /etc/logrotate.d/nginx /var/log/nginx/*.log &#123; daily rotate 365 missingok notifempty create 644 www www postrotate if [ -f /application/nginx/logs/nginx.pid ]; then kill -USR1 `cat /application/nginx/logs/nginx.pid` fiendscript&#125; 2.系统日志切割 123456789101112cat /etc/logrotate.d/syslog/var/log/cron/var/log/maillog/var/log/messages/var/log/secure/var/log/spooler&#123; sharedscripts postrotate /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true endscript&#125; logrotate无法自动轮转解决1.检查日志切割的配置文件是否有问题 cat /etc/logrotate.d/xx 需要分割的文件 cat /etc/cron.daily/logrotate 2.查看cron的日志 cat /var/log/cron 3.查看/etc/cron.daily/logrotate（这是logrotate自动轮转的脚本）的内容 4.应该有可能是logroate认为nginx日志太小，不进行轮询。 故需要强制轮询，即在/etc/cron.daily/logrotate脚本中将 -t 参数替换成 -f 参数 5.重启下cron服务]]></content>
  </entry>
  <entry>
    <title><![CDATA[rsyslog]]></title>
    <url>%2F2018%2F09%2Frsyslog%2F</url>
    <content type="text"><![CDATA[日志介绍sysklogd，centos5 rsyslog，centos6，centos7 支持多线程，UDP，SSL，TCP，mysql日志存储、自定义输出格式等等 facility：设施，从功能或程序上对日志进行归类 auth : 认证相关的 authpri : 权限,授权相关 cron : 任务计划相关 daemon: 守护进程相关 kern : 内核相关的 lpr : 打印相关的 mail : 邮件相关的 mark : 标记相关的 news : 新闻相关的 security : 安全相关的,和auth类似 syslog : 日志自己的 user : 用户相关的 uucp : Unix to unix cp相关的 local0到local7 : 用户自己定义的 * : 所有的facility Priority 优先级别，从低到高排序 debug, info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) 日志配置使用yum install rsyslog安装 配置文件：/etc/rsyslog.conf /etc/rsyslog.d/*.conf 配置格式：facility.priority;... target 库文件： /lib64/rsyslog/*.so 配置文件格式：由三部分组成 MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置 facility *：表示所有的facility priority *：所有级别 none：没有级别，不记录 PRIORITY：指定包含该级别以及以上的所有级别 target 文件路径：通常在/var/log，文件路径前-表示异步写入 用户：将日志时间通知个指定用户，*表示登录的所有用户 日志服务器： @host：将日志发送指定的主机，支持UDP的主机 @@host：将日志发送指定的主机，支持TCP的主机 管道： | COMMAND，转发给其它命令 启动配置成为日志服务器 vim /etc/rsyslog/rsyslog.conf #### MODULES #### # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # Provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 测试工具 logger -p local0.info &apos;ssh event&apos; 系统默认日志/var/log/secure：安全日志 /var/log/btmp：失败登录日志，可使用lastb查看 /var/log/wtmp：正常登录的日志，可使用last查看 /var/log/lastlog:每一个用户最近一次的登录信息，lastlog查看 /var/log/dmesg：系统的引导日志，可使用dmesg查看 /var/log/message：系统一般的信息记录保存日志文件 /var/log/anaconda：anaconda日志 journalctSystemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。 日志的配置文件 /etc/systemd/journald.conf k，查看内核日志 -b，查看启动日志 -n，查看日志最新10行 -f，滚动显示最新日志 --no-pager 改为正常的标准输出 --since=&quot;TIME&quot;，查看指定时间的日志 _PID=PID，查看指定进程的日志 _UID=UID，查看指定用户的日志 -u UINT_FILE，查看指定unit的日志 rsyslog将日志记录于MySQL中(1) 准备MySQL Server (2) 在mysql server上授权rsyslog能连接至当前服务器 GRANT ALL ON Syslog.* TO &apos;USER&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;PASSWORD&apos;; (3) 在rsyslog服务器上安装mysql模块相关的程序包 yum install rsyslog-mysql (4) 为rsyslog创建数据库及表； mysql -uUSERNAME -hHOST -pPASSWORD &lt; /usr/share/doc/rsyslog7.4.7/mysql-createDB.sql (5) 修改/etc/rsyslog.conf，添加如下字段 $ModLoad ommmysql 确定那些规则记录到mysql服务器中，格式如下： facility:priority :ommysql:HOST,DBNAME,USER,PASSWORD (6). 重启rsyslog systemctl restart rsyslog 通过loganalyzer展示mysql数据库生成的日志1. 在rsyslog服务器上准备amp或nmp组合 yum install httpd php-fpm php-mysql php-gd 2. 下载loganalyzer并解压至站点目录 tar xf loganalyzer-4.1.5.tar.gz cp -a loganalyzer-4.1.5/src /vhosts/apps/loganalyzer cd /vhosts/apps/loganalyzer touch config.php chmod 666 config.php 3.编辑/usr/local/httpd24/conf/extra/httpd-vhosts.conf添加如下 4.连接 systemctl start httpd.service http://logs.test.com/loganalyzer 5.安全加强 cd /vhosts/apps/loganalyzer chmod 644 config.php]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F09%2FAnsible%2F</url>
    <content type="text"><![CDATA[ansible中文指南 Github上的ansible-galaxy示例 相关运维管理工具使用方法： pssh saltstack puppet 常用自动化运维工具 PSSH：适用于主机数量很少的环境(基础ssh的key验证) Ansible:python,Agentless,中小型应用环境(自带代理功能) Saltstack:python，一般需部署agent，执行效率更高 Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境 Fabric：python，agentless Chef: ruby,国内应用少 Cfengine func 特性最多管理500台主机，更多效率会降低 1. 模块化 Paramiko，PyYAML，Jinja2 2. 支持自定义模块 3. 基于Python语言实现的agentless 4. 基于OpenSSH 5. 支持Playbook任务编排 6. 幂等性，重复执行不会带来意外的情况 7. YAML格式，支持丰富的数据结构 架构 主机清单，HOST Inventory 剧本，Playbook 核心模块，Core Modules 自定义模块，Custom Modules 插件，Plugins 应用程序接口，API ansible的重要&amp;主要文件配置文件： /etc/ansible/ansible.cfg 配置ansible的工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles 存放的角色目录 程序文件： /usr/bin/ansible ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 配置文件 /etc/ansible/ansible.cfg，主配置文件 [defaults] inventory = /etc/ansible/hosts - 主机列表配置文件 library = /usr/share/my_modules/ - 库文件存放目录 remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录 local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录 forks = 5 - 默认并发数 sudo_user = root - 默认sudo 用户 ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 [color] 定义ansible命令的执行结果颜色的 *配置文件说明和建议修改的项 local_tmp和remote_tmp： 本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地 家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除. host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 module_name = command -默认使用的命令模块，可以修改成shell 建议修改为：module_name = shell 配置文件只提供默认值，但可以通过playbook的设置进行覆盖 配置文件可以放在/etc/ansible/ansible.cfg中 也可以放到一个工作目录下命名为.ansible.cfg 安装 EPEL源 yum install -y ansible 编译安装： yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto tar xf ansible-1.5.4.tar.gz cd ansible-1.5.4 python setup.py build python setup.py install mkdir /etc/ansible cp -r examples/* /etc/ansible Git方式: git clone git://github.com/ansible/ansible.git --recursive cd ./ansible source ./hacking/env-setup pip安装： pip是安装Python包的管理器，类似yum yum install python-pip python-devel yum install gcc glibc-devel zibl-devel rpm-bulid openssl-devel pip install --upgrade pip pip install ansible --upgrade 确认安装： ansible --version 主机清单inventory /etc/ansible/hosts，主机清单 示例： [webservs] 192.168.80.40:6868 192.168.80.3:6868 还可以使用列表式主机列表 示例： [websrvs] www[0:100].abc.com [dbsrvs] ab-[a:f].abc.com /etc/ansible/roles，角色的目录 Ansible主要操作对象：HOSTS主机 NETWORKING网络设备 注意事项执行ansible的主机一般称为主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows不能做为主控端 ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态：绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 ansible使用ansible-doc，查看ansible模块的帮助 -a，显示所有模块的文档 -l，列出所有的模块 -s，以分片查看该模块的帮助 ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 ansible-playbook *.yml 执行相关的剧本文件 -C --check 只检测可能会发生的改变，但不真正执行操作 --list-hosts 列出运行任务的主机 --limit 主机列表 只针对主机列表中的主机执行 -v 显示过程 -vv -vvv 更详细 ansible-galaxy 已经生成好角色文件 连接 https://galaxy.ansible.com 下载相应的roles 列出所有已安装的galaxy ansible-galaxy list 安装galaxy ansible-galaxy install geerlingguy.redis 删除galaxy ansible-galaxy remove geerlingguy.redis ansible all --list-hosts 查看所有主机角色 Ansible-vault 功能：管理加密解密yml文件 ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 ansible &lt;HOST-PATTERN&gt; [-m modules -a args] -k，以密码的形式的验证主机 -all，所有主机清单列表中的主机 -v，查看执行过程 -K，提示输入sudo时的密码 -a，该模块的参数 -C，检查，并不执行 -u，执行远程命令时的用户 Ansible-console：2.0+新增，可交互执行命令，支持tab root@all (2)[f:5]$ 执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$ 设置并发数： forks n 例如： forks 10 切换组： cd 主机组 例如： cd web 列出当前组主机列表： list 列出所有的内置命令： ?或help ansible HOST-PATTERNALL表示所有清单中的所有主机 ansible all -m ping *通配符 ansible 192.168.56.* -m ping :表示主机清单的中的或的关系 ansible &quot;websrvs:appsrvs&quot; -m ping :&amp;表示主机清单中与的关系 ansible &quot;websrvs:&amp;dbsrvs&quot; -m ping :!表示主机清单内非的关系 ansible &apos;websrvs:!dbsrvs&apos; -m ping 在websrvs，但不在dbsrvs的主机列表 注意：单使用非的关系时，需要用单引号 常用模块ping：探测目标主机是否存活 ansible websrvs -m ping command：在远程主机执行命令；不支持|管道命令 ，（默认模块，可忽略-m选项） ansible websrvs -m command -a &apos;COMMAND&apos; shell：在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等 ansible websrvs -m shell -a &apos;COMMAND&apos; 注意：command和shell模块的核心参数直接为命令本身；而其它模块的参数通常为“key=value”格式； script：发送脚本到各被管理节点，并执行。不需要参数 copy：复制文件到远程主机，可以改权限等 src ：本地文件路径，可以是绝对和相对 dest ：不可省，如果src是目录，则dest也是目录。只能是绝对路径 group ：指明文件属组 mode ：指明权限 owner ：指明所有者 content :直接写出内容，并将其复制给远程主机 backup：如果文件事先存在，则创建备份 file ：设置文件属性 state：absent，link|hard，file，directory(创建时，需要指定src)，touch src：指定源 path：指定目标 owner：文件的所有者 group：文件的所属组 mode：文件的权限 backup：如果文件事先存在，则创建备份 fetch： 从远程某一个主机获取文件到本地 dest：服务器端的保存路径 src：客户端的源文件路径 cron: 管理cron计划任务 minute hour day month weekday name：任务计划的名称 disable：true|False yum：yum安装软件，也有apt,zypper state：latest（创建），absent（删除） name：指定需要安装或者卸载的程序的名称，多个程序之间用,隔开 service: 服务程序管理 name：指定的服务的名称，只能是单个服务 enabled：yes|no，指定服务是否开机自启 state：started，stopped，reloaded，restarted group: 组管理 name：组的名称 gid：组的gid state：present（创建，默认选项），absent（删除） system：yes，创建系统组 User:用户管理 name：账号的名称 uid：账号的uid home：账号的家目录 password：指定账号的密码 state：absent，present remove：yes，删除时同时删除其家目录 shell：指定用户的shell system：yes，创建系统账号 hostname:主机名 name：主机名 template：模板 用于将模版文件渲染后，输出到远程主机上，模版文件一般以.j2为结尾，标识其是一个jinja2模版文件 - src：模版文件的路径 - dest：拷贝到远程主机上的位置 - mode：权限 - attributes: 特殊权限 类似于 chattr - force：存在覆盖 - group：属组 - owner：属主 ansible playbookplaybook是由一个或多个“play”组成的列表 Playbook采用YAML语言编写 playbook核心元素： Host 执行远程主机列表 Tasks 任务集 Varniables 内置变量或自定义变量在playbook中调用 Template 模板 Handlers和notify结合使用，由特定条件触发操作，满足条件方才执行，否则不执行 tags 标签选择性运行playbook部分代码 playbook基础组件： Host 主机用于指定要执行任务的主机 remote_user：可用于Host和task中，也可使用sudo方式在远程主机执行任务 示例： - hosts: websrvs remote_user: root task和action 主机部分是task list，task list各任务按次序逐个在hosts中指定的所有主机上执行 每个task都应该有其name tasks的格式 1. action: module arguments 2. module: arguments 注意：shell和command模块后面跟命令，而非key=value 语法简介1.在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三个点号(... )用来表示档案结尾 2. 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 3.使用#号注释代码 4.缩进必须是统一的，不能空格和tab混用 5.缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行来实现的 6.YAML文件内容是区别大小写的，k/v的值均需大小写敏感 7.k/v的值可同行写也可换行写。同行使用:分隔  v可是个字符串，也可是另一个列表 8. 一个完整的代码块功能需最少元素需包括 name: task 9.一个name只能包括一个task 10.YAML文件扩展名通常为yml或yaml 123456789---- hosts: appsrvs remote_user: root tasks: - name: first task ping: - name: second task shell: /bin/ls /data/ handlers和notify结合使用触发条件12345678910111213---- hosts: webser remote_user: root tasks: - name: copy copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf backup=yes notify: restart httpd - name: server service: name=httpd state=started handlers: - name: restart httpd service: name=httpd state=restarted Playbook中tags使用1234567891011---- hosts: webser remote_user: root tasks: - name: copy yum: name=autofs state=latest tags: conf - name: server service: name=autofs state=restarted enabled=yes tags: service ansible-playbook -t conf test.yml Playbook中变量使用变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1.facts是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts，可使用如下命令进行： ansible hostname -m setup 12345- hosts: webser remote_user: root tasks: - name: create file file: name=/root/&#123;&#123; ansible_machine &#125;&#125; state=touch 2.register(注册器) 把任务的输入定义为变量，然后用于其它任务 task： - shell：/usr/bin/foo register: foo_result ignore_errors: True - name: test shell: echo ‘hello world&apos; when: foo_result.success # wen条件判断foo_result 3.在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 1234vim /etc/ansible/hosts [websrv] www1.magedu.com http_port=80www2.magedu.com http_port=8080 公共（组）变量：针对主机组中所有主机定义统一变 1234567891011121314151617181920212223[websrvs] www1.magedu.com www2.magedu.com [websrvs:vars] ntp_server=ntp.magedu.comnfs_server=nfs.magedu.com 组嵌套：inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。不过，这些变量只能在ansible-playbook中使用，而ansible不支持。[apache]httpd1.magedu.comhttpd2.magedu.com[nginx]ngx1.magedu.comngx2.magedu.com[webservers:children] # 引用其他组作为自己组内的主机(子组)apache # apache组nginx # nginx组[webservers:vars]ntp_server=ntp.magedu.com 4.通过命令行指定变量，优先级最高 12345- hosts: webser remote_user: root tasks: - name: create file file: name=/root/&#123;&#123; filename &#125;&#125; state=touch ansible-playbook -e filename=test test1.yml 5.在playbook中定义 vars: - var1: value1 - var2: value2 1234567- hosts: webser remote_user: root vars: - filename: test2 tasks: - name: create file file: name=/root/&#123;&#123; filename &#125;&#125; state=touch 6.在独立的变量YAML文件中定义 1234567891011cat vars.yml var1: http var2: ftpcat test1.yml - hosts: webser remote_user: root vars_files: - /data/vars.yml tasks: - name: create file file: name=/root/&#123;&#123; var1 &#125;&#125; state=touch 7.在role中定义 给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量，示例如下： - hosts: webservers roles: - common - { role: foo_app_instance, dir: &apos;/web/htdocs/a.com&apos;, port: 8080 } 注意： ansible中变量的优先级 extra vars （-e 选项指定的变量）最高 inventory 主机清单中定义的变量（ansible_ssh_user等) vars_files自定义的变量 play剧本中vars 系统的facts变量 角色定义的默认变量 最低 从上到下优先级逐渐降低，高优先级会覆盖掉低优先级的变量 变量定义： key=value 示例：http_port=80 变量调用 通过{{ variable_name }} 调用变量，且变量名前后必须有空格，有时用 “{{variable_name }}”才生效 模板templatesJinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1,item2,...] 元组：(item1,item2...) 字典：{key:value1,key:value2,...} 布尔型：true/false 算术运算： + 把两个对象加到一起。通常对象是素质，但是如果两者是字符串或列表，你可以用这种方式来衔接它们。无论如何这不是首选的连接字符串的方式！连接字符串见 ~ 运算符。 {{ 1 + 1 }} 等于 2 。 - 用第一个数减去第二个数。 {{ 3 - 2 }} 等于 1 。 / 对两个数做除法。返回值会是一个浮点数。 {{ 1 / 2 }} 等于 {{ 0.5 }} 。 // 对两个数做除法，返回整数商。 {{ 20 // 7 }} 等于 2 。 % 计算整数除法的余数。 {{ 11 % 7 }} 等于 4 。 * 用右边的数乘左边的操作数。 {{ 2 * 2 }}会返回4。也可以用于重复一个字符串多次。 {{ ‘=’ * 80 }}会打印 80 个等号的横条。 ** 取左操作数的右操作数次幂。 {{ 2**3 }} 会返回 8 比较操作： == 比较两个对象是否相等。 != 比较两个对象是否不等。 &gt; 如果左边大于右边，返回 true 。 &gt;= 如果左边大于等于右边，返回 true 。 &lt; 如果左边小于右边，返回 true 。 &lt;= 如果左边小于等于右边，返回 true 。 逻辑运算： 对于 if 语句，在 for 过滤或 if 表达式中，它可以用于联合多个表达式: and 如果左操作数和右操作数同为真，返回 true 。 or 如果左操作数和右操作数有一个为真，返回 true 。 not 对一个表达式取反（见下）。 (expr) 表达式组。 流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为.j2结尾 yml文件须和templates目录平级 123456.├── templates│ └── test.j2├── test1.yml├── test.yml└── vars.yml 示例：123456vim temnginx.yml - hosts: websrvs remote_user: root tasks: - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ansible-playbook temnginx.yml 使用template变更替换 123456789cat nginx.conf.j2 worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;; cat temnginx2.yml - hosts: websrvs remote_user: root tasks： - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf 算数运算123vim nginx.conf.j2 worker_processes &#123;&#123; ansible_processor_vcpus**2 &#125;&#125;; worker_processes &#123;&#123; ansible_processor_vcpus+2 &#125;&#125;; when 条件测试:如果需要根据变量、 facts或此前任务的执行结果来做为某task执行与否 示例： tasks: - name： Install mysql-server yum： name=mariadb-server state=present when: ansible_distribution_major_version == &quot;7&quot; 迭代对迭代项的引用，固定变量名为&quot;item&quot; 要在task中使用with——items给定要迭代的元素列表 列表格式： 字符串 字典 示例： - name: add groups group: name={{ item }} state=present - with_items: - test1 - test2 - name: user: name={{ item.name }} group={{ item.group }} state=present - with_items: - { name: &apos;user1&apos;, group:&apos;test1&apos; } - { name: &apos;user2&apos;, group:&apos;test2&apos; } 上面语句的功能等同于下面的语句： - name: add user testuser1 user: name=user1 state=present groups=test1 - name: add user testuser2 user: name=user2 state=present groups=test2 for ifcat tmeplates/test.conf.j2 {% for vhost in vhosts %} server { listen {{ vhost.listen }} {%if vhost.host_name is defined %} server_name {{ vhost.host_name }} {%endif%} root {{ vhost.dirname }} } {% endfor %} cat test_for.yml - hosts: appsrvs remote_user: root vars: vhosts: - host1: listen: 81 host_name: www.a.com dirname: /data/www1 - host2: listen: 82 dirname: /data/www2 tasks: - name: template template: src=test.conf.j2 dest=/data/test_for.conf roles常见的目录结构 nginx.yml //调用该角色需使用的文件 roles/ ├── nginx //角色的名称 │ ├── files //存放copy或script等模块调用用到的文件 │ ├── handlers //至少包含一个main.yml文件，用来存放notify触发条件的文件 │ ├── tasks//至少应该包含一个名为main.yml的文件，是该角色执行任务的基本元素 │ ├── templates //存放模板模块所需要用到的文件的路径 │ └── vars //存放该角色所需要的变量的文件，至少包含一个main.yml文件 执行调用role： cat nginx.yml - hosts: websrv remote_user: root roles: - role: nginx 也可以向roles传递参数，例如： --- - hosts: webservers roles: - common - { role: foo_app_instance, dir: &apos;/opt/a&apos;, port: 5000 } - { role: foo_app_instance, dir: &apos;/opt/b&apos;, port: 5001 } 甚至也可以条件式地使用roles，例如： --- - hosts: webservers roles: - { role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; } 完整的roles架构 cat handlers/main.yml - name: restart service: name=httpd state=restarted cat tasks/http_install.yml - name: install yum: name=httpd - name: template template: src=httpd.j2 dest=/etc/httpd/conf/httpd.conf tags: - install notify: - restart - name: start service: name=httpd state=started cat tasks/http_remove.yml - name: remove yum: name=httpd state=absent tags: - remove cat tasks/main.yml - include: http_install.yml - include: http_remove.yml cat templates/httpd.j2 #Listen 12.34.56.78:80 Listen {{ http_port }} cat vars/main.yml http_port: 8080 roles playbook tags使用tags用于让用户选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断。 cat nginx.yml - hosts: websrv remote_user: root roles: - { role: nginx,tags: [ &apos;nginx&apos;,&apos;web&apos; ] ,when: ansible_distribution_major_version == &quot;6“ } - { role: httpd,tags: [ &apos;httpd&apos;,&apos;web&apos; ] } - { role: mysql,tags: [ &apos;mysql&apos;,&apos;db&apos; ] } - { role: marridb,tags: [ &apos;mysql&apos;,&apos;db&apos; ] }]]></content>
      <categories>
        <category>linux</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables之FORWARD和NAT]]></title>
    <url>%2F2018%2F08%2Fiptables%E4%B9%8BFORWARD%E5%92%8CNAT%2F</url>
    <content type="text"><![CDATA[iptables作为网络防火墙网络防火墙往往处于网络的入口或者边缘，那么，如果想要使用iptables充当网络防火墙，iptables所在的主机则需要处于网络入口 当外部网络中的主机与网络内部主机通讯时，不管是由外部主机发往内部主机的报文，还是由内部主机发往外部主机的报文，都需要经过iptables所在的主机，由iptables所在的主机进行&quot;过滤并转发&quot;，所以，防火墙主机的主要工作就是&quot;过滤并转发&quot; 在FORWARD链上定义规则，注意以下几个问题： (1) 请求-响应均经由FORWARD链，要注意规则的方向性； (2)如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行 示例：3台虚拟机，A、B、C A主机与B主机网卡2在vm1网络，B主机网卡1与C主机在vm2 1.需要打开路由转发功能 查看当前主机是否已经开启了核心转发，0表示为开启，1表示已开启 cat /proc/sys/net/ipv4/ip_forward (1)如果需要永久打开路由转发功能，可修改sysctl.conf配置文件 vim /etc/sysctl.conf net.ipv4.ip_forward = 1 //将0（关闭）改为1（开启） sysctl -p //读取修改后的配置 (2）如果只希望临时开启路由转发，可执行以下操作 echo 1 &gt; /proc/sys/net/ipv4/ip_forward 或 sysctl -w net.ipv4.ip_forward=1 2.在主机B上添加FORWARD规则 配置规则时需要考虑&quot;方向问题&quot;，针对请求报文与回应报文,添加一条默认拒绝的规则 iptables -I FORWARD -s 10.0.0.0/8 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD -d 10.0.0.0/8 -p tcp --sport 80 -j ACCEPT iptables -A FORWARD -j REJECT 可以使用state扩展模块，对上述规则进行优化，使用如下配置可以省略许多&quot;回应报文放行规则&quot; iptables -I FORWARD -s 10.0.0.0/8 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A FORWARD -j REJECT 3.测试 结论： 1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器 进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址 [root@centos7 data]# tcpdump -i ens33 -nn icmp 11:10:34.541810 IP 10.0.0.3 &gt; 192.168.80.10: ICMP echo request, id 1764, seq 3, length 64 11:10:34.541877 IP 192.168.80.10 &gt; 10.0.0.3: ICMP echo reply, id 1764, seq 3, length 64 2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务 是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护 这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT FORWARD链是都需要设置规则的！ NAT当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的 NAT: network address translation，地址转换 NAT技术的产生核心原因：隐藏本不需要公开的主机 1.请求报文的源地址地址转换是人为在NAT上加规则实现的 2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预 比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的 地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就 会隐藏我们内网机器访问互联网时的真正IP地址和端口。 实现隐藏的原理： 1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的. 2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。 NAT的方式：SNAT,DNAT,FullNAT,PortNAT NAT规则可加的链： 支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和 POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT SNAT，源地址转换，只能用在POSTROUTING处理数据包的时机是在选择路由之后（nat表的POSTROUTING链）进行，将局域网外发数据包的源IP地址（私有地址）修改为网关服务器的外网接口IP地址（公网地址） 作用： 1.隐藏内网主机的IP地址，防止被攻击 2.SNAT可以解决IPV4端口不够用的问题： IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址， 所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转 换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接 追踪功能返回给原来的私网地址。 静态地址 iptables -t nat -A POSTROUTING -s LOCALNET ！ -d LOCALNET -j SNAT --to-source[ipaddr[-ipaddr]] --persistent(持久连接) 动态地址 iptables -t nat -A POSTROUTING -s LOCALNET ! -d LOCALNET -j MASQUERADE SNAT实验： 192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行 规则如下： NAT的POSTROUTING链规则： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 注意：这里的source是一个固定的地址，如果这个地址是变动的呢？ 那么可能下次这条规则就不生效了！--&gt; 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT DNAT，目标地址转换，只能用在PREROUTING iptables -t nat -A PREROUTING -d LOCALIP -j DNAT --to-destination[ipaddr[-ipaddr]][:port[-:port]] 一般服务器不会直接提供公网地址给用户访问，服务器在企业防火墙后面，通常只是暴露一个公网给用户， iptables -t nat -A PREROUTING -d 192.168.31.168 -p tcp -m tcp --dport 80 -j DNAT --to-destination 192.168.31.167:8080 原理: 请求报文的目标地址需要修改成真正的IP地址 响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址 作用： 1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等 2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题 DNAT实验： 访问192.168.80.10的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.80.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat 规则如下： NAT的POSTROUTING链规则： ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.80.10:80 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT PortNAT:端口映射进程与进程的通信，实际上就是端口号之间的通信 1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可 2.而对于DNAT的情况来说： a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA， 而是当访问主机A的某个服务特定端口时，才进行地址转换 b.而访问F的端口和要转换的IPA的端口不一定需要一样 即IPF：port1--&gt;IPA:port2，port1和port2可以不一样 端口重转向（同一台主机端口重定向） iptables -t nat -A PREROUTING -d LOCALIP -j REDIRECT 示例： 假设系统的80端口被屏蔽，所以要通过8081跳转至80端口 iptables -t nat -A PREROUTING -p tcp -m tcp --dport 8081 -j REDIRECT --to-ports 80]]></content>
  </entry>
  <entry>
    <title><![CDATA[iptables命令]]></title>
    <url>%2F2018%2F08%2Fiptables%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[通过iptables引用规则是是需要大写的 命令格式iptables [-t table] COMMAND chain [-m matchs [per-match-options]] [-j targetname [per-target-options]] -t table： 默认为filter；其它可用的有raw, mangle, nat； COMMAND:链： -N：new，新建自定义链,被内建链上的规则调用才能生效 iptables -N name_rules -X：只能删除一条自定义、空、引用计数为零的链 -E：rename，只能改引用计数为零的自定义链 -P：policy，改变链的默认策略 -F：flush，清空链 -Z：zero，用于每条链ptks、bytes计数器置零 规则： -A：append，追加，在指定链的尾部追加一条规则； -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则； -D：delelte，删除，删除指定的规则； -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换； 查看： -L：list，列出表中的链上的规则； -n：numeric，以数值格式显示； -v：verbose，显示详细格式信息； -vv, -vvv -x：exactly，计数器的精确结果； --line-numbers：显示链中的规则编号； chain： (1) 内建链； (2) 自定义链； 示例： 只不过在自定义链上是由计数器的 iptables -N new_rules 新建自定义链 iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references 自定义规则链的创建、调用、删除； 以在自定义链中加入samba服务;然后主链在调用自定义链为例 先设置入栈的规则 iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT iptables -A cifs_rules -j RETURN 还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则 没有被匹配到，则return到主链上继续匹配主链上的后续规则. 在INPUT链去调用自定义链cifs_rules iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules 删除自定义链：需要先删除引用 iptables -D INPUT 5 iptables -F cifs_rules iptables -X cifs_rules matches:多重条件：逻辑关系为“与”， 基本匹配条件，扩展匹配条件 基本匹配条件：[!] -s, --source address[/mask][,...]：检查报文中的源IP地址是否符合此处指定的地址或范围； [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围； [!] -p, protocol：{tcp|udp|icmp} [!] -i, --in-interface name：数据报文的流入接口；INPUT, FORWARD and PREROUTING [!] -o, --out-interface name：数据报文的流出接口； FORWARD, OUTPUT and POSTROUTING 扩展匹配条件1.隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配； -p tcp：隐含了-m tcp； [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口； [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口； [!] --tcp-flags mask comp SYN，ACK，FIN，RST，URG，PSH； mask：要检查的标志位列表，以逗号分隔； comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0； --tcp-flags SYN,ACK,FIN,RST SYN [!] --syn：匹配tcp第一次建立，相当于--tcp-flags SYN,ACK,FIN,RST SYN -p udp：隐含了-m udp： [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口； [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口； -p icmp：隐含了-m icmp: [!] --icmp-type {type[/code]|typename} 8：echo-request 0：echo-reply 示例： 开放ssh iptables -t filter -A INPUT -d 192.168.56.82 -p tcp --dport 6868 -j ACCEPT iptables -t filter -A OUTPUT -d 192.168.56.82 -p tcp --sport 6868 -j ACCEPT 将所有的地址的都置于REJECT，有利于修改规则 iptables -A INPUT -j REJECT iptables -A OUTPUT -j REJECT 同时开放127.0.0.1 iptables -R INPUT 2 ! -i lo -j ACCEPT iptables -R OUTPUT 2 ! -o lo -j ACCEPT 允许ping通别人 iptables -I OUTPUT -p icmp -o eth0 --icmp-type 8 -j ACCEPT iptable -I INPUT -p icmp -i eth0 --icmp-type 0 -j ACCEPT 开放DNS服务 iptables -I OUTPUT -p udp --dport 53 -j ACCEPT iptables -I INPUT -p udp --sport 53 -j ACCEPT 开放samba服务 iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT iptables -A cifs_rules -j RETURN iptables -I INPUT -s 192.168.80.0/24 -j cifs_rules 2.显式扩展：必须使用-m选项指出matchs，有的match可能存在专用的选项 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 1. multiport 可以使用离散或连续的多端口 [!] --source-ports，--sports port[,port|,port:port]... 指定多个源端口 [!] --destination-port，--dports port[,port|,port:port]...指定多个目标端口 [!] --ports port[,port|,port:port]... 指定多个端口 iptables -I INPUT -p tcp -m multiport --dports 21,6868,80,139,445 -j ACCEPT iptables -I OUTPUT -p tcp -m multiport --sports 21,6868,80,139,445 -j ACCEPT 2. iprange 使用IP地址范围 [!] --src-range from[-to] 源IP地址范围 [!] --dst-range from[-to] 目标IP地址范围 iptables -I INPUT -p icmp --icmp-type 0 -m iprange ! --src-range 192.168.56.81-192.168.56.88 -j ACCEPT iptables -I OUPUT -p icmp --icmp-type 8 -m iprange --dst-range 192.168.56.81-192.168.56.88 -j ACCEPT 3. set 建立规则集合 首先需要安装ipset set存在类型，常用有两个 hash:net hash:ip 使用 先创建集合：ipset create NAME TYPE 向集合添加元素：ipset add NAME ELEMENT 在iptables中使用 iptables -I INPUT -p icmp --icmp-type 8 -m set --match-set SET_NAME src -j ACCEPT iptables -I OUTPUT -p icmp --icmp-type 0 -m set --match-set SET_NAME src -j ACCEPT 4. string 对报文中应用层数据做字符串匹配检测 [!] --string Pattern：要检查的字符串 [!] --hex-string pattern：要检测字符串模式，16进制编码 --algo bm|kmp （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！） iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJEC 5. time 对报文到达时间与指定时间范围进行匹配检测 --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestart hh:mm[:ss]，指定开始时间 --timestop hh:mm[:ss]，指定停止时间 --weekdays day[,day...]，指定周几 --monthdays day[,day...]，指定日期 --kerneltz：使用内核中配置的时区 iptables -I INPUT -d 192.168.56.81 -p icmp --icmp-type 8 -m set --match-set SET_NAME src --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT 6. connlimit 每个客户达IP并发连接数量限制 --connlimit-upto # 连接数量小于等于#限制 --connlimit-above # 连接数量大于#限制 iptables -I INPUT 2 -p tcp --dport 6868 -m connlimit --connlimit-above 2 -j REJECT 7. limit 报文的收发速率限制，基于令牌桶 --limit #[minute|second|] --limit-brust number iptables -I INPUT -p icmp --icmp-type 8 -m set --match-set SET_NAME src -m limit --limit 3/minute --limit-brust 5 -j ACCEPT 8、state扩展 连接跟踪（CONNTRACK），顾名思义，就是跟踪并且记录连接状态。Linux为每一个经过网络堆栈的数据包，生成一个新的连接记录项（Connection entry）。此后，所有属于此连接的数据包都被唯一地分配给这个连接，并标识连接的状态。连接跟踪是防火墙模块的状态检测的基础，同时也是地址转换中实 现SNAT和DNAT的前提。那么Netfilter又是如何生成连接记录项的呢？每一个数据，都有“来源”与“目的”主机，发起连接的主机称为“来源”，响应“来源”的请求的主机即为目的，所谓生成记录项，就是对每一个这样的连接的产生、传输及终止进行跟踪记录。由所有记录项产生的表，即称为连接跟踪表 状态检测；连接追踪机制（conntrack）； [!] --state STATE INVALID：无法识别的状态； ESTABLISHED：已建立的连接； NEW：新连接； RELATED：相关联的连接； UNTRACKED：未追踪的连接； nf_conntrack内核模块； 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，建议必要时调整到足够大； 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ 如何开放被模式的ftp服务： (1) 装载追踪ftp协议的模块； # modprobe nf_conntrack_ftp (2) 放行命令连接 iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行数据连接 iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作（目标） -j targetname [per-target-options] targetname DROP，丢弃 REJECT，拒绝 ACCEPT，接受 RETURN，返回 REDIRECT，重定向 SNAT，源地址转换 DNAT，目标地址转换 MASQUERADE，地址伪装 LOG，日志 保存规则： iptables-save iptables-save &gt; file 恢复规则： iptables-restore iptables-restore &lt; file 示例： 使用yum安装软件 # iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # iptables -I INPUT -p udp -m udp --sport 53 -j ACCEPT # iptables -I OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # iptables -I OUTPUT -p tcp -m tcp -m state --state NEW --dport 80 -j ACCEPT # iptables -I OUTPUT -p udp -m udp --dport 53 -j ACCEPT #iptables-save &gt; /PATH/TO/SOMEFILE]]></content>
  </entry>
  <entry>
    <title><![CDATA[iptables]]></title>
    <url>%2F2018%2F08%2Fiptables%2F</url>
    <content type="text"><![CDATA[安全技术入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主，提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式 防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略 防火墙的实现方式与分类从逻辑上讲。防火墙可以大体分为主机防火墙和网络防火墙。 主机防火墙：针对于单个主机进行防护。 网络防火墙：往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。 网络防火墙和主机防火墙并不冲突，可以理解为，网络防火墙主外（集体），主机防火墙主内（个人）。 从物理上讲，防火墙可以分为硬件防火墙和软件防火墙。 硬件防火墙：在硬件级别实现部分防火墙功能，另一部分功能基于软件实现，性能高，成本高。 软件防火墙：应用软件处理逻辑运行于通用硬件平台之上的防火墙，性能低，成本低。 iptables和netfilter的关系iptables/netfilter：软件实现的主机或网络防火墙； netfilter是一个系统的内核模块，防火墙真正的安全框架（framework），通过netfilter内核控制硬件设备，5个勾子(hook)函数 iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架 数据包在本机的流向报文由传送到本机网卡（PREROUTING链），由内核接收并放到接收缓存区（内存上）中。每当进来一个网络报文，系统就会向内核发送一个中断，由内核来接收、处理报文。若缓冲区满了就开始拒绝收包（也有可能放到消息队列）。 内核拆开数据包分析报文中的目标IP和源IP，由目标IP分析报文是传给谁，若是本机则传送至INPUT链，开始拆ip首部，tcp/udp首部（得到端口，端口号要在内核中注册过），最后把数据包交给相应进程处理。相关进程处理完后，把响应包发给源IP经由OUTPUT链离开本机。数据包由哪个网络接口流出取决于路由结果。 若目的IP不是本机，要么丢弃，要么转发（本机为网关）。FORWARD链 若要转发，继续封装帧首部，物理层首部。转发至下一跳或者目标主机。POSTROUTING链 防火墙可提高主机的安全性，但对系统性能会有影响。因为数据包每次经由链时，都会由链内的 规则匹配一遍，规则条目越多，性能越差。若要优化防火墙，提高性能，可尽量把多条规则合并成一条规则。 前3个hook是防火功能 input+output+forward 访问本机内部的应用 后2个hook:是实现地址转换，报文修改和连接追踪的关闭 prerouting:在进入本机网卡接收队列前的瞬间：路由前 postrouting:由本机发出或者forward转发的离开本机网卡接收队列的瞬间：路由后 而prerouting是不能做过滤的 三种报文流向： 流入的报文： prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程 流出的报文：这里说的流出报文是指由本机主动发出的请求报文 用户空间进程 –&gt;output–&gt;postrouting 转发的报文： prerouting–&gt;forward–&gt;postrouting 而数据报文是有来有往的，有请求报文就应该有响应报文，所以整个通信的过程报文流向应该是 先流入报文：请求报文 prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程 再出去：响应报文 用户空间进程 –&gt;output–&gt;postrouting 转发报文：请求 prerouting–&gt;forward–&gt;postrouting 转发报文的：响应 也是prerouting–&gt;forward–&gt;postrouting 注意，因为客户端和服务端是相对的，进来的都是prerouting出去的都是postrouting 而请求和响应的数据报文，因方向不同，数据报文内封装的源IP+端口和目标IP+端口是相反的 客户端和服务端则是相对的，转发报文也是类似的，也是有来有往的 而为了服务器资源来说，如果要阻止报文，控制的是请求报文而非响应报文 功能：filtter : 过滤，防火墙； nat : network address translation, 网络地址转换；只拆解报文修改地址(ip层地址，传输层地址)的那一部分 snat :源地址转换 dnat :目标地址转换 pnat :端口转换 mangle ： 拆解报文，做出修改，封装报文 raw ： 关闭nat表上启用的连接追踪机制 链(chain)： netfilter的勾子函数 内置链 PREROUTING ：刚刚进入网卡，马上要由内核进行处理时（路由前） INPUT：到本机内部来的 FORWARD： 经由本机转发的 OUTPUT：经由本机发出的 POSTROUNTING：报文即将离开本机时（路由后） 自定义链 名字可以自取，对内置链的扩展，可实现更灵活的规则组织管理机制。只有把自定义链链接到内置链上才能生效 表(table)与链关系与链关系有多种不同的工作方式，每种工作方式称为一个table，在每一个table上可以有多个链 filter：INPUT，FORWARD，OUTPUT nat：PREROUTING，INPUT，OUTPUT，POSTROUTING mangle：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING raw：PREROUTING， OUTPUT 优先级次序(由高而低)： raw --&gt; mangle --&gt; nat --&gt; filter 就算filter和nat上都在同一个input链上，因为不属于一个table的，规则是各自生效的 那么input上同时有filter和nat表的规则时，则是有优先级的 为了实验，要先关闭firewalld设置开机不启动 systemctl stop firewalld systemctl disabled firewalld systemctl is-enabled firewalld 规则顺序很重要 因为有些规则具有一票否则权比如drop，一旦报文匹配到drop规则，后面的规则都不看 因为有些规则具有一票否则权比如accept，一旦报文匹配到drop规则，即使后面有drop也无效 从这两条来说 把检查条件苛刻的规则放前面 规则调用的模块化管理：自定义链，由主链取调用才会生效，删除或更改时方便管理 rule规则规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动 作作出处理 报文的匹配的匹配是从链的头部 向尾部匹配，一旦匹配成功，不再匹配后面的规则 匹配条件： 基本匹配条件：简单检查IP、TCP、UDP等报文的某属性进行匹配的机制； 扩展匹配条件：需要借助于扩展模块进行的匹配条件指定即为扩展匹配； 处理动作： ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，过了超时时间才会有反应。 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。 MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。 DNAT：目标地址转换。 REDIRECT：在本机做端口映射。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配 扩展动作：需要借助扩展模块进行的动作； 添加防火墙规则时的注意点： (1) 报文的流经路径，判断添加规则至哪个链上； (2) 确定要实现的功能，判断添加规则至哪个表上； (3) 要指定的匹配条件，以用于匹配目标报文； 规则优化： (1) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接； (2) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面； (3) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面； (4) 设置默认策略； (a) 最后一条规则设定； (b) 默认策略设定； iptables的黑白名单机制链的默认策略（默认动作），链的默认策略通常设置为ACCEPT或者DROP 黑名单： 当链的默认策略为ACCEPT时，链中的规则对应的动作应该为DROP或者REJECT，表示只有匹配到规则的报文才会被拒绝，没有被规则匹配到的报文都会被默认接受 白名单： 当链的默认策略为DROP时，链中的规则对应的动作应该为ACCEPT，表示只有匹配到规则的报文才会被放行，没有被规则匹配到的报文都会被默认拒 使用&quot;白名单&quot;的机制，最好将链的默认策略保持为&quot;ACCEPT&quot;，然后将&quot;拒绝所有请求&quot;这条规则放在链的尾部，将&quot;放行规则&quot;放在前面，这样做，既能实现&quot;白名单&quot;机制，又能保证在规则被清空时，管理员还有机会连接到主机 生产环境下设置防火墙防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果 不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了 注意：如果不想意外的事情发生，记得上22端口的ACCEPT规则在拒绝之前，防止远程连接端口]]></content>
  </entry>
  <entry>
    <title><![CDATA[加密与安全]]></title>
    <url>%2F2018%2F07%2F%E5%8A%A0%E5%AF%86%E4%B8%8E%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[墨菲定律一种心理学效应，是由爱德华·墨菲（Edward A. Murphy）提出的。 原话：如果有两种或两种以上的方式去做某件事情，而其中一种选择方式将导致灾难，则必定有人会做出这种选择 主要内容： 任何事都没有表面看起来那么简单 所有的事都会比你预计的时间长 会出错的事总会出错 如果你担心某种情况发生，那么它就更有可能发生 安全机制防护的目标 保密性 Confidentiality 完整性 Integrity 可用性 Usability 可控制性 Controlability 不可否认性 Non-repudiation 安全防护环节 物理安全：各种设备主机、机房环境 系统安全：主机或设备的操作系统 应用安全：各种网络服务、应用程序 网络安全：对网络访问的控制、防火墙规则 数据安全：信息的备份与恢复、加密解密 管理安全：各种保障性的规范、流程、方法 安全攻击的手段：STRIDE 假冒Spoofing 篡改Tampering 否认Repudiation 信息泄露Information Disclosure 拒绝服务Denial of Service 提升权限Elevation of Privilege 安全算法常用安全技术 认证 授权 审计 安全通信 对称加密加密解密共用一套密匙 DES：Data Encryption Standard，56bits 3DES： AES：Advanced Encryption Standard Blowfish，Twofish IDEA，RC6，CAST5 特点： 加密、解密使用同一密钥，效率高 将原始数据分割成固定大小的块，逐一加密 缺点： 密钥无法分发 数据来源无法确定是发送方发送 密钥过多 非对称加密公钥加密 加密和解密使用不同一个密钥，密钥成对出现 公钥：公开给所有人；public key 私钥：只在自身留存，secret key 特点，用公钥加密的数据，只能使用与之配对的私钥解密，反之亦然 常见用途 身份认证（数字签名）：主要用于认证接收方确认发送方的身份 密钥交换：发送方用对方的公钥加密一个对称密钥，并发送给对方 数据加密：可用于短小的数据加密，如密钥 常见算法： RSA，既能实现数字签名，又能用户数据加密 DSA，只能用于数字签名，不能用于数据加密 ELGamal，商业加密 数字签名 发送者 生成公钥/密钥对：P和S 公开公钥P，保密密钥S 使用密钥S来加密消息M 发送给接收者S(M) 接收者 使用发送者的公钥来解密M=P(S(M)) 单向散列只能解密，不能解密，提取数据指纹 特性： 意长度输入 固定长度输出 若修改数据，指纹也会改变（“不会产生冲突”） 无法从指纹中重新生成数据（“单向”） 功能：数据完整性 常见算法 md5，128bit md5sum -c，检查md5 sha sha1，160bit sha224 sha256 sha384 sha512 常用工具 md5sum | sha1sum [ --check ] file openssl、gpg rpm -V 密钥交换协议密钥交换：IKE 公钥加密 DH（Deffie-Hellman）：生成会话密钥 DH参考文档 DH： A: g,p 协商生成公开的整数g, 大素数p B: g,p A:生成隐私数据 :a (a&lt;p )，计算得出 g^a%p，发送给B B:生成隐私数据 :b,计算得出 g^b%p，发送给A A:计算得出 [(gb%p)a] %p = g^ab%p，生成为密钥 B:计算得出 [(ga%p)b] %p = g^ab%p，生成为密钥 应用程序：RPM文件完整性的两种实施方式 被安装的文件 MD5单向散列 rpm --verify package_name (or -V) 发行的软件包文件 GPG公钥签名 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat* rpm --checksig pakage_file_name (or -K) 使用gpg实现对称加密对称加密file文件 gpg -c file ls file.gpg 在另一台主机上解密file gpg -o file -d file.gpg 使用gpg工具实现公钥加密在hostB主机上用公钥加密，在hostA主机上解密 在hostA主机上生成公钥/私钥对 gpg --gen-key 在hostA主机上查看公钥 gpg --list-keys 在hostA主机上导出公钥到wang.pubkey gpg -a --export -o wang.pubkey 从hostA主机上复制公钥文件到需加密的B主机上 scp wang.pubkey hostB: 在需加密数据的hostB主机上生成公钥/私钥对 gpg --list-keys gpg --gen-key 在hostB主机上导入公钥 gpg --import wang.pubkey gpg --list-keys 用从hostA主机导入的公钥，加密hostB主机的文件file,生成file.gpg gpg -e -r wang file -e 加密 -r 指定接受信息的人 file file.gpg 复制加密文件到hostA主机 scp fstab.gpg hostA: 在hostA主机解密文件 gpg -d file.gpg gpg -o file -d file.gpg 删除公钥和私钥 gpg --delete-keys wang gpg --delete-secret-keys wang 中间人攻击 CA和证书PKI: Public Key Infrastructure 签证机构：CA（Certificate Authority） 注册机构：RA 证书吊销列表：CRL 证书存取库： X.509：定义了证书的结构以及认证协议标准 版本号 序列号 签名算法 颁发者 有效期限 主体名称 主体公钥 CRL分发点 扩展信息 发行者签名 证书获取证书类型： 证书授权机构的证书 服务器 用户证书 获取证书两种方法： 使用证书授权机构 生成证书请求（csr） 将证书请求csr发送给CA CA签名颁发证书 自签名的证书 自已签发自己的公钥 搭建ca配置文件 再次申请CA证书，申请证书填写的信息与根CA证书信息不一致,解决方法 自签名证书方法一：生成一个自签名的根证书 openssl req -new -x509 -newkey rsa:1024 -out server.crt 方法二： openssl genrsa -out server.key 1024 -- 生成私钥 openssl req -new -x509 -key server.key -out server.crt [-subj &quot;/CN=www.magedu.net&quot;] --私钥生成自签名证书 方法三： 自己扮演ca机构给自己签名 openssl genrsa -out server.key 1024 ---- 生成私钥 openssl req -new -key server.key -out server.csr --根据私钥生成请求文件 openssl x509 -req -in server.csr -out server.crt --- 根据请求文件生成证书 创建CA和申请证书创建私有CA： openssl的配置文件：/etc/pki/tls/openssl.cnf 三种策略：匹配、支持和可选 匹配指要求申请填写的信息跟CA设置信息必须一致 支持指必须填写这项申请信息 可选指可有可无 1、创建所需要的文件 touch /etc/pki/CA/index.txt 生成证书索引数据库文件 echo 01 &gt; /etc/pki/CA/serial 指定第一个颁发证书的序列号 注意：如果没有创建/etc/pki/CA/index.txt和/etc/pki/CA/serial文件，在颁发证书时会出错 2、 CA自签证书 生成私钥 cd /etc/pki/CA/ (umask 066; openssl genrsa -out /etc/pki/CA/private/ca.pem 2048) 生成自签名证书 openssl req -new -x509 –key /etc/pki/CA/private/ca.pem -days 7300 -out /etc/pki/CA/ca.crt -new: 生成新证书签署请求 -x509: 专用于CA生成自签证书 -key: 生成请求时用到的私钥文件 -days n：证书的有效期限 -out /PATH/TO/SOMECERTFILE: 证书的保存路径 注意：创建时，要填写必要的信息：国家、省、公司名等 3、生成私钥以及证书申请 在需要使用证书的主机生成证书请求，给web服务器生成私钥 (umask 066; openssl genrsa -out /etc/pki/tls/private/test.key 2048) 生成证书申请文件 openssl req -new -key /etc/pki/tls/private/test.key -days 365 -out /etc/pki/tls/test.csr (-day 365可以省略不写，因为证书有效期由颁发机构指定) 注意：申请CA证书填写的内容中国家、省、公司名必须与服务器端自签名证书中的一致 把证书申请传递到服务器端 将证书请求文件传输给CA scp /etc/pki/tls/test.csr x.x.x.x:/etc/pki/CA (x.x.x.x为服务器ip地址) 4、CA签署证书，并将证书颁发给请求者 openssl ca -in /etc/pki/CA/test.csr –out /etc/pki/CA/certs/test.crt -days 365 或 openssl x509 -req -CA ca.crt -CAKey ca.pem -CAcreateserial -in test.csr -out test.crt 注意：默认国家，省，公司名称三项必须和CA一致 5.查看证书中的信息： openssl x509 -in /PATH/FROM/CERT_FILE -noout -text|issuer|subject|serial|dates openssl ca -status SERIAL 查看指定编号的证书状态 6、吊销证书 在客户端获取要吊销的证书的serial openssl x509 -in /PATH/FROM/CERT_FILE -noout -serial -subject 在CA上，根据客户提交的serial与subject信息，对比检验是否与index.txt文件中的信息一致， 吊销证书： openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem 指定第一个吊销证书的编号,注意：第一次更新证书吊销列表前，才需要执行 echo 01 &gt; /etc/pki/CA/crlnumber 更新证书吊销列表 openssl ca -gencrl -out /etc/pki/CA/crl.pem 查看crl文件： openssl crl -in /etc/pki/CA/crl.pem -noout -text CA公钥传递过程A和B通讯,寻找可信的权威机构 A把自己的公钥发送给CA，CA拥有自己的公钥和私钥 通过审核后，CA用自己的私钥对A的公钥做数字签名(除了数字签名还包括CA信息，A的信息、有效期)，这些信息就是所谓的CA证书，CA把此证书颁发给A 此时，假设B已经获取CA的公钥信息，那么通过解密证书文件，即可获取A的公钥信息 以此类推，A通过CA证书获取B的公钥信息最权威的CA证书颁发机构根CA(顶层CA)有自己的公钥和私钥；子CA通过向根CA申请获取证书，在上述过程中，假设B获得CA公钥信息，此时A和B获取的CA公钥为根CA颁发的公钥，此公钥是必须可信的，因此确保了CA公钥的可信度 在安装windows系统时，知名机构的公钥已经被安装在系统中，即获取了根CA的公钥，那么子CA颁发的证书也就确保了可信度 安全协议SSL：Secure Socket Layer，TLS: Transport Layer Security 1995：SSL 2.0 Netscape 1996：SSL 3.0 1999：TLS 1.0 2006：TLS 1.1 IETF(Internet工程任务组) RFC 4346 2008：TLS 1.2 当前使用 2015：TLS 1.3 功能：机密性，认证，完整性，重放保护 重放：不解密数据，把数据截取下来重新发送该数据，利用截取的数据假冒数据发送方把数据发送给接收方以获取其信息 两阶段协议，分为握手阶段和应用阶段 握手阶段(协商阶段):客户端和服务器端认证对方身份（依赖于PKI体系，利用数字证书进行身份认证），并协商通信中使用的安全参数、密码套件以及主密钥。后续通信使用的所有密钥都是通过MasterSecret生成。 应用阶段:在握手阶段完成后进入，在应用阶段通信双方使用握手阶段协商好的密钥进行安全通信 https工作过程HTTPS 协议：就是“HTTP 协议”和“SSL/TLS 协议”的组合。 HTTP over SSL”或“HTTP over TLS”，对http协议的文本数据进行加密处理后，成为二进制形式传输 https工作过程： 1、客户端client向服务端server发出请求，要登录https://www.baidu.com 2、服务端把已经拥有的证书发送给客户端，该证书内容包括服务端自己的公钥、ca的私钥签名、网站信息、证书有效期；而且该证书已经用数字签名(即使用CA的私钥加密)保证其来源的可靠性 3、客户端信任CA，使用已经获取的CA的公钥进行解密，获取证书中服务端的公钥，此公钥确定是可靠可信的 4、客户端生成随机字符串session key(即会话密钥，也叫对称密钥)，使用服务端的公钥加密随机字符串key，传递给服务端 5、服务器使用自己的私钥解密公钥加密的数据，获取key 6、随后，通讯双方即可使用key加密数据进行通讯 opensslOpenSSL：开源项目 三个组件： openssl：多用途的命令行工具，包openssl libcrypto：加密算法库，包openssl-libs libssl：加密模块应用库，实现了ssl及tls，包nss openssl命令： 两种运行模式：交互模式和批处理模式 openssl version：程序版本号 标准命令、消息摘要命令、加密命令 标准命令：enc, ca, req, ... 对称加密： 工具：openssl enc, gpg 算法：3des, aes, blowfish, twofish 公钥加密： 算法：RSA, ELGamal 工具：gpg, openssl rsautl（man rsautl） 数字签名： 算法：RSA, DSA, ELGamal 密钥交换： 算法：dh DSA：Digital Signature Algorithm DSS：Digital Signature Standard RSA： enc命令：帮助：man enc 加密： openssl enc -e -des3 -a -salt -in testfile -out testfile.cipher 解密： openssl enc -d -des3 -a -salt –in testfile.cipher -out testfile 单向加密： 工具：md5sum, sha1sum, sha224sum,sha256sum… openssl dgst dgst命令：摘要算法 帮助：man dgst openssl dgst -md5 [-hex默认] /PATH/SOMEFILE openssl dgst -md5 testfile md5sum /PATH/TO/SOMEFILE MAC: Message Authentication Code单向加密的一种延伸应用，用于实现网络通信中保证所传输数据的完整性机制 CBC-MAC HMAC：使用md5或sha1算法 生成用户密码： 帮助：man sslpasswd openssl passwd -1 -salt SALT(最多8位) openssl passwd -1 –salt centos 例： 输入密码，生成加密的随机字符，由于加的盐不同，即使密码相同，生成的字符串也不相同 [root@centos7-1 data]#openssl passwd -1 Password: Verifying - Password: $1$6xpH2Wqj$i7MsvvvrzmAZrVG1tfd8K1 [root@centos7-1 data]#openssl passwd -1 Password: Verifying - Password: $1$2rhWY8eg$PUrw57YH.8ifw9g1tFykQ0 可以通过指定盐，相同的密码会生成相同的随机字符串 [root@centos7-1 data]#openssl passwd -1 -salt 1$2rhWY8eg Password: $1$1rhWY8eg$Xr3rR0UjxAthuQtJwdVp/. [root@centos7-1 data]#openssl passwd -1 -salt 1$2rhWY8eg Password: $1$1rhWY8eg$Xr3rR0UjxAthuQtJwdVp/. 生成随机数： 帮助：man sslrand openssl rand -base64|-hex NUM NUM: 表示字节数，使用-hex，每个字符为十六进制，相当于4位二进制，出现的字符数为NUM*2 例： base64编码详解： openssl rand -base64 N 生成N字节的随机数 基于base64生成的随机数，64为2^6 一个字节占8位，如果N*8能够被6整除，那么生成的随机数后不带=号(当随机数不够时，会使用=号占位)，如果N*8不能被6整除，则生成的随机数后会有=号补全 [root@centos7-1 data]#openssl rand -base64 3 3*8=24，能够被6整除 1hBC [root@centos7-1 data]#openssl rand -base64 5 5*8=40，不能够被6整除 l6y7GxA= base64编码： abc，一个字符占8位，三个字符24位，能够被6整除，因此base64编码中没有=号， 生成密钥对man genrsa 生成私钥 openssl genrsa -out /PATH/TO/PRIVATEKEY.FILE NUM_BITS (umask 077; openssl genrsa –out test.key –des 2048) openssl rsa -in test.key –out test2.key 将加密key解密 从私钥中提取出公钥 openssl rsa -in PRIVATEKEYFILE –pubout –out PUBLICKEYFILE openssl rsa –in test.key –pubout –out test.key.pub 随机数生成器伪随机数字 键盘和鼠标，块设备中断 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞 /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机 数, Openssh相关包： openssh openssh-clients openssh-server 工具： 基于C/S结构 Client: ssh, scp, sftp，slogin Windows客户端： xshell, putty, securecrt, sshsecureshellclient Server: sshd SSHssh: secure shell, protocol, 22/tcp, 安全的远程登录 具体的软件实现： OpenSSH: ssh协议的开源实现，CentOS默认安装 dropbear：另一个开源实现 SSH协议版本 v1: 基于CRC-32做MAC，不安全；man-in-middle v2：双方主机协议选择安全的MAC方式 基于DH算法做密钥交换，基于RSA或DSA实现身份认证 两种方式的用户登录认证： 基于password 基于key ssh, 配置文件：/etc/ssh/ssh_config Host PATTERN StrictHostKeyChecking no 首次登录不显示检查提示 格式：ssh [user@]host [COMMAND] ssh [-l user] host [COMMAND] 常见选项 -p port：远程服务器监听的端口 -b：指定连接的源IP -v：调试模式 -C：压缩方式 -X：支持x11转发 -t：强制伪tty分配 多台设备通过逐个跳转，远程连接到远端主机,最后一个终端可以不用加-t选项 ssh -t remoteserver1 ssh -t remoteserver2 ssh remoteserver3 允许实现对远程系统经验证地加密安全访问 当用户远程连接ssh服务器时，会复制ssh服务器/etc/ssh/ssh_host*\key.pub（CentOS7默认是ssh_host_ecdsa_key.pub）文件中的公钥到客户机的~./ssh/know_hosts中。 下次连接时，会自动匹配相应私钥，不能匹配，将拒绝连接 自动登陆root用户： 编辑/etc/gdm/custom.conf AutomaticLoginEnable=true AutomaticLogin=root ssh服务登录验证ssh服务登录验证方式： 用户/口令 基于密钥 基于用户和口令登录验证 1、客户端发起ssh请求，服务器会把自己的公钥发送给用户 2、用户会根据服务器发来的公钥对密码进行加密 3、加密后的信息回传给服务器，服务器用自己的私钥解密，如果密码正确，则用户登录成功 基于密钥的登录方式 1、首先在客户端生成一对密钥（ssh-keygen） 2、并将客户端的公钥ssh-copy-id 拷贝到服务端 3、当客户端再次发送一个连接请求，包括ip、用户名 4、服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，就会随机生成一个字符串，例如：acdf 5、服务端将使用客户端拷贝过来的公钥进行加密，然后发送给客户端 6、得到服务端发来的消息后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端 7、服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录 ssh命令实现基于key认证基于密钥的认证： (1) 在客户端生成密钥对 ssh-keygen -t rsa [-P &apos;&apos;] [-f &quot;~/.ssh/id_rsa&quot;] ssh-keygen -t rsa (2) 把公钥文件传输至远程服务器对应用户的家目录 ssh-copy-id [-i [identity_file]] [user@]host ssh-copy-id 192.168.32.128(目标ip地址) (3) 在SecureCRT或Xshell实现基于key验证 在SecureCRT工具—&gt;创建公钥—&gt;生成Identity.pub文件 转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文件authorized_keys中,注意权限必须为600，在需登录的ssh 主机上执行： ssh-keygen -i -f Identity.pub &gt;&gt; .ssh/authorized_keys (4)重设私钥口令： ssh-keygen –p (5)验证代理（authentication agent）保密解密后的密钥 这样口令就只需要输入一次 在GNOME中，代理被自动提供给root用户 否则运行ssh-agent bash (7)钥匙通过命令添加给代理 ssh-add 排错总结： ssh是基于key连接通讯双方，如果有主机通过冒充ip地址以及mac地址连接某主机是行不通的，会有警告信息出现，因此基于key的验证方法相对更为安全 hostA向hostB发起连接请求， 第一次通讯时，hostA把hostB的公钥/etc/ssh/ssh_host_rsa_key.pub复制到自己主机/root/.ssh/know_hosts文件下 主机hostB用自己的私钥进行签名加密数据发送给主机hostA，而此时主机hostA已经存有hostB的公钥，如果可以解密，说明hostB是原来的设备，如果无法解密，则说明是另外的设备 注意：如果hostB的私钥被窃取，那么获取hostB私钥的设备可以冒充hostB与之前和hostB验证过的设备通信，因此对于私钥要做好保密措施 复制私钥到其他主机时，注意文件的用户、组以及权限问题 如果使用新设备代替旧设备，而新设备的地址改为旧地址的ip，此时，新设备的key与老设备不同，此时想通过该ip地址连接到新设备时，会提示错误信息：提示目标主机的key发生变化 解决方法：删除本机记录的旧设备的key信息，再次连接新设备即可 rm -rf /root/.ssh 1.如何确认第一次连接的目标主机为可信的目标主机 拿到目标主机的公钥信息/etc/ssh/ssh_host_rsa_key.pub与当前显示的key进行比较，如果一致，则表示目标可信 ssh 192.168.32.129 The authenticity of host &apos;192.168.32.129 (192.168.32.129)&apos; can&apos;t be established. RSA key fingerprint is 3a:19:e1:94:56:01:ed:08:15:7c:1c:30:9d:93:d7:28. Are you sure you want to continue connecting (yes/no)? 计算方法： cp ssh_host_rsa_key.pub(目标主机公钥) /data base64 -d /data/ssh_host_rsa_key.pub &gt;pubkey md5sum pubkey --- centos7中出来md5运算，还有sha256运算得出的值 3a19e1945601ed08157c1c309d93d728 pubkey key一致，说明目标主机可信 2.批量导入公钥信息copy.sh 12345678910111213141516vim ssh_push_key.sh#!/bin/bashpass="magedu"rpm -q expect &amp;&gt; /dev/null || yum -y install expectssh-keygen -t rsa -P "" -f /root/.ssh/id_rsawhile read ip ;doexpect &lt;&lt;EOFspawn ssh-copy-id -i /root/.ssh/id_rsa.pub $ip#若要增加用户名，则$ip更改为用户@$ip,如：yuan@$ipexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125;"password" &#123; send "$pass\n" &#125;&#125;expect eofEOFdone &lt; iplist.txt 注意：脚本中iplist.txt文件需要生成，可通过脚本实现 scp命令scp命令： scp [options] SRC... DEST/ 两种方式： scp [options] [user@]host:/sourcefile /destpath scp [options] /sourcefile [user@]host:/destpath 常用选项： -C 压缩数据流 -r 递归复制 -p 保持原文件的属性信息 -q 静默模式 -P PORT 指明remote host的监听的端口 缺点：当某个文件发生变化时，scp会把所有文件全部复制一遍到远程主机，这样一来就会浪费带宽 rsync命令基于ssh和rsh服务实现高效率的远程系统之间复制文件 使用安全的shell连接做为传输方式 rsync –av /etc server1:/tmp 复制目录和目录下文件 rsync –av /etc/ server1:/tmp 只复制目录下文件 比scp更快，只复制不同的文件 选项： -n 模拟复制过程 -v 显示详细过程 -r 递归复制目录树 -p 保留权限 -t 保留时间戳 -g 保留组信息 -o 保留所有者信息 -l 将软链接文件本身进行复制（默认） -L 将软链接文件指向的文件复制 -a 存档，相当于–rlptgoD，但不保留ACL（-A）和SELinux属性（-X） 该命令基于增量型复制，只复制发生变化文件，未发生变化的文件不会复制，节约流量带宽,很好的解决了scp的问题 sftp命令交互式文件传输工具 用法和传统的ftp工具相似 利用ssh服务实现安全的文件上传和下载 使用ls cd mkdir rmdir pwd get put等指令，可用？或help获取帮助信息 sftp [user@]host sftp&gt; help pssh工具pssh是一个python编写可以在多台服务器上执行命令的工具，也可实现文件复制,使用epel源安装才能使用 pssh命令默认基于key验证 选项如下： --version：查看版本 -h：主机文件列表，内容格式”[user@]host[:port]” -H：主机字符串，内容格式”[user@]host[:port]” -A：手动输入密码模式 -i：每个服务器内部处理信息输出 -l：登录使用的用户名 -p：并发的线程数【可选】 -o：输出的文件目录【可选】 -e：错误输入文件【可选】 -t：TIMEOUT 超时时间设置，0无限制【可选】 -O：SSH的选项 -P：打印出服务器返回信息 -v：详细模式 示例： 1.通过pssh批量关闭seLinux pssh -H root@192.168.23.130 -i &quot;sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/&quot; /etc/selinux/config&quot; pssh -H root@192.168.32.120 -i setenforce 0 2.将标准错误和标准正确重定向都保存至/app目录下 pssh -H 192.168.32.130 -o /app -e /app -i &quot;hostname&quot; pssh -H 192.168.32.130 -i hostname 3.当不支持ssh的key认证时，通过 -A选项，使用密码认证批量执行指令 pssh -H 192.168.32.130 -A -i hostname 4.管理多台主机时，需要输入多个密码(假设密码不一致) pssh -H 192.168.32.130 -H 192.168.32.128 -A -i hostname 输入第一个密码，则第二个主机命令执行失败 解决方法：使用基于key验证管理多台主机(无需输入密码) 前提时主机之间已经实现基于key的验证 5.管理大批量主机时，可以把ip地址存入文本中，调用该文本即可 -h 调用主机文件列表 pssh -h iplist.txt -i hostname 6.批量创建账号 pssh -h iplist.txt -i &quot;useradd testuser&quot; pssh -h iplist.txt -i &quot;getent passwd testuser&quot; PSCP.PSSH命令pscp.pssh功能是将本地文件批量复制到远程主机 pscp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par] [-o outdir] [-e errdir] [-t timeout] [-O options] [-x args] [-X arg] local remote Pscp-pssh选项 -v 显示复制过程 -r 递归复制目录 将本地curl.sh 复制到/app/目录 pscp.pssh -H 192.168.1.10 /root/test/curl.sh /app/ pscp.pssh -h host.txt /root/test/curl.sh /app/ 将本地多个文件批量复制到/app/目录 pscp.pssh -H 192.168.1.10 /root/f1.sh /root/f2.sh /app/ 将本地目录批量复制到/app/目录 pscp.pssh -H 192.168.1.10 -r /root/test/ /app/ PSLURP命令pslurp功能是将远程主机的文件批量复制到本地 pslurp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par][-o outdir] [-e errdir] [-t timeout] [-O options] [-x args] [-X arg] [-L localdir] remote local（本地名） Pslurp选项 -L 指定从远程主机下载到本机的存储的目录，local是下载到本地后的名称 -r 递归复制目录 批量下载目标服务器的passwd文件至/app下，并更名为user pslurp -H 192.168.1.10 -L /app/ /etc/passwd user SSH端口转发SSH端口转发 SSH会自动加密和解密所有SSH客户端与服务端之间的网络数据。但是SSH还能够将其他TCP端口的网络数据通过SSH链接来转发，并且自动提供了相应的加密及解密服务。 这一过程也被叫做“隧道”（tunneling），这是因为SSH为其他TCP链接提供了一个安全的通道来进行传输而得名。 例如， Telnet，SMTP，LDAP这些TCP应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。 而与此同时，如果工作环境中的防火墙限制了一些网络端口的使用，但是允许SSH的连接，也能够通过将TCP端口转发来使用SSH进行通讯 SSH 端口转发能够提供两大功能： 加密 SSH Client 端至 SSH Server 端之间的通讯数据 突破防火墙的限制完成一些之前无法建立的 TCP 连接 本地转发： -L localport:remotehost:remotehostport sshserver 选项： -f 后台启用 -N 不打开远程shell，处于等待状态 -g 启用网关功能 示例: ssh –L 9527:telnetsrv:23 -Nfg sshsrv telnet 127.0.0.1 9527 当访问本机的9527的端口时，被加密后转发到sshsrv的ssh服务，再解密被转发到telnetsrv:23 data&lt;- -&gt;ocalhost:9527&lt;- -&gt;localhost:XXXXX&lt;- -&gt;shsrv:22&lt;- -&gt;shsrv:YYYYY&lt;- -&gt;telnetsrv:23 远程转发-R sshserverport:remotehost:remotehostport sshserver 示例： ssh –R 9527:telnetsrv:23 –Nf sshsrv 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh服务转发请求到本 机ssh客户端，再由本机解密后转发到telnetsrv:23 Data&lt;--&gt; sshsrv:9527 &lt;--&gt; sshsrv:22 &lt;--&gt; localhost:XXXXX &lt;--&gt; localhost:YYYYY&lt;--&gt; telnetsrv:23 动态端口转发动态端口转发： 当用firefox访问internet时，本机的1080端口做为代理服务器，firefox的访问 请求被转发到sshserver上，由sshserver替之访问internet ssh -D 1080 root@sshserver -fNg 在本机firefox设置代理socket proxy:127.0.0.1:1080 curl --socks5 127.0.0.1:1080 http://www.baidu.com X 协议转发ssh -X 192.168.32.6 让远程主机图形界面在本机显示，无论目标主机是否为图形界面，本机调用目标主机的图形界面不受影响 底层通过X协议实现通过图形程序让客户端和服务器端的通讯 对于X协议来说，客户端与服务器端与ssh协议正好相反，本机充当服务器，远程主机相当于客户端 windows通过远程连接linux，并显示图形界面，使用xmanager中的xstart软件可以实现，退出当前用户登录即可退出xstart远程连接 ssh服务器服务器端：sshd, 配置文件: /etc/ssh/sshd_config 常用参数： Port ListenAddress ip LoginGraceTime 2m PermitRootLogin yes StrictModes yes 检查.ssh/文件的所有者，权限等 MaxAuthTries 6 MaxSessions 10 同一个连接最大会话 PubkeyAuthentication yes PermitEmptyPasswords no PasswordAuthentication yes GatewayPorts no ClientAliveInterval：单位:秒 ClientAliveCountMax：默认3 UseDNS yes GSSAPIAuthentication yes 提高速度可改为no MaxStartups 未认证连接最大值，默认值10 Banner /path/file 限制可登录用户的办法： AllowUsers user1 user2 user3 DenyUsers AllowGroups DenyGroups ssh服务的最佳实践建议使用非默认端口 禁止使用protocol version 1 限制可登录用户 设定空闲会话超时时长 利用防火墙设置ssh访问策略 仅监听特定的IP地址 基于口令认证时，使用强密码策略 tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 12| xargs 使用基于密钥的认证 禁止使用空密码 禁止root用户直接登录 限制ssh的访问频度和并发在线数 经常分析日志 /var/log/secure，把失败连接次数过多的ip地址扔到防火墙 awk &apos;/Failed password for root from/{ip[$(NF-3)]++}END{for (i in ip){if(ip[i]&gt;=3)system(&quot;iptables -A INPUT -s &quot;i&quot; -j REJECT&quot;)}}&apos; /var/log/secure dropbearDropbear是一个相对较小的SSH服务器和客户端。它运行在一个基于POSIX的各种平台。 Dropbear是开源软件， Dropbear是特别有用的“嵌入”式的Linux（或其他Unix）系统， dropbear实现安全Shell（SSH）协议版本2。 源码编译安装： 1、安装开发包组:yum groupinstall “Development tools” 2、下载dropbear-2017.75.tar.bz2 3、解压源码包tar xf dropbear-2017.75.tar.bz2 4、查看相关编译文档less INSTALL README 5、开始编译，指定配置文件安装路径 ./configure --prefix=/app/dropbear --sysconfdir=/etc/dropbear --disable-zlib 6、make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; 7、make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; install 8、配置PATH路径，在任意目录下都可以执行该命令 echo PATH=/app/dropbear/bin:/app/dropbear/sbin:$PATH &gt;&gt; /etc/profile.d/dropbear.sh source /etc/profile.d/dropbear.sh 9、生成运行服务所需的key mkdir /etc/dropbear cd /app/dropbear/bin dropbearkey -t rsa -f /etc/dropbear/dropbear_rsa_host_key -s 2048 dropbearkey -t dss -f /etc/dropbear/dropbear_dsa_host_key 10、运行服务，指定服务端口为2222： cd /app/dropbear/sbin dropbear -p :2222 -F –E #前台运行 或dropbear -p :2222 #后台运行 ss -ntl 查看端口是否启动 cat /var/run/dropbear.pid 查看dropbear进程号 11、dropbear软件工具测试 cd /app/dropbear/bin (1)使用dbclient客户端连接其他主机 source /etc/profile.d/dropbear.sh dbclient 192.168.32.128 (2)使用scp远程复制文件 此时系统默认使用/usr/bin/下的dbclient，创建软链接指向/app/dropbear/下的dbclient ln -s /app/dropbear/bin/dbclient /usr/bin/dbclient 12、把此服务设置为开机自启动 dropbear -p :2222 #后台运行 把dropbear设备后台运行 方法1：在/usr/lib/systemd/system/下配置service文件 方法2：写入/etc/rc.local文件 /app/dropbear/sbin/dropbear -p 2222 chmod +x /etc/rc.d/rc.local 给文件加上执行全兴 13、如果使用完毕，不再需要该工具，可以删除 删除此服务 删除etc/rc.local配置文件中的内容 杀掉dropbear进程 killall dropbear 删除配置文件 rm -rf /app/dropbear rm -rf /etc/dropbear 删除源码文件 rm -rf dropbear-2018.76* 此时本机的scp复制文件存在问题 删除PATH变量下的路径 rm -rf /etc/profile.d/dropbear.sh 删除hash缓存，缓存中存的是/app/dropbear/sbin下的scp hash -r 删除全部缓存 hash -d 删除某条缓存记录 AIDE当一个入侵者进入了你的系统并且种植了木马，通常会想办法来隐蔽这个木马 （除了木马自身的一些隐蔽特性外，他会尽量给你检查系统的过程设置障碍）， 通常入侵者会修改一些文件，比如管理员通常用ps -aux来查看系统进程，那 么入侵者很可能用自己经过修改的ps程序来替换掉你系统上的ps程序，以使用 ps命令查不到正在运行的木马程序。 如果入侵者发现管理员正在运行crontab作业，也有可能替换掉crontab程序等等。 由此可以看出对于系统文件或是关键文件的检查是很必要的。 目前就系统完整性检查的工具用的比较多的有两款： Tripwire 商业软件 AIDE 免费的但功能也很 强大的工具 AIDE(Advanced Intrusion Detection Environment) 高级入侵检测环境)是一个入侵检测工具，主要用途是检查文件的完整性，审计计算机 上的那些文件被更改过了 AIDE能够构造一个指定文件的数据库，它使用aide.conf作为其配置文件。 AIDE数据库能够保存文件的各种属性，包括：权限(permission)、索引节点序号(inode number)、 所属用户(user)、所属用户组(group)、文件大小、最后修改时间(mtime)、创建时间 (ctime)、最后访问时间(atime)、增加的大小以及连接数。 AIDE还能够使用下列算法： sha1、md5、rmd160、tiger，以密文形式建立每个文件的校验码或散列号 这个数据库不应该保存那些经常变动的文件信息，例如：日志文件、邮件、/proc文件系统、用户起始目录以及临时目录 AIDE安装配置 yum install aide 修改配置文件 vim /etc/aide.conf (指定对哪些文件进行检测) /test/chameleon R /bin/ps R+a /usr/bin/crontab R+a /etc PERMS !/etc/mtab #“!”表示忽略这个文件的检查 R=p+i+n+u+g+s+m+c+md5 权限+索引节点+链接数+用户+组+大小+ 最后一次修改时间+创建时间+md5校验值 NORMAL = R+rmd60+sha256 初始化默认的AIDE的库： /usr/local/bin/aide --init 生成检查数据库（建议初始数据库存放到安全的地方） cd /var/lib/aide mv aide.db.new.gz aide.db.gz 检测： /usr/local/bin/aide --check 更新数据库 aide --update TCP_Wrappers作者：Wieste Venema，IBM，Google 工作在第四层（传输层）的TCP协议 对有状态连接的特定服务进行安全检测并实现访问控制 以库文件形式实现 某进程是否接受libwrap的控制取决于发起此进程的程序在编译时是否针对libwrap进行编译的 判断服务程序是否能够由tcp_wrapper进行访问控制的方法： ldd /PATH/TO/PROGRAM|grep libwrap.so strings PATH/TO/PROGRAM|grep libwrap.so 注意：ldd，strings后要跟命令的绝对路径 配置文件：/etc/hosts.allow, /etc/hosts.deny 帮助参考：man 5 hosts_access，man 5 hosts_options 检查顺序：hosts.allow，hosts.deny（默认允许） 注意：一旦前面规则匹配，直接生效，将不再继续 基本语法: daemon_list@host: client_list [ :options :option… ] Daemon_list@host格式 单个应用程序的二进制文件名，而非服务名，例如vsftpd 以逗号或空格分隔的应用程序文件名列表，如:sshd,vsftpd ALL表示所有接受tcp_wrapper控制的服务程序 主机有多个IP，可用@hostIP来实现控制 如：in.telnetd@192.168.0.254 客户端Client_list格式 以逗号或空格分隔的客户端列表 基于IP地址：192.168.10.1 192.168.1. 基于主机名：www.magedu.com .magedu.com 较少用 基于网络/掩码：192.168.0.0/255.255.255.0 基于net/prefixlen: 192.168.1.0/24（CentOS6不支持此写法，只能centos7使用） 基于网络组（NIS 域）：@mynetwork 内置ACL：ALL，LOCAL，KNOWN，UNKNOWN，PARANOID EXCEPT用法： 示例： vsftpd: 172.16. EXCEPT 172.16.100.0/24 EXCEPT 172.16.100.1 1.只允许192.168.1.0/24的主机访问sshd /etc/hosts.allow sshd: 192.168.1. /etc/hosts.deny sshd :ALL 2.只允许192.168.1.0/24的主机访问telnet和vsftpd服务 /etc/hosts.allow vsftpd,in.telnetd: 192.168.1. /etc/host.deny vsftpd,in.telnetd: ALL 帮助：man 5 hosts_options deny 主要用在/etc/hosts.allow定义“拒绝”规则 如：vsftpd: 172.16. :deny allow 主要用在/etc/hosts.deny定义“允许”规则 如：vsftpd:172.16. :allow spawn 启动一个外部程序完成执行的操作 twist 实际动作是拒绝访问,使用指定的操作替换当前服务,标准I/O和ERROR发送到客户端,默认至/dev/null 测试工具： tcpdmatch [-d] daemon[@host] client -d 测试当前目录下的hosts.allow和hosts.deny 示例： 当ssh登录所有主机时，执行记录日志动作 sshd: ALL :spawn echo &quot;$(date +%%F) login attempt from %c to %s,%d&quot; &gt;&gt;/var/log/sshd.log 说明： 在/etc/hosts.allow中添加，允许登录，并记录日志 在/etc/hosts.deny中添加，拒绝登录，并记录日志 %c 客户端信息 %s 服务器端信息 %d 服务名 %p 守护进程的PID %% 表示% 拒绝172.16.0.0网段访问，并提示connection prohibited vsftpd: 172.16. :twist /bin/echo &quot;connection prohibited&quot; PAM认证机制PAM:Pluggable Authentication Modules 认证库：文本文件，MySQL，NIS，LDAP等 Sun公司于1995 年开发的一种与认证相关的通用框架机制 PAM是关注如何为服务验证用户的API，通过提供一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开 使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序 一种认证框架，自身不做认证 它提供了对所有服务进行认证的中央机制，适用于login，远程登录（telnet,rlogin,fsh,ftp,点对点协议（PPP）），su等应用程序中。 系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略 应用程序开发者通过在服务程序中使用PAM API(pam_xxxx())来实现对认证方法的调用 而PAM服务模块的开发者则利用PAM SPI来编写模块（主要调用函数pam_sm_xxxx()供PAM接口库调用，将不同的认证机制加入到系统中 PAM接口库（libpam）则读取配置文件，将应用程序和相应的PAM服务模块联系起来 PAM相关文件 模块文件目录：/lib64/security/*.so 环境相关的设置：/etc/security/ 主配置文件:/etc/pam.conf，默认不存在 为每种应用模块提供一个专用的配置文件：/etc/pam.d/APP_NA 注意：如/etc/pam.d存在，/etc/pam.conf将失效 PAM认证原理PAM认证一般遵循这样的顺序：Service(服务)→PAM(配置文件)→pam_*.so PAM认证首先要确定那一项服务，然后加载相应的PAM的配置文件(位于/etc/pam.d下)，最后调用认证文件(位于/lib/security下)进行安全认证 PAM认证过程： 1.使用者执行/usr/bin/passwd 程序，并输入密码 2.passwd开始调用PAM模块，PAM模块会搜寻passwd程序的PAM相关设置文件，这个设置文件一般是在/etc/pam.d/里边的与程序同名的文件，即PAM会搜寻/etc/pam.d/passwd此设置文件 3.经由/etc/pam.d/passwd设定文件的数据，取用PAM所提供的相关模块来进行验证 4.将验证结果回传给passwd这个程序，而passwd这个程序会根据PAM回传的结果决定下一个动作（重新输入密码或者通过验证） PAM配置文件与模块通用配置文件/etc/pam.conf格式 application type control module-path arguments 专用配置文件/etc/pam.d/* 格式 type control module-path arguments 说明： 服务名（application） telnet、login、ftp等，服务名字“OTHER”代表所有没有在该文件中明确配置的其它服务 模块类型（module-type） control PAM库该如何处理与该服务相关的PAM模块的成功或失败情况 module-path 用来指明本模块对应的程序文件的路径名 Arguments 用来传递给该模块的参数 例： cat /etc/pam.d/login 1234567891011#%PAM-1.0auth [user_unknown=ignore success=ok ignore=ignore default=bad] pam_securetty.soauth substack system-authauth include postloginaccount required pam_nologin.soaccount include system-authpassword include system-auth# pam_selinux.so close should be the first session rulesession required pam_selinux.so closesession required pam_loginuid.sosession optional pam_console.so /etc/pam.d/* 格式模块类型（module-type） Auth 账号的认证和授权 Account 与账号管理相关的非认证类的功能，如：用来限制/允许用户对某个服务的访问时间，当前有效的系统资源(最多可以有多少个用户)，限制用 户的位置(例如：root用户只能从控制台登录) Password 用户修改密码时密码复杂度检查机制等功能 Session 用户获取到服务之前或使用服务完成之后需要进行一些附加的操作， 如：记录打开/关闭数据的信息，监视目录等 -type 表示因为缺失而不能加载的模块将不记录到系统日志,对于那些不总是 安装在系统上的模块有用 Control: PAM库如何处理与该服务相关的PAM模块成功或失败情况 两种方式实现： 简单和复杂 1.简单方式实现：一个关健词实现 required ：一票否决，表示本模块必须返回成功才能通过认证，但是如果该模块返回失败，失败结果也不会立即通知用户，而是要等到同一type中的所有模块全部执行完毕再将失败结果返回给应用程序，即为必要条件 requisite ：一票否决，该模块必须返回成功才能通过认证，但是一旦该模块返回失败，将不再执行同一type内的任何模块，而是直接将控制权返回给应用程 序。是一个必要条件 sufficient ：一票通过，表明本模块返回成功则通过身份认证的要求，不必再执行同一type内的其它模块，但如果本模块返回失败可忽略，即为充分条件 optional：表明本模块是可选的，它的成功与否不会对身份认证起关键作用，其返回值一般被忽略 include： 调用其他的配置文件中定义的配置信息 2.复杂详细实现：使用一个或多个“status=action” [status1=action1 status2=action …] Status:检查结果的返回状态 Action:采取行为 ok，done，die，bad，ignore，reset ok 模块通过，继续检查 done 模块通过，返回最后结果给应用 bad 结果失败，继续检查 die 结果失败，返回失败结果给应用 ignore 结果忽略，不影响最后结果 reset 忽略已经得到的结果 module-path: 模块路径 相对路径： /lib64/security目录下的模块可使用相对路径 如：pam_shells.so、pam_limits.so 绝对路径： 模块通过读取配置文件完成用户对系统资源的使用控制 /etc/security/*.conf 注意：修改PAM配置文件将马上生效 建议：编辑pam规则时，保持至少打开一个root会话，以防止root身份验证错误 Arguments 用来传递给该模块的参数 PAM模块示例模块：pam_shells 功能：检查有效shell 帮助：man pam_shells 示例：不允许使用/bin/csh的用户本地登录 vim /etc/pam.d/login auth required pam_shells.so vim /etc/shells 去掉 /bin/csh useradd –s /bin/csh test test将不可登录 tail /var/log/secure 模块：pam_securetty.so 功能：只允许root用户在/etc/securetty列出的安全终端上登陆 示例：允许root在telnet登陆 vi /etc/pam.d/remote #auth required pam_securetty.so #将这一行加上注释 或者 /etc/securetty文件中加入 pts/0,pts/1…pts/n 模块：pam_nologin.so 功能： 如果/etc/nologin文件存在,将导致非root用户不能登陆 如果用户shell是/sbin/nologin 时，当该用户登陆时，会显示/etc/nologin文件内容，并拒绝登陆 模块：pam_limits.so 功能：在用户级别实现对其可使用的资源的限制， 例如：可打开的文件数量， 可运行的进程数量，可用内存空间 修改限制的实现方式： (1) ulimit命令，立即生效，但无法保存 -n 每个进程最多的打开的文件描述符个数 -u 最大用户进程数 -S 使用 soft（软）资源限制 -H 使用 hard（硬）资源限制 (2) 配置文件： /etc/security/limits.conf, /etc/security/limits.d/*.conf 配置文件：每行一个定义； &lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt; image &lt;domain&gt; 应用于哪些对象 Username 单个用户 @group 组内所有用户 * 所有用户 &lt;type&gt; 限制的类型 Soft 软限制,普通用户自己可以修改 Hard 硬限制,由root用户设定，且通过kernel强制生效 - 二者同时限定 &lt;item&gt; 限制的资源 nofile 所能够同时打开的最大文件数量,默认为1024 nproc 所能够同时运行的进程的最大数量,默认为1024 &lt;value&gt; 指定具体值 例： 限制用户最多打开的文件数和运行进程数 vim /etc/pam.d/system-auth session required pam_limits.so vim /etc/security/limits.conf apache – nofile 10240 用户apache可打开10240个文件 student hard nproc 20 用户student不能运行超过20个进程]]></content>
      <categories>
        <category>linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https机制]]></title>
    <url>%2F2018%2F07%2Fhttps%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[httpsHTTPS其实是有两部分组成：HTTP + SSL/TLS，也就是在HTTP上又加了一层处理加密信息的模块。 服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。 SSL协议实现的安全机制包括： 数据传输的机密性：利用对称密钥算法对传输的数据进行加密。 身份验证机制：基于证书利用数字签名方法对服务器和客户端进行身份验证，其中客户端的身份验证是可选的。 消息完整性验证：消息传输过程中使用MAC算法来检验消息的完整性 SSL通过握手过程在客户端和服务器之间协商会话参数，并建立会话。 会话包含的主要参数有会话ID、对方的证书、加密套件（密钥交换算法、数据加密算法和MAC算法等）以及主密钥（master secret）。通过SSL会话传输的数据，都将采用该会话的主密钥和加密套件进行加密、计算MAC等处理。 不同情况下，SSL握手过程存在差异。下面将分别描述以下三种情况下的握手过程： 只验证服务器的SSL握手过程 验证服务器和客户端的SSL握手过程 恢复原有会话的SSL握手过程 加解密过程 实现过程如下： 1.1.客户端发起HTTPS请求： 客户端访问某个web端的https地址，一般都是443端口 1.2.服务端的配置： 采用https协议的服务器必须要有一套证书，可以通过一些组织申请，也可以自己制作，目前国内很多网站都自己做的，当你访问一个网站的时候提示证书不可信任就表示证书是自己做的，证书就是一个公钥和私钥匙，就像一把锁和钥匙， 1.3.传送证书： 传递的证书其实就是公钥，里面包含了很多信息，例如证书得到颁发机构、过期时间等等。 1.4.客户端解析证书： 这部分工作是有客户端的TLS完成的，首先回验证公钥的有效性，比如颁发机构、过期时间等等，如果发现异常则会弹出一个警告框提示证书可能存在问题，如果证书没有问题就生成一个随机值，然后用证书对该随机值进行加密 1.5.传送4步骤的加密数据： 就是将用证书加密后的随机值传递给服务器，目的就是为了让服务器得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值进行加密解密了。 1.6.服务端解密信息： 服务端用私钥解密5步骤加密后的随机值之后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，对称加密就是将信息和私钥通过某种算法混合在一起，这样除非你知道私钥，不然是无法获取其内部的内容，而正好客户端和服务端都知道这个私钥，所以只要机密算法够复杂就可以保证数据的安全性。 1.7.传输加密后的信息: 服务端将用私钥加密后的数据传递给客户端，在客户端可以被还原出原数据内容。 1.8.客户端解密信息： 客户端用之前生成的私钥获解密服务端传递过来的数据，由于数据一直是加密得，因此即使第三方获取到数据也无法知道其详细内容。 客户端与服务端的通信过程 1.客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。 2.服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 3.之后服务器发送Certificate报文。报文中包含公开密钥证书。 4.最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束。 5.SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。 6.接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密。 7.客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 8.服务器同样发送Change Cipher Spec报文。 9.服务器同样发送Finished报文。 10.服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求。 11.应用层协议通信，即发送HTTP响应。 12.最后由客户端断开连接。断开连接时，发送close_notify报文。这步之后再发送TCP FIN报文来关闭与TCP的通信。。 注意： Change Cipher Spec消息属于SSL密码变化协议，其他握手过程交互的消息均属于SSL握手协议，统称为SSL握手消息。 计算Hash值，指的是利用Hash算法（MD5或SHA）将任意长度的数据转换为固定长度的数据。 Nginx实现https协议1.安装Nginx wget http://nginx.org/download/nginx-1.14.2.tar.gz tar xvf nginx-1.14.2.tar.gz cd nginx-1.14.2 ./configure --prefix=/usr/local/nginx --sbin-path=/usr/local/nginx/sbin/nginx --conf-path=/usr/local/nginx/conf/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx/nginx.pid --lock-path=/var/lock/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client/ --http-proxy-temp-path=/var/tmp/nginx/proxy/ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi --http-scgi-temp-path=/var/tmp/nginx/scgi --with-pcre &amp;&amp; make &amp;&amp; make install 2.启动nginx useradd nginx -s /sbin/nologin mkdir -pv /var/tmp/nginx/client/ /usr/local/nginx/sbin/nginx 4.生成Server私钥、申请签名证书的csr证书及证书 mkdir /usr/local/nginx/ssl &amp;&amp; cd /usr/local/nginx/ssl openssl genrsa -des3 -out server.key 2048 openssl req -new -key server.key -out server.csr openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 删除服务器私钥的密码，其实不删除也可以，只是以后重启nginx都要密码，其实要密码更安全 cp server.key server.key.bak openssl rsa -in server.key.bak -out server.key 5.配置Nginx： upstream web { #ip_hash; server 192.168.80.20 weight=1 max_fails=2 fail_timeout=2; server 192.168.80.30 weight=1 max_fails=2 fail_timeout=2; } server { listen 443 ssl; ssl_certificate /usr/local/nginx/key/server.crt; ssl_certificate_key /usr/local/nginx/key/server.key; server_name hfnginx.chinacloudapp.cn; #access_log logs/host.access.log main; location / { root html; index index.html; } location ~* ^/login { #当访问login页面的时候，就转发到后端服务器，后端有两台服务器 proxy_pass http://web; proxy_hide_header field; #proxy_set_header X-Real-IP $remote_addr; } } 6.配置两台后端Web服务器，实现负载访问，当其中一台WebServer挂掉之后，还有一台可以访问 1).web1 echo &quot;HTTPS Server1&quot; &gt; /var/www/html/login/index.html 2).web2 echo &quot;HTTPS Server2&quot; &gt; /var/www/html/login/index.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Inotify与rsync实现实时同步]]></title>
    <url>%2F2018%2F07%2FInotify%E4%B8%8Ersync%E5%AE%9E%E7%8E%B0%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[实现实时同步 要利用监控服务（inotify），监控同步数据服务器目录中信息的变化 发现目录中数据产生变化，就利用rsync服务推送到备份服务器上 实现实时同步的方法 inotify+rsync 方式实现数据同步 sersync ：金山公司周洋在 inotify 软件基础上进行开发的，功能更加强大 inotify+rsync使用方式 inotify 对同步数据目录信息的监控 rsync 完成对数据信息的实时同步 利用脚本进行结合 Rsync简介rsync是linux系统下的数据镜像备份工具。使用快速增量备份工具Remote Sync可以远程同步，支持本地复制，或者与其他SSH、rsync主机同步。 官方网站http://rsync.samba.org/ 部署Rsync1、在服务器A和服务器B上同时安装rsync服务 rpm -q rsync 可以查看系统自带了rsync服务 yum install -y rsync 2.在服务器A 配置 vim /etc/rsyncd.conf uid = root gid = root address = 192.168.80.20 #监听地址 use chroot = yes #禁锢在源目录 max connections = 0 #最大连接数不限制 port 873 #监听的端口 ignore errors log file = /var/log/rsyncd.log pid file = /var/run/rsyncd.pid reverse lookup = no hosts allow = 192.168.80.0/24 [data] #共享模块名称 path = /backup/ #源目录的实际路径 comment = www.abc.cn #项目描述 read only = no #只读 dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2 #同步时不再压缩的文件类型 auth users = rsync #授权账户,默认情况下无需密码就可以连接模块(也就是匿名方式) secrets file = /etc/rsyncd_users #存放账户信息的数据文件 3、在服务器A上创建用户认证信息文件，格式：[账号]:[密码]，这里注意一点就是权限必须设置成600 mkdir /data echo &quot;rsync:123456&quot; &gt; /etc/rsyncd_users chmod 600 /etc/rsyncd_users 4.服务器A端启动rsync服务 rsync -daemon echo &quot;/usr/bin/rsync -daemon&quot; &gt;&gt; /etc/rc.local 实现开机启动 5.客户端B配置 (1).为了在同步过程中不需要输入密码，需要创建一个密码文件 echo &quot;123456&quot; &gt;&gt;/etc/rsync.pass chmod 600 /etc/rsync.pass (2).测试 推送到服务器A rsync -avz --password-file=/etc/rsync.pass /data rsync@192.16.80.20::backup 访问rsync同步源，并下载到本地 /opt 目录下进行备份 格式一： rsync -avz rsync@192.168.80.20::data /opt/ 格式二： rsync -avz rsync://rsync@192.168.80.20/data /opt/ 这两种方法都需要进行交互 输入密码后即可进行备份。 免交互进行备份 rsync -az --delete --password-file=/etc/rsync.pass rsync@192.168.80.20::data /opt 1234567891011-v, -verbose 详细模式输出-z, -compress 对备份的文件在传输时进行压缩处理-r, -recursive 对子目录以递归模式处理-t, -times 保持文件时间信息-o, -owner 保持文件属主信息-p, -perms 保持文件权限-g, -group 保持文件属组信息-delete 删除那些DST中SRC没有的文件-exclude=PATTERN 指定排除不需要传输的文件模式-progress 在传输时现实传输过程 -password-file=FILE 从FILE中得到密码,这个文件必须是600权限 配置 rsync + inotify 实时同步 1、一旦同步源出现变化，立即启动备份 2、只要同步源无变化，则不执行备份 避免了按固定周期备份时存在的延迟性、周期过密等问题 Inotify简介Inotify 是一个Linux特性，从版本2.6.13开始提供，它监控文件系统操作，比如读取、写入和创建。Inotify反应灵敏，用法非常简单，并且比cron任务的繁忙轮询高效得多。学习如何将 inotify 集成到您的应用程序中，并发现一组可用来进一步自动化系统治理的命令行工具。 ll /proc/sys/fs/inotify #列出下面的文件，说明服务器内核支持inotify -rw-r-r- 1 root root 0 Dec 7 10:10 max_queued_events -rw-r-r- 1 root root 0 Dec 7 10:10 max_user_instances -rw-r-r- 1 root root 0 Dec 6 05:54 max_user_watches 配置Inotify1、在服务器A上调整inotify内核参数 vim /etc/sysctl.conf fs.inotify.max_queued_events = 16384 ##监控事件队列 fs.inotify.max_user_instances = 1024 ##最多监控实例数 fs.inotify.max_user_watches = 1048576 ##每个实例最多监控文件数 2、使调整inotify内核参数立刻生效 sysctl -p 3、安装Inotify-Tool工具 inotify参考文档https://github.com/rvoicilas/inotify-tools/wiki yum install -y inotify-tools 注：epel源 4.打开两个终端，一个终端执行创建删除等操作，另一个执行Inotify-Tool工具，测试Inotify-Tool工具时候正常 inotifywait -mrq -e modify,create,move,delete /var/www/html inotifywait：用于持续监控，实时输出结果 inotifywatch：用于短期监控，任务完成后再出结果 5.接下来编写触发时同步脚本 inotify.sh 12345678#!/bin/bash SRC='/data/'DEST='rsync@192.168.80.20::backup'inotifywait -mrq --timefmt '%Y-%m-%d %H:%M' --format '%T %w %f' -e create,delete,moved_to,close_write $&#123;SRC&#125; |while read DATE TIME DIR FILEdo FILEPATH=$&#123;DIR&#125;$&#123;FILE&#125; rsync -az --delete --password-file=/etc/rsync.pass $SRC $DEST &amp;&amp; echo "At $&#123;TIME&#125; on $&#123;DATE&#125;, file $FILEPATH was backuped up via rsync" &gt;&gt; /var/log/changelist.logdone chmod +x inotify.sh]]></content>
  </entry>
  <entry>
    <title><![CDATA[ftp]]></title>
    <url>%2F2018%2F06%2Fftp%2F</url>
    <content type="text"><![CDATA[存储的类型1. DAS：直接存储 2. SAN：存储区域网络，基于SCSI、IP等协议实现数据块的文件共享 3. NAS：网络存储服务，通过基于文件的协议（FTP、NFS、SAMBA）实现文件共享 ftp主动模式：服务器主动连接 命令端口：客户端：随机端口--&gt;服务器21 数据端口：客户端：随机端口&lt;--服务器20 被动模式：客户端主动连接 命令端口：客户端：随机端口--&gt;服务器21 数据端口：客户端：随机端口--&gt;服务器随机端口 工作原理： 1. 客户端通过命令端口连接的随机端口连接服务器的tcp 21端口 2. 如果服务器工作在主动模式，服务器打开数据端口的tcp 20，主动连接客户端的随机端口，该随机端口是通过客户端命令端口连接服务器时生成的端口号 如果服务器工作于被动模式，客户端随机生成一个端口，主动通过命令端口连接服务器的随机生成端口，客户使用该端口与服务器建立数据端口连接 状态码： 1XX：信息类 2XX：成功类 3XX：登录类 4XX：客户端错误 5XX：服务器错误 用户类型： 匿名用户：ftp，anonymous，与ftp用户关联，默认家目录作为服务器默认路径 系统用户：系统上真实存在的用户 虚拟用户：特定服务的专用用户，被统一映射为一个指定的系统账号，各虚拟用户可以有不同的访问权限，不同用户密码 FTP服务器软件： Wu-ftpd，Proftpd，Pureftpd，ServU，IIS vsftpd:Very Secure FTP Daemon，CentOS默认FTP服务器 高速，稳定，下载速度是WU-FTP的两倍 ftp.redhat.com数据:单机最多可支持15000个并发 客户端软件： ftp，lftp，lftpget，wget，curl ftp -A ftpserver port -A主动模式 –p 被动模式 lftp –u username ftpserver lftp username@ftpserver lftpget ftp://ftpserver/pub/file gftp：GUI centos5 最新版2.0.19 (11/30/2008) filezilla，CuteFtp，FlashFXP，LeapFtp IE ftp://username:password@ftpserver vsftp用户认证配置文件：/usr/lib64/vsftpd.conf 主配置文件：/etc/vsftpd/vsftpd.conf 常见的配置选项： 命令端口 listen_port=21 主动模式端口 connect_from_port_20=YES 主动模式端口为20 ftp_data_port=20 （默认） 指定主动模式的端口 被动模式端口范围 linux 客户端默认使用被动模式 windows 客户端默认使用主动模式 pasv_min_port=6000 0为随机分配 pasv_max_port=6010 使用当地时间 use_localtime=YES 使用当地时间（默认为NO，使用GMT） 匿名用户 annonmous_enable=YES：支持匿名用户 anon_world_readable_only：默认为yes只能下载全部读的文件 anon_upload_enable=YES：匿名上传，注意文件系统的权限 anon_mkdir_write_enable=YES：匿名建立目录 anon_umask=0333：默认匿名上传时文件的掩码，默认为077 anon_other_write_enable=YES：匿名可修改删除文件 指定上传文件的默认的所有者和权限 chown_uploads=YES(默认NO) chown_username=wang chown_upload_mode=0644 系统用户 local_enable=YES：支持系统用户 write_enable=YES：允许系统用户上传文件 local_umask=022：系统用户默认上传文件的默认权限 guest_enable=YES：所有的系统用户都映射为guest用户 guest_username=FTP：指定guest用户 local_root=/ftproot：指定guest用户登录的所在的目录 禁锢用户 chroot_local_user=YES：禁锢系统用户，默认为NO chroot_list_enable=YES chroot_list_file=/etc/vsftd/chroot_list： 当chroot_local_user=YES时，则chroot_list文件中的用户不禁锢，否则，则禁锢 日志相关 xferlog_enable=YES：启用上传下载的记录日志，默认为YES xferlog_std_format=YES：使用wu-ftp日志格式，默认为YES xferlog_file=/var/log/xferlog：默认自动生成 dual_log_enable=YES：使用vsftpd日志格式，默认为NO vsftpd_log_file=/var/log/vsftpd.log：vsftpd日志，默认自动生成 使用pam模块验证用户 pam_service_name=vsftpd pam配置文件：/etc/pam.d/vsftpd /etc/vsftpd/ftpusers：默认文件中用户拒绝登录 是否启用控制用户登录的列表文件 userlist_enable=YES：启用用户控制登录列表 userlist_deny=YES：记录在users_list文件的用户列表，默认不提示输入口令直接拒绝登录，默认为YES（黑名单），NO（白名单） vsftpd服务指定用户身份运行 nopriv_user=nobody (默认值） 连接数限制 max_client=：可以支持的最大连接数 max_per_ip=：每个IP的最大连接数 速度限制 anon_max_rate=：限制匿名用户最大传输速率 local_max_rate=：限制本地用户最大传输速率 连接时长 connect_timeout：主动模式连接的超时时长 accept_timeout：被动模式连接的超时时长 data_connectiong_timeout=300：数据连接无数据传输时的超时时长 idle_session_timeout=60：无命令操作是的超时时长 优先以文本方式传输 （文本传输会乱码，默认使用binary） ascii_upload_enable=YES ascii_download_enable=YES 配置vsftpd是否以非独立服务运行 listen=NO，默认为独立模式运行 实现基于SSL的FTPS1. vsftpd是否支持ssl ldd `which vsftpd` 查看到libssl.so 2. 创建自签名证书，且复制vsftpd配置目录下 cd /etc/pki/tls/certs make vsftpd.pem mkdir /etc/vsftpd/ssl/ cp -a /etc/pki/tls/certs/vsftpd.pem /etc/vsftpd/ssl/ 3. 配置vsftpd支持ssl 4.测试 vsftpd基于虚拟用户登录验证虚拟用户： 所有虚拟用户会统一映射为一个指定的系统帐号：访问共享位置，即为此系统帐号 的家目录 虚拟用户帐号的存储方式： 文件：编辑文本文件，此文件需要被编码为hash格式 奇数行为用户名，偶数行为密码 db_load -T -t hash -f vusers.txt vusers.db 关系型数据库中的表中： 实时查询数据库完成用户认证 mysql库：pam要依赖于pam-mysql /lib64/security/pam_mysql.so /usr/share/doc/pam_mysql-0.7/README 基于文件的虚拟用户的实现过程(1). 建立系统账号用于虚拟用户的映射关系，并更改相应的权限 useradd -d /var/ftproot -s /sbin/nologin vuser chmod +rx /var/ftproot/ chmod -w /var/ftproot/ centos7 根目录要取消读权限才能进入 mkdir /var/ftproot/upload setfacl -m u:vuser:rwx /var/ftproot/upload (2). 建立虚拟用户加密文件，该文件需要支持HASH格式编码 奇数行为用户名，偶数行为密码 vim /etc/vsftpd/vusers.txt wang wangpass mage magepass cd /etc/vsftpd/ db_load -T -t hash -f vusers.txt vusers.db 使用db_load将普通文件转换成hash编码文件，根据vusers.txt文件来生成将来pam模块能识别的二进制数据库 chmod 600 vusers.db (3). 创建pam认证文件 vim /etc/pam.d/vsftpd.db auth required pam_userdb.so db=/etc/vsftpd/vusers account required pam_userdb.so db=/etc/vsftpd/vusers (4). 在/etc/vsftpd/vsftpd.conf中调用pam认证文件 vim /etc/vsftpd/vsftpd.conf guest_enable=YES guest_username=vuser pam_service_name=vsftpd.db (5).SELinux设置： 禁用SELinux 或者 setsebool -P ftpd_full_access 1 (6).为每个虚拟用户授权不同的权限 在/etc/vsftpd/vuser.d/下创建不同虚拟用户文件，并在主配置文件中调用该配置 mkdir /etc/vsftpd/vusers.d/ 创建配置文件存放的路径 vim /etc/vsftpd/vsftpd.conf user_config_dir=/etc/vsftpd/vusers.d/ cd /etc/vsftpd/vusers.d/ 建各用户自已的配置文件 vim wang anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES 注意：允许wang用户可读写，其它用户只读 (7).测试 基于关系型数据库的虚拟用户 IP地址 操作系统 服务器角色 192.168.80.10 CentOS 7 vsftpd服务器 192.168.80.20 CentOS 7 mysql服务器 一，配置数据库服务器 1，在数据库服务器端安装mariadb-server包 yum install mariadb-server -y systemctl start mariadb # 设为开机自动启动 systemctl enable mariadb 2.运行一下mariadb安全脚本 mysql_secure_installation 3.在mariadb服务器端建立虚拟用户账号 (1).创建存储虚拟用户数据库和连接的数据库用户 一般情况下授予select权限 (2).准备存放用户的相关表,在user表中添加虚拟用户 二、配置FTP服务器 1.在FTP服务器上安装vsftpd和pam_mysql包,centos7：无对应rpm包，需手动编译安装 pam_mysql下载https://sourceforge.net/projects/pam-mysql/ yum -y groupinstall &quot;Development Tools&quot; yum -y install mariadb-devel pam-devel vsftpd tar xvf pam_mysql-0.7RC1.tar.gz cd pam_mysql-0.7RC1/ ./configure --with-pam-mods-dir=/lib64/security --with-mysql=/usr -with-pam=/usr make &amp;&amp; make install 2.在FTP服务器上建立pam认证所需文件 vim /etc/pam.d/vsftpd.mysql auth required pam_mysql.so user=vsftpd passwd=centos host=192.168.80.20 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2 account required pam_mysql.so user=vsftpd passwd=centos host=192.168.80.20 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2 配置字段说明 • auth 表示认证 • account 验证账号密码正常使用 • required 表示认证要通过 • pam_mysql.so模块是默认的相对路径，是相对/lib64/security/路 径而言，也可以写绝对路径；后面为给此模块传递的参数 • user=vsftpd为登录mysql的用户 • passwd=magedu 登录mysql的的密码 • host=mysqlserver mysql服务器的主机名或ip地址 • db=vsftpd 指定连接msyql的数据库名称 • table=users 指定连接数据库中的表名 • usercolumn=name 当做用户名的字段 • passwdcolumn=password 当做用户名字段的密码 • crypt=2 密码的加密方式为mysql password()函数加密 注意 ：crypt是加密方式，0表示不加密，1表示crypt(3)加密，2表示使用mysql password()函数加密，3表示md5加密，4表示sha1 加密 3.建立系统用户用于映射虚拟用户 useradd -s /sbin/nologin -d /var/ftproot vuser chmod 555 /var/ftproot 需除去ftp根目录的写权限 mkdir /var/ftproot/{upload,pub} -pv setfacl -m u:vuser:rwx /var/ftproot/upload 4编辑/etc/vsftpd/vsftpd.conf并添加如下字段 5.建立虚拟用户映射的系统用户及对应的目录 mkdir /etc/vsftpd/vusers.d/ 创建配置文件存放的路径 vim /etc/vsftpd/vsftpd.conf user_config_dir=/etc/vsftpd/vusers.d/ cd /etc/vsftpd/vusers.d/ vim wang anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES 6.Selinux相关设置：在FTP服务器上执行 restorecon -R /lib64/security setsebool -P ftpd_connect_db 1 setsebool -P ftp_home_dir 1 chcon -R -t public_content_rw_t /var/ftproot/ ` 6.测试 总结： &gt;在window中亦可使用FileZilla连接测试，如果测试不成功，检查下防火墙和SELinux的配置，在配置中也注意改动项的字母的书写，保持相应的一致性。 &gt;基于虚拟用户的用户存放地点有两种，二进制文件验证和MySQL，因为我们的用户一般不多，使用mysql验证还要通过TCP三次握手四次分手，比较慢，因此常用二进制文件来进行存放验证比较好]]></content>
  </entry>
  <entry>
    <title><![CDATA[NFS]]></title>
    <url>%2F2018%2F06%2FNFS%2F</url>
    <content type="text"><![CDATA[NFSNFS基于远程过程调用（Remote Procedure Call Protocol)的一种网络文件系统，通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件 管理软件包：nfs-utils 默认端口：其它端口由portmap(111)随机分配，nfsd(2049) 配置文件：/etc/exports /etc/exports.d/*.exports CentOS7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同  相关软件包:rpcbind（必须），tcp_wrappers CentOS6开始portmap进程由rpcbind代替 NFS服务主要进程： rpc.nfsd 最主要的NFS进程，管理客户端是否可登录 rpc.mountd 挂载和卸载NFS文件系统，包括权限管理 rpc.lockd 非必要，管理文件锁，避免同时写出错 rpc.statd 非必要，检查文件一致性，可修复文件 日志：/var/lib/nfs/ 工作原理 配置NFS如系统没有，则需要使用yum install nfs-utils安装，之后使用systemctl start nfs-server启动 /etc/exports导出文件系统的格式 /DIR HOST1(opt1,opt2) HOST2(opt1,opt2)... HOST1支持通配符，网络地址 opt: ro：只读 rw：读写 sync：同步，数据请求时立即写入磁盘 async：异步，数据不立即写入磁盘 all_squash：将所有远程用户包括root用户都压缩成nfsnobody root_squash：将远程root用户压缩成nfsnobody no_root_squash：不压缩远程root用户 anonuid和anongid：指定匿名用户映射为指定用户UID和组GID，一般配合all_squash使用 NFS常用命令rpcinfo -p hostname：查看指定主机的rpc注册信息 rpcinfo -s hostname：查看RPC注册的程序 exportfs -v 查看北极所有NFS共享 -r 重读配置文件，并共享目录 -a 输出本机所有共享 -au 停止本机所有共享 showmount -e hostname：查看指定服务器的共享信息 NFS的挂载mount -t nfs -o[option] IP:/SHARE /MOUNTPIONT [option] fg：前台挂载 bg：后台挂载 hard：持续请求 soft：非持续请求 rsize、wsize：一次读和写数据的最大字节数 _netdev：无网络不挂载 nosuid：没有suid权限 nodev：设备文件不可用 noexec：不能运行可执行二进制文件 自动挂载 由autofs服务提供，将/etc/auto.master文件的匹配的文件自动挂载至指定的目录 支持含通配符的目录名 * server:/export/&amp; 挂在目录与共享目录名称相同 示例： /etc/auot.master /- /etc/auto.direct /test /etc/auto.test /etc/auot.test /abc server:/PATH /etc/auto.direct /user/local/ server1:/usr/local 实验：实现NFS伪根配置NFS服务器 vim /etc/fstab /data/read /exports/read none bind 0 0 /data2/write /exports/write none bind 0 0 vim /etc/exports /exports *(fsid=0,ro,crossmnt) /exports/read 192.168.0.0/24(ro) /exports/write 192.168.0.0/24(rw) 配置NFS客户端 mount nfsserver:/ /mnt/nfs vim /etc/fstab nfsserver:/ /mnt/ nfs4 ro 0 0]]></content>
  </entry>
  <entry>
    <title><![CDATA[samba]]></title>
    <url>%2F2018%2F06%2Fsamba%2F</url>
    <content type="text"><![CDATA[samba简介SMB：Server Message Block服务器消息块，IBM发布，最早是DOS网络文件共享协议 Cifs：common internet file system，微软基于SMB发布 SAMBA:1991年Andrew Tridgell,实现windows和UNIX相通 SAMBA的功能： 共享文件和打印，实现在线编辑 实现登录SAMBA用户的身份认证 可以进行NetBIOS名称解析 外围设备共享 计算机网络管理模式： 工作组WORKGROUP：计算机对等关系，帐号信息各自管理 域DOMAIN:C/S结构，帐号信息集中管理，DC,AD 相关包： Samba 提供smb服务 Samba-client 客户端软件 samba-common 通用软件 cifs-utils smb客户端工具 samba-winbind 和AD相关 服务进程 smbd：tcp 139,445 nmb：udp 137,138 主配置文件：/etc/samba/smb.conf 语法检查：testparm [-v] [/etc/samba/smb.conf] 客户端工具：smbclient,mount.cifs 服务器配置全局设置： [global] 服务器通用或全局设置的部分 特定共享设置： [homes] 用户的家目录共享 [printers] 定义打印机资源和服务 [sharename] 自定义的共享目录配置 其中：#和;开头的语句为注释，大小写不敏感 宏定义： %m 客户端主机的NetBIOS名 %M 客户端主机的FQDN %H 当前用户家目录路径 %U 当前用户用户名 %g 当前用户所属组 %h samba服务器的主机名 %L samba服务器的NetBIOS名 %I 客户端主机的IP %T 当前日期和时间 %S 可登录的用户名 workgroup：指定工作组信息 hots allow可用， 空格，tab分隔：默认允许所有主机访问，也可在每个共享独立配置， 如在[global]设置，将应用并覆盖所有共享设置 IPv4 network/prefix: 172.25.0.0/24 IPv4前缀: 172.25.0. IPv4 network/netmask: 172.25.0.0/255.255.255.0 主机名: desktop.example.com 以example.com后缀的主机名: .example.com 示例： hosts allow = 172.25. hosts allow = 172.25. .example.com hosts deny 拒绝指定主机访问 config file=/etc/samba/conf.d/%U：用户独立的配置文件 log file=/var/log/samba/log.%m：不同客户端采用不同的日志 log level=2：日志级别，默认为0，不记录日志 max log size=50：日志文件达到50k，将自动轮循 Security三种认证方式： share：匿名(CentOS7不再支持) user：samba用户（采有linux用户，samba的独立口令） domain：使用DC（DOMAIN CONTROLLER)认证 passdb backend = tdbsam 密码数据库格式 SAMBA用户管理实现samba用户： 包： samba-common-tools 工具：smbpasswd pdbedit samba用户须是Linux用户，建议使用/sbin/nologin smbpasswd -a &lt;user&gt; 将一个系统添加进samba用户 smbpasswd &lt;user&gt; 修改用户密码 smbpasswd -x &lt;user&gt; 删除用户 查看samba用户列表： /var/lib/samba/private/passdb.tdb pdbedit –L –v 查看samba服务器状态 smbstatus 配置共享目录每个共享目录应该有独立的[ ]部分 [共享名称] 远程网络看到的共享名称 comment 注释信息 path 所共享的目录路径 public 能否被guest访问的共享，默认no，和guest ok类似 browsable 是否允许所有用户浏览此共享,默认为yes,no为隐藏 writable=yes 可以被所有用户读写，默认为no read only=no 和writable=yes等价，如与以上设置冲突，放在后面的设置生效，默认只读 write list 三种形式：用户，@组名，+组名,用，分隔 如writable=no，列表中用户或组可读写，不在列表中用户只读 valid users 特定用户才能访问该共享，如为空，将允许所有用户，用户名之间用空格分隔 例： [share] path = /app/dir valid users=wang,@admins writeable = no browseable = no 访问SAMBA共享资源smbclient -L HOST 列出指定主机的共享资源 -U username 指定访问该共享资源的用户名 -P password 指定访问该共享资源的密码 挂载smabamount -t cifs //share_ip/shared_resource /mount_piont -o username=shared_user_name [password=shared_user_password] mount -t cifs //192.168.50.1/sda1 /media/smb -o username=admin 示例： 建立samba共享，共享目录为/data，要求： 1)共享名为shared，工作组为workgroup； 2)添加组tom，添加用户wang,li和wu，其中wang和li以tom为附加组，wu不属于tom组；密码均为用户名； 3)添加samba用户wang,li和wu，密码同用户名； 4)此samba共享shared仅允许tom组具有写权限，其他用户只能以只读方式访问； 5)此samba共享服务仅允许来自于192.168.80.0/24络的主机访问； mkdir /data chown 777 /data groupadd tom useradd -G tom wang echo &quot;wang&quot; | passwd --stdin wang useradd -G tom li echo &quot;li&quot; | passwd --stdin li useradd wu echo &quot;wu&quot; | passwd --stdin wu smbpasswd -a wang smbpasswd -a li smbpasswd -a wu vim /etc/samba/smb.conf workgroup = workgroup [shared] path=/data read only = No browsable = Yes guest ok = Yes writelist = @tom host list = 192.168.80.0/24]]></content>
  </entry>
  <entry>
    <title><![CDATA[shell编程进阶]]></title>
    <url>%2F2018%2F06%2Fshell%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[选择执行语句if语句 单分支 if 判断条件；then 条件为真的分支 fi 双分支 if 判断条件；then 条件为真的分支1 else 条件为假的分支2 fi 多分支 if 判断条件1；then 条件为真的分支 elif 判断条件2；then 条件为真的分支 elif 判断条件3；then 条件为真的分支 else 以上条件均不符合的分支 fi case语句 case语句用于多分支的情况 根据变量匹配对应的分支来执行。 case 变量引用 in par1） 执行分支1 ；； pat2） 执行分支2 ；； ………… *） 执行分支 seac case语句支持通配符写法 循环执行语句for语句 for 变量名 in 列表；do 循环体 done 双小括号方法 即((…))格式 也可以用于算术运算 双小括号方法也可以使bash Shell实现C语言风格的变量操作 I=10 ((I++)) 列表可通过以下方式生成 1）直接给出 在”in”后直接列出要循环的数值 2）数列 通过{start..end}表示一个集合作为列表 3）用命令生成列表 例如”ls ~root/”命令可显示root家录下文件名。 4）通配符生成列表 例如”*.sh”可显示”sh”后缀文件作为循环列表 5）还可使用变量作为列表 例题： 编写脚本 猴子偷桃 while循环 while CONDITION; do 循环体 done 特殊用法（遍历文件的每一行） while read line; do 循环体 done &lt; /PATH/file 依次读取/PATH/file文件中的每一行 且将行赋值给变量line 进入条件：CONDITION为true 退出条件：CONDITION为false until循环 until CONDITION; do 循环体 done 进入条件：CONDITION为true 退出条件：CONDITION为false select 菜单生成 select NAME；do 命令 done 用户输入的保存在REPLY变量里 主要用于创建菜单，按数字顺序排列的菜单项将显示在标准错误上， 并显示 PS3 提示符，等待用户输入 用户输入菜单列表中的某个数字，执行相应的命令 select 是个无限循环，因此要记住用 break或用 exit 命令终止。也可以按 ctrl+c 退出循环 经常和 case 联合使用 与 for 循环类似，可以省略 in list，此时使用位置参量 循环控制语句continue [N]： 提前结束第N层的本轮循环 而直接进入下一轮判断；最内层为 第1层 shift [n] 用于将参量列表 list 左移指定次数 缺省为左移一次。 参量列表 list 一旦被移动 最左端的那个参数就从列表中删除。while 循环遍 历位置参量列表时常用shift ​​ ./doit.sh a b c d e f g h break [N]，结束第N层循环 函数 f_name ( ) { 函数体 } 或 function f_name { 函数体 } 或 funtion f_name ( ){ 函数体 } 函数返回值 return，提前结束本函数体 示例：取出指定网卡的IP ip() { ifconfig $1 | sed -nr &quot;s@.* inet (addr:)?([^ ]+).*@\2@p&quot; } export -f funtion_name 函数递归 信号捕捉trap &apos;触发指令&apos; 信号 trap &apos;-&apos; 恢复原信号 trap &apos;p&apos; 列出自定义信号列表 trap finish EXIT 脚本执行完执行finish函数 数组多个变量的集合，连续的内存空间 数组中的元素有索引编号 1. 从0开始，属于数值索引 2. 索引可以是其它格式，属于关联索引，（注意，该功能在bash4.0后才能使用） 定义数组 1. declare -a ARRAY 2. declare -A ARRAY，关联数组 数组赋值 1. 一次只给一个元素赋值 ARRAY_NAME[INDEX]=VALUE 示例 students[0]=&quot;myname&quot; 2. 给数组的所有元素赋值 ARRAY_NAME=(&quot;VALUE1&quot; &quot;VALUE2&quot; ...) 3. 给数组中的特定元素赋值 ARRAY_NAME=([0]=&quot;VALUE1&quot; [1]=&quot;VALUE2&quot;) 4. 交互式输入数组的各元素 read -p ARRARY_NAME 显示数组的长度 ${#ARRAY[@]} ${#ARRAY[*]} 显示数组的所有元素 ${ARRAY[*]} ${ARRAY[@]} 示例，给数组增加新元素 title[${#title[*]}]=&quot;VALUE&quot; 数组切片 ${ARRAY[*]:offset:NUMBER} offset，要跳过的元素个数 NUMBER，要显示的个数 字符串切片${#var}：返回字符串长度 ${var:offset}：返回从var中第offset以后的字符 ${var:offset:number}：返回从var中第offset个字符后的字符开始，长度为number的部分 ${var: -length}：取字符串最右侧几个字符 ${var:offset:-length}：从最左侧跳过offset字符，一直向右取到距离最右侧lengh个字符之前的内容 ${var: -length:-offset}：先从最右侧向左取到length个字符开始，再向右取到距离最右侧offset个字符之间的内容 字符串处理${var#*word}，自左向右，查找第一次与word匹配，删除该字符串开头至word之间的字符 ${var##*word},贪婪模式 示例 file=“var/log/messages” ${file#*/}: log/messages ${file##*/}: messages ${var%word*}，自右向左，查找第一次与word匹配，删除该字符串开头至word之间的字符 ${var%%word*}贪婪模式 示例： url=http：//www.sss.com:80 echo ${url%%:*} 结果：http echo ${url##*:} 结果：80 字符串查找替换 ${var/pattern/substr}：查找var所表示的字符串中，第一次被pattern所匹 配到的字符串，以substr替换之 ${var//pattern/substr}: 查找var所表示的字符串中，所有能被pattern所匹 配到的字符串，以substr替换之 ${var/#pattern/substr}：查找var所表示的字符串中，行首被pattern所匹 配到的字符串，以substr替换之 ${var/%pattern/substr}：查找var所表示的字符串中，行尾被pattern所匹 配到的字符串，以substr替换之 字符串查找并删除 ${var/pattern}：删除var表示的字符串中第一次被pattern匹配到的字符串 ${var//pattern}：删除var表示的字符串中所有被pattern匹配到的字符串 ${var/#pattern}：删除var表示的字符串中所有以pattern为行首匹配到的 字符串 ${var/%pattern}：删除var所表示的字符串中所有以pattern为行尾所匹配 到的字符串 字符大小写转换 ${var^^}：把var中的所有小写字母转换为大写 ${var,,}：把var中的所有大写字母转换为小写 declare-r 声明或显示只读变量 -i 将变量定义为整型数 -a 将变量定义为数组 -A 将变量定义为关联数组 -f 显示已定义的所有函数名及其内容 -F 仅显示已定义的所有函数名 -x 声明或显示环境变量和函数 -l 声明变量为小写字母 declare –l var=UPPER -u 声明变量为大写字母 declare –u var=lower eval对变量进行两次扫描 示例： n=10 echo {1..$n} 结果：{1..10} eval echo {1..$n} 结果：1 2 3 4 5 6 7 8 9 10 变量间接引用 eval tempvar=\$$variable1 tempvar=${!variable1} 示例： name=ssss ssss=aaaa eval echo \$$name echo ${!aaa} 结果：aaaa mktemp 创建临时文件或目录mktemp [option] fileXXX 生成随机字符文件，随机X最少个数为3个 -d: 创建临时目录 -p DIR或--tmpdir=DIR：指明临时文件所存放目录位置 install，安装复制文件install [option] src dest [option] -m 权限 -o 所有者 -g 所有组 -d 目录 示例： install -m 600 -osss -gaaa /etc/fstab /tmp/file 结果： 1. 复制/etc/fstab到/tmp/并改名为file 2. 把该文件的权限改为600 3. 把该文件的所有者改为sss，所属组改为aaa expect主要应用于自动化交互式操作的场景，借助Expect处理交互的命令，可以将交互 过程如：ssh登录，ftp登录等写在一个脚本上，使之自动化完成。尤其适用于需 要对多台服务器执行相同操作的环境中，可以大大提高系统管理人员的工作效率 expect [option] -c，从命令行执行expect -d，打开调试模式 相关的命令 spawn，启动一个进程 send，发送相应的指令 exp_continue 匹配多个字符串在执行动作后加此命令 expect 从进程接收字符串 interact，停留在终端不退出 exp_continue 匹配多个字符串在执行动作后加此命令 expect最常用的语法(tcl语言:模式-动作) 单一分支模式语法： expect “hi” {send “You said hi\n&quot;} 匹配到hi后，会输出“you said hi”，并换行 多分支模式语法： expect &quot;hi&quot; { send &quot;You said hi\n&quot; } \ &quot;hehe&quot; { send &quot;Hehe yourself\n&quot; } \ &quot;bye&quot; { send &quot;Good bye\n&quot; } 匹配hi,hello,bye任意字符串时，执行相应输出。等同如下： 12345expect &#123;"hi" &#123; send "You said hi\n"&#125;"hehe" &#123; send "Hehe yourself\n"&#125;"bye" &#123; send "Good bye\n"&#125;&#125; 示例: 1234567#!/usr/bin/expectspawn scp /etc/fstab 192.168.8.100:/appexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125;"password" &#123; send “magedu\n" &#125;&#125;expect eof 。。。。。。1234567#!/usr/bin/expect spawn ssh 192.168.8.100 expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send “magedu\n" &#125; &#125; interact #expect eof 示例:变量 1234567891011#!/usr/bin/expectset ip 192.168.8.100set user rootset password mageduset timeout 10spawn ssh $user@$ipexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125;"password" &#123; send "$password\n" &#125;&#125;interact 示例:位置参数 1234567891011#!/usr/bin/expectset ip [lindex $argv 0]set user [lindex $argv 1]set password [lindex $argv 2]spawn ssh $user@$ipexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125;"password" &#123; send "$password\n" &#125;&#125;interact#./ssh3.exp 192.168.8.100 root magedu 示例：执行多个命令 1234567891011121314#!/usr/bin/expectset ip [lindex $argv 0]set user [lindex $argv 1]set password [lindex $argv 2]set timeout 10spawn ssh $user@$ipexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125;&#125;expect "]#" &#123; send "useradd haha\n" &#125;expect "]#" &#123; send "echo magedu |passwd --stdin haha\n" &#125;send "exit\n"expect eof#./ssh4.exp 192.168.8.100 root magedu 示例：shell脚本调用expect 1234567891011121314151617#!/bin/baship=$1user=$2password=$3expect &lt;&lt;EOFset timeout 10spawn ssh $user@$ipexpect &#123;"yes/no" &#123; send "yes\n";exp_continue &#125;"password" &#123; send "$password\n" &#125;&#125;expect "]#" &#123; send "useradd hehe\n" &#125;expect "]#" &#123; send "echo magedu |passwd --stdin hehe\n" &#125;expect "]#" &#123; send "exit\n" &#125;expect eofEOF#./ssh5.sh 192.168.8.100 root magedu]]></content>
  </entry>
  <entry>
    <title><![CDATA[shell编程基础]]></title>
    <url>%2F2018%2F06%2Fshell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[编程基础程序编程风格： 过程式：以指令为中心 数据服务于指令 对象式：以数据为中心 指令服务于数据 shell程序：提供了编程能力 解释执行 高级编程语言： 编译：高级语言--&gt;编译器--&gt;机器代码--&gt;执行 C C++ 解释：高级语言--&gt;执行--&gt;解释器--&gt;机器代码 shell python php JavaScript perl 脚本基础格式要求： 第一行必须包括shell声明序列 #!/bin/bash #!/usr/bin/python #!/usr/bin/perl 添加注释 以#开头 脚本规范 1、第一行一般为调用使用的语言 2、程序名 避免更改文件名为无法找到正确的文件 3、版本号 4、更改后的时间 5、作者相关信息 6、该程序的作用 及注意事项 7、最后是各版本的更新简要说明 脚本的用途有： 自动化常用命令 执行系统管理和故障排除 创建简单的应用程序 处理文本或文件 脚本调试 bash -n file 检查语法错误 bash -x file 调试执行 测试命令 [ 表达式 ] [[ 表达式 ]] 中括号表达式之间必须要有空格 退出状态码 exit [n]:自定义退出状态码 注意：退出中一旦遇到exit命令 脚本会立即终止；终止退出状态取决于exit命令后面的数字 注意：如果未给脚本指定状态码 整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 示例 12345678910111213#!/bin/bash# ------------------------------------------# Filename: hello.sh# Revision: 1.1# Date: 2017/06/01# Author: wang# Email: wang@gmail.com# Website: www.ma.com# Description: This is the first script# ------------------------------------------# Copyright: 2017 wang# License: GPLecho “hello world 12#!/bin/bashecho "hello world" 1234[root@cen7 bin]#bash -n hello.sh [root@cen7 bin]#bash -x hello.sh + echo 'hello world'hello world 变量字符型： 数值型：整型、浮点型 弱类型：定义变量时无需指定类型默认，均为字符型参与运算时会自动进行隐式转换，变量无需事先定义可直接调用； 强类型：定义变量时，必须指定类型，参与运算时必须符合类型要求，调用未声明的变量会出错； 变量命名法则： 1、不能使程序中的保留字：例如if, for 2、只能使用数字、字母及下划线，且不能以数字开头 3、见名知义 4、统一命名规则：驼峰命名法（包括小驼峰和大驼峰） 如：studentName；小驼峰命名，第一个单词首字母不大写，后续单词首字母全部大写 StudentName;大驼峰命名，第一个单词首字母大写，后续单词首字母全部大写 变量种类局部变量：生效范围为当前shell进程中某代码片段，生效范围为当前shell进程；对当前shell之外的其它shell进程，包括当前shell的子shell进程均无效 环境（全局）变量：生效范围为当前shell进程及其子进程 本地变量：生效范围为当前shell进程中某代码片断，通常指函数 只读变量：只能声明 但不能修改和删除 位置变量：$1, $2, ...来表示，用于让脚本在脚本代码中调用通过命令行传递给它的参数 特殊变量：$?, $0, $*, $@, $#,$$ 局部变量变量赋值：name=‘value’ 变量引用：${name} $name &quot;&quot;：弱引用 其中的变量引用会被替换为变量值 &apos;&apos;：强引用 其中的变量引用不会被替换为变量值 而保持原字符串 显示已定义的所有变量：set 删除变量：unset name 环境（全局）变量变量声明并赋值： export var_name=value declare -x var_name=value 变量引用同本地变量 显示所有环境变量： export env printenv 撤销变量： unset name 内建环境变量： PATH SHELL UID PS1 PWD OLDPWD HISTSIZE 只读变量声明 readonly name declare -r name 查看 readonly -p declare -r 位置变量$1, $2, ...：对应第1、第2等参数 $0: 命令本身 $*: 传递给脚本的所有参数 全部参数合为一个字符串 $@: 传递给脚本的所有参数 每个参数为独立字符串 $#: 传递给脚本的参数的个数 $@ $* 只在被双引号包起来的时候才会有差异 当位置变量参数数量达到10以上$后面的变量需要用{}括起来，否则第10个以后的变量会被当成两个参数，如$10会被当成$1和0 set -- 清空所有位置变量 退出状态进程使用退出状态来报告成功或失败 * 代表成功，1-255代表失败 * $?保存最近的命令退出状态，使用echo $?查看退出状态值 bash自定义退出状态码 exit [n]：自定义退出状态码 注意：脚本中一旦遇到exit命令，脚本会立即终止；终止退出状态取决于exit命令后面的数字 注意：如果未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 示例： ping -c1 -W1 1.1.1.1 &amp;&gt; /dev/null echo $? 示例： 1、显示系统信息（包括操作系统版本、内核版本、cpu型号、内存大小、硬盘大小、ip地址、用户名、主机名） 12345678910#!/bin/bashecho "os version is:^[[1;31m `cat /etc/centos-release`^[[m"#^[[1;31m ^[[m 是给输出结果添加颜色echo "kernel version is^[[1;31m `uname -r`^[[m"echo "cpu type is ^[[1;31m`lscpu |grep -s "Model name"|tr -s " " |cut -d: -f2`^[[m"echo "^[[1;31m`cat /proc/meminfo |head -n1`^[[m"echo "Disk:^[[1;31m`lsblk |grep "^sd"|tr -s " "|cut -d" " -f1,4`^[[m"echo "Network ip: ^[[1;31m`ifconfig ens33 |grep -w "inet"|grep -Eo '([0-9]&#123;1,3&#125;\.)&#123;3&#125;[ 0-9]&#123;1,3&#125;'|head -n1`^[[m"echo "My username is ^[[1;31m$USER^[[m"echo "My hostname is ^[[1;31m`hostname`^[[m" 2、编写脚本/root/bin/backup.sh，可实现每日将/etc/目录备份到/root/etcYYYY-mm-dd中 12#!/bin/bashcp -a /etc/ /root/etc`date "+%F"` 3、编写脚本/root/bin/disk.sh,显示当前硬盘分区中空间利用率最大的值 12#!/bin/bashdf |grep "/dev/sd" |tr -s " " %|cut -d% -f5|sort -nr|head -n1 4、编写脚本/root/bin/links.sh,显示正连接本主机的每个远程主机的IPv4地址和连接数，并按连接数从大到小排序 12#!/bin/bashnetstat -nt |tr -s " " :|cut -d: -f6 |sort|uniq -c |sort -nr 5.创建用户 设置初始口令magedu 并且初次登录提醒更改口令 123456#!/bin/bashuseradd $1echo magedu |passwd --stdin $1 &gt;&gt; /dev/nullecho "password is changed"passwd -e $1 &gt;&gt; /dev/nullecho "please change password" 算术运算实现算术运算： +,-,* / %取模（取余） **（乘方） (1)let num=算术表达式 let r=9+9 (2)var=$[算术表达式] r=$[9+9] (3)var=$((算术表达式)) r=$((9+9)) (4)外部命令 expr expr 8+3 (5)declare -i var = 数值 declare -i r=9+9 (6)echo ‘算术表达式’ | bc echo “8+8” | bc bash内建的随机数生成器:$RANDOM(0-32767) echo $[$RANDOM%50] ：0-49之间随机数 echo $[$RANDOM%7] ：0-6之间随机数 赋值 增强型赋值： += -= *= /= %= let varOPERvalue 例如：let count+=3 自加3后自赋值 自增 自减： let var+=1 let var++ let var-=1 let var– 逻辑运算 判断 true：1 false：0 | 或 1|1=1 1|0=1 0|0=0 &amp; 与 1&amp;1=1 1&amp;0=0 0&amp;0=0 ！非 ！1=0 ！0=1 &amp;&amp; 短路与 cmd1 &amp;&amp; cmd2 第一个为0 结果必定为0 ;第一个为1 第二个必须要参与运算 || 短路或 cmd1 || cmd2 第一个为0 第二个必须要参与运算；第一个为1 结果为1 ^ 异或 1^0=1 1^1=0 示例： 1. 1234567891011121314151617181920[root@centos7 ~]#x=10[root@centos7 ~]#y=20[root@centos7 ~]#let s=x+y[root@centos7 ~]#echo $s30[root@centos7 ~]#s=$[x+y][root@centos7 ~]#echo $s30[root@centos7 ~]#s=$((x+y))[root@centos7 ~]#echo $s30[root@centos7 ~]#expr 2 + 35[root@centos7 ~]#expr 2 \* 36[root@centos7 ~]#declare -i n=10[root@centos7 ~]#declare -i m=20[root@centos7 ~]#declare -i s=$n+$m[root@centos7 ~]#echo $s30 2. 12345678[root@centos7 ~]#n=10[root@centos7 ~]#let n+=1[root@centos7 ~]#echo $n11[root@centos7 ~]#n=10[root@centos7 ~]#let n++[root@centos7 ~]#echo $n11 let var-=1;let var--同理。 3.检查磁盘利用率是否大于80，大于80就报警，低于80不报警 12345678#!/bin/bashn=`df | grep "/dev/sd"|tr -s " " %|cut -d% -f5 |sort -nr |head -n1`Inode=`df -i | grep "/dev/sd"|tr -s " " |cut -d" " -f2 |sort -nr|head -n1`#把磁盘inode值取出export m=80[ $n -gt $m ] &amp;&amp; echo `wall disk will be full`[ $Inode -gt $m ] &amp;&amp; echo `wall inode will be full`#把inode值与80作比较，如果大于80就做出报警 条件测试 条件判断 若真 则返回0 若假 则返回1 测试命令： [ EXPRESSION ] [ [ EXPRESSION ] ] 注意：EXPRESSION前后必须有空白字符 数值测试： -gt：大于 -ge：大于等于 -lt：小于 -le：小于等于 -eq：等于 -ne：不等于 字符串测试： ==： !=： =~：左侧的字符串是否能够被右侧的pattern匹配 此表达式一般要这样使用[[ 表达式 =~ ]] -z &quot;string&quot;：测试字符串是否为空 空为真 不空为假 -n &quot;string&quot; ：测试字符串是否为不空 不空为真 空为假 判断变量是否为空： [ x&quot;$VAR&quot; = x ] 文件测试： -e file：文件存在测试 存在为真 否则为假 类型测试： -b file：存在并为块设备文件测试 -d file：存在并为目录文件测试 -f file：存在并为普通文件测试 -c file：存在并为字符文件测试 -p file：存在并为管道文件测试 -L file：存在并为符号链接文件测试 -s file：存在并为套接字文件测试 文件权限测试： -r file：存在且可读 -w file：存在且可写 -x file：存在且可执行 特殊权限测试： -g file：存在并设置为sgid权限的文件 -u file：存在并设置为suid权限的文件 -k file：存在并设置为sticky权限的文件 文件大小测试： -s file：存在且非空 文件是否打开： -t fd：fd表示文件描述符是否已经打开且与某终端相关 -N file：文件自上一次被读取之后是否被修改过 -O file：当前用户是否为文件属主 -G file：当前用户是否为文件属组 双目测试： file1 -ef file2 file1与file2是否执行同一个设备上的相同的inode file1 -nt file2 file1是否新于file2 file2 -ot file2 file1是否旧于file2 组合测试 表达式1 -a 表达式2 表达式1 -o 表达式2 ！表达式 示例： [ ! \( -r /tmp/file.txt -o -w /tmp/file.txt \) ] [[]]不能使用组合的测试条件 read [option] [name...] -s 静默输入 默认用于输入密码 示例： read -s -p &quot;input you passwd&quot; passwd -n 指定输入字符的长度 -t 指定超时时长 -p prompt 批量输入 echo &quot;$1 $2 $3&quot; &gt;file read $1 $2 $3 &lt;file read &lt;&lt; &quot;$1 $2 $3&quot; 示例： [root@centos7 ~]#[ -z &quot;&quot; ] &amp;&amp; echo true || echo false true [root@centos7 ~]#[ -z &quot;x&quot; ] &amp;&amp; echo true || echo false false [root@centos7 ~]#[ -n &quot;&quot; ] &amp;&amp; echo true || echo false false [root@centos7 ~]#[ -n &quot;x&quot; ] &amp;&amp; echo true || echo false true 判断变量HOSTNAME非空或等于localhost.localdomain，如果满足该条件则执行localhost.localdomain命令 [ -z “$HOSTNAME” -o $HOSTNAME &quot;==\&quot;localhost.localdomain&quot; ] &amp;&amp; hostname www.magedu.com 判断/bin/cat为普通文件并且有执行权限，如果满足则执行cat /etc/fstab [ -f /bin/cat -a -x /bin/cat ] &amp;&amp; cat /etc/fstab 判断ip地址：如果是ip地址，则输出true，否则为false ip=1.1.1.1;[[ &quot;$ip&quot; =~ ^(([0-9][1-9]?|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9][1-9]?|1[0-9]{2}|2[0-4][0-9]|25[0-5])$ ]] &amp;&amp; echo true ||echo false 用户工作环境交互式shell 等待用户输入 执行提交的命令 exit su - username /etc/profile-&gt;/etc/profile.d/*.sh--&gt;~/.bash_profile--&gt;~/.bashrc--&gt;/etc/bashrc 非交互式shell 执行shell脚本 脚本执行结束shell退出 图形界面打开的终端 su username /etc/profile-&gt;/etc/profile.d/*.sh--&gt;~/.bash_profile--&gt;~/.bashrc--&gt;/etc/bashrc Bash的配置文件保存用户的工作环境 个人配置文件 ~/.bash_profile ~/.bashrc 全局配置文件 /etc/profile /etc/profile.d/*.sh /etc/bashrc profile类 设定环境变量 登录前运行的脚本和命令 bashrc类 设定本地变量 定义命令别名 注意： 全局配置和个人配置设置冲突 以个人设置为准 编辑配置文件生效 修改profile和bashrc文件后需立即生效 两种方法: 1重新启动shell进程 2 . 或source（不推荐使用，全局变量生效会对当前环境产生影响） 例: . ~/.bashrc bash退出任务 在退出登录shell时运行 保存在~/.bash_logout文件中（用户） • 创建自动备份 • 清除临时文件 $-变量 [root@centos7 ~]#echo $- himBH h表示开启hash缓存 通过set +h将h选项关闭 i判断是不是交互式shell m监控模式 B支持大括号扩展 H历史命令]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cobbler]]></title>
    <url>%2F2018%2F05%2FCobbler%2F</url>
    <content type="text"><![CDATA[PXE不支持UEFI 更多使用Cobbler来实现自动化部署 Cobbler快速网络安装linux操作系统的服务，支持众多的Linux发行版：RedHat、Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windows PXE的二次封装，将多种安装参数封装到一个菜单 Python编写 提供了CLI和Web的管理形式 但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的 cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合 BIOS+MBR：分区最多支持2T的 UEFI+GPT：分区可以支持大于2T的分区 在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了 Cobbler工作原理 Server端： 第一步，启动Cobbler服务 第二步，进行Cobbler错误检查，执行cobbler check命令 第三步，进行配置同步，执行cobbler sync命令 第四步，复制相关启动文件文件到TFTP目录中 第五步，启动DHCP服务，提供地址分配 第六步，DHCP服务分配IP地址 第七步，TFTP传输启动文件 第八步，Server端接收安装信息 第九步，Server端发送ISO镜像与Kickstart文件 Client端： 第一步，客户端以PXE模式启动 第二步，客户端获取IP地址 第三步，通过TFTP服务器获取启动文件 第四步，进入Cobbler安装选择界面 第五步，客户端确定加载信息 第六步，根据配置信息准备安装系统 第七步，加载Kickstart文件 第八步，传输系统安装的其它文件 第九步，进行安装系统 基础环境准备安装包 cobbler 基于EPEL源 cobbler 服务集成 前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务 PXE DHCP rsync Httpd DNS Kickstart syslinux tftp-server IPMI 电源管理 启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd systemctl start httpd tftp dhcp systemctl start cobblerd 然后再检查cobbler环境 cobbler check cobbler的相关配置文件安装：yum install cobbler dhcp 配置文件目录 /etc/cobbler /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行) /etc/cobbler/iso/: iso模板配置文件 /etc/cobbler/pxe: pxe模板文件 /etc/cobbler/power: 电源配置文件 /etc/cobbler/user.conf: web服务授权配置文件 /etc/cobbler/users.digest: web访问的用户名密码配置文件 /etc/cobbler/dhcp.template : dhcp服务器的的配置末班 /etc/cobbler/dnsmasq.template : dns服务器的配置模板 /etc/cobbler/tftpd.template : tftp服务的配置模板 /etc/cobbler/modules.conf : 模块的配置文件 数据目录 /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件 /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令 /var/lib/cobbler/kickstart/: 默认存放kickstart文件 /var/lib/cobbler/loaders/: 存放各种引导程序 镜像目录 /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据 /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动 /var/www/cobbler/repo_mirror/: yum 仓库存储目录 日志目录 /var/log/cobbler/installing: 客户端安装日志 /var/log/cobbler/cobbler.log : cobbler日志 /etc/cobbler/settings中重要的参数设置 default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot; //修改成用openssl rand passwd -1 生成的口令 server: 192.168.34.17 //修改成本地网卡的监听地址server next_server: 192.168.34.17 //修改成tftp服务器的监听地址server manage_dhcp: 1 manage_tftpd：1 pxe_just_once：1 //下次重启不在重装系统，不会覆盖系统 Cobbler命令介绍cobbler check 检查当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录，更改配置最好都要执行下 cobbler reposync 同步yum 仓库 cobbler distro 查看导入的发行版系统信息 cobbler distro remove –name= 可用于删除菜单选项 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 cobbler profile add 可用于添加菜单选项 Remove 删除菜单选项，删除关联文件 Rename 改名字 安装配置配置阿里epel源 wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 1.yum install cobbler cobbler-web dhcp -y 2.确认httpd、tftp-sever已经启动且已经开机自启systemctl start httpd tftpd 3.启动cobbler systemctl start cobblerd.service 4. 初次cobbler check //检查cobbler运行环境 执行Cobbler check报错解决方式 1).修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相 应的IP地址或主机名：384行，然后重新启动cobbler server: 192.168.34.107 2).修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机 相应的IP地址:272行，指定的tftp的服务器地址 next_server: 192.168.34.107 3).执行cobbler get-loaders和cobbler sync； 联网：执行&quot;cobbler get-loaders&quot;命令即可； cobbler会自动通过互联网把最小化的系统启动文件下载下来放到 /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下 不联网：cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot 4).cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在 这里，由于是在cnetos7上安装的，这项可以忽略 5).执行“chkconfig rsync on”命令即可 4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的 7).第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己 去修改一个自定义的密码(通过openssl passwd -1)生成：101行 default_password_crypted：修改成自己设置的密码 备注： 在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务， dhcpd.conf文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成， 但是需要改/etc/cobbler/settings一项配置：242行 manage_dhcp: 0 改成 manage_dhcp: 1 再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf 只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件 把dhcp.template里的网段地址改一下 subnet 192.168.34.0 netmask 255.255.255.0 { option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.34.20 192.168.34.100; 再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务 5. 再次cobbler check检查cobbler运行环境 6. cobbler sync，同步配置到数据目录 上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经配置接近完成 7./var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了 8.这里用import选项将6和7的光盘导入cobbler的主机上 mount /dev/sr0 /mnt/ ---&gt;挂载centos7光盘 cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64 cp *.ks /var/lib/cobbler/kickstarts vim /var/lib/cobbler/kickstarts/ks.cfg url --url=$tree 9.cobbler profile list 10.将自定义的应答文件和安装版本进行绑定 cobbler profile add --name=centos-7.5-x86_64_mini --distro=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg Cobbler安装CentOS 7网卡命名修改 准备上线CentOS 7.x，在Cobbler上导入后，发现网卡名称变成了eno1这样的，好吧，那就添加两个内核参数上去，让它变回eth0. cobbler profile edit --name=CentOS-7.5-x86_64 --kopts=&apos;net.ifnames=0 biosdevname=0&apos; cobbler的WEB界面提供cobbler的基于web管理界面，epel源 yum install cobbler-web systemctl reload httpd 访问浏览器https://IP/cobbler_web 1.给cobbler加管理员： htdigest -c /etc/cobbler/users.digest Cobbler cobbleradmin Cobbleradmin管理员登录名字 cat /etc/cobbler/users.digest 看到账户已经覆盖原有内容 2.修改cobbler的验证方式 vim /etc/cobbler/modules.conf [authentication] module = authn_configfile 3.创建cobbler账号 useradd -s /sbin/nologin cobbleradm vim /etc/cobbler/users.conf（ authn_pam模块的配置文件，验证方法设置） [admins] admin = “cobbleradm” 将useradd创建的用户添加 cobbler = “” Cobbler中自定义应答文件1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中 2.把之前制作的ks7.cfg拷贝到此目录，但是拷贝完，但cobbler是无法识别这些应答文件是对应的那个发行版本的，所以要绑定 3.将自定义的应答文件和安装版本进行绑定 4.这两个应答文件有一项需要修改 即url --url=这一项， 要改成cobbler的yum源路径，$tree 或者改成具体的地址：即光盘拷贝到cobbler的具体路径 将KS和OS关联，生成启动新的菜单在cobberl中 distro中记录的是cobbler中安装的发型版本对应的原文件的 [root@mini7-1 kickstarts]#cobbler distro list Centos-7.5-x86_64 在cobberl中 profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个 就对应多少个菜单栏 [root@mini7-1 kickstarts]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定 cobbler profile add --name=centos-7.5-x86_64_mini --distro=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg 也可以删除应答文件： cobbler profile remove --name=Centos-7.5-x86_64 也可以修改带单名 cobbler profile rename --name=Centos-7.5-x86_64 --newname=centos-7.5-x86_64_desktop 查看菜单项对应的具体是哪个应答文件信息 cobbler profile report --name=centos-7.5-x86_64_mini /var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来 [root@mini7-1 tftpboot]#cobbler profile list Centos-7.5-x86_64 centos-7.5-x86_64_mini]]></content>
  </entry>
  <entry>
    <title><![CDATA[DHCP和PXE]]></title>
    <url>%2F2018%2F05%2FDHCP%E5%92%8CPXE%2F</url>
    <content type="text"><![CDATA[PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobbler cobbler实现系统自动化安装cobbler自动化系统安装 DHCP官方文档 BIND官网文档 DNS搭建的相关文档 搭建DHCP和在centos7实现基于PXE安装centos7和centos6(centos6上原理类似) PXE+DHCP服务关闭防火墙和SELINUX yum install httpd tftp-server dhcp syslinux system-config-kickstart -y DHCP服务器基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68) DHCP: （Dynamic Host Configuration Protocol） 动态主机配置协议 局域网协议，UDP协议(67端口) 主要用途： 用于内部网络和网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作集中管理的手段 使用场景 自动化安装系统 解决IPV4资源不足问题 DHCP的工作流程1. 客户端发起一个DHCP DISCOVER请求发现当前局域网中DHCP的服务器 2. DHCP服务器收到客户端请求后，响应DHCP OFFER，确定一个没有使用的IP地址给客户端 3. 客户端收到后，发送DHCP REQUEST确定使用该地址 4. 最后DHCP服务器发送DHCP ACK确认客户端的连接后，发送DHCP服务器的相关配置给客户端 地址 DHCP DECLINE ：客户端到服务器，指示地址已被使用 DHCP RELEASE：客户端到服务器，放弃网络地址和取消 剩余的租约时间 DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP 服务器端获取更为详细的配置信息，则发送Inform报文向 服务器进行请求，极少用到 同网段多DHCP服务 DHCP服务必须基于本地 先到先得的原则 续租 50% ：租赁时间达到50%时来续租，刚向DHCP服务器发向新的DHCPREQUEST请求。如果dhcp服务没有拒绝的理由，则回应DHCPACK信息。当DHCP客户端收到该应答信息后，就重新开始新的租用周期 87.5%：如果之前DHCPServer没有回应续租请求，等到租约期的7/8时，主机会再发送一次广播请求 跨网段 RFC 1542 Compliant Routers dhcrelay: 中继 相关协议 Arp rarp DHCP服务器的实现Linux DHCP协议的实现程序：dhcp, dnsmasq（dhcp,dns） 1.实现DHCP的软件有两个：dnsmasp,这个软件是安装系统是默认的一个 可以同时提供dns和dhcp两种服务，不是很专业 如：ss -ntl 看到的默认就有dnsmasp服务 LISTEN 0 5 192.168.122.1:53 users:((&quot;dnsmasq&quot;,pid=1506,fd=6)) 2.DHCP更专业 Dhcp Server相关配置文件： /etc/dhcp/dhcpd.conf ---&gt;主要配置文件 /usr/lib/systemd/system/dhcpd.service ---&gt;服务名 /usr/sbin/dhcpd ---&gt;dhcp的主程序 /etc/dhcp/dhcpd.conf --&gt; /etc/rc.d/init.d/dhcpd /etc/dhcp/dhcpd6.conf--&gt; /etc/rc.d/init.d/dhcpd6 /var/lib/dhcpd/dhcpd.leases ---&gt;租出去的地址信息库文件 /usr/sbin/dhcrelay /etc/rc.d/init.d/dhcrelay dhcp server:67/udp dhcp client: 68/udp dhcpv6 client:546/udp Dhcp client dhclient 自动获取的IP信息： /var/lib/dhclient dhcp配置安装DHCP完,默认是启动不了的，因为配置文件dhcpd.conf是空的 该文件中定义了： 1.默认续租时间和最长租期 2.DHCP默认分配的网段和分配的IP地址范围 3.DHCP服务提供的默认网关地址和DNS地址 1.先通过模板生成新的配置文件 cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf 2.配置文件/etc/dhcp/dhcpd.conf 全局配置： default-lease-time //默认租期时间 max-lease-time //最大租期时间 子网配置： subnet IPADDR netmask NETMASK { //定义子网 range IPRANG; //定义IP的范围 option route IP; //定义默认网关 option domain-name-servers DNS;//定义默认DNS filename //定义引导文件名称 示例： filename &quot;pxelinux.0&quot;; next-server //提供引导文件的服务器的IP地址 示例： next-server 192.168.56.81; } 单个主机配置： host 名称 { hardware ethernet //主机的MAC地址 fixed-address //固定分配一个IP地址 } 上面是主要配置内容，在dhcpd.conf中还可以把指定的mac地址与IP绑定 host passacaglia { hardware ethernet 00:0c:29:af:45:f7; fixed-address 192.168.56.80 } 重新获取地址：dhclient -d，如出现bound new ip表示dhcp服务器正常启动 地址分配记录 /var/lib/dhcpd/dhcpd.leases TFTPyum install tftp-server，服务器端 yum install tftp，客户端 默认监听 69/udp 默认路径,存放下载上传的路径:系统所需要的文件 /var/lib/tftpboot centos7和centos6上安装tftp是由区别的 centos7上需要安装tftp-server服务--&gt;UDP69端口 yum install tftp-server systemctl start tftp 在centos6上安装和telnet是一个道理，都依赖于xinetd chkconfig tftp on--&gt; /etc/xinetd.d/tftp配置文件 service restart xinted http配置systemctl enable httpd systemctl start httpd mkdir /var/www/html/7/{os,ksdir} mount /dev/sr0 /var/www/html/7/os 准备kickstart文件 /var/www/html/7/ksdir/7.cfg 注意：权限 PXE介绍PXE： Preboot Excution Environment 预启动执行环境 Intel公司研发 基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载 映像，并由此支持通过网络启动操作系统 PXE可以引导和安装Windows,linux等多种操作系统 实验：在centos7实现基于PXE安装centos7和centos61.安装前准备：关闭防火墙和SELINUX，DHCP服务器静态IP 2.安装软件包 httpd tftp-server dhcp syslinux system-config-kickstart httpd:实现yum源 tftp-server：实现网络下载的文件 syslinux: 准备pxelinux.0文件 备注：centos6上是安装syslinux-nonlinux system-config-kickstart制作kickstart软件，建议自己制作 3.配置文件共享服务： 准备centos7&amp;centos6的yum源 systemctl enable httpd systemctl start httpd mkdir -pv /var/www/html/centos/{6,7}/os/x86_64 mount /dev/sr0 /var/www/html/centos/7/os/x86_64 mount /dev/sr1 /var/www/html/centos/6/os/x86_64 4.准备kickstart文件 拷贝已经安装机器上的anaconda文件，按照自定义稍微修改，放到http目录下 注意：644权限 cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg ks应答文件的内容可以用system-config-kickstart或者anaconda修改就行了 最好是通过system-config-kickstart做一个应答文件，通过界面更深刻理解 每一项代表的意义 大概内容如下：(最后附件的有详细的ks文件内容) url --url=http://192.168.34.7/centos/7/os/x86_64/ text firewall --disabled selinux --disabled clearpart --all --initlabel zerombr reboot %packages @core %end 5.配置tftp服务 systemctl enable tftp.socket systemctl start tftp.socket 6.配置DHCP服务 cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcpd/dhcpd.conf vim /etc/dhcp/dhcpd.conf option domain-name &quot;example.com&quot;; default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; next-server 192.168.34.103; filename &quot;pxelinux.0&quot;; } systemctl enable dhcpd systemctl start dhcpd 7.准备PXE相关文件 放pxelinux.0的专用目录，启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ 分别存放6和7的vmliuz和initrd.img文件 mkdir linux{6,7} 拷贝6和7安装必要文件 cp /var/www/html/centos/6/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux6/ cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux7/ cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/ 将光盘里的启动菜单拷贝到并改名为default cp /var/www/html/centos/7/os/x86_64/isolinux.cfg /var/lib/tftpboot/ pxelinux.cfg/default 拷贝完所有文件,文件列表如下： /var/lib/tftpboot/ . ├── linux6 │ ├── initrd.img │ └── vmlinuz ├── linux7 │ ├── initrd.img │ └── vmlinuz ├── menu.c32 ├── pxelinux.0 └── pxelinux.cfg └── default 8.准备启动菜单 菜单项可以自定义多个，如只有mini7和mini6的，还有必须要有本地硬盘启动的菜单项 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 timeout 100 menu title PXE Install CentOS label mini7 menu label ^Auto Install Mini CentOS 7 kernel linux7/vmlinuz append initrd=linux7/initrd.img ks=http://192.168.34.7/ksdir/ks7-mini.cfg label mini6 menu label ^Auto Install Mini CentOS 6 kernel linux6/vmlinuz append initrd=linux6/initrd.img ks=http://192.168.34.7/ksdir/ks6-mini.cfg label local menu default menu label Boot from ^local drive localboot 0xffff. 9.准备完所有的文件和软件后，启动所有的服务，就可以测试PXE安装了。 centos7和centos6的ks应答文件模板通过ystem-config-kickstart做一个应答文件 也可以修改anaconda-ks.cfg文件 ks6-mini.cfginstall url --url=http://192.168.34.103/centos/6/os/x86_64/ #httpd的yum源路径 lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 ks7-mini.cfgauth --enableshadow --passalgo=sha512 url --url=http://192.168.34.103/centos/7/os/x86_64/ text firstboot --enable ignoredisk --only-use=sda keyboard --vckeymap=us --xlayouts=&apos;us&apos; lang en_US.UTF-8 network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --activate network --hostname=centos7.localdomain rootpw --iscrypted $6$j2QVLmDO2xasQEW0$xEvr1jyj1mHs0HBtCc7jD73r6u4NrQCxwVoAu.SMXhwm8GiKBHq5ETZ2zFxP4rFsNavYbG0u6Gq13 Igxrn1Ry. firewall --disabled selinux --disabled services --enabled=&quot;chronyd&quot; timezone Asia/Shanghai --isUtc user --name=test --password=$6$Awcwirg.mougtUlL$Yr1a9e2Vfs2k/Nizdn/ZeiunlsU.rJAmI1vhp1iafeccRt48h3PVIlnVwGvKPPt4dVum a/W32jzYIsn1XCrva. --iscrypted --gecos=&quot;test&quot; bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda clearpart --all --initlabel zerombr reboot part / --fstype=&quot;xfs&quot; --ondisk=sda --size=51200 part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024 part swap --fstype=&quot;swap&quot; --ondisk=sda --size=4096 part /data --fstype=&quot;xfs&quot; --ondisk=sda --size=30720 %packages @core %end]]></content>
  </entry>
  <entry>
    <title><![CDATA[系统部署基础]]></title>
    <url>%2F2018%2F05%2F%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Centos启动流程 加电自检—mbr—grub—kernel—rc.sysinit—-rootfs—-/sbin/init Anaconda:系统安装程序 Gui：图形窗口 Tui：=基于图形库curses的文本窗口 安装程序启动过程 MBR：isolinux/boot.cat stage 2：isolinux/isolinux.bin 配置文件：isolinux/isolinux.cfg 菜单选项： 加载内核：isolinux/vmlinuz 向内核传递参数：append initrd=initrd.img... 装载根文件系统，启动anaconda 若是显式指定使用TUI接口：向内核传递text参数即可 1. 按tab键 2. 按ESC键 boot引导选项：boot： text，以文本安装方式 askmethod，手动指定安装方法 网络相关引导选项： ip=IP netmask=NETMASK gateway=GW dns=DNS ifname=NAME:MAC_ADDR 指定安装源， boot: linux asmethod 手动指定安装方法 Centos6： repo=cdrom: repo=http://host/path repo=frp://USERNAME:password@host/path centos7： inst.repo=cdrom inst.repo=http://host/IP inst.repo=frp://USERNAME:password@host/path 安装系统分成三个阶段： （安装向导）安装前配置阶段安装过程使用的语言 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 特殊设备：iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置 创建一个普通用户 选定要安装的程序包 安装阶段在目标磁盘创建分区，执行格式化操作等 将选定的程序包安装至目标位置 安装bootloader和initramfs 图形模式首次启动iptables selinux core dump 生成kickstart安装配置文件手动生成*.cfg的文件,可对照系统模板修改/root/anaconda-ks.cfg 图形界面生成： yum install system-config-kickstart xshell 显示无法启动x server，可以试下安装xorg-x11-xauth 显示乱码的情况 dejavu-sans-fonts dejavu-serif-fonts centos7中system-config-kickstart打开没有rpm组，需要将/etc/yum.repos.d/base.repo中的【base】改名为【development】 kickstart命令段：指明各种安装前配置，如键盘类型等创建逻辑卷 # System bootloader configuration bootloader --location=mbr # Clear the Master Boot Record zerombr # Partition clearing information clearpart --all --initlabel # Disk partitioning information part /boot --fstype ext3 --size=400 part swap --size=2048 part pv.01 --size=1 --grow volgroup vg_rekfan pv.01 logvol / --vgname=vg_rekfan --size=40000 --name=lv_root logvol /var --vgname=vg_rekfan --size=50000 --name=lv_var logvol /tmp --vgname=vg_rekfan --size=2048 --name=lv_tmp logvol /spare --vgname=vg_rekfan --size=1 --grow --name=lv_spare 程序包段：指明要安装的程序包组或程序包，不安装的程序包等 %packages @group_name package -package %end 脚本段： %pre: 安装前脚本 运行环境：运行于安装介质上的微型Linux环境 %post: 安装后脚本 运行环境：安装完成的系统 命令段中的命令： 必备命令: authconfig: 认证方式配置 authconfig –useshadow –passalgo=sha512 bootloader：bootloader的安装位置及相关配置 bootloader –location=mbr –driveorder=sda – append=”crashkernel=auto rhgb quiet” keyboard: 设定键盘类型 lang: 语言类型 part: 创建分区 rootpw: 指明root的密码 timezone: 时区 可选命令: install OR upgrade text: 文本安装界面 reboot 重启 user：安装完成后为系统创建新用户 url: 指明安装源 key –skip 跳过安装号码,适用于rhel版本 检查ks文件的语法错误：ksvalidator ksfile 制作引导光盘mkisofs-o 指定映像文件的名称。 -b 指定在制作可开机光盘时所需的开机映像文件。 -c 制作可开机光盘时，会将开机映像文件中的no-eltorito-catalog全部内容作成一个文件。 -no-emul-boot 非模拟模式启动。 -boot-load-size 4 设置载入部分的数量 -boot-info-table 在启动的图像中现实信息 -R 或 -rock 使用 Rock RidgeExtensions -J 或 -joliet 使用 Joliet 格式的目录与文件名称 -v 或 -verbose 执行时显示详细的信息 -T 或 -translation-table 建立文件名的转换表，适用于不支持Rock RidgeExtensions 的系统上 系统光盘中isolinux目录isolinux.bin：光盘引导程序，在mkisofs的选项中需要明确给出文件路径，这个文件属于SYSLINUX项目 isolinux.cfg：isolinux.bin的配置文件，当光盘启动后（即运行isolinux.bin），会自动去找isolinux.cfg文件 vesamenu.c32：是光盘启动后的安装图形界面，也属于SYSLINUX项目，menu.c32版本是纯文本的菜单 Memtest：内存检测，这是一个独立的程序 splash.jgp：光盘启动界面的背景图 vmlinuz是内核映像 initrd.img是ramfs (先cpio，再gzip压缩） 制作步骤mount /dev/cdrom /mnt mkdir -pv /data/iso cp -r /mnt/isolinux/ /data/iso 编辑/data/iso/isolinux/isolinux.cfg mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V&quot;CentOS 6&quot; -b isolinux/isolinux.bin -c isolinux/boot.cat -o /root/myiso.iso /data/iso 注意：以上相对路径都是相对于光盘的根，和工作目录无关使用创建的光盘半自动化安装系统 创建u盘启动盘 注意：制作U盘启动时，可能MBR的512个字节没有，需要用Isohybrid boot.iso做格式装换，写入U盘 dd if=/root/myiso.iso /dev/sdb 制作完整版的iso启动 复制光盘内容 cp -rv /misc/cd /app/centos6 将不需要文件删除 find /app/centos6/ -name TRANS.TBL -exec rm {} \; rm -f /app/centos6/repodata/* 在光盘repodata目录中，有一行没有被压缩的内容，存放着rpm包的信息，不能被删除 cp /misc/cd/repodata/43d8fd068164b0f042845474d6a22262798b9f0d1f49ad1bf9f95b953089777d-c6-x86_64-comps.xml /app/centos6/repodata/ 重新创建rpm包组信息（生成rpm包的元数据） createrepo -g repodata/43d8fd068164b0f042845474d6a22262798b9f0d1f49ad1bf9f95b953089777d-c6-x86_64-comps.xml ./ 查看repodata元数据是否生成 创建应答文件 修改isolinux/isolinux.cfg 启动路径修改为cdrom 制作为光盘文件 mkisofs -R -J -T -v –no-emul-boot –boot-load-size 4 –boot-info-table -V “CentOS 6.9 x86_64 boot” -b isolinux/isolinux.bin -c isolinux/boot.cat -o /root/centos6ks.iso /app/centos6/ 用制作成的光盘启动计算机]]></content>
  </entry>
  <entry>
    <title><![CDATA[DNS]]></title>
    <url>%2F2018%2F05%2FDNS%2F</url>
    <content type="text"><![CDATA[DNS基本概念： DNS是Domain Name System的缩写，即域名系统。DNS服务主要功能是将域名转换为相应的IP地址 DNS服务器可以分为3种，即主域名服务器(Master DNS)、辅助域名服务器(Slave DNS)、缓存服务器 Master DNS: 本身提供DNS 服务，并且本身含有区域数据文件，管理和维护所负责解析的域内解析库的服务器 Slave DNS： 和Master一起提供DNS服务，当Master服务器上的配置信息修改的时候，从主DNS服务器或其它的从DNS服务器那里“复制”（区域传递）一份解析库； 序列号：解析库的版本号；前提：主服务器解析库内容发生变化，其序列递增； 刷新时间间隔：从服务器从主服务器请求同步解析库的时间间隔； 重试时间间隔：从服务器从主服务器请求同步解析库失败时，再次尝试的时间间隔； 过期时长：从服务器始终联系不到主服务器时，多久多后放弃从服务器角度，停止提供服务； 缓存服务器(转发器)： 没有自己的区域数据文件，只是帮助客户端向外部DNS请求查询，然后将查询的结果保存到它的缓存中。 “通知” 机制：主服务器解析库发生变化时，会主动通知从服务器 区域传送： 全量传送：传送整个解析库 增量传送：传递解析库变化的那部分内容 端口 ：tcp(用于同步）/udp（用于查询）53 本地名称解析配置文件：hosts /etc/hosts DNS域名： 根域：. 一级域名：com,edu,mil,gov,net,org,int,arpa 二级域名： 三级域名： 工作原理： 当客户端输入一个网址时， 1.客户端先去查找hosts文件是否有与之相匹配的IP地址，有则返回结果， 2.没有则去查找DNS服务的本地缓存，有则返回， 3.没有则会发送请求到DNS服务器，有则返回结果， 4.没有则DNS服务器，会去查找服务器缓存，有则返回， 5.没有DNS服务器则会直接找根，根指向其下面顶级域可能有，这样DNS则会找顶级域，顶级域表示自己也不负责该区域，而自己包含该网址的二级可能有，这样以此查找，查找到负责该区域的域，有该网址的对应IP地址，则返回肯定答案，没有则返回否 一次完整的查询请求经过的流程： Client --&gt; hosts文件 --&gt; DNS Service Local Cache --&gt; DNS Server (recursion) --&gt; Server Cache --&gt; iteration(迭代) --&gt; DNS查询类型： 递归查询 recursion 迭代查询 iteration 名称服务器：域内负责解析本域内的名称的主机； 根服务器：13组服务器 解析类型： Name --&gt; IP IP --&gt; Name 注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 资源记录定义的格式： 语法：name [TTL] IN rr_type value 注意： (1) TTL可从全局继承； (2) @可用于引用当前区域的名字； (3) 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询方式响应； (4) 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值进行定义；此仅表示通过多个不同的名字可以找到同一个主机而已 1.SOA: name [TTL] IN SOA MAIL (VALUE) name: 当前区域的名字，例如“magedu.com.”； value: 有多部分组成 (1) 当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字； (2) 录前区域管理员的邮箱地址；但地址中不能使用@符号，一般用.替换，例如linuxedu.magedu.com； (3) (主从服务协调属性的定义以及否定的答案的统一的TTL) 例如： $TTL 1d @ IN SOA ns1.magedu.com. admin.magedu.com. ( 20181101 ;序列号 2H ;刷新时间 10M ;重试时间 1W ;过期时间 1D ;否定答案的TTL值 ) 2.NS记录： name IN NS VALUE name：当前区域的名称 VALUE：当前区域的DNS服务器的名称 例如： magedu.com. IN NS ns1.magedu.com. 3.MX: name: 当前区域的名字 value: 当前区域的某邮件服务器(smtp服务器)的主机名； 一个区域内，MX记录可有多个；但每个记录的value之前应该有一个数字(0-99)，表示此服务器的优先级；数字越小优先级越高； 例如： magedu.com. IN MX 10 mx1.magedu.com. IN MX 20 mx2.magedu.com. 注意： (1) 对MX记录而言，任何一个MX记录后面的服务器名字，都应该在后续有一个A记录 4.A name: 某主机的FQDN，例如www.magedu.com. value: 主机名对应主机的IP地址； 例如： mx1.magedu.com. IN A 1.1.1.3 mx2.magedu.com. IN A 1.1.1.3 注意： *.magedu.com. IN A 1.1.1.4 magedu.com. IN A 1.1.1.4 避免用户写错名称时给错误答案，可通过泛域名解析进行解析至某特定地址； 5.AAAA: name: FQDN value: IPv6 6.PTR: name: IP，有特定格式，把IP地址反过来写，1.2.3.4，要写作4.3.2.1；而有特定后缀：in-addr.arpa.，所以完整写法为：4.3.2.1.in-addra.arpa. value: FQDN 例如： 4.3.2.1.in-addr.arpa. IN PTR www.magedu.com 简写成： 4 IN PTR www.magedu.com. 注意：网络地址及后缀可省略；主机地址依然需要反着写； 7.CNAME： name: 别名的FQDN value: 名字的FQDN； 例如： web.magedu.com. IN CNAME www.magedu.com. DNS服务器dns服务，程序包名bind，程序名named 程序包： bind bind-libs bind-utils bind-chroot: /var/named/chroot/ rndc: remote name domain controller，提供辅助性的管理功能； 953/tcp bind： 服务脚本：/etc/rc.d/init.d/named /usr/lib/systemd/system/named.service 解析库文件：/var/named/ 语法检查：named-checkconf 主配置文件：/etc/named.conf 全局配置：options {} 日志子系统配置：logging {} 区域定义：本机能够为哪些zone进行解析，就要定义哪些zone； zone &quot;ZONE_NAME&quot; IN {} 注意：任何服务程序如果期望其能够通过网络被其它主机访问，至少应该监听在一个能与外部主机通信的IP地址上 /etc/named.rfc1912.zones /etc/rndc.key 注意： (1) 一台物理服务器可同时为多个区域提供解析； (2) 必须要有根区域文件；named.ca (3) 应该有两个（如果包括ipv6的，应该更多）实现localhost和本地回环地址的解析库； 缓存DNS服务器的配置：监听外部地址即可 dnssec: 建议关闭dnssec，设为no 示例：/etc/named.conf options { listen-on port 53 {{ 外部IP; }}; dnssec-enable no; dnssec-validation no; } 主DNS名称服务器配置 正向区域： 一般在/etc/named.rfc1912.zones中定义 zone &quot;ZONE_NAME&quot; IN { type {master|slave|hint|forward}; file &quot;ZONE_NAME.zone&quot;; }; 示例： 定义区域解析库文件 /var/name/yh.com.zone 示例： $TTL 86400 $ORIGIN yh.com. @ IN SOA ns1 admin ( 2015042201 1H 5M 7D 1D ) IN NS ns1 IN NS ns2 IN MX 10 mx1 IN MX 20 mx2 mx1 IN A 192.168.0.1 mx2 IN A 192.168.0.2 ns1 IN A 192.168.0.188 ns2 IN A 192.168.0.189 www IN A 199.247.21.135 解析库文件语法检查： named-checkzone &quot;zone_name.zone&quot; /var/named/zone.name.zone 反向区域： 区域名称：网络地址反写.in-addr.arpa. 172.16.100. --&gt; 100.16.172.in-addr.arpa. (1) 定义区域 zone &quot;ZONE_NAME&quot; IN { type {master|slave|forward}； file &quot;网络地址.zone&quot; }; (2) 区域解析库文件 注意：不需要MX和A，以及AAAA记录；以PTR记录为主； 示例： $TTL 86400 $ORIGIN 0.168.192.in-addr.arpa. @ IN SOA ns1.magedu.com. admin.magedu.com. ( 2015042201 1H 5M 7D 1D ) IN NS ns1.magedu.com. IN NS ns2.magedu.com. #对于反向区域文件来说，从服务器的NS记录是必须写全，否则区域文件的同步会有问题， 注意：正反向解析是两个不同的名称空间，是两棵不同的解析树； 从DNS服务器配置主从复制： 1、应该为一台独立的名称服务器； 2、主服务器的区域解析库文件中必须有一条NS记录是指向从服务器； IN NS ns1 IN NS ns2 3、从服务器只需要定义区域，而无须提供解析库文件；解析库文件应该放置于/var/named/slaves/目录中; 4、主服务器得允许从服务器作区域传送； allow-transfer { ip; }; 5、主从服务器时间应该同步，可通过ntp进行； 6、bind程序的版本应该保持一致；否则，应该从高，主低； 定义从区域的方法： zone &quot;ZONE_NAME&quot; IN { type slave; masters { MASTER_IP; }; file &quot;slaves/ZONE_NAME.zone&quot;; }; DNS支持两种域维护的方式：全量传输（AXFR）和增量传输（IXFR）全量传输AXFR 全量传输时，DNS从服务器会从DNS主服务器上请求区域文件，其间隔时间由SOA记录中的refresh标签所定义。请求区域文件的过程是DNS从服务器向DNS主服务器发送查询来实现的，如果DNS主服务器中SOA记录中的序列号(serial)大于DNS从服务器SOA记录的序列号，DNS从服务器就会向DNS主服务器发送全量传输请求。全量传输使用TCP的53端口进行传输。 增量传输IXFR 传递非常大的区域文件是非常耗资源的（时间、带宽等），尤其是只有区域中的一个记录改变的时候，没有必要传递整个区域文件，增量传输是允许DNS主服务器和DNS从服务器之间只传输那些改变的记录。 通告notify DNS从服务器会每隔SOA记录中的设置refresh时间值来向DNS主服务器主服务器发送请求，只有在主服务器的serial大于从服务器的serial时才进行传输，但是倘若refresh值设置得比较大，那么有可能在这段时间中就会积累大量的更新，此时DNS的时效性就会很差。 此时notify通告就提供了这样的功能：DNS主服务器的zone文件发生改变后，它立即向从服务器发送一个NOTIFY消息，告诉从服务器我的zone文件发生改变了，接着从服务器马上对比两者的序列号，再采用上面介绍的全量传输或者增量传输的方法请求zone文件。BIND本身支持通告，通告的配置是在named.conf中的zone中的option中配置，配置指令是notify, also-notify和notify-source。 DNS转发服务器注意：被转发的服务器需要能够为请求者做递归，否则，转发请求不予进行； (1) 全部转发: 凡是对非本机所有负责解析的区域的请求，统统转发给指定的服务器； Options { forward {first|only} fowwarders { iP; }; } first意思是如果请求不能得到响应，则DNS会向根一级级询问，而only如果不能响应就会报无法解析。 (2) 区域转发：仅转发对特定的区域的请求至某服务器； zone &quot;ZONE_NAME&quot; IN { type forward; forward {first|only} #only表示仅转发 ；first表示先进行转发，如果没查询到结果，那么它自己还会根据根提示向外迭代查询 forwarders { iP; }; } 注意：关闭dnssec功能： dnssec-enable no; dnssec-validation no; 子域子域授权:每个域的名称服务器，都是通过其上级名称服务器在解析库进行授权 正向解析区域子域方法： 如果主机不多，则直接加子域的A记录即可，如果主机较多，则可单建一个独立子域。 当然也可以把父域和子域分离在两台主机上，此时需在父域主机的zone里上定义 name NS dnsN dns10 A IP 之后在子域的主机上直接像定义父域那样定义zone就OK了，这样就实现的父子域分离，原理就像根域往下指派子域一样 类似根域授权tld: .com. IN NS ns1.com. .com. IN NS ns2.com. ns1.com. IN A 2.2.2.1 ns2.com. IN A 2.2.2.2 magedu.com. 在.com的名称服务器上，解析库中添加资源记录： magedu.com. IN NS ns1.magedu.com. magedu.com. IN NS ns2.magedu.com. ns1.magedu.com. IN A 3.3.3.1 ns2.magedu.com. IN A 3.3.3.2 bind中基础的安全相关的配置：acl: 把一个或多个地址归并为一个集合，并通过一个统一的名称调用； acl acl_name { ip; net/prelen; }; 示例： acl mynet { 172.16.0.0/16; } bind有四个内置的acl: none: 没有一个主机； any: 任意主机； local: 本机； localnet: 本机的IP同掩码运算后得到的网络地址； 注意：只能先定义，后使用；因此，其一般定义在配置文件中options的前面； 访问控制的指令： allow-query { ip; }： 允许查询的主机；白名单； allow-transfer { ip; }：允许区域传送的主机；白名单； allow-recursion { ip; }: 允许递归的主机；建议全局建议 allow-update { ip; }: 允许更新区域数据库中的内容；一般为none 智能dns CDN: Content Delivery Network view:视图：实现智能DNS 一个bind服务器可定义多个view，每个view中可定义一个或多个zone； 每个view用一来匹配一组客户端； 多个view内可能需要对同一个区域进行解析，但使用不同的区域解析库文件； view VIEW_NAME { match-clients { ip; }; } 注意： (1) 一旦启用了view，所有的zone都只能定义在view中； (2) 仅有必要在匹配到允许递归请求的客户所在view中定义根区域； (3) 客户端请求到达时，是自上而下检查每个view所服务的客户端列表； 1.配置/etc.named.conf 1234567891011121314acl "telecom"&#123; 192.168.0.0/25; &#125;;acl "unicom"&#123; 192.168.0.128/25; &#125;;options&#123; ...&#125;;logging&#123; ...&#125;; include "/etc/named.rfc1912.zones";include "/etc/named.root.key"; 2.配置/etc/named.rfc1912.zones 123456789101112131415161718192021222324252627282930view telecom &#123;match-clients &#123; telecom;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "yh.com" IN &#123; type master; file "yh.com.zone.telecom";&#125;;&#125;;view unicom &#123;match-clients &#123; unicom;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "yh.com" IN &#123; type master; file "yh.com.zone.unicom";&#125;;&#125;;view others &#123;match-clients &#123; any;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;&#125;; 3.新建 /var/named/yh.com.zone.unicom /var/named/yh.com.zone.telecom 4.检查相应的配置文件,重启，解析测试 使用DNS支持镜像Web站点vi /etc/named.conf options { rrset-order { order random; }; }; rrset-order 支持三个参数：fixed, random, cyclic 。 fix 会将多个A记录按配置文件的顺序固定给出 random 会随机给出 cyclic 会循环给出 在区域文件给一个域名添加多个IP地址。 vi /var/named/named.91xueit.com.liantong $TTL 1D 91xueit.com. IN SOA webserver.91xueit.com. han@hotmail.com. ( 0 ;serial 1D ;refresh 1H ;retry 1W ;expire 3H ;minimum ); 91xueit.com. IN NS webserver.91xueit.com. 91xueit.com. IN MX 10 mail webserver IN A 192.168.80.222 www IN A 22.22.22.22 IN A 33.33.33.33 IN A 44.44.44.44 DNS工具测试命令：dig的使用 dig [-t type] name [@SERVER] [query options] dig用于测试dns系统，因此，不会查询hosts文件进行解析； 查询选项： +[no]trace：跟踪解析过程 +[no]recurse：进行递归解析 测试反向解析： dig -x IP @SERVER 模拟区域传送： dig -t axfr ZONE_NAME @SERVER 例如：dig -t axfr magedu.com @172.16.100.11 host命令： host [-t type] name [SERVER] nslookup命令： nslookup [-option] [name | -] [server] 交互式模式： nslookup&gt; server IP: 指明使用哪个DNS server进行查询； set q=RR_TYPE: 指明查询的资源记录类型； NAME: 要查询的名称； rndc命令 953/tcp rndc COMMAND COMMAND reload：重载主配置文件和区域解析库文件 reload zonename：重载区域解析库文件 retransfer zonename: 手动启动区域传送，而不管序列号是否增加 notify zonename: 重新对区域传送发通知 reconfig: 重载主配置文件 querylog: 开启或关闭查询日志文件/var/log/message trace: 递增debug一个级别 trace LEVEL: 指定使用的级别 notrace：将调试级别设置为 0 flush：清空DNS服务器的所有缓存记录 DNS排错NOERROR不代表没有问题，也可以是过时的记录 查看是否为权威记录，flags:aa标记判断 被删除的记录仍能返回结果，可能是因为*记录存在 如：*.example.com． IN A 172.25.254.254 注意“.”的使用 避免CNAME指向CNAME记录，可能产生回环 test.example.com. IN CNAME lab.example.com. lab.example.com. IN CNAME test.example.com. 正确配置PTR记录，许多服务依赖PTR，如sshd,MTA 正确配置轮询round-robin记录 打开日志功能rndc querylog rndc status queryperf -d test.txt -s 127.0.0.1 wc -l /var/log/message 压力测试vim test.txt www.magedu.com A magedu.com NS magedu.com MX pop3.magedu.com A web.magedu.com A queryperf -d test.txt -s 127.0.0.1]]></content>
      <categories>
        <category>linux</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sudo]]></title>
    <url>%2F2018%2F05%2Fsudo%2F</url>
    <content type="text"><![CDATA[更改身份su 切换身份执行命令:su username –c &apos;command&apos; sudo 来自sudo包，man 5 sudoers 能够限制指定用户在指定主机上运行某些命令。 可以提供日志，忠实地记录每个用户使用sudo做了些什么，且能将日志传到中心主机或者日志服务器。 为系统管理员提供配置文件，允许系统管理员集中地管理用户的使用权限和使用的主机。它默认的存放位置是/etc/sudoers。 使用时间戳文件来完成类似“检票”的系统。 配置文件（/etc/sudoers）提供集中的用户管理、权限与主机等参数； 验证密码的后5分钟内（默认值）无须再让用户再次验证密码 visudo visudo –c 检查语法 visudo -f /etc/sudoers.d/test 配置用户权限时将禁止多个用户同时修改sudoers配置文件 还可以对配置文件内的参数进行语法检查 并在发现参数错误时进行报错 只有root管理员才可以使用visudo命令编辑sudo服务的配置文件 l sudo配置文件：/etc/sudoers, /etc/sudoers.d/ 时间戳文件：/var/db/sudo 日志文件：/var/log/secure 配置文件支持使用通配符glob： ？:任意单一字符 * ：匹配任意长度字符 [wxc]:匹配其中一个字符 [!wxc]:除了这三个字符的其它字符 \x : 转义 [[alpha]] :字母 示例： /bin/ls [[alpha]]* 配置文件规则有两类； 1、别名定义:不是必须的 2、授权规则:必须的 sudoers配置授权规则格式： 用户 登入主机=(代表用户) 命令 谁可以使用 允许使用的主机=（以谁的身份） 可执行命令的列表 执行流程： 1.用户执行sudo时，会判断配置文件/etc/sudoers，查看用户是否有执行sudo的权限； 2.若用户有执行sudo的权限，查看/var/db/sudo/zhangsan(密码的时间戳在这里)，是否密码过期，过期则输入密码，若没有权限则报错 3.输入正确密码后则开始sudo后续的命令 4.执行sudo读取的配置文件是/etc/sudoers 示例： inuxprobe ALL=(ALL) ALL 添加NOPASSWD参数 使得用户执行sudo命令时不再需要密码验证 linuxprobe ALL=NOPASSWD: /usr/sbin/poweroff 写在子配置文件/etc/sudoers.d目录下，把授权命令写入该目录下自定义的文件中 cat /etc/sudoers.d/f1 wang ALL=(root) /bin/mount /dev/sr0 /mnt 注意“=”号后的(root)可以省略不写，默认代表root cat /etc/sudoers.d/wa wa 192.168.32.128= /bin/cat /etc/shadow cat /etc/sudoers.d/ma ma 192.156.32.128=(wa) ALL 在ma用户界面 sudo -u ma sudo /bin/cat /etc/shadow ###别名 Users和runas: username #uid %group_name %#gid user_alias|runas_alias host: ip或hostname network(/netmask) host_alias command: command name directory sudoedit Cmnd_Alias 别名有四种类型：User_Alias, Runas_Alias, Host_Alias ，Cmnd_Alias 别名格式：[A-Z]([A-Z][0-9])* 大写字母开头，除了开头，后续的也必须是大写字母、数字或下划线 别名定义： Alias_Type NAME1 = item1, item2, item3 : NAME2 = item4, item5 示例1： Student ALL=(ALL) ALL %wheel ALL=(ALL) ALL 示例2： student ALL=(root) /sbin/pidof,/sbin/ifconfig %wheel ALL=(ALL) NOPASSWD: ALL 示例3 User_Alias NETADMIN= netuser1,netuser2 Cmnd_Alias NETCMD = /usr/sbin/ip NETADMIN ALL=（root） NETCMD 示例4 User_Alias SYSADER=wang,mage,%admins User_Alias DISKADER=tom Host_Alias SERS=www.magedu.com,172.16.0.0/24 Runas_Alias OP=root Cmnd_Alias SYDCMD=/bin/chown,/bin/chmod Cmnd_Alias DSKCMD=/sbin/parted,/sbin/fdisk SYSADER SERS= SYDCMD,DSKCMD DISKADER ALL=(OP) DSKCMD 示例4 User_Alias ADMINUSER = adminuser1,adminuser2 Cmnd_Alias ADMINCMD = /usr/sbin/useradd，/usr/sbin/usermod, /usr/bin/passwd [a-zA-Z]*, !/usr/bin/passwd root ADMINUSER ALL=(root) NOPASSWD:ADMINCMD， PASSWD:/usr/sbin/userdel 示例5 Defaults:wang runas_default=tom wang ALL=(tom,jerry) ALL 示例6 wang 192.168.1.6,192.168.1.8=(root) /usr/sbin/,!/usr/sbin/useradd 示例7 wang ALL=(ALL) /bin/cat /var/log/messages* sudo命令ls -l /usr/bin/sudo sudo –i –u wang 切换身份 sudo [-u user] COMMAND -V 显示版本信息等配置信息 -u user 默认为root -l,ll 列出用户在主机上可用的和被禁止的命令 -v 再延长密码有效期限5分钟,更新时间戳 -k 清除时间戳（1970-01-01），下次需要重新输密码 -K 与-k类似，还要删除时间戳文件 -b 在后台执行指令 -p 改变询问密码的提示符号 示例：-p &quot;password on %h for user %p:&quot;]]></content>
  </entry>
  <entry>
    <title><![CDATA[计划任务]]></title>
    <url>%2F2018%2F04%2F%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[任务计划Linux任务计划、周期性任务执行 未来的某时间点执行一次任务 at 指定时间点，执行一次性任务 batch 系统自行选择空闲时间去执行此处指定的任务 周期性运行某任务 cron at任务包：at at命令：at [option] TIME 注意：配置计划任务时，要确保时间是准确的，否则，任务计划将会出现问题 指定时间点 执行一次 执行方式： 1）交互式 2）输入重定向 3）at –f 文件 依赖与atd服务,需要启动才能实现at任务 at队列存放在/var/spool/at目录中 /etc/at.{allow,deny}控制用户是否能执行at任务 at.deny：黑名单 默认存在在该文件中写入用户名即拒绝该用户制定计划任务 at.allow：白名单 该文件默认不存在，需要手动创建；在该文件中写入用户名即允许该用户制定计划任务 如果白名单、黑名单都存在，白名单优先级高于黑名单； 运行计划任务时先查询白名单，允许白名单里的用户制定计划任务，不在白名单的用户被拒绝制定计划任务，此时不在白名单的用户全被拒绝制定计划任务 如果白名单不存在，查询黑名单，禁止黑名单里的用户制定计划任务，不在黑名单里的用户全被允许制定计划任务 如果白名单、黑明但都不存在，普通用户都不被允许制定计划任务，root用户可以执行at命令 常用选项： -V：显示版本信息: -l：列出指定队列中等待运行的作业；相当于atq -d：删除指定的作业；相当于atrm -c：查看具体作业任务，后跟计划任务编号 -f /path/file：指定的文件中读取任务 -m：当任务被完成之后，将给用户发送邮件，即使没有标准输出 注意：作业执行命令的结果中的标准输出和错误以邮件通知给相关用户，会产生大量无用信息占用系统资源，因此计划任务在非必要情况下不要产生标准输出或隐藏标准输出(或放到/dev/null中) at命令防止配置出错 远程配置服务器时，会出现把自己排除的情况，此时可以提前使用at做计划任务，在多长时间内还原原有配置 at时间格式TIME：定义出什么时候进行 at 这项任务的时间 HH:MM [YYYY-mm-dd] noon, midnight, teatime（4pm） tomorrow now+#{minutes,hours,days, OR weeks} HH:MM 02:00 在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务 HH:MM YYYY-MM-DD 02:00 2016-09-20 规定在某年某月的某一天的特殊时刻进行该项任务 HH:MM[am|pm] [Month] [Date] 04pm March 17 17:20 tomorrow HH:MM[am|pm] + number [minutes|hours|days|weeks] 在某个时间点再加几个时间后才进行该项任务 now + 5 min 02pm + 3 days 示例： [root@centos7-1 ~]#at now +1min at&gt; wall &quot;system will reboot&quot; //ctrl +d 退出编辑 job 7 at Sun Sep 2 13:34:00 2018 [root@centos7-1 ~]#at -l 7 Sun Sep 2 13:34:00 2018 a root 周期性任务计划cron相关的程序包： cronie: 主程序包，提供crond守护进程及相关辅助工具 cronie-anacron：cronie的补充程序，用于监控cronie任务执行状况，如cronie中的任务在过去该运行的时间点未能正常运行，则anacron会随后启动一次此任务 crontabs：包含CentOS提供系统维护任务 确保crond守护处于运行状态： CentOS 7: systemctl status crond CentOS 6: service crond status 计划周期性执行的任务提交给crond，到指定时间会自动运行 系统cron任务：系统维护作业 /etc/crontab 用户cron任务： crontab命令 日志：/var/log/cron 系统的计划任务 指定的计划任务可根据需求写入以下配置文件中 /etc/crontab 配置文件 /etc/cron.d/ 配置文件 /etc/cron.hourly/ 脚本 /etc/cron.daily/ 脚本 /etc/cron.weekly/ 脚本 /etc/cron.monthly/ 脚本 crontab格式： * * * * * command 分 时 天 月 周 命令 时间格式 时间 格式 @reboot(每次重启) @yearly(每年) 0 0 1 1 * @annually(每年) 0 0 1 1 * @monthly(每月) 0 0 1 @weekly(每周) 0 0 0 @daily(每天) 0 0 * @hourly(每小时) 0 时间表示法： (1) 特定值 给定时间点有效取值范围内的值 (2) * 给定时间点上有效取值范围内的所有值 如*/2表示“每(分|时|日|月|周)” (3) 离散取值 #,#,# (4) 连续取值 #-# (5) 在指定时间范围上，定义步长 /#: #即为步长 例如：晚上9点10分运行echo命令 10 21 * * * wang /bin/echo &quot;Hi!&quot; anacron系统运行计算机关机时cron不运行的任务，CentOS6以后版本取消anacron服务，由 crond服务管理 对笔记本电脑、台式机、工作站、偶尔要关机的服务器及其它不一直开机的系统 很重要对很有用 配置文件：/etc/anacrontab，负责执行/etc/ cron.daily /etc/cron.weekly /etc/cron.monthly中系统任务 字段1：如果在这些日子里没有运行这些任务…… 字段2：在重新引导后等待这么多分钟后运行它 字段3：任务识别器，在日志文件中标识 字段4：要执行的任务 由/etc/cron.hourly/0anacron执行 当执行任务时，更新/var/spool/anacron/cron.daily 文件的时间戳 管理临时文件CentOS6使用/etc/cron.daily/tmpwatch定时清除临时文件 CentOS7使用systemd-tmpfiles-setup服务实现 配置文件： /etc/tmpfiles.d/*.conf /run/tmpfiles.d/*.conf /usr/lib/tmpfiles/*.conf /usr/lib/tmpfiles.d/tmp.conf d /tmp 1777 root root 10d d /var/tmp 1777 root root 30d 命令： systemd-tmpfiles –clean|remove|create configfile 用户计划任务crontab命令定义 普通用户可通过该命令创建计划任务 每个用户都有专用的cron任务文件： /var/spool/cron/USERNAME crontab命令： crontab [-u user] [-l | -r | -e] [-i] crontab [-u user] file 将文件作为计划内容 -l: 列出所有任务 -e: 编辑任务 -r: 移除所有任务 -i：同-r一同使用，以交互式模式移除指定任务,删除前确认 -u user: 仅root可运行，指定用户管理cron任务 -s SELinux字符串作为 MLS_LEVEL 设置追加到 crontab 文件中 -n [ hostname ] 设置群集中哪个主机以运行作业 -c 查询群集中当前设置的哪个主机以运行作业 控制用户执行计划任务： /etc/cron.{allow,deny}，该文件用法类似于/etc/at.{allow,deny} at和crontab的区别一次性作业使用at命令 重复性作业使用crontab命令 二者的区别： 功能 at命令 crontab命令 Create at time crontab -e List at -l crontab -l Details at -c jobnum 无 Remove at -d jobnum crontab -r Edit 无 crontab -e 没有被重定向的输出会被邮寄给用户 root能够修改其它用户的作业 注意：运行结果的标准输出和错误以邮件通知给相关用户 (1) COMMAND &gt; /dev/null (2) COMMAND &amp;&gt; /dev/null 对于cron任务来讲，%有特殊用途；如果在命令中要使用%，则需要转义，将%放置于单引号中，则可不用转义 思考： 如何在秒级别运行任务？ * * * * * sleep 10; date &gt;&gt; /mnt/file sleep命令： sleep NUMBER[SUFFIX]... s: 秒, 默认 m: 分 h: 小时 d: 天]]></content>
  </entry>
  <entry>
    <title><![CDATA[raid和lvm]]></title>
    <url>%2F2018%2F04%2Fraid%E5%92%8Clvm%2F</url>
    <content type="text"><![CDATA[磁盘阵列RAIDRAID:RedundantArrays of Inexpensive（Independent）Disks 早期被称为RedundantArrays of Inexpensive Disks(廉价的磁盘阵列)，后来随着技术的不断完善，又被称为RedundantArrays of Independent Disks(独立的磁盘冗余阵列) 其作用是：多个磁盘合成一个“阵列”来提供更好的性能、冗余，或者两者都提供 RAID提高IO能力 磁盘并行读写 提高耐用性 磁盘冗余来实现 级别：多块磁盘组织在一起的工作方式有所不同 RAID实现的方式 外接式磁盘阵列：通过扩展卡提供适配能力 内接式RAID：主板集成RAID控制器，安装OS前在BIOS里配置 软件RAID：通过OS实现 RAID级别RAID0：带区(带区)卷 读、写性能提升； 可用空间：N*min(S1,S2,...) 无容错能力 最少磁盘数：2, 2+ 在读写数据时，多块硬盘同时进行读写操作，大大提升了读写的性能 RAID1:镜像卷 读性能提升、写性能略有下降； 可用空间：1*min(S1,S2,...) 有冗余能力 最少磁盘数：2, 2N 在写入数据时，要同时对两块硬盘写入相同的数据，这样一来，写入一份数据要花费更多的资源，降低了系统写性能 RAID5 读、写性能提升 可用空间：(N-1)*min(S1,S2,...) 有容错能力：允许最多1块磁盘损坏 最少磁盘数：3, 3+ 每一个硬盘都有一个异或校验值，一旦其中某块硬盘发生故障，通过异或校验值可以计算出该硬盘的数据，以达到冗余的目的。同时，服务器将会处于“忙碌(降级)”状态，系统读写性能大大降低，需要及时把发生故障的硬盘替换。异或校验值会占用硬盘空间，因此硬盘利用率会被稍微降低，利用率为(n-1)/n RAID-6： 读、写性能提升 可用空间：(N-2)*min(S1,S2,...) 有容错能力：允许最多2块磁盘损坏 最少磁盘数：4, 4+ 该模式与raid5类似，不同之处在于raid6每个成员内存有两个异或校验值，因此允许损坏2块硬盘，硬盘利用率为(n-2)/n RAID10 读、写性能提升 可用空间：N*min(S1,S2,...)/2 有容错能力：每组镜像最多只能坏一块 最少磁盘数：4, 4+ raid10即对硬盘先两两做raid1，再对两组raid1做raid0 RAID01 多块磁盘先实现RAID0,再组合成RAID1 注意：raid10和raid01硬盘利用率均为50%，但raid10容错性比raid01更好 当RAID 10有一个硬盘受损,其余硬盘会继续运作,几率为1/3, RAID 01只要有一个硬盘受损,同组RAID0的所有硬盘都会停止运作,只剩下其他组的硬盘运作,可靠性较低,几率为2/3。 如果以六个硬盘建RAID01,再用三个建RAID0,那么坏一个硬盘便会有三个硬盘离线。所以10好于01 因此，RAID 10远较RAID 01常用，零售主板绝大部份支持RAID 0/1/5/10，但不支持RAID 01。 RAID-50 多块磁盘先实现RAID5,再组合成RAID0 JBOD：Just a Bunch Of Disks 功能：将多块磁盘的空间合并一个大的连续空间使用 可用空间：sum(S1,S2,...) 该模式对每个磁盘成员大小没有要求，写入数据时，将第一块磁盘写满后，再写入第二块磁盘，以此类推；因此既无容错性，读写性能也大大降低，一般情况下不推荐这种模式 RAID7 可以理解为一个独立存储计算机，自身带有操作系统和管理工具，可以独立运行，理论上性能最高的RAID模式 常用RAID级别： RAID-0, RAID-1, RAID-5, RAID-10, RAID-50, JBOD 软RAID实现mdadm Llinux中分区类型：fd 示例： mdadm -C /dev/md# -a yes -l 5 -c 32 -n 3 -x1 /dev/sd# 利用软件创建一个软raid5 -C：创建 -a：检查 -l：raid级别 -c：thunk大小 默认512K -n：硬盘成员 -x：备用硬盘 mdadm -D /dev/md# 查看raid状态 mdadm -Ds /dev/md# &gt; /etc/mdadm.conf 生成配置文件 下次开机自动生效 mdadm -S /dev/md# 停用raid设备 mdadm -A /dev/md# 激活raid设备 mdadm /dev/md# -f /dev/sd# 模拟硬盘损坏 mdadm /dev/md# -r /dev/sd# 手动移除硬盘 mdadm /dev/md# -a /dev/sd# 手动添新硬盘 mdadm -G /dev/md# -n4 -a /dev/sd# 扩展raid mdadm --zero-superblock /dev/sd# 删除已移除硬盘的superblock 避免再次使用的影响 逻辑卷管理传统分区扩展性差，逻辑卷能够很好的解决该问题 允许对卷进行方便操作的抽象层，包括重新设定文件系统的大小 允许在多个物理设备间重新组织文件系统 将设备指定为物理卷(PV) 用一个或者多个物理卷来创建一个卷组(VG) 物理卷是用固定大小的物理区域（Physical Extent，PE）来定义的 在物理卷上创建的逻辑卷(LVM)是由物理区域（PE）组成 可以在逻辑卷上创建文件系统(FS_TYPE) PV管理工具显示pv信息 pvs：简要pv信息显示 pvdisplay 创建pv pvcreate /dev/DEVICE VG管理工具显示卷组 vgs vgdisplay 创建卷组 vgcreate [-s #[kKmMgGtTpPeE]] VolumeGroupNamePhysicalDevicePath[PhysicalDevicePath...] 管理卷组 vgextend VolumeGroupName PhysicalDevicePath[PhysicalDevicePath...] vgreduce VolumeGroupName PhysicalDevicePath[PhysicalDevicePath...] 删除卷组 先做pvmove，再做vgremove LV管理工具显示逻辑卷 lvs Lvdisplay 创建逻辑卷 lvcreate -L #[mMgGtT] -n NAME VolumeGroup lvcreate -l 60%VG -n mylvtestvg lvcreate -l 100%FREE -n yourlvtestvg 删除逻辑卷 lvremove /dev/VG_NAME/LV_NAME 重设文件系统大小 fsadm [options] resize device [new_size[BKMGTEP]] resize2fs [-f] [-F] [-M] [-P] [-p] device [new_size] xfs_growfs /mountpoint 扩展和缩减逻辑卷扩展逻辑卷： lvextend -L [+]#[mMgGtT] /dev/VG_NAME/LV_NAME resize2fs /dev/VG_NAME/LV_NAME lvresize -r -l +100%FREE /dev/VG_NAME/LV_NAME 缩减逻辑卷： umount /dev/VG_NAME/LV_NAME e2fsck -f /dev/VG_NAME/LV_NAME resize2fs /dev/VG_NAME/LV_NAME #[mMgGtT] lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME mount 跨主机迁移卷组源计算机上 1 在旧系统中，umount所有卷组上的逻辑卷 2 vgchange –a n vg0 lvdisplay 3 vgexport vg0 pvscan vgdisplay 拆下旧硬盘 在目标计算机上 4 在新系统中安装旧硬盘，并vgimport vg0. 5 vgchange –ay vg0 6 mount所有卷组上的逻辑卷 注意：centos6默认文件系统为ext系列，因此从centos7迁移到centos6版本，会有问题，如果从centos6往centos7上迁移，则没问题 逻辑卷管理器快照快照是特殊的逻辑卷，它是在生成快照时存在的逻辑卷的准确拷贝 对于需要备份或者复制的现有数据临时拷贝以及其它操作来说，快照是最合适的选择 快照只有在它们和原来的逻辑卷不同时才会消耗空间 在生成快照时会分配给它一定的空间，但只有在原来的逻辑卷或者快照有所改变才会使用这些空间 当原来的逻辑卷中有所改变时，会将旧的数据复制到快照中。 快照中只含有原来的逻辑卷中更改的数据或者自生成快照后的快照中更改的数据 建立快照的卷大小只需要原始逻辑卷的15%～20%就够了,也可以使用lvextend放大快照 快照就是将当时的系统信息记录下来，就好像照相一般，若将来有任何数据改动了，则原始数据会被移动到快照区，没有改动的区域则由快照区和文件系统共享 由于快照区与原本的LV共用很多PE的区块，因此快照与被快照的LV必须在同一个VG中.系统恢复的时候的文件数量不能高于快照区的实际容量 使用LVM快照为现有逻辑卷创建快照 lvcreate -l 64 -s -n data-snapshot -p r /dev/vg0/data -s：快照功能 -p r：快照只读属性 挂载快照 mkdir -p /mnt/snap mount -o ro /dev/vg0/data-snapshot /mnt/snap 注意：在xfs文件系统中 要挂载快照卷需要加入--nouuid的选项 如 mount -o nouuid /dev/SNAP_LV_NAME mountpoint 恢复快照 umount /dev/vg0/data-snapshot umount /dev/vg0/data lvconvert --merge /dev/vg0/data-snapshot 删除快照 umount /mnt/databackup lvremove /dev/vg0/databackup 示例： 实验：创建LV pvcreate /dev/sd{a5,b1} 创建物理逻辑卷 vgcreate vg0 /dev/sd{a5,b1} 为卷组分配物理卷 lvcreate -n lv0 -L 10G vg0 创建逻辑卷大小名字 mkfs.ext4 /dev/vg0/lv0 创建逻辑卷文件系统 mount 挂载逻辑卷 vim /etc/fstab 写入配置文件 实验：扩展LVM 扩展逻辑卷，首先要扩展卷组 1、查看卷组空间 vgdisplay 2、如果空间足够，直接扩展 lvextend -l 100%FREE /dev/vg0/lv0 然后扩展文件系统： ext系列文件系统：resize2fs /dev/vg0/lv0 xfs文件系统：xfs_grow /mnt/lv0 或者一步完成：lvextend -r -l 100%FREE /dev/vg0/lv0 3、如果空间不足，则需要新增物理卷 (1)pvcreate /dev/sdc 增加物理卷 (2)vgextend vg0 /dev/sdc 扩展卷组 (3)lvextend -L +1G /dev/vg0/lv0 逻辑卷在原来的基础上增加大小+1G lvextend -L 3G /dev/vg0/lv0 逻辑卷直接指定大小3G (4)扩展文件系统 ext系列文件系统 resize2fs /dev/vg0/lv0(设备名) xfs文件系统 xfs_grow /mnt/lv1(挂载点) 扩展逻辑卷，由于新增分区没有文件系统，因此硬盘容量虽然加入逻辑卷，但是却不能写入数据，因此需要扩展文件系统 或者： 扩展空间和扩展文件系统一步完成，不用管是哪种文件系统 lvextend -r -L +1G /dev/vg0/lv0 实验：缩减LVM（xfs不能缩减），数据要提前做备份 逻辑卷缩减（ext系列） 1、缩减不支持在线缩减，要先取消挂载要缩减的逻辑卷 umount /mnt/lv0 2、检查系统完整性(必须执行该步骤,否则后续会报错) fsck -f /dev/vg0/lv0 3、缩减文件系统 resize2fs /dev/vg0/lv0 2G 缩减后的大小必须大于逻辑卷大小 4、缩减逻辑卷 lvreduce -L 2G /dev/vg0/lv0 逻辑卷缩减大小必须和文件系统缩减大小一致 5、重新挂载 mount -a 6、查看缩减后的结果 df -h 实验：迁移LV到新主机(直接拆硬盘过去 卷组都在一个硬盘） * 确认VG名和目标主机不同 vgrename vg1 vg100 修改自己的VG名 lvrename lv2 lv100 修改自己的LV名 umout /mnt/lv2 取消挂载 vhchange -an vg100 禁用（启用是-ay） vgexport vg100 设置成导出状态 vgdisplay 观察逻辑卷状态 * 拆除 在新主机插入硬盘 pvscan 观察磁盘的pv状态 vgimport vg100 导入vg100 vgchange -ay vg100 启用vg100 mount /dev/vg100/lv100 /mnt 挂载 pvs 实验：删除vg中的pv （搬家前先检查vg里的容量） pvmove /dev/sdc 把pv：sdc里的所有用了的空间移动到同一个组里的其他空间 vgreduce vg0 /dev/sdc 从vg0里吧sdc移除 pvremove /dev/sdc 把逻辑卷sdc变成普通硬盘 echo ‘- – – ‘ &gt; /sys/class/scsi_host/host0/scan 识别新硬盘]]></content>
  </entry>
  <entry>
    <title><![CDATA[三剑客之AWK]]></title>
    <url>%2F2018%2F04%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8BAWK%2F</url>
    <content type="text"><![CDATA[基本用法：awk [option] &apos;program&apos; var=value file... Porgram：pattern{action action;...} pattren，指明要处理的语句的条件 action action，处理的动作 awk [option] -f programfile var=value file... awk [options] &apos;BEGIN{action;...}pattern{action;...}END{action;...}&apos; file... [options] -F &quot;分隔符&quot;，输入时的分隔符 -v 变量 awk自带的变量$1,$2,...表示以指定分隔符分割出的字段 $0，表示整个字段 示例： awk -F: &apos;{print $0}&apos; /etc/passwd FS，输入分割符 示例： awk -v FS=&quot;:&quot; &apos;{print $1,$3}&apos; /etc/passwd fs=: awk -v FS=$fs &apos;{print $1,$3}&apos; /etc/passwd OFS，输出分隔符，默认为空格 示例： awk -v OFS=&quot;:&quot; &apos;{print $1,$3}&apos; /etc/passwd RS，输入行的分隔符，默认为\n 示例： awk -v RS=: &apos;{print $0}&apos; /etc/passwd ORS，输出的行的分隔符 示例： awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS=&quot;+++&quot; &apos;{print $0}&apos; NF，字段数量 示例: awk -F: &apos;{print NF}&apos; /etc/passwd $NF，表示最后一个字段 NR，行的编号 示例： awk -F: &apos;{print NR,$1}&apos; /etc/passwd FNR，每个文件单独行编号 示例： awk -F &apos;{print FNR,$1}&apos; /etc/passwd /etc/fstab ARGC，参数的个数 示例： awk &apos;{print ARGC}&apos;/etc/fstab /etc/inittab ARGV，命令行中的各参数 示例 awk &apos;{print ARGV[1]}&apos; /etc/passwd /etc/shadow awk自定义变量自定义变量(区分字符大小写) 1. -v var=value 2. 在program中直接定义 示例： awk -v name=&quot;shuinoo&quot; {print name,$1} /etc/fstab awk的简单使用awk &apos;{print $0}&apos; /etc/passwd 结果：打印文件的所有内容 awk &apos;{print &quot;abc&quot; $0}&apos; /etc/passwd 如果要打印字符串，则需要加&quot;&quot; 如需要使用变量则无需加&quot;&quot; awk &apos;BEGIN{print &quot;1+2&quot;}{print $0}END{print &quot;end&quot;}&apos; /etc/passwd df | awk -F&quot;[[:space:]]|%&quot; &apos;/\dev\/sd/{print $1,$5}&apos; 取出设备名和硬盘使用率 awk -F: &apos;{print $1,$3}&apos; /etc/passwd awk -F&quot;[[ ]&quot; &apos;{print $5}&apos; /var/log/httpd/access_log awk printf命令printf &quot;format&quot;，item1，item2，... 1. 必须指定format 2. 不自动换行 3. 需分别为每个item指定格式符 格式符： %c，显示字符ascii %s，显示字符串 %f，显示浮点数 %d，显示十进制 %u，显示无符号整数 %g，显示科学计数法 %%，显示%自身 修饰符： #[.#]，第一个显示宽度，第二个#表示小数点后精度 默认为右对齐，可以使用-变成左对齐 + 显示数值正负符号 awk 操作符算术操作符：+ - * / ^ % 示例： awk &apos;BEGIN{print 2^3}&apos; 赋值操作符：= += -= *= /= %= ^= ++ -- 示例： awk &apos;BEGIN{i=0;print ++i,i}&apos; ++i，先自加i，然后输出i awk &apos;BEGIN{i=0;print i++,i}&apos; i++，先输出i，在自加i 逻辑操作符：&amp;&amp; || ！ 示例： awk -F： &apos;!($3&lt;=1000){print $1,$3}&apos; /etc/passwd 比较操作符：== != &gt; &gt;= &lt; &lt;= 示例： awk &apos;BEGIN{i=6;if(i==5)print &quot;equal&quot;;else print &quot;no equal&quot;}&apos; 示例： awk -F: &apos;$3&gt;=0&amp;&amp;$3&lt;=1000{print $1,$3}&apos; /etc/passwd 模式匹配符： ~ 左边是否和右边匹配 !~ 是否不匹配 示例： awk -F: &apos;$3 ~/xfs/{print $0}&apos; /etc/fstab 条件表达式： selector?if true Expr;if false Expr 示例： awk -F：{$3&gt;=100?user=&quot;comon user&quot;:user=&quot;sys user&quot;;printf &quot;%-15s:%-10s\n&quot;,$1,user}&apos; /etc/passwd awk pattern1. 空模式，匹配每一行 2. /Regex/，仅处理能够匹配到的行 3. 关系表达式 真，结果为非0，非空字符串 假，结果为空字符串或0 4. 行范围 5.BEGIN、END BEGIN，仅在开始处理文件文本之前执行一次 END，仅在文本处理后执行一次 示例： awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=20{print $1}&apos; /etc/passwd awk -F &apos;/^UUID/{print $0}&apos; /etc/fstab seq 10 | awk &apos;i=1&apos; seq 10 | awk &apos;i=!i&apos;相当于 seq 10 | awk -v i=0 &apos;i=!i&apos; seq 10 | awk -v i=11 &apos;i=!i&apos;相当于 seq 10 | awk &apos;!(i=!i)&apos; awk if-elseif(判断条件){语句1;...}[else{语句}] if(判断条件){语句1;...}else if(判断条件2){语句2...}else{语句3} 示例： awk -F: &apos;{if(NF&gt;5)print $0}&apos; /etc/passwd ifconfig | awk -F: &apos;{if(NR==2)print $2}&apos; awk -F: -v OFS=: &apos;{if($3&gt;=100)print $1,$3}&apos; /etc/passwd awk &apos;BEGIN{score=80;if(score&lt;=60){print &quot;is fall&quot;}else if(score&gt;=80){print &quot;OK&quot;}else{print &quot;good&quot;}}&apos; awk whilewhile(判断条件){语句} 示例： awk &apos;BEGIN{i=0;sum=0;while(i&lt;=100){sum+=i;i++};print sum}&apos; awk &apos;{i=1;while(i&lt;NF){print length($i);i++}}&apos; /etc/issue /etc/issue每个字段的长度 awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfg 显示/etc/grub2.cfg的包含linux16的行的每个字段及每个字段的长度 awk do-whiledo{语句;...}while(判断条件) 无论真假，至少执行一次循环体 示例： awk &apos;BEGIN{total=0;i=0;do{total+=i;i++;}while(i&lt;=100);print total}&apos; awk forfor(expr1;expr2;expr3){语句;...} 示例： awk &apos;BEGIN{for(i=0;i&lt;=100;i++){total+=i};print total}&apos; awk switchswitch(判断条件){case VALUE1 or /REGEXP/:语句1;case VAULE2 or /REGEXP/:语句2;default:默认语句} awk break&amp;continueawk -v total=0 &apos;BEGIN{for(i=0;i&lt;=100;i++){if(i==50)continue;total+=i};print total}&apos; awk -v total=0 &apos;BEGIN{for(i=0;i&lt;=100;i++){if(i==66)break;total+=i};print total}&apos; awk 数组关联数组：array[索引] 索引： 1. 可使用任意字符串，字符串使用双引号 2. 如某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化“空串” 3. 判断数组是否某元素，要使用“index in array”格式遍历 遍历数组每个元素，要使用for循环 for(变量 in 数组){循环体} 示例： awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;mage&quot;;title=[&quot;coo&quot;]=&quot;zhangsir&quot;;print title[&quot;ceo&quot;]}&apos; awk &apos;{ip[$1]++}END{for(i in ip)print i,ip[i]}}&apos; /var/log/httpd/access_log 统计/var/log/httd/access_log每个IP的访问数量 ss -nt | awk -F &quot;[[:space:]]+|:&quot; &apos;/ESTAB/{ip[$(NF-2)]++}END{for(i in ip);print i;ip[i];}&apos; 生成1000个以,分隔的随机数，求出最大值和最小值 for i in {1..1000};do if [ $i -eq 1000 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; num.txt ;else echo -e &quot;$RANDOM,\c&quot; &gt;&gt; num.txt;fi;done awk -F&quot;,&quot; &apos;{i=1;max=$1;min=$2;while(i&lt;=NF){if(max&gt;$i){max=$i}else if(min&lt;$i){min=$i};{print &quot;max=&quot; max,&quot;min=&quot; min}}}&apos; num.txt awk 自带函数rand()，生成0和1之间的随机数 示例： awk &apos;BEGIN{srand();for(i=1;i&lt;=3;i++)print rand()}&apos; length(s)，返回字符串s的长度 示例： awk &apos;{for(i=1;i&lt;=NF;i++){print $i,length($i)}&apos; /etc/issue sub(r,s,[t])，对t字符串搜索r匹配到的内容，并将第一次匹配到s的替换成s 示例： echo &quot;2018:11:18 15:08:09&quot; | awk &apos;sub(&quot;:&quot;, &quot;-&quot; ,$2)&apos; gsub(r,s,[t])，同上，所不同的是替换时将全部替换 示例： echo &quot;2018:11:18 15:08:09&quot; | awk &apos;gsub(&quot;:&quot;, &quot;-&quot; ,$2)&apos; split(s,array,[r])，以r为分隔符，切割字符串s，并将切割后的字符串保存到array数组中，第一个索引值为1，以此类推... 示例： netstat -tn | awk &apos;/tcp\&gt;{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for(i in count){print i,count[i]}}&apos; awk 自定义函数函数名 (形参1,形参2,...) { 语句 return expression } 示例： function max(x,y) { x&gt;y?var=x:var=y return var } BEGIN{a=3;b=2;print max(a,b)} awk中调用shell命令system命令 示例： awk &apos;BEGIN{system(&quot;ls /&quot;)}&apos; awk 脚本可以将awk语句写成脚本，使用-f选项读入或执行 示例： cat f.awk {ip[$1]++}END{for(i in ip)print i;ip[i]}} awk -f f.awk /var/log/httpd/access_log 向awk脚本传递参数AWKFILE.awk var1=value1 var2=value2 ... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数 示例： cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3} chmod +x test.awk test.awk -F: min=100 max=200 /etc/passwd 示例 文件ip_list.txt如下格式，请提取” .magedu.com” 前面的主机名部分并写入到回到该文件中 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4 news.sina.com.cn 5 blog.sina.com.cn 6 weather.sina.com.cn 7 auto.sina.com.cn awk -F&quot;.&quot; &apos;{print $1}&apos; ip.txt | cut -d&quot; &quot; -f2 &gt;&gt; ip.txt 统计/etc/fstab文件中每个文件系统类型出现的次数 awk &apos;/^UUID/{filesystem[$3]++}END{for(i in filesystem){print i,filesystem[i]}}&apos; /etc/fstab 统计/etc/fstab文件中每个单词出现的次数 grep -Eo &quot;\&lt;[[:alpha:]]+\&gt;&quot; /etc/fstab | awk &apos;{word[$0]++}END{for(i in word){print i,word[i]}}&apos; 提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot; | awk &apos;gsub(&quot;[[:alpha:]]|[[:punct:]]&quot;, &quot;&quot;, $1)&apos; 解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT awk &apos;{ip[$1]++}END{for(i in ip){if(ip[i]&gt;=100){system(&quot;iptables -A INPUT -s i -j REJECT&quot;)}}}&apos; /var/log/httpd/access_log 将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html awk -F &quot;/.&quot; &apos;{print $2}&apos; fqdn.txt | sort | uniq -c | sort -nr 将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出同一inode中，beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 106|3363120000|3368579999|30000| 123456789#!/bin/awk -f !/^inode/&#123; sum[$1]+=$4 if(!bn[$1])&#123;bn[$1]=$2&#125;else if(bn[$1]&gt;$2)&#123;bn[$1]=$2&#125; if(!en[$1])&#123;en[$1]=$3&#125;else if(en[$1]&lt;$3)&#123;en[$1]=$3&#125;&#125;END&#123; for(i in sum)print i"|"bn[i]"|"en[i]"|"sum[i]"|"&#125;]]></content>
      <categories>
        <category>linux</category>
        <category>文本处理</category>
      </categories>
      <tags>
        <tag>三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SElinux]]></title>
    <url>%2F2018%2F04%2FSElinux%2F</url>
    <content type="text"><![CDATA[SElinuxSecurity Enhanced Linux 美国国家安全局(NSA=TheNational Security Agency)和SCC(Secure Computing Corporation)开发的Linux的一个强制访问控制的安全模块 DAC：Discretionary Access Control自由访问控制 MAC：Mandatory Access Control 强制访问控制 相比其他强制性访问控制系统，SELinux 有如下优势： 控制策略是可查询而非程序不可见的。 可以热更改策略而无需重启或者停止服务。 可以从进程初始化、继承和程序执行三个方面通过策略进行控制。 控制范围覆盖文件系统、目录、文件、文件启动描述符、端口、消息接口和网络接口。 SELinux工作类型四种工作类型： strict: centos5,每个进程都受到selinux的控制 targeted: 用来保护常见的网络服务,仅有限进程受到selinux控制，只监控容易被入侵的进程，centos4只保护13个服务，centos5保护88个服务 minimum：centos7,修改的targeted，只对选择的网络服务 mls:提供MLS（多级安全）机制的安全性 targeted为默认类型，minimum和mls稳定性不足，未加以应用，strict已不再 使用 安全上下文传统Linux，一切皆文件，由用户，组，权限控制访问 在SELinux中，一切皆对象（object），由存放在inode的扩展属性域的安全元素所控制其访问 安全上下文是 SELinux 的核心。 安全上下文我自己把它分为「进程安全上下文」和「文件安全上下文」。 一个「进程安全上下文」一般对应多个「文件安全上下文」。 只有两者的安全上下文对应上了，进程才能访问文件。它们的对应关系由政策中的规则决定 所有文件和端口资源和进程都具备安全标签：安全上下文（security context） 需要注意的是，单纯的移动文件操作并不会改变文件的安全上下文。 安全上下文有五个元素组成： user:role:type:sensitivity:category user_u:object_r:tmp_t:s0:c0 user：指示登录系统的用户类型,进程 Role：定义文件，进程和用户的用途 Type：指定数据类型 Sensitivity：限制访问的需要，由组织定义的分层安全级别 Category：对于特定组织划分不分层的分类 SElinu模式配置文件 /etc/selinux/config getenforce 查询模式状态 setenforce 0 开启Permissive 只发出警告信息 setenforce 1 开启Enforcing ，记录警告且阻止可疑行为，文件权限多个. Disabled 与 Permissive 或者 Enforcing 需要重启计算机 禁用SElinux CentOS7 /boot/grub2/grub.cfg 下面启动选项最后添加selinux=0为禁用 /etc/selinux/config SELINUX=disabled 查询文件或目录的安全上下文 ls -Z ls -Z /etc/hosts -rw-r--r--. root root system_u:object_r:net_conf_t:s0 /etc/hosts 修改SELinux安全标签给文件打标 chcon [OPTION]... [-u USER] [-r ROLE] [-t TYPE] FILE... chcon [OPTION]... --reference=RFILE FILE... -R：递归打标 chcon -R -t public_content_t /data 恢复目录或文件默认的安全上下文： restorecon [-R] /FILE 修改SELinux安全规则semanage port -a -t http_port_t -p 9527 -a 增加 -t type -p 端口号 semanage port -m -t ssh_port_t -p 9527 -m 修改 -t type -p 9257 注意：修改端口时，端口需事先存在 semanage port -d -t ssh_port_t -d 删除 SELinux布尔值getsebool -a 显示系统所有的布尔值 semanage boolean -L setsebool 设置指定的boolean值 示例 setsebool ftpd_anon_write=1 -P 永久更改boolean值 SELinux日志/var/log/audit/audit.log 整理并分析日志 sealert -a SElinux帮助 yum install selinux-policy-devel yum install selinux-policy-doc]]></content>
      <categories>
        <category>linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理三剑客之sed]]></title>
    <url>%2F2018%2F04%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed%2F</url>
    <content type="text"><![CDATA[sedStream EDitor, 行编辑器 sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时 缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的 内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。 如果没有使诸如‘D’的特殊命令，那会在两个循环之间清空模式空间，但不会清 空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重 定向存储输出。 功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等 sed工具1.常用选项： -n 不输出模式空间内容到屏幕，即不自动打印 -e 多点编辑 -f /PATH/SCRIPT_FILE 从指定文件中读取编辑脚本 -r 支持使用扩展正则表达式 -i.bak 备份文件并原处编辑 2.编辑命令 d 删除模式空间匹配的行，并立即启用下一轮循环 p 打印当前模式空间内容，追加到默认输出之后 \a 在指定行后面追加文本，支持使用\n实现多行追加 \i 在行前面插入文本 \c 替换行为单行或多行文本 w /path/file 保存模式匹配的行至指定文件 r /path/file 读取指定文件的文本至模式空间中匹配到的行后 = 为模式空间中的行打印行号 ! 模式空间中匹配行取反处理 N 读取当前行以及下一行 3.地址定界 不给地址：对全文处理 单地址： # 指定的行 /pattern/ 被此处模式所能够匹配到的每一行 地址范围： #，# 从第#行到第#行的所有行 #,+# 从第#行开始以及之后#行的所有行 /pat1/,/pat2/ 从第一次匹配到/pat1/的行到匹配到/pat2/的行 #,/pat1/ 从第#行到第一次匹配到/pat1/的行的所有行 跳行： sed -n ‘1~2p’ 只打印奇数行 sed -n ‘2~2p’ 只打印偶数行 sed -n ‘1~3p’ 从第1行开始，每隔3行显示一次 4.搜索替换 s/// 查找替换,支持使用其它分隔符，s@@@，s### 5.替换标记 p，显示被替换成功的行 g，全局替换 i，忽略大小写 当被替换的内容需要引用变量可使用&apos;&apos;&apos;$VAR&apos;&apos;&apos; 5.高级编辑命令 模式空间：pattern space临时缓冲区，内容会主动打印到标准输出，并自动清空，相当于流水线 保持空间：hold space 辅助临时缓冲区,相互独立，内容不会主动清空，也不会主动打印到标准输出 需要sed命令来进行处理，相当于仓库 P： 打印模式空间开端至\n内容，并追加到默认输出之前 d D: 删除pattern space的内容/及第一个换行符，开始下一个循环 h H: 复制/追加pattern space的内容到hold space.（复制会覆盖原内容） g G: 复制/追加hold space的内容到pattern space.复制会覆盖原内容） x : 交换hold space和pattern space的内容 示例： 取ip ifconfig | sed -nr &apos;/^[^ lv]/{N;s/(^[^ :]+).*\n[^0-9]+([0-9.]+).*/\1 \2/;/.* 6/d;p}&apos; ifconfig | sed -nr &apos;2s/[^0-9]+([0-9.]+).*/\1/p&apos; sed –n ‘s/root/&amp;superman/p’ /etc/passwd 单词后 sed –n ‘s/root/superman&amp;/p’ /etc/passwd 单词前 sed ‘/root/a\superman’ /etc/passwd行后 sed ‘/root/i\superman’ /etc/passwd 行前 sed ‘/root/c\superman’ /etc/passwd 代替行 sed –n ‘2,/root/p’ /etc/passwd 从2行开始 sed -n ‘/^$/=’ file 显示空行行号 sed &apos;s/[[:alpha:]]/\u&amp;/g&apos; file 文件中所有字母变为大写 例： 1、使用sed命令，在/etc/default/（centos7）grub目录中GRUB_CMDLINE_LINUX=&quot;rhgb quiet&quot;行后添加 net.ifname=0 参考答案： sed -r &apos;s/(^.*quiet.*)&quot;/\1 net.ifname=0&quot;/&apos; /etc/default/grub 或sed -r &apos;s/(LINUX.*)&quot;/\1 net.ifname=0&quot;/&apos; /etc/default/grub 或sed -r &apos;/LINUX/s/&quot;$/ net.ifname=0&quot;/&apos; /etc/default/grub 2、使用sed命令，获取ip地址（centos7） ifconfig ens33 |sed -nr &apos;2s/(^.*inet)(.*)(netmask.*$)/\2/p&apos; 或ifconfig ens33 |sed -n &apos;2p&apos;|sed &apos;s/^.*inet//&apos; |sed &apos;s/netmask.*//&apos; 或ifconfig ens33 |sed -n &apos;2p&apos;|sed -e &apos;s/^.*inet//&apos; -e &apos;s/netmask.*//&apos; 或ifconfig ens33 | sed &apos;2!d;s/^.*inet//;s/netmask.*//&apos; 3、使用sed命令，取/etc/sysconfig/network-script/的基名 echo &quot;/etc/sysconfig/network-script/&quot; |sed -r &apos;s#(^.*/)([^/]+/?$)#\2#&apos; 4、使用sed命令，把/etc/httpd/conf/httpd.conf文件中&lt;VirtualHoat *:80&gt;到&lt;VirttualHost&gt;内容前的#号删除 要更改的内容如下： #&lt;VirtualHost *:80&gt; # ServerAdmin webmaster@dummy-host.example.com # DocumentRoot /www/docs/dummy-host.example.com # ServerName dummy-host.example.com # ErrorLog logs/dummy-host.example.com-error_log # CustomLog logs/dummy-host.example.com-access_log common #&lt;/VirtualHost&gt; 参考答案： sed &apos;/^#&lt;VirtualHost/,/^#&lt;\/VirtualHost&gt;/s/#//&apos; /etc/httpd/conf/httpd.conf 5、使用sed命令，在/etc/fstab目录中不以#号开头的行前面加上#号 sed -r &apos;s/(^[^#].*)/#\1/&apos; /etc/fstab 在非#号开头行前加上#号 或sed -r &apos;s/^([^#])/#\1/&apos; /etc/fstab 在非#号[\^#]开头的行，以#号代替[^#] 或sed &apos;s/^[^#]/#&amp;/&apos; /etc/fstab 其中，&amp;表示模式匹配的内容是什么，&amp;就代表什么 6、把/etc/fstab中的字母全部变为大写 sed -r &apos;s/[[:alpha:]]/\u&amp;/g&apos; /etc/fstab \u 转换为大写 \l 转换为小写 7、将s/[[:alpha:]]/\u&amp;/g写入脚本sed.script，使用sed命令调用该脚本可直接将文件改为大写 sed -f 可以调用脚本 如：sed -r -f sed.script /etc/fstab 8、对某目录下文件加上随机数后缀 ls |sed &quot;s/.*/&amp;_$RANDOM/&quot; 或ls |sed &apos;s/.*/&amp;_&apos;&apos;&apos;$RANDOM&apos;&apos;&apos;/&apos; 在sed查找替换中引用变量，要&quot; &quot;或使用三个单引号把变量括起来 如 &quot;s//$变量/&quot;或s//&apos;&apos;&apos;$变量&apos;&apos;&apos;/ 9、删除文件中所有空行和以#开头（即注释）的行 sed &apos;/^$/d;/^[ ]*#/d&apos; file 注意：编辑命令写在模式匹配之后，而不是在模式（即//）里面 10、获取光盘镜像文件中rpm的cpu架构（如x86_64）分别是多少 ls /misc/cd/Packages/| sed -r &apos;s/.*\.([^.]+)\.rpm/\1/&apos; |sort|uniq -c]]></content>
  </entry>
  <entry>
    <title><![CDATA[系统启动和内核管理（二）]]></title>
    <url>%2F2018%2F03%2F%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E5%92%8C%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[/proc目录内核相关参数通过配置参数通过proc伪文件系统加以输出 其配置保存在/etc/sysctl.conf net.ipv4.ip_forword=1，打开内核核心转发 kerenl.shmmax=687194767736，共享内存大小，默认为64G大小 vm.drop_caches=1，打开清理缓存 net.ipv4.icmp_echo_ignore_all，禁止ping 关于网络配置/proc/sys/net/ipv4/ /sys目录sysfs：为用户使用的伪文件系统，输出内核识别出的各硬件设备的相关属 性信息，也有内核对硬件特性的设定信息；有些参数是可以修改的，用于调整硬件 工作特性 udev通过此路径下输出的信息动态为各设备创建所需要设备文件，udev是 运行用户空间程序 专用工具：udevadmin, hotplug udev为设备创建设备文件时，会读取其事先定义好的规则文件，一般在 /etc/udev/rules.d及/usr/lib/udev/rules.d目录下 sysctl默认配置文件：/etc/sysctl.conf (1) 设置某参数 sysctl -w parameter=VALUE (2) 通过读取配置文件设置参数 sysctl -p [/path/to/conf_file] (3) 查看所有生效参数 sysctl -a 常用的几个参数： /sys net.ipv4.ip_forward net.ipv4.icmp_echo_ignore_all vm.drop_caches 内核模块存放位置/lib/modules/version/kernel或/lib/modules/uname -r/kernel 内核组成部分： kernel：内核核心，一般为bzImage，通常在/boot目录下 名称为 vmlinuz-VERSION-RELEASE kernel object：内核对象，一般放置于 /lib/modules/VERSION-RELEASE/ [ ]: N [M]: M [*]: Y 辅助文件： ramdisk initrd initramfs lsmod 查看加载的模块 modinfo 更详细的模块信息 uname -n: 显示节点名称 -r: 显示版本号 -a:显示所有信息 modinfo-a ；仅列出作者名称 -d : 仅列出modules的说明 -l : 仅列出授权 -n : 仅列出指定模块的详细路径 模块的加载与删除modprobe-l :列出当前系统中所有模块完整文件名 -c :列出所有模块 -f :强制加载模块 -r :删除指定模块 depmod命令：内核模块依赖关系文件及系统信息映射文件的生成工具 insmod命令：指定模块文件，不自动解决依赖模块insmod [ filename ] [ module options... ] insmod `modinfo –n exportfs` insmod `modinfo –n xfs` rmmod命令：卸载模块rmmod [ modulename ] rmmod xfs rmmod exportfs 内核编译1.开发环境准备 Development Tools 包 2. 获取目标主机上硬件设备的相关信息 lspci -v -vv lsusb -v -vv lsblk 3. 获取目标主机系统功能的相关信息 例如:需要启用相应的文件系统 4.获取内核源代码包 示例 ： tar xf linux-3.10.67.tar.xz -C /usr/src cd /usr/src ln -sv linux-3.10.67 linux cd /usr/src/linux cp /boot/config-$(uname -r) ./.config make menuconfig make -j 2 //CPu核心数 make modules_install make install reboot (1) 配置内核选项支持“更新”模式进行配置：make help (a) make config：基于命令行以遍历的方式配置内核中可配置的每个选项 (b) make menuconfig：基于curses的文本窗口界面 (c) make gconfig：基于GTK (GNOME）环境窗口界面 (d) make xconfig：基于QT(KDE)环境的窗口界面 支持“全新配置”模式进行配置 (a) make defconfig：基于内核为目标平台提供的“默认”配置进行配置 (b) make allyesconfig: 所有选项均回答为“yes“ (c) make allnoconfig: 所有选项均回答为“no“ 在已经执行过编译操作的内核源码树做重新编译 需要事先清理操作： make clean：清理大多数编译生成的文件，但会保留config文件等 make mrproper: 清理所有编译生成的文件、config及某些备份文件 make distclean：mrproper、清理patches以及编辑器备份文件 [root@centos6 ~]#cat /proc/sys/vm/drop_caches 0 #0代表保留缓存 [root@centos6 ~]#free -h #缓存有371M total used free shared buffers cached Mem: 1.4G 671M 776M 2.6M 35M 371M -/+ buffers/cache: 264M 1.2G Swap: 3.9G 0B 3.9G [root@centos6 ~]#cat /proc/sys/vm/drop_caches 1 [root@centos6 ~]#free -h #释放过之后只有54M total used free shared buffers cached Mem: 1.4G 316M 1.1G 2.6M 164K 54M -/+ buffers/cache: 261M 1.2G Swap: 3.9G 0B 3.9G]]></content>
      <categories>
        <category>linux</category>
        <category>base</category>
      </categories>
      <tags>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理三剑客之grep]]></title>
    <url>%2F2018%2F03%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bgrep%2F</url>
    <content type="text"><![CDATA[grepgrep: Global search REgular expression and Print out the line 作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行 模式：由正则表达式字符及文本字符所编写的过滤条件 用法： grep [OPTIONS] PATTERN [FILE...] grep root /etc/passwd grep &quot;$USER&quot; /etc/passwd grep &apos;$USER&apos; /etc/passwd grep `whoami` /etc/passwd 选项： --color=auto: 对匹配到的文本着色显示 -v: 显示不被pattern匹配到的行,取反 -i: 忽略字符大小写 -n：显示匹配的行号 -c: 统计匹配的行数 -o: 仅显示匹配到的字符串，字符会一个字符占用一行显示，排成一列 -q: 静默模式，不输出任何信息，用于设置密码 -A #: after, 后#行 -B #: before, 前#行 -C #：context, 前后各#行 -e：实现多个选项间的逻辑或关系 grep -e test1 -e test2 file 搜索既属于test1用户又属于test2用户的文件 -w：匹配整个单词 -E：使用ERE，相当于扩展正则表达式 -F：相当于fgrep，不支持正则表达式 查找1到100中包含9的数字 seq 100 |grep 9 |wc -l]]></content>
  </entry>
  <entry>
    <title><![CDATA[系统启动和内核管理（一）]]></title>
    <url>%2F2018%2F03%2F%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E5%92%8C%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Linux组成Linux: kernel+rootfs kernel: 进程管理、内存管理、网络管理、驱动程序、文件系统、安全功能 rootfs:程序和glibc(GNU发布的libc库，即c运行库) 库:函数集合，function,调用接口（头文件负责描述） 过程调用：procedure，无返回值 函数调用：function 程序：二进制执行文件 内核设计流派： 单内核(monolithic kernel)：Linux 把所有功能集成于同一个程序 微内核(micro kernel)：Windows, Solaris 每种功能使用一个单独子系统实现 内核Linux内核特点： 支持模块化：.ko（内核对象） 如：文件系统，硬件驱动，网络协议等 支持内核模块的动态装载和卸载 组成部分： 核心文件：/boot/vmlinuz-VERSION-release ramdisk：辅助的伪根系统 CentOS 5: /boot/initrd-VERSION-release.img CentOS 6,7: /boot/initramfs-VERSION-release.img 模块文件：/lib/modules/VERSION-release CentOS6启动流程 1.POST加电自检 完成对各硬件的情况的检测，并按照次序查找到的引导设备，第一次有引导程序的设备为本次启动设备 2.bootloader引导加载器 完成引导启动设备的引导选定的内核至内存空间中，并把系统控制权交给内核 BootLoader分类： LILO：linux loader GRUB：grand unified bootloader grub legacy grub 2 grub首先启动Stage1：mbr，之后加载stage1.5并加载其中启动/boot分区的驱动，之后启动stage2 3. kernel自身初始化： 1. 探测可识别的硬件信息 2. 加载驱动程序 3. 以只读的方式挂载根目录 4. 启动系统的第一个进程init或者systemd 4. Centos5 加载/etc/inittab下的默认的启动级别， Centos6加载/etc/inittab和/etc/init/*.conf 5. 启动rc.sysinit脚本 1. 设置主机名 2. 设置时钟 3. 加载udev和selinux 4. 挂载/etc/fstab定义的文件系统 5. 以读写的方式重新挂载根分区 6. 挂载swap分区 7. 设置定义在/etc/sysctl.conf中的参数 8. 激活lvm和raid设备 9. 加载额外的驱动 10. 后续的清理工作 6./sbin/init --&gt; (/etc/inittab) -&gt; 设置默认运行级别rc N -&gt; 运行系统初始脚本、完成系统初始化 -&gt; (关闭对应下需要关闭的服务)启动需要启动服务 -&gt; 设置登录终端 1.init程序的类型：SysV: init, CentOS 5之前 配置文件：/etc/inittab Upstart: init,CentOS 6 配置文件：/etc/inittab, /etc/init/*.conf Systemd：systemd, CentOS 7 配置文件：/usr/lib/systemd/system /etc/systemd/system 2./sbin/init （CentOS6之前），之后 /etc/inittab运行级别：为系统运行或维护等目的而设定；0-6：7个级别 0：关机 1：单用户模式(root自动登录), single, 维护模式 2: 多用户模式，启动网络功能，但不会启动NFS；维护模式 3：多用户模式，正常模式；文本界面 4：预留级别；可同3级别 5：多用户模式，正常模式；图形界面 6：重启 默认级别：3, 5 切换级别：init # 查看级别：runlevel ; who -r 3.rc N –&gt; 意味着读取/etc/rc.d/rcN.d/ 实际上为软连接K*: K##*：##运行次序；数字越小，越先运行；数字越小的服务，通常为 依赖到别的服务 S*: S##*：##运行次序；数字越小，越先运行；数字越小的服务，通常为 被依赖到的服务 服务脚本定义在/etc/init.d下 123456789101112131415161718192021222324252627#!/bin/bash## chkconfig:LLLL nn nn# Description:. /etc/inid/functionscase $1 in start) touch /var/lock/subsys/ action "starting ..." ;;stop) rm -f /var/lock/subsys/ action "stopping..." ;;status) if [ -f /var/lock/subsys ] then echo "is running..." else echo "is stopped" fi ;;restart) ;;*) echo "Usage $0 &#123;start|stop|restart|status&#125;"esac 注意：正常级别下，最后启动一个服务S99local没有链接至/etc/rc.d/init.d一个服务脚本，而是指向了/etc/rc.d/rc.local脚本，因此，不便或不需写为脚本放置于/etc/rc.d/init.d，且又想开机时自动运行的命令，可直接放置于/etc/rc.d/rc.local中chkconfig --list xinetd管理的服务service 命令：手动管理服务 service 服务 start|stop|restart service --status-all 瞬态（Transient）服务被xinetd进程所管理 进入的请求首先被xinetd代理 配置文件：/etc/xinetd.conf、/etc/xinetd.d/&lt;service&gt; 与libwrap.so文件链接 用chkconfig控制的服务： 示例：chkconfig tftp on ramdisk内核中的特性之一：使用缓冲和缓存来加速对磁盘上的文件访问，并加载相应的硬件驱动 ramdisk --&gt; ramfs 提高速度 CentOS 5: initrd 工具程序：mkinitrd CentOS 6，7: initramfs 工具程序：mkinitrd, dracut (1) mkinitrd命令 mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) (2) dracut命令 dracut /boot/initramfs-$(uname -r).img $(uname -r) chkconfig 列出当前系统的服务的运行级别chkconfig [--level levels] name &lt;on|off|rest&gt; --level llll：默认值为2345 chkconfig --level 35 dhcpd on chkconfig --add atd on 加入开机自动启动 chkconfig --del name 删除 ntsysvntsysz命令以图形化的形式，设定服务在当前模式下是否启动 光标在服务名字上，space可以添加*为开机启动 tab键退出确定 自制linux系统1. 准备一个空闲硬盘，分区并创建文件系统 挂载 fdisk /dev/sdb /dev/sdb1对应/boot /dev/sdb2对应根 / mkfs.ext4 /dev/sdb1 mkfs.ext4 /dev/sdb2 mount /dev/sdb1 /mnt/boot 子目录必须为boot mount /dev/sda2 /mnt/sysroot 2.安装grub grub-install --root-directory=/mnt /dev/sdb 3.复制现有的内核文件和现有的initramfs至根目录所在的分区 cp /boot/vmlinuz-2.6.32-642.el6.x86_64 /mnt/boot/ cp /boot/initramfs-2.6.32-642.el6.x86_64.img /mnt/boot 4. 创建根目录所需要的目录结构 mkdir -pv /mnt/sysroot/{tmp,root,proc,bin,sbin,root,sys,lib,lib64,usr/{bin,sbin},media,mnt} 5. 创建启动grub.conf文件 6. 复制所需的二进制文件 cpcmd.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#!/bin/bash#Auther: CaiJingshui Yanghao Zhaowenguang#Descript: copy command and it's dependents to a directory#Usage: cpcmd.sh [CMD] [PATH]#Contact: shuinoo@163.com tuduo204306@163.com wenguang612@sohu.com################################################################### 变量声明 ##如果用户没有输入目标路径，将使用如下路径DIR=/mnt/tmp# 函数 #. /etc/init.d/functions#复制命令cpcmd()&#123;cmdpath=$2$(dirname `which --skip-alias $1`)[ -d $cmdpath ] || mkdir -p $cmdpathcp -a `which --skip-alias $1` $cmdpathaction "$1 finish copy" true&#125;#复制库cplib()&#123; libs=$(ldd `which --skip-alias $1`| egrep -o "/[^ ]+") for i in $libs;do libpath=`dirname $i` [ -d $2$libpath ] || mkdir -p $2$libpath cp $i $&#123;2&#125;$&#123;libpath&#125; doneaction "$1's dependent libs finish copy" true&#125;# 主体部分 ##判断是否是管理员[ $UID -ne 0 ] &amp;&amp; &#123; echo "Pls runas root user"; exit; &#125;#如果命令行没有传参，提示用户重新输入flag=0while [ $flag -ne 1 ]; do if [ $# -eq 2 ];then which --skip-alias $1 &amp;&gt;/dev/null [ $? -ne 0 ] &amp;&amp; &#123; echo -e "\033[1;33mUsage: $0 [CMD] [PATH]\033[0m";exit 1; &#125; cmd=$1 path=$2 flag=1 else #1.提示用户输入命令名 while : ; do read -p "ESC[1;32m请输入需要拷贝的命令(quit退出)ESC[0m " cmd #判断用户输入的是否是quit，是则退出 tmp=$&#123;cmd^^&#125; [ "$tmp" == "QUIT" ] &amp;&amp; exit which --skip-alias $cmd &amp;&gt;/dev/null [ $? -eq 0 ] &amp;&amp; break echo -e "\a\033[1;31m输入的命令名不正确，或者输入了多个命令名，请重新输入一个命令名\033[0m" done #2.提示用户输入目标路径 read -p "ESC[1;32m请输入需要拷贝的目标路径:ESC[0m " path path=$&#123;path:=$DIR&#125; [ -d $path ] || mkdir -p $path fi #3.拷贝命令到指定目录 cpcmd $cmd $path #4.拷贝函数到指定目录 cplib $cmd $pathdone]]></content>
      <categories>
        <category>linux</category>
        <category>base</category>
      </categories>
      <tags>
        <tag>内核 启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7-启动与管理]]></title>
    <url>%2F2018%2F03%2FCentos7-%E5%90%AF%E5%8A%A8%E4%B8%8E%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[centos7启动流程1. POST加点自检 2. 选择启动设备 3. 引导加载器，默认为grub2 /etc/grub.d/* /boot/grub2/grub2.cfg /etc/grub.conf 4. 加载initramfs 5. 加载内核选项 6. 内核初始化，启动系统第一个进程systemd 7. 执行initrd.target所有单元 8. 从initramfs根目录切换至磁盘根目录 9. systemd执行默认target配置，配置文件/etc/systemd/system/default.target 10. systemd执行sysinit.target初始化系统及basic.target准备操作系统 11. systemd执行sysinit.target初始化系统及basic.target准备操作系统 12. systemd启动multi-user.target下的本机与服务器服务 13. systemd执行multi-user.target下的/etc/rc.d/rc.local 14. Systemd执行multi-user.target下的getty.target及登录服务 systemd配置文件：/usr/lib/systemd/system和/etc/systemd/system Unit类型 service unit 文件扩展名为.service, 用于定义系统服务 Target unit 文件扩展名为.target，用于模拟实现运行级别 Device unit 用于定义内核识别的设备 Socket unit 用于标识进程间通信用的socket文件，也可在系统启动时，延迟启动服务，实现按需启动 Mount unit 定义文件系统挂载点 挂起：systemctl suspend 休眠：systemctl hibernate 休眠并挂起：systemctl hybrid-sleep 启动 systemctl start 停止 systemctl stop 重启 systemctl restart 状态 systemctl status 重载 systemctl reload 紧急救援 systemctl rescue emergency模式 systemctl emergency 禁止自动和手动启动 systemctl mask 取消禁止 systemctl unmask 禁止开机自动启动 systemctl disable 开机自启 systemctl enable 查看所有服务 systemctl list-units -t service 只显示服务单元的状态 systemctl –type=service 查看服务是否已经激活 systemctl is-active 查看服务是否已经开机自启 systemctl is-enable 设置开机级别 systemctl set-default *.target 查看开机级别 systemctl get-default *.target 查看服务的依赖关系 systemctl list-dependencies name.service service文件的格式 [unit] Description=系统服务的描述信息 After=启动该服务，需要先启动什么服务 [Service] Type=该服务启动的类型 simple：启动后常驻内存 forking：启动在后台 oneshot：服务启动完就结束，不会常驻内存 d-bus：取得一个D-Bus的名称后，才会继续运作.因此通常也要同时设定BusNname= notify：启动完成后会发送一个通知消息 idle：启动该服务要所有的工作都顺利执行完毕后才会执行 EvironmentFile：环境配置文件 ExecStart：启动该服务的二进制程序的绝对路径 ExecStop：停止该服务的二进制程序的绝对路径 ExecRestart：重启该服务的二进制程序的绝对路径 ExecReload：重载该服务的二进制程序的绝对路径 [Install] Alias：别名，可使用systemctl command Alias.service RequiredBy：被哪些units所依赖，强依赖 WantedBy：被哪些units所依赖，弱依赖 Also：安装本服务的时候还要安装别的相关服务 运行级别0 ==&gt; runlevel0.target, poweroff.target 1 ==&gt; runlevel1.target, rescue.target 2，3，4 ==&gt; runlevel2.target, multi-user.target 5 ==&gt; runlevel5.target, graphical.target 6 ==&gt; runlevel6.target, reboot.target 查看依赖性： systemctl list-dependencies graphical.target 级别切换：init N ==&gt; systemctl isolate name.target systemctl isolate multi-user.target 注：只有/lib/systemd/system/*.target文件中AllowIsolate=yes 才能切换(修改文件需执行systemctl daemon-reload才能生效) 设置内核参数只影响当次启动 启动时，在linux16行后添加systemd.unit=desired.target systemd.unit=emergency.target systemd.unit=rescue.target rescue.target 比emergency 支持更多的功能，例如日志等 systemctl default 进入默认target 破解root口令启动时任意键暂停启动 按e键进入编辑模式 将光标移动linux16开始的行，添加内核参数 init=/bin/bash rw 按crtl +x echo 密码 | pwsswd --stdin root touch /.autorelabel exec /sbin/init reboot 修复GRUB2GRUB“the Grand Unified Bootloader” 引导提示时可以使用命令行界面 grub&gt; insmod xfs grub&gt; set root=(hd0,msdos1) （----&gt; 这个为你上一步中找到的boot分区） grub&gt; linux16 /vmlinuz-xxxxx root=/dev/mapper/centos-root grub&gt; initrd16 /initramfs-.xxxxx.img grub&gt; boot 主要配置文件 /boot/grub2/grub.cfg 修复配置文件 grub2-mkconfig &gt; /boot/grub2/grub.cfg grub2-o mkconfi -o /boot/grub2/grub.cfg 于上一条命令等价 修复grub grub2-install /dev/sda BIOS环境 grub2-install UEFI环境 调整默认启动内核 vim /etc/default/grub GRUB_DEFAULT=0]]></content>
      <categories>
        <category>linux</category>
        <category>linux base</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件查找和压缩]]></title>
    <url>%2F2018%2F03%2F%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%92%8C%E5%8E%8B%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[文件查找在文件系统上查找符合条件的文件 文件查找：locate，find 非实时查找（数据库查找）：locate 实时查找：find locate查询系统上预建的文件索引数据库 /var/lib/mlocate.db 依赖于实现构建的索引 索引的构建是在系统较为空闲时自动进行（周期性任务）,手动更新数据库 updatedb 索引构建过程需要遍历整个根文件系统，极消耗资源 工作特点: 查找速度快 模糊查找 非实时查找 搜索的是文件的全路径，不仅仅是文件名 可能只搜索用户具备读取和执行权限的目录 用法：locate keyword 常用选项： -i 不区分大小写的搜索 -n N 只列举前N个匹配项目 -r 使用正则表达式 示例： 搜索名称或路径中带有“conf”的文件 locate conf 使用Regex来搜索以“.conf”结尾的文件 locate -r &apos;&apos;\.conf$&apos; find实时查找工具，通过遍历指定路径完成文件查找 工作特点： 查找速度略慢 精确查找 实时查找 可能只搜索用户具备读取和执行权限的目录 语法：find [OPTION]... [查找路径] [查找条件] [处理动作] 查找路径：指定具体目标路径；默认为当前目录 查找条件：指定的查找标准，可以文件名、大小、类型、权限等标准进行 默认为找出指定路径下的所有文件 处理动作：对符合条件的文件做操作，默认输出至屏幕 查找条件： 1)指搜索层级： -maxdepth # 最大搜索目录深度#级 -mindepth level 最小搜索目录深度#级 先处理目录内的文件，再处理目录 -depth 2)根据文件名和inode查找 -name &quot;文件名称&quot;：支持使用glob *, ?, [], [^] -iname &quot;文件名称&quot;：不区分字母大小写 -inum n 按inode号查找 -samefile name 相同inode号的文件 -links n 链接数为n的文件 -regex “PATTERN”：以PATTERN匹配整个文件路径，而非文件名称 3)根据属主、属组查找 -user USERNAME：查找属主为指定用户(UID)的文件 -group GRPNAME: 查找属组为指定组(GID)的文件 -uid UserID：查找属主为指定的UID号的文件 -gid GroupID：查找属组为指定的GID号的文件 -nouser：查找没有属主的文件 -nogroup：查找没有属组的文件 4)根据文件类型查 -type TYPE:文件类型 -empty 空文件或目录 find /app -type d -empty 与：-a 或：-o 非：-not, ! 示例： !A -a !B = !(A -o B) !A -o !B = !(A -a B) find / -user joe -o -uid 500 find /tmp -not \( -user root -o -name &apos;f*&apos; \) 5)根据文件大小来查 -size 常用单位：k, M, G，c（byte） #UNIT: (#-1, #] 如：6k 表示(5k,6k] -#UNIT：[0,#-1] 如：-6k 表示[0,5k] +#UNIT：(#,∞) 如：+6k 表示(6k,∞) 6)根据时间 以“天”为单位 -atime #: [#,#+1) +#: [#+1,∞] -#: [0,#) -mtime -ctime 以“分钟”为单位 -amin -mmin -cmin 7)根据权限查 -perm # 精确匹配 /# 任何一个匹配 -#：每一类对象都必须同时拥有指定权限，与关系 0 表示不关注 find -perm 755 会匹配权限模式恰好是755的文件 • 只有当每个人都有写权限时，find -perm -222才会匹配 只有当其它人（other）有写权限时，find -perm -002才会匹配 8)处理动作 -print：默认的处理动作，显示至屏幕 -ls：类似于对查找到的文件执行“ls -l”命令 -delete：删除查找到的文件 -fls file：查找到的所有文件的长格式信息保存至指定文件中 -ok CMD {} \;要求用户确认 -exec CMD {} \; 不用确认 例： 查找/data下的权限为644，后缀为sh的普通文件，增加执行权限 find /data –type f -perm 644 -name &quot;*.sh&quot; –exec chmod 755 {} \; 9)参数替换xargs 由于很多命令不支持管道|来传递参数，而日常工作中有这个必要，所以就有了xargs命令 xargs用于产生某个命令的参数，xargs可以读入stdin的数据，并且以空格符或回车符将stdin的数据分隔成为arguments 注意：文件名或者是其他意义的名词内含有空格符的情况 有些命令不能接受过多参数，命令执行可能会失败，xargs可以解决 压缩、解压缩及归档工具注意：打包和压缩不是同一个概念 打包相当于将许多文件放在一个目录中，并没有对文件进行压缩，压缩比很低，几乎没有 压缩是将文件中相同字节进行压缩。文件大小会发生很大变化，如：etc.tar.gz 该文件是打包(tar后缀)并压缩的文件(gz后缀) zcat：不显式解压缩的前提下查看文本文件内容 file-roller是一种图形化压缩工具，在命令行界面写入该命令即可使用，该工具并不常用，再次不多做介绍 compress/uncompress压缩文件，会删除原来文件，生成压缩文件 格式：.Z -d: 解压缩，会删除压缩文件，相当于uncompress -c: 结果输出至标准输出,不删除原文件 -v: 显示详情 -f：强制压缩，默认不对硬链接数为2及以上的文件压缩，而其他同inode的文件硬链接数减1 uncompress 解压缩 zcat file.Z &gt;file 解压缩文件重定向到指定文件，不删除原文件，但因为&gt;生成新文件，权限会变 gzip/gunzip压缩文件，会删除原来文件，生成压缩文件 格式：.gz -d 解压文件，会删除压缩文件，和gunzip相同 -c: 结果输出至标准输出,不删除原文件 -f：强制压缩 -v: 显示详情 -#：1-9 指定压缩比 值越大压缩比越大，速度越慢，文件越小，默认为6 zcat X.gz &gt; X 解压缩文件重定向到指定文件，不删除原文件 gzip -c messages &gt;messages.gz cat messages | gzip &gt; m.gz bzip2格式：.bz2 压缩文件，会删除原来文件，生成压缩文件 -k：keep, 保留原文件 -d：解压缩 -v: 显示详情 -#：1-9 压缩比，数字越大，压缩比越高，速度越慢，文件越小， 默认为9 bzcat：不显式解压缩的前提下查看文本文件内容 xz/unxz压缩文件，会删除原来文件，生成压缩文件 格式：.xz -k: keep, 保留原文件 -d：解压缩 -#：1-9 压缩比 ，数字越大，压缩比越高，速度越慢，文件越小默认为6 xzcat: 不显式解压缩的前提下查看文本文件内容 注意：可以将一个命令的执行结果进行压缩并重定向到其他文件，gzip，bzip2，xz都支持这种写法 如果压缩命令后面不跟文件名，可以把标准输入压缩并传给标准输出(即可以重定向到其他文件 cat /etc/fstab | gzip &gt;fstab.gz 比较:压缩比：xz &gt; bzip2 &gt; gzip &gt; compress（不一定，有的情况bzip2 比xz要好） xz 压缩比最大，文件最小 zip/unzip打包压缩(自动生成后缀.zip) zip –r 生成文件(自动生成.zip) 打包文件(目录，普通文件都行) 例：zip -r f1.zip f1 压缩f1 解包解压缩 unzip -p 仅显示不解压 例： cat /var/log/messages | zip messages - unzip -p messages.zip &gt; message tar-c: 建立压缩档案 -x：解压 -t：查看内容 -r：向压缩归档文件末尾追加文件 -u：更新原压缩包中的文件 这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。 -z：有gzip属性的 -j：有bz2属性的 -Z：有compress属性的 -v：显示所有过程 -O：将文件解开到标准输出 下面的参数-f是必须的 -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。 -T 指定个列表，包含需要被打包的文件，以换行符为间隔 -X 指定个排除列表，以换行符为间隔 例： 1.创建归档 tar -cpvf /data/f1.tar file 2.追加文件至归档： 注：不支持对压缩文件追加 tar -rf /data/f1.tar file 3.查看归档文件中的文件列表 tar -tf /data/f1.tar 4.展开归档 tar -xf /data/f1.tar tar -xf /data/f1.tar -C /PATH/ 5.-exclude 排除文件 tar zcvf /root/a3.tgz --exclude=/app/1 --exclude=/app/2 /app 6.-T选项指定输入文件,-X选项指定包含要排除的文件列表 用法：可以将指定输入以及要排除的文件复制到文件中，然后分别制定即可 tar zcvf backup.tar.gz -T /root/inlist -X /root/exlist 压缩 1.tar -cvf jpg.tar *.jpg 将目录里所有jpg文件打包成jpg.tar 2.tar -czf jpg.tar.gz *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包 3.tar -cjf jpg.tar.bz2 *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包 4.tar -cZf jpg.tar.Z *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包 5.rar a jpg.rar *.jpg rar格式的压缩，需要先下载rar for linux 6.zip jpg.zip *.jpg zip格式的压缩，需要先下载zip for linux 解压 1.tar -xvf file.tar 解压 tar包 2.tar -xzvf file.tar.gz 解压tar.gz 3.tar -xjvf file.tar.bz2 解压 tar.bz2 4.tar -xZvf file.tar.Z 解压tar.Z 5.unrar e file.rar 解压rar 6.unzip file.zip 解压zip splistsplist:：分割一个文件为多个文件 分割大的tar 文件为多份小文件 split –b Size –d tar-file-name prefix-name split -b 1M –d bak.tgz bak-parts split -b 1M bak.tgz bak-parts 合并： cat 被分隔出的多个文件名 &gt; 单个文件名 cat bak-parts* &gt; bak.tar.gz 注意：-b 文件切割后，后缀自动跟字母（a-z）后缀 -b -d 文件切割后，后缀自动跟数字后缀 cpio复制文件从或到归档，此选项不常用 cpio通过重定向将文件进行打包备份、还原恢复、可以解压以&quot;.cpio&quot;或者&quot;.tar&quot;结尾的文件 cpio [选项] &gt; 文件名或者设备名 cpio [选项] &lt; 文件名或者设备名 -o 将文件拷贝打包成文件或者将文件输出到设备上 -O filename 输出到指定的归档文件名 -A 向已存在的归档文件中追加文件 -i 解包 将打包文件解压或将设备上的备份还原到系统 -I filename 对指定的归档文件名解压 -t 预览 查看文件内容或者输出到设备上的文件内容 -F filename 使用指定的文件名替代标准输入或输出 -d 解包生成目录 在cpio还原时 自动的建立目录 -v 显示打包过程中的文件名称 例： 将etc目录备份： find ./etc -print |cpio -ov &gt;bak.cpio 将/data内容追加bak.cpio find /data | cpio -oA -F bak.cpio 内容预览 cpio –tv &lt; etc.cpio 解包文件 cpio –idv &lt; etc.cpio 总结1、*.tar 用 tar -xvf 解压 2、*.gz 用 gzip -d或者gunzip 解压 3、*.tar.gz和*.tgz 用 tar -xzf 解压 4、*.bz2 用 bzip2 -d或者用bunzip2 解压 5、*.tar.bz2用tar -xjf 解压 6、*.Z 用 uncompress 解压 7、*.tar.Z 用tar -xZf 解压 8、*.rar 用 unrar e解压 9、*.zip 用 unzip 解压]]></content>
  </entry>
  <entry>
    <title><![CDATA[文件管理]]></title>
    <url>%2F2018%2F03%2F%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[文件系统文件和目录被组织成一个单根倒置树结构 文件系统从根目录下开始，用“/”表示 根文件系统(rootfs)：root filesystem 文件名称区分大小写 以.开头的文件为隐藏文件 路径分隔的 / 文件有两类数据： 元数据：metadata (数据的属性、inode信息) 数据：data 文件系统分层结构：LSB Linux Standard Base FHS: (Filesystem Hierarchy Standard) 文件系统层次化标准，多数Linux版本采用这种文件组织形式，类似于Windows操作系统中c盘的文件目录，FHS采用树形结构组织文件。 FHS定义了系统中每个区域的用途、所需要的最小构成的文件和目录 文件名规则文件名最长255个字节 包括路径在内文件名称最长4095个字节 蓝色--&gt;目录 绿色--&gt;可执行文件 红色--&gt;压缩文件 浅蓝色--&gt;链接文件 灰色--&gt;其他文件 除了斜杠和NUL,所有字符都有效.但使用特殊字符的目录名和文件不推荐使用，有些字符需要用引号来引用它们。 注意： Linux系统中文件名称是否区分大小写与文件系统有关，linux下文件系统有ext4，xfs，vfat等。 标准Linux文件系统（如ext4），文件名称区分大小写。例如：MAIL, Mail, mail, mAiL。但vfat文件系统则不区分大小写 文件系统结构 /boot：引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录 /bin：供所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序 /sbin：管理类的基本命令；不能关联至独立分区，OS启动即会用到的程序 /lib：启动时程序依赖的基本共享库文件以及内核模块文件(/lib/modules /lib64：专用于x86_64系统上的辅助共享库文件存放位置 /etc：配置文件目录 /home/USERNAME：普通用户家目录 /root：管理员的家目录 /media：便携式移动设备挂载点 /mnt：临时文件系统挂载点 /dev：设备文件及特殊文件存储位置 b: block device，随机访问 c: character device，线性访问 /opt：第三方应用程序的安装位置 /srv：系统上运行的服务用到的数据 /tmp：临时文件存储位置 /proc: 用于输出内核与进程信息相关的虚拟文件系统 /sys：用于输出当前系统上硬件设备相关信息虚拟文件系统 /var: variable data files 可变数据的存储位置 cache: 应用程序缓存数据目录 lib: 应用程序状态信息数据 local：专用于为/usr/local下的应用程序存储可变数据； lock: 锁文件 log: 日志目录及文件 opt: 专用于为/opt下的应用程序存储可变数据； run: 运行中的进程相关数据,通常用于存储进程pid文件 spool: 应用程序数据池 tmp: 保存系统两次重启之间产生的临时数据 /usr: universal shared, read-only data 共享只读文件 bin: 保证系统拥有完整功能而提供的应用程序 sbin: 超级用户的一些管理程序 lib： 32位使用 lib64：只存在64位系统 include: C程序的头文件(header files) share：结构化独立的数据，例如doc, man等 local：第三方应用程序的安装位置 bin, sbin, lib, lib64, etc, share /misc：自动挂载光盘，该目录与autofs服务有关。 一般情况下，系统镜像在系统启动以后会挂载到/media（centos6）或/run（centos7）目录下，但在启动autofs服务之后，镜像文件也会自动挂载到该目录下，即/misc/cd目录。 linux上的应用程序的组成部分二进制程序：/bin, /sbin, /usr/bin, /usr/sbin, /usr/local/bin, /usr/local/sbin 库文件：/lib, /lib64, /usr/lib, /usr/lib64, /usr/local/lib, /usr/local/lib64 配置文件：/etc, /etc/DIRECTORY, /usr/local/etc 帮助文件：/usr/share/man, /usr/share/doc, /usr/local/share/man, /usr/local/share/doc 文件类型普通文件(f)：C语言元代码、SHELL脚本、二进制的可执行文件等。分为纯文本和二进制。 目录文件(d)：目录，存储文件的唯一地方。 链接文件(l)：指向同一个文件或目录的的文件。 设备文件：分为块设备(b)和字符设备(c)。 块设备文件不会显示文件大小，而是在同样的位置显示设备号,主设备号为第一列数字8，次设备号为第二列数字0-5 管道文件(p): 提供进程之间通信的一种方式 套接字(socket) 文件： 该文件类型与网络通信有关 可以通过ls –l, file, stat几个命令来查看文件的类型等相关信息 显示当前工作目录每个shell和系统进程都有一个当前的工作目录 CWD:current work directory 显示当前shell CWD的绝对路径 pwd: printing working directory -P 显示真实物理路径 -L 显示链接路径（默认） 绝对和相对路径绝对路径 以正斜杠开始 完整的文件的位置路径 可用于任何想指定一个文件名的时候 相对路径名 不以斜线开始 指定相对于当前工作目录或某目录的位置 可以作为一个简短的形式指定一个文件名 基名:basename 是指路径中最后一个/后的内容 目录名:dirname 是指路径中最后一个/前的内容 更改(切换)目录cd：change directory 改变目录 cd .：当前目录 cd或cd ~：回到当前用户家目录 cd ..：回到上一级目录即父目录 cd -：回到上一次离开的目录 与cd相关环境变量 PWD：当前目录路径 OLDPWD：上一次目录路径 &quot;cd -&quot;的原理：与OLDPWD变量有关，当目录切换时，会将上一次目录路径记录到OLDPWD变量，当使用cd -时，调用该变量即可 文件通配符* 匹配零个或多个字符 ？ 匹配任何单个字符 ~ 当前用户家目录，如：cd ~，切换到用户家目录 ~+ 当前工作目录 ~- 前一个工作目录 [0-9] 匹配数字范围 [a-z] 匹配小写字母 [A-Z] 匹配大写字母 [wang] 匹配列表中（wang）任何一个字符 [^wang] 匹配列表（wang）中的所有字符以外的字符 预定义的字符类： 查看man帮助：man 7 glob [:digit:]：任意数字，相当于0-9。 因此[:digit:]需再加[]即[[:digit:]]才相当于[0-9]，其他通配符与此类似 [:lower:]：任意小写字母 [:alnum:]：任意数字或字母 [:blank:]：水平空白字符 [:space:]：水平或垂直空白字符 [:punct:]：标点符号 [:print:]：可打印字符 [:cntrl:]：控制（非打印）字符 [:graph:]：图形字符 [:xdigit:]：十六进制字符 管理命令cdcd .. 切换至上级目录 cd 切换至当前用户主目录 cd - 切换至以前的工作目录 -P 物理真实路径 当前路径和上一个路径保存在这两个变量中 [root@Web ~]# echo $PWD [root@Web ~]# echo $OLDPWD /home/han /root返回到其他用户的主目录 [root@Web ~]# cd ~han ls用法： ls [options] [files_or_dirs] list 列出文件夹中的内容 文件 文件夹 -a 列出目录中全部文件和目录 包括隐藏文件 -l 长格式显示 -R 递归显示 -d 只显示目录本身一些属性 –S 按从大到小排序 –t 按mtime排序 –u 配合-t选项，显示并按atime从新到旧排序 –U 按目录存放顺序显示 –X 按文件后缀排序 -r 逆序排序输出 mkdir-p, --parents 需要时创建目标目录的上层目录， -v, --verbose 每次创建新目录都显示信息 rmdir只能删除空文件夹 -p, --parents 删除指定目录及其上级文件夹 -v, --verbose 输出处理的目录详情 -m MODE: 创建目录时直接指定权限 tree-d: 只显示目录 -L level：指定显示的层级数目 -P pattern: 只显示由指定pattern匹配到的路径 stat查看文件状态 三个时间戳： atime：Access time，访问时间，读取文件内容 mtime：Modify time，修改时间，改变文件内容 ctime：Change time，改变时间，元数据发生改变 数据分为两部分：元数据（metadata），数据（data） 元数据是指数据本身所包含的属性信息，如：大小、权限、存储位置、历史记录、所有者等 数据是指数据内容 touch当文件不存在时，创建新文件；当文件存在时，刷新该文件的访问时间 -a 仅改变 atime和ctime -m 仅改变 mtime和ctime -t [[CC]YY]MMDDhhmm[.ss] 指定atime和mtime的时间戳 -c 如果文件不存在，则不予创建 touch -- -a == touch /data/-a touch ~a rm删除 -i 交互式 -f 强制删除 -r 递归 rm -- -a == rm ./-a mv移动和重命名文件 -i: 交互式 -f: 强制 -b: 目标存在，覆盖前先备份 file文件可以包含多种类型的数据 检查文件的类型，然后确定适当的打开命令或应用程序使用 语法：file [options] ... -b 列出文件辨识结果时，不显示文件名称 -f filelist 列出文件filelist中文件名的文件类型 -F 使用指定分隔符号替换输出文件名后默认的”:”分隔符 -L 查看对应软链接对应文件的文件类型 mktemp创建临时文件或目录 mktemp [option] fileXXX 生成随机字符文件，随机X最少个数为3个 -d: 创建临时目录 -p DIR或--tmpdir=DIR：指明临时文件所存放目录位置 install安装复制文件 install [option] src dest [option] -m 权限 -o 所有者 -g 所有组 -d 目录 示例： install -m 600 -osss -gaaa /etc/fstab /tmp/file 结果： 1. 复制/etc/fstab到/tmp/并改名为file 2. 把该文件的权限改为600 3. 把该文件的所有者改为sss，所属组改为aaa cpcp SRC DEST SRC是文件： 如果目标不存在：新建DEST，并将SRC中内容填充至DEST中 如果目标存在： 如果DEST是文件：将SRC中的内容覆盖至DEST中 基于安全，建议为cp命令使用-i选项 如果DEST是目录：在DEST下新建与原文件同名的文件，并将SRC中内容填充至新文件中 cp SRC... DEST SRC...：多个文件 DEST必须存在，且为目录，其它情形均会出错； cp SRC DEST SRC是目录：此时使用选项：-r 如果DEST不存在：则创建指定目录，复制SRC目录中所有文件至DEST中； 如果DEST存在： 如果DEST是文件：报错 如果DEST是目录： -a：复制文件所有属性，相当于-dR --preserv=all -d：--no-dereference --preserv=links 不复制原文件，只复制链接名，该命令针对链接文件。 -i：覆盖前提示 -n：不覆盖，注意两者顺序 -r，-R：递归复制目录及内部的所有内容，针对于目录中存在目录或文件。 -p --preserv[=ATTR_LIST] 复制文件时，指定复制的属性（权限） mode: 权限 ownership: 属主属组 timestamp: links xattr context all -v：--verbose复制时显示详细过程 -f：--force，强行复制文件或目录，不论目标文件或目录是否已存在 -u：只复制发生变化的文件，文件更新时使用 -s：对源文件建立符号连接，而非复制文件 -l：对源文件建立硬连接，而非复制文件 --backup=numbered 目标存在，覆盖前先备份，并且本分文件加数字后缀 示例：1、rename 批量更改文件 touch f{1..10}.txt rename &apos;txt&apos; &apos;txt.bak&apos; *.txt 把txt后缀批量修改为txt.bak rename &apos;.bak&apos; &apos;&apos; *.bak 把.bak后缀删除 2、如何立即删除大文件。 当删除一个文件bigfile时，该文件正在被访问，使用rm删除该文件后，该文件占用的空间不会被立即释放，需要等待一段时间后才会释放空间。 解决方法：&gt; bigfile 将bigfile文件内容清0 rm -f bigfile 再rm删除big文件 3.给屏幕录像： 开始：script -t 2&gt; time.log -a cmd.session 结束：exit 播放：scriptreplay time.log cmd.session 超级块(Superblock)1.整个文件系统的第一块空间。包括整个文件系统的基本信息 2.块大小，inode/block的总量、使用量、剩余量，指向空间inode和数据块的指针等相关信息 3.一个文件系统由一个超级块、inode和数据区域块组成。Inode包含文件的属性(如读写属性、owner等，以及指向数据块的指针)，数据区域块则是文件内容。 当查看某个文件时，会先从inode table中查出文件属性及数据存放点，再从数据块中读取数据 索引节点具体概念 inode（index node）表中包含文件系统所有文件列表，文件系统索引,记录文件的属性 1.它是文件系统的最基本单元，是文件系统连接任何子目录、任何文件的桥梁。每个子目录和文件只有唯一的一个 inode 块。 2.它包含了文件系统中文件的基本属性(文件的长度、创建及修改时间、权限、所属关系)、存放数据的位置等相关信息.,一般是128字节或256字节 3.硬连接和源文件具有相同的 inode 4.mv或rename文件，只是改变文件名，不影响inode号码 5.更后文件同样的文件名，生成新的inode，下次运行，文件名就自动指向新文件，旧文件的inode被回收 inode表运行原理： inode表中存储内容：元数据、直接指针（ext系统结构有12个直接指针）、间接指针（双重间接指针、三重间接指针） inode表中的直接指针和间接指针指向数据块，每个直接指针指向一个数据块，每个数据块大小4K，那么直接指针能够寻找的数据块大小只有48K。 当继续存储数据时，48K空间被占用完后，若想要继续存储数据，就需要使用到双重间接块指针，间接指针指向一个数据块，该数据块是一个指针块，不存储数据，被分割成若干小块，每个小块大小4个字节（byte），那么共有1024个小块。每个小块又将指针指向磁盘中存储数据的数据块，那么该数据块能够存储的数据大小为4k*1024=4M。 当4M空间被占用完以后，若想要再存储数据，就要使用三重间接块指针，按照以上运行原理，可存储数据空间为4T。 如何访问目录、文件： 首先，查询目录、文件的节点编号 然后根据节点编号找到inode表中对应的inode信息， 最后，根据inode信息找到指针指向的数据块（block），该数据块指向存放该文件的磁盘路径。 ls -i 查看inode节点编号 不同分区的节点编号一样 不同分区节点编号即使一致，也不是同一个文件 同一个分区中，节点编号一致，就是同一个文件 提示no space left on device，可能节点编号inode被用完 cp、rm、mv和inodecp命令： 分配一个空闲的inode号，在inode表中生成新条目 在目录中创建一个目录项，将名称与inode编号关联 拷贝数据生成新的文件 rm 命令： 目录链接数递减，从而释放的inode号可以被重用 把数据块放在空闲列表中 删除目录项 数据实际上不会马上被删除，但当另一个文件使用数据块时将被覆盖。 mv命令 mv命令的目标和源在相同的文件系统 用新的文件名创建对应新的目录项 删除旧目录条目对应的旧的文件名 不影响inode表（除时间戳）或磁盘上的数据位置：没有数据被移动！ 如果目标和源在一个不同的文件系统， mv相当于cp和rm 软和硬链接硬连接： 原文件名和连接文件名都指向相同的物理地址。 1)目录不能有硬连接； 2)硬连接不能跨越文件系统（不能跨越不同的分区） 3)不能对不存在的文件创建硬链接 4)文件在磁盘中只有一个拷贝，节省硬盘空间 5)创建硬链接会增加额外的记录项以引用文件 6)创建时链接数递增 7)删除文件时： rm命令递减计数的链接 文件要存在，至少有一个链接数 当链接数为零时，该文件被删除 8)新旧文件的inode编号一致 由于删除文件要在同一个索引节点属于唯一的连接时才能成功，因此可以防止不必要的误删除。 软连接： 用ln -s命令建立文件的符号连接作为一个文件，它的数据是它所连接的文件的路径名。 类似windows下的快捷方式。 1)可以对目录创建，遍历操作会忽略目录的软连接 2)原始文件一般路径用相对路径，相对路径一定相对于软链接文件的路径 3)新旧文件的inode编号不一致 4)可以对不存在文件创建 5)可以跨文件系统 6)指向的是另一个文件的路径； 7)其大小为指向的路径字符串的长度 8)不增加或减少目标文件 可以删除原有的文件而保存连接文件，没有防止误删除功能。 取消软链接： unlink file 注意：任何目录&quot;硬链接&quot;总数等于2加上它的子目录总数（含隐藏目录）,2是父目录对其的“硬链接”和当前目录下的&quot;.硬链接” 区别硬链接和软链接的区别 1 同一个文件？ 硬链接指的是同一个文件，是给文件起了一个新名，节点编号一致; 软链接不是同一个文件，是给文件增加一个快捷方式，节点编号不一致。 2 跨分区？ 硬链接不可以，软链接可以 3 链接数增长？ 硬链接，链接数+1；软链接，链接数不变 4 inode Number 是否相同？ 硬链接相同，软链接不同 5 原始文件删除，链接文件可否访问？ 硬链接和原始文件之间的关系是平等关系，硬链接被删除，只要不是删除的最后一个硬链接，源文件不受影响，只是链接数-1 软链接是依赖源文件而存在的，源文件被删除，软链接不可用 6 大小？ 软链接为指向的路径字符串的长度，硬链接为源文件大小 7 支持目录？ 软链接可以创建目录的软链接；硬链接不能]]></content>
  </entry>
  <entry>
    <title><![CDATA[进程管理]]></title>
    <url>%2F2018%2F03%2F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[进程概念内核的功用：进程管理、文件系统、网络功能、内存管理、驱动程序、安全功能等 Linux系统各进程的相关信息均保存在/proc/PID目录下的各文件中 Process: 运行中的程序的一个副本，是被载入内存的一个指令集合 进程ID（Process ID，PID）号码被用来标记各个进程 UID、GID、和SELinux语境决定对文件系统的存取和访问权限 通常从执行进程的用户来继承 存在生命周期 进程process和线程thread 进程:相当于一个任务(项目)，需要人员(线程)、资源(内存空间，文件等)，完成该任务的集合 线程:相当于进程中的人员，也就是说，线程属于进程 同一个进程中的线程之间使用的资源是共享的,因此线程之间会相互影响 进程和进程之间不共享资源，因此彼此之间不会相互影响 进程和线程的关系：一对一、一对多的关系，进程占用的资源更多 task struct：Linux内核存储进程信息的数据结构格式 task list：多个任务的的task struct组成的链表 进程创建： init：第一个进程 进程：都由其父进程创建，父子关系，CoW fork(), clone() 进程创建基于CoW CoW copy on write 写时复制 创建子进程完毕以后，暂时不给子进程分配空间，只分配一个进程编号，此时子进程指向父进程的内存空间，和父进程共享相同的内存空间 当子进程的内容发生变化时，会给子进程分配一个新的内存空间，并把父进程的内容或数据复制给子进程，此时子进程指向新的内存空间，然后再对内容或数据进行修改 该过程类似于逻辑卷创建快照的过程 进程的基本状态创建状态：进程在创建时需要申请一个空白PCB(process control block进程控制块)，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态：进程已准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态：进程处于就绪状态被调度后，进程进入执行状态 阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 运行——&gt;就绪： 1，主要是进程占用CPU的时间过长，而系统分配给该进程占用CPU的时间是有限的； 2.在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行时，该进程就被迫让出CPU，该进程便由执行状态转变为就绪状态。 就绪——&gt;运行：运行的进程的时间片用完，调度就转到就绪队列中选择合适的进程分配CPU 运行——&gt;阻塞： 正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如发生了I/O请求,从磁盘上读取一个文件，读取速度慢，该进程在没有获取到数据之前，处于阻塞状态 阻塞——&gt;就绪:进程所等待的事件已经发生，就进入就绪队列 以下两种状态是不可能发生的： 阻塞——&gt;运行：即使给阻塞进程分配CPU，也无法执行，操作系统在进行调度时不会从阻塞队列进行挑选，而是从就绪队列中选取 就绪——&gt;阻塞：就绪态根本就没有执行，谈不上进入阻塞态 进程相关概念进程优先级： 系统优先级：数字越小，优先级越高 0-139（CentOS4,5） 各有140个运行队列和过期队列 0-98，99（CentOS6） 实时优先级: 99-0 值最大优先级最高 nice值：-20到19，对应系统优先级100-139或99 Big O：时间复杂度，用时和规模的关系 O(1), O(logn), O(n)线性, O(n^2)抛物线, O(2^n) 进程优先级调整： 静态优先级：100-139 进程默认启动时的nice值为0，优先级为120 只有根用户才能降低nice值（提高优先性） nice命令： nice [OPTION] [COMMAND [ARG]...] renice命令： renice [-n] priority pid... 查看： ps axo pid,comm,ni 进程内存Page Frame：页框 存储页面数据 最小页框大小4k LRU：Least Recently Used 近期最少使用算法 释放内存物理地址空间和线性地址空间 如内存中有长期不使用的数据 则被调出内存空间 当内存中有一数据被调用 则把其从内存的空间中移到首位 与当前内存空间的首位数据 调换位置 并将其它数据依次后推 MMU：Memory Management Unit 负责转换线性和物理地址 TLB：Translation Lookaside Buffer 译后备缓冲器,用于保存虚拟地址和物理地址映射关系的缓存 IPC: Inter Process Communication 同一主机：signal信号 shm：shared memory semaphore：信号量 一种计数器 不同主机：socket：IP和端口号 RPC：remote procedure call MQ：消息队列 物理地址空间(物理内存空间)和线性地址空间(虚拟内存空间) 物理地址空间：给进程实际分配的空间 虚拟内存空间：进程认为自己拥有主机全部的物理空间，但实际上该进程用不完全部的物理空间，因此需要模拟出一个虚拟内存空间来代替实际上的全部内存空间 MMU：把虚拟内存和物理内存做映射关系，把物理内存转换为虚拟内存 进程状态Linux内核：抢占式多任务 进程类型： 守护进程: daemon,在系统引导过程中启动的进程，和终端无关进程 前台进程：跟终端相关，通过终端启动的进程 注意：两者可相互转化 进程状态： 运行态：running 就绪态：ready 睡眠态：sleep 可中断：interruptable 不可中断：uninterruptable 停止态：stopped 暂停于内存，但不会被调度，除非手动启动 僵死态：zombie 父进程结束前，子进程不关闭 睡眠态和停止态区别： 睡眠态可以还原，进程可以醒过来，可能是自己醒过来，也可能是人为干预醒过来 停止态只要人为不干预，无法醒过来，会停在内存中，不会有任何操作 僵死态：程序发生故障，进程已经死去，但是会一直占用内存不释放，僵死态进程无法处理 管理工具进程的分类： CPU-Bound：CPU密集型，非交互;只消耗cpu，如进行加减运算 IO-Bound：IO密集型，交互;读取或写入数据 Linux系统状态的查看即管理工具 查看进程：pstree，ps 进程优先级：nice，renice 搜索进程：pgrep，pidof 进程管理工具：uptime，top，htop(epel源)，kill，pkill，killall 内存查看工具：free，vmstat，pmap 系统资源(cpu,IO)统计vmstat，iostat，dstat(代替vmstat，iostat) 系统监控工具：glances(epel源)，dstat(需要安装)，iotop(需要安装) 系统文件查看工具：lsof 作业管理：jobs，fg，bg，nohup 查看进程树pstreepstree 显示进程树 只显示名字 -p 显示进程及子进程pid -a 相同名称的进程不合并显示 并且显示命令行参数 扩展： 进程的上下文切换：在不同cpu之间执行进程任务，切换的过程叫做上下文切换。 这种切换会消耗大量的资源 如apache服务并发性不够，不适合并发数量高的场景 该服务存在C10k问题，即进程并发数达到10万，会出现问题 查看进程工具psps：process state，显示当前进程的状态 注意：ps显示当前进程的快照，该命令并不能动态跟踪进程状态，只能看到当时那个时间点的进程状态 Linux系统各进程的相关信息均保存在/proc/PID目录下的各文件中 UNIX风格 ：-A -e BSD风格 ：a GNU选项 如--help BSD选项：默认显示当前终端中的进程 a 选项包括所有终端中的进程 x 选项包括所有终端的进程 u 选项显示进程所有者的信息 f 选项显示进程树,相当于 --forest(GNU风格选项) k|--sort 属性 对属性排序,属性前加- 表示倒序 o 属性… 选项显示定制的信息 pid、cmd、%cpu、%mem L 显示支持的属性列表 UNIX选项： -C：cmdlist 指定命令，多个命令用，分隔 -L：显示线程 -e：显示所有进程，相当于-A -f：显示完整格式程序信息 -F：显示更完整格式的进程信息 -H：以进程层级格式显示进程相关信息 -u：userlist 指定有效的用户ID或名称 -U：userlist 指定真正的用户ID或名称 -g：gid或groupname 指定有效的gid -G：gid或groupname 指定真正的gid或组名称 -p：pid 显示指pid的进程 --ppid pid 显示属于pid的子进程 -M：显示SELinux信息，相当于Z ps输出属性 VSZ: Virtual memory SiZe，虚拟内存集，线性内存 RSS: ReSident Size, 常驻内存集 STAT：进程状态 R：running S: interruptable sleeping D: uninterruptable sleeping T: stopped Z: zombie +: 前台进程 l: 多线程进程 L：内存分页并带锁 N：低优先级进程 &lt;: 高优先级进程 s: session leader，会话（子进程）发起者 ni: nice值 pri: priority 优先级 psr: processor CPU编号 rtprio: 实时优先级 示例： ps axo pid,cmd,psr,ni,pri,rtprio 常用组合： aux -ef -eFH -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,comm axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm 搜索进程最灵活：ps 选项 | 其它命令 按预定义的模式：pgrep 语法：pgrep [options] pattern 该命令支持正则表达式 -u uid: effective user，生效者 -U uid: real user，真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名 -a: 显示完整格式的进程名 -P pid: 显示指定进程的子进程 按确切的程序名称：/sbin/pidof pidof bash uptimeuptime 显示结果中各项内容含义： 显示当前时间，系统已启动的时间、当前上线人数，系统平均负载（1、5、10分钟的平均负载，一般不会超过1） 系统平均负载: 指在特定时间间隔内运行队列中的平均进程数 通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。如果每个CPU内核的任务数大于5，那么此主机的性能有严重问题 如果linux主机是1个双核CPU，当Load Average 为6的时候说明机器已经被充分使用 tophtopkillkill命令： 向进程发送控制信号，以实现对进程管理,每个信号对应一个数字，信号名称以SIG开头（可省略），不区分大小写 常用信号：man 7 signal 1) SIGHUP: 无须关闭进程而让其重读配置文件 2) SIGINT: 中止正在运行的进程；相当于Ctrl+c 3) SIGQUIT:相当于ctrl+\(相当于quit) 9) SIGKILL: 强制杀死正在运行的进程 15) SIGTERM：正常终止正在运行的进程 18) SIGCONT：继续运行 19) SIGSTOP：后台休眠 指定信号的方法： (1) 信号的数字标识：1, 2, 9 (2) 信号完整名称：SIGHUP (3) 信号的简写名称：HUP 按名称：killall [-SIGNAL] comm… 某应用程序具有多个进程号，使用该命令可以一次全部删除 pkill -SIGNAL ：仅pkill可用 -u uid: effective user 生效者 -U uid: real user 真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名（pgrep可用） -a: 显示完整格式的进程名（pgrep可用） -P pid: 显示指定进程的子进程 freevmstatiostatdstatglancesiotoplsof作业管理Linux的作业控制 前台作业：通过终端启动，且启动后一直占据终端 后台作业：可通过终端启动，但启动后即转入后台运行（释放终端） 让作业运行于后台 (1) 运行中的作业： Ctrl+z (2) 尚未启动的作业： COMMAND &amp; 后台作业虽然被送往后台运行，但其依然与终端相关；退出终端，将关闭后台作业。 如果希望送往后台后，剥离与终端的关系 nohup COMMAND &amp;&gt;/dev/null &amp; screen；COMMAND 注意：nohup命令把任务放到后台执行，断网也能继续执行该进程，并把输出结果存放到hohup.out文件中 远程执行大的任务建议开启screen或者nohup 以防止断网引起任务终止 查看当前终端所有作业：jobs 作业控制： fg [[%]JOB_NUM]：把指定的后台作业调回前台 bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行 kill [%JOB_NUM]： 终止指定的作业 kill命令发送信号： 18 把处于后台休眠的命令继续运行 19 把处于后台运行状态的命令继续睡眠 状态切换 三种状态：前台运行、后台停止、后台运行 并行运行 同时运行多个进程，提高效率 方法1 vi all.sh f1.sh&amp; f2.sh&amp; 方法2 (f1.sh&amp;);(f2.sh&amp;);(f3.sh&amp;) 方法3 { f1.sh&amp; f2.sh&amp; f3.sh&amp; } 方法4：在脚本 { com1 com2 }&amp;]]></content>
  </entry>
  <entry>
    <title><![CDATA[文件系统特殊权限]]></title>
    <url>%2F2018%2F02%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[1) 对于目录来说： “r”表示能够读取目录内的文件列表 “w”表示能够在目录内新增、删除、重命名文件 “x”则表示能够进入该目录 读取文件数据 “X”只给目录加执行权限 2) 对于目录来说 读（r）可使用文件查看类工具获取其内容 写（w）可修改其内容 执行（x）可执行的文件、脚本 umask默认管理员的umask为0022 默认的普通用户的umask为0002 对于目录 新建目录的权限为777-umask 对于文件 新建的文件所减后的数如果某位数为奇数 则在该位数字+1 umask -S 显示权限列表 umask -p 显示umask值 显示结果，可用于重定向或追加到文件中，方便操作。 设置umask值只对当前登录用户有效，一旦退出该用户，umask值将不会对下次登录用户有效 ~/.bashrc 只对当前用户有效 /etc/bashrc 对所有用户有效 特殊权限位SUID, SGID, Sticky 三种常用权限：r, w, x user, group, other 安全上下文 前提：进程有属主和属组；文件有属主和属组 (1) 任何一个可执行程序文件能不能启动为进程,取决发起者对程序文件是否拥有 执行权限 (2) 启动为进程之后，其进程的属主为发起者,进程的属组为发起者所属的组 (3) 进程访问文件时的权限，取决于进程的发起者 (a) 进程的发起者，同文件的属主：则应用文件属主权限 (b) 进程的发起者，属于文件属组；则应用文件属组权限 (c) 应用文件“其它”权限 SUID任何一个可执行程序文件能不能启动为进程：取决发起者对程序文件是否拥有 执行权限 启动为进程之后，其进程的属主为原程序文件的属主 让二进制程序的执行程序临时拥有属主的权限 chmod u+s FILE... chmod u-s FILE... SGID让执行者临时拥有属组的权限（对拥有执行权限的二进制程序进行设置）； 在某个目录中创建的文件自动继承该目录的用户组（只可以对目录进行设置） chmod g+s FILE... chmod g-s FILE... SBIT粘滞位 具有写权限的目录通常用户可以删除该目录中的任何文件，无论该文件的权限 或拥有权 除了管理员外 可确保用户只能删除自己的文件 sticky 设置在文件上无意义 chmod o+t DIR... chmod o-t DIR... 权限位映射SUID: user,占据属主的执行权限位 s：属主拥有x权限 S：属主没有x权限 SGID: group,占据属组的执行权限位 s： group拥有x权限 S：group没有x权限 Sticky: other,占据other的执行权限位 t：other拥有x权限 T：other没有x权限 文件的隐藏属性chattr i 无法对文件进行修改；若对目录设置了该参数，则仅能修改其中的子文件内容而不能新建或删除文件 a 仅允许补充（追加）内容 无法覆盖/删除内容（Append Only） S 文件内容在变更后立即同步到硬盘（sync） s 彻底从硬盘中删除 不可恢复（用0填充原文件所在硬盘区域） A 不再修改这个文件或目录的最后访问时间（atime） b 不再修改文件或目录的存取时间 D 检查压缩文件中的错误 d 使用dump命令备份时忽略本文件/目录 c 默认将文件或目录进行压缩 u 当删除该文件后依然保留其在硬盘中的数据 方便日后恢复 t 让文件系统支持尾部合并（tail-merging） x 可以直接访问压缩文件中的内容 lsattr 显示文件的隐藏权限 ACL访问控制列表基于普通文件或目录设置ACL其实就是针对指定的用户或用户组设置文件或目录的操作权限。 对某个目录设置了ACL 则目录中的文件会继承其ACL； 对文件设置ACL 则文件不继承其所在目录的ACL 最后一个点（.）变成了加号（+） Mask需要与用户的权限进行逻辑与运算后 才能变成有限的权限 可以将mask值理解为最高权限 除了所有者 Other之外 其他的都在mask 的管辖之内 通过ACL赋予目录默认x权限 目录内文件也不会继承x权限 base ACL 不能删除 用户或组的设置必须存在于mask权限设定范围内才会生效 setfacl -m mask::rx file setfacl -x 用户名 文件名 删除acl权限 -R -m 递归设置acl权限 -b 删除所有ACL -k 删除默认ACL -d 设定默认的acl规则 例：setfacl -m u：用户名：权限 文件名 --set选项会把原有的ACL项都删除，用新的替代，需要注意的是一定要包含UGO的设置，不能象-m一样只是添加ACL就可以 例：setfacl --set u::rw,u:wang:rw,g::r,o::- file1 getfacl 查看ACL权限 getfacl file1 | setfacl --set-file=- file2 复制file1的acl权限给file2 备份和恢复ACL主要的文件操作命令cp和mv都支持ACL 只是cp命令需要加上-p 参数。 但是 tar等常见的备份工具是不会保留目录和文件的ACL信息 CentOS7 默认创建的xfs和ext4文件系统具有ACL功能 CentOS7 之前版本 默认手工创建的ext4文件系统无ACL功能,需手动增加 tune2fs –o acl /dev/sdb1 mount –o acl /dev/sdb1 /mnt/test 用法： getfacl -R /tmp/dir1 &gt; acl.txt 备份acl权限到acl.txt文件 setfacl -R -b /tmp/dir1 删除dir1目录所有权限 setfacl -R --set-file=acl.txt /tmp/dir1 用新权限代替原有权限 setfacl --restore acl.txt 从acl.txt获取权限列表 getfacl -R /tmp/dir1 查看权限]]></content>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F02%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式REGEXP： Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能 程序支持：grep,sed,awk,vim, less,nginx,varnish等 分两类： 基本正则表达式：BRE 扩展正则表达式：ERE grep -E, egrep 正则表达式引擎： 采用不同算法，检查处理正则表达式的软件模块 PCRE（Perl Compatible Regular Expressions） 元字符分类：字符匹配、匹配次数、位置锚定、分组 man 7 regex 基本正则表达式元字符1.字符匹配: . 匹配任意单个字符 [] 匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z] [^] 匹配指定范围外的任意单个字符 [:alnum:] 字母和数字 [:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z [:lower:] 小写字母 [:upper:] 大写字母 [:blank:] 空白字符（空格和制表符） [:space:] 水平和垂直的空白字符（比[:blank:]包含的范围广） [:cntrl:] 不可打印的控制字符（退格、删除、警铃...） [:digit:] 十进制数字 [:xdigit:]十六进制数字 [:graph:] 可打印的非空白字符 [:print:] 可打印字符 [:punct:] 标点符号 2.匹配次数：用在要指定次数的字符后面，用于指定前面的字符要出现的次数 * 匹配前面的字符任意次，包括0次贪婪模式：尽可能长的匹配 .* 任意长度的任意字符 ? 匹配其前面的字符0或1次 + 匹配其前面的字符至少1次 \{n\} 匹配前面的字符n次 \{m,n\} 匹配前面的字符至少m次，至多n次 \{,n\} 匹配前面的字符至多n次 \{n,\} 匹配前面的字符至少n次 3.位置锚定：定位出现的位置 ^ 行首锚定，用于模式的最左侧 $ 行尾锚定，用于模式的最右侧 ^PATTERN$ 用于模式匹配整行 ^$ 空行 ^[[:space:]]*$ 空白行 \&lt; 或 \b 词首锚定，用于单词模式的左侧 \&gt; 或 \b 词尾锚定，用于单词模式的右侧 \&lt;PATTERN&gt; 匹配整个单词 4.分组：() 将一个或多个字符捆绑在一起，当作一个整体处理，如：\(root\)+ 分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些 变量的命名方式为: \1, \2, \3, ... \1 表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符 示例： (string1+(string2)) \1 ：string1+(string2) \2 ：string2 后向引用：引用前面的分组括号中的模式所匹配字符，而非模式本身 5.或者：| 示例：a|b: a或b C|cat: C或cat (C|c)at:Cat或cat egrep及扩展的正则表达式egrep = grep -E egrep [OPTIONS] PATTERN [FILE...] 扩展正则表达式的元字符： 字符匹配： . 任意单个字符 [] 指定范围的字符 [^] 不在指定范围的字符 次数匹配： * 匹配前面字符任意次 ? 0或1次 + 1次或多次 {m} 匹配m次 {m,n} 至少m，至多n次 位置锚定： ^ 行首 $ 行尾 &lt;, \b 语首 &gt;, \b 语尾 分组： () 后向引用：\1, \2, ... 或者： a|b a或b C|cat C或cat (C|c)at Cat或cat]]></content>
  </entry>
  <entry>
    <title><![CDATA[vim]]></title>
    <url>%2F2018%2F02%2Fvim%2F</url>
    <content type="text"><![CDATA[vim -c cmd file: 在打开文件前，先执行指定的命令； vim -r file: 恢复上次异常退出的文件； vim -o file1 file2:水平分割窗口 vim -O file1 file2:垂直分割窗口 vim -R file: 以只读的方式打开文件，但可以强制保存； vim -M file: 以只读的方式打开文件，不可以强制保存； vim -y num file: 将编辑窗口的大小设为num行； vim + file: 从文件的末尾开始； vim +num file: 从第num行开始； vim +/string file: 打开file，并将光标停留在第一个找到的string上 正常模式：可以使用快捷键命令:r file 读文件内容到当前文件 :w file 将当前文件内容写入另一个文件 :! cmd 执行命令 : r! cmd 将命令的输出到文件内容 ：sp 文件水平分割窗口 插入模式：i 在光标所在处输入 I 在当前光标所在行的行首输入 a 在光标所在处后面输入 A 在当前光标所在行的行尾输入 o 在当前光标所在行的下方打开一个新行 O 在当前光标所在行的上方打开一个新行 多文件格式vim FILE1 FILE2 FILE3 … :next 下一个 :prev前一个 :first 第一个 :last 最后一个 :wall 保存所有 :qall退出所有 :wqall 单文件窗口分割 Ctrl+w,s: split, 水平分割 Ctrl+w,v: vertical, 垂直分割 ctrl+w,q：取消相邻窗口 ctrl+w,o:取消全部窗口 多文件分割 vim -o|-O FILE1 FILE2 … -o: 水平分割 -O: 垂直分割 在窗口间切换：Ctrl+w, Arrow 可视模式：正常模式下按v总是整行整行的选中。ctrl+v进入可视块模式。 shift+i在这一列前插入 shift+a后面插入一列， ESC即可生效 光标的移动h:左 j:下 k:上 l:右 M：页中间 b: 后移 ^: 跳转至行首的第一个非空白字符 0: 跳转至行首 $: 跳转至行尾 G：最后一行 gg: 第一行 w ：到下一个单词开头 e：到下一个单词结尾 翻屏ctrl+f: 下翻一屏 ctrl+b: 上翻一屏 ctrl+d: 下翻半屏 ctrl+u: 上翻半屏 ctrl+e: 向下滚动一行 ctrl+y: 向上滚动一行 编辑字符间跳转 h 左 l 右 j 下 k 上 单词间的跳转 w 下个单词的词首 e 下个单词词尾 b 当前单词单词的词首 当前页跳转 H 头部 M 中间 L 底部 zt 将光标的所在的行移到屏幕顶端 zz 将光标所在行移到屏幕中间 zb 将光标所在行移到屏幕底端 行首行尾的跳转 ^ 跳转光标处的行首 当前行的非空白字符的行首 $ 跳转光标处的行尾 0 跳转光标处的行首 当前行的绝对行首 行间一低昂 G 最后一行 1gg 跳到行首 gg 句间移动 ) 下一句 ( 上一句 段落间移动 { 上一段 } 下一段 字符编辑操作 x 删除光标所在处字符 xp 交换当前光标处以后字符位置 ~ 装换当前光标处的大小写 J 删除光标出行的换行符 替换 r 替换当前光标处的字符 R 进入替换模式 删除 d 删除 d$ 删除光标处到当前行的行尾 d0 删除光标所在处的行首 dw db de dd 删除当前行整行 输入p命令粘贴删除的内容 相当于剪贴复制 dG 删除光标所在处整个文件尾部 dgg di&quot; 删除两个&quot;&quot;之间的内容 di( 删除()之间的内容 di{ 删除{}之间的内容 dtx 删除至光标处当前行遇到第一个x字符 复制 y 复制 yy yw yb ye 复制当前单词 y$ 复制光标到行尾 y^ 复制行首的第一个非空白字符 y0 复制光标到行头 yi&quot; 复制两个&quot;&quot;之间的内容 yi( yi{ yi[ ytx 复制至光标处当前行遇到第一个x字符 粘贴 p 粘贴在下一行 P 粘贴在上一行 更改 c: 修改后切换成插入模式 c$ 删除到行尾并进入插入模式 c^ 删除到行头并进去插入模式 c0 删除到行头并进去插入模式 cb 删除光标的前一个字符并进入插入模式 ce 删除光标到单词结尾并进入插入模式 cw 删除光标到单词结尾并进入插入模式 cc：删除当前行并输入新内容，相当于S C 删除当前行 并进入插入模式 ?C：删除当前光标到行尾，并切换成插入模式 地址定界# 具体第#行 例如2表示第2行 #,# 从左侧#表示起始行 到右侧#表示结尾行 #,+# 从左侧#表示的起始行 加上右侧#表示的行数 2,+3 表示2到5行 . 当前行 $ 最后一行 .,$-1 当前行到倒数第二行 % 全文, 相当于1,$ /pat1/,/pat2/ 从pat1匹配pat2匹配的行结束 2,/pat/ /pat/,$ 使用方式：后跟一个编辑命令 d y s 查找/#：从当前光标向尾部查找 ?#：从当前光标向首部查找 n：向下查找 N：向上查找 替换gU (变大写) gU3e gU3w gu (变小写) gu3e gu3w 配置文件 全局：/etc/vimrc 个人：~/.vimrc 扩展模式：当前vim进程有效 (1) 行号 显示： set nu 取消： set nonu (2) 忽略字符的大小写 启用：set ic 不忽略：set noic (3) 自动缩进 启用：set ai 禁用：set noai (4)智能缩进 启用：set si 禁用：set nosi (5) 高亮搜索 启用：set hlsearch 禁用：noh (6) 语法高亮 启用：syntax on 禁用：syntax off (7) 显示Tab和换行符 ^I 和$显示 启用：set list 禁用：set nolist (8) 文件格式 set ff=dos|unix (9) 设置文本宽度 set textwidth=65 (vim only) set wrapmargin=15 (10) 设置光标所在行的标识线 启用：cul 禁用：set no cursorline (11) 复制保留格式 启用：set paste 禁用：set nopast 标记和宏ma 将当前位置标记为a，26个字母均可做标记，mb、mc 等等； ‘a 跳转到a标记的位置；实用的文档内标记方法，文档中跳跃编辑时很有用 qa录制宏a，a为宏的名称 q 停止录制宏， @a 执行宏a @@ 重新执行上次执行的宏]]></content>
  </entry>
  <entry>
    <title><![CDATA[文本处理工具]]></title>
    <url>%2F2018%2F02%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[文件查看命令####cat 用于连接多个文件并且打印到屏幕输出或重定向到指定文件中 cat [OPTION]… [FILE]… -E：显示行结束符$ -n：对显示出的每一行进行编号 -A：显示所有控制符 -b：非空行编号 -s：压缩连续的空行成一行 取前10位除了字母和数字的随机数作为密码 cat /dev/urandom | tr -dc &apos;[:alnum:]&apos; | head -c10 tac反向显示文件内容（上下方向） rev反向显示文件内容（左右方向） 分页查看文件内容more分页查看文件 用法：more [OPTIONS...] FILE... -d: 显示翻页及退出提示 注意：more查看文件，到文件内容底部以后会自动退出 less一页一页地查看文件或STDIN输出 查看时有用的命令包括： less 该命令是man命令使用的分页器 显示文本前或后行内容head前面部分，默认前10行 head [OPTION]... [FILE]... -c 获取前#字节 -n 获取前#行 tail后面部分，默认后10行 tail [OPTION]... [FILE]... -c #：获取#字节 -n #: 指定获取后#行 -f：跟踪显示文件fd新追加的内容,常用日志监控。但是文件在其他窗口被删除，不会有提示 相当于 --follow=descriptor -F：以文件名跟踪显示文件内容，文件在其他窗口被删除，会出现提示 tailf 类似 tail -f 文件不增长不访问文件 按列抽取和合并字符cut剪切字节、字符和字段 cut [OPTION]... [FILE]... -b：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了-n标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域 #: 第#个字段 #,#[,#]：离散的多个字段，例如1,3,6 #-#：连续的多个字段, 例如1-6 混合使用：1-3,7 -n ：取消分割多字节字符。仅和 -b 标志一起使用。 paste合并两个文件同行号的列到一列 paste [OPTION]... [FILE]... -d 分隔符默认tab -s 所有行合成一行 paste f1 f2 文件（横向）合到一块 paste -s f1 f2 所有行合成一行 tr转换和删除字符 tr [OPTION]... SET1 [SET2] -c：反选替换设定字符。 -d：删除指令字符 -s：缩减连续重复的字符成指定的单个字符 -t：将第一个字符集对应字符转化为第二字符集对应的字符 tr -d &apos;\n&apos; &lt; 文件名 把windows文件转换为linux文件（把windows文件中的换行符去掉） 转换小工具（需要安装软件包才能使用） dos2unix windows文件转换为linux文件 unix2dos linux文件转换为windows文件 分析文本的工具文本数据统计：wc 整理文本：sort uniq 比较文本：diff和patch wc统计的内容分别是：单词总数、行总数、字节总数和字符总数 注意：当文本中出现汉字时，一个汉字占3个字符,加上换行符,会多出4个字符(字符和字节不是同一概念) 常用选项 -l：只计数行数 -w：只计数单词总数 -c：只计数字节总数 -m：只计数字符总数 -L：显示文件中最长行的长度 wc /etc/passwd 45 88 2311 /etc/passwd 行数 字数 字节数 strings查看文件中的可打印的字符 strings file sort把整理过的文本显示在STDIN，不改变原始文件 sort [options] file(s) -r 反向排序 -R 随机排序 -n 按数字大小整理 -u 删除输出中的重复行 -f 忽略字符串的字符大小写 -t c：使用c字符做字段界定符 -k x ：按照c字符分割的x列整理 seq 75 |sort -R |head -n1 随机从75个数中取出一个数字，数字75可自定义 uniquniq [OPTION]... [FILE]... 从输入中删除前后相接重复行 -c 显示每行重复出现的次数 -d 仅显示重复行 -u 仅显示不重复行 注：连续且完全相同方为重复 常和sort命令配合使用： sort xx | uniq -c 去重并排序 cat file1 file2 |sort |uniq -d 取两个文件的交集（重复的行） diff比较两个文件之间的区别 输出被保存在一种叫做“补丁(diff.log)”的文件中 -u 输出“统一的（unified）”diff格式文件，最适用于补丁文件 patch赋值在其他文件中践行的改变（谨慎使用） * 使用-b选项来自动备份改变了的文件 diff -u foo.conf foo2.conf &gt; foo.patch patch -b foo.conf foo.patch 示例： diff -u f1 f2 &gt;diff.log 把比较结果重定向到diff.log文件中 patch 根据“补丁”文件（diff.log）还原源文件（f2） rm -rf f1 删除f1文件 patch -b f1 diff.log 根据diff.log文件恢复f1文件 先备份f1文件并将该文件重命名为f1.orig 然后根据diff.log恢复f2文件,但f2文件恢复后被重命名为f1 因此恢复后，f1文件即为f2文件内容，f1.orig文件为f1文件内容 例： 1、找出ifconfig “网卡名” 命令结果中本机的IPv4地址 ifconfig ens33|head -n2 |tail -n1|tr -s &quot; &quot;|cut -d&quot; &quot; -f3 2、查出分区空间使用率的最大百分比值 df |tr -s &quot; &quot; %|cut -d% -f5|sort -nr|head -n1 3、查出用户UID最大值的用户名、UID及shell类型 cat /etc/passwd |cut -d: -f1,3,7|sort -t: -k2 -nr|head -n1 4、查出/tmp的权限，以数字方式显示 stat /tmp |head -n4 |tail -n1|tr -dc [:digit:]|cut -c1-4 5、统计当前连接本机的每个远程主机IP的连接数，并按从大到小排序 netstat -nt|tr -s &quot; &quot; : |cut -d: -f6|tr -dc &quot;[:digit:].\n&quot;|sort|uniq -c|sort -nr]]></content>
  </entry>
  <entry>
    <title><![CDATA[磁盘管理]]></title>
    <url>%2F2018%2F02%2F%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[硬盘接口类型并行： IDE：133MB/s在实际应用中也被称为ATA，早期普通计算机使用的接口类型，现已淘汰 SCSI：640MB/s使用与早期服务器上的接口类型，逐渐被代替 串口： SATA：6Gbps即serial ATA;稳定性较强，仍是目前大多数服务器使用的接口类型 SAS：6Gbps向下兼容SATA硬盘，传输速率较高，但因其昂贵的价格，没有普及使用 USB：480MB/s移动存储设备接口(如u盘，移动硬盘等) rpm: rotations per minute，即每分钟转数 设备文件磁盘设备的设备文件命名：/dev/DEV_FILE SCSI, SATA, SAS, IDE,USB: /dev/sd 虚拟磁盘：/dev/vd 不同磁盘标识：a-z,aa,ab… /dev/sda, /dev/sdb, ... 同一设备上的不同分区：1,2, ... /dev/sda1, /dev/sda5 硬盘存储术语 head：磁头 track：磁道 cylinder: 柱面 ector: 扇区，512bytes CHS和LBACHS ： 采用24bit位寻址 其中前10位表示cylinder 中间8位表示head 后面6位表示sector 最大寻址空间8GB LBA（logical block addressing）： 一个整数 通过转换成CHS格式完成磁盘具体寻址 ATA-1规范中定义了28位寻址模式 以每扇区512位组来计算 ATA-1所定 义的28位LBA上限达到128 GiB。2002年ATA-6规范采用48位LBA 同样以 每扇区512位组计算容量上限可达128 Petabytes 由于CHS寻址方式的寻址空间在大概8GB以内，所以在磁盘容量小于大概8GB时，可以使用CHS寻址方式或是LBA寻址方式 在磁盘容量大于大概8GB时则 只能使用LBA寻址方式 分区优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不同文件系统 两种分区方式：MBR，GPT 按柱面分区 mbr主引导记录，偏移地址0000H--0088H，它负责从活动分区中装载，并运行 系统引导程序 MBR磁盘的第0磁道 0柱面 1扇区 一共512字节 主引导记录 Master Boot Record 占446byte 64字节 4个16byte分区 2byte magic number 标记 MBR：4个分区 分区不能超过2T mbr分区用4个字节存储分区的总扇区数 最大能表示2的32次方的扇区个数 按每扇区512字节计算（2^32*512byte=2199023255552byte=2T GPTGPT:GUID（Globals Unique Identifiers） 支持128个分区，使用64位，支持8Z（ 512Byte/block ）64Z （ 4096Byte/block） 使用128位UUID(Universally Unique Identifier) 表示磁盘和分区 GPT分区表自动备份在头和尾两份，并有CRC校验位 UEFI (统一扩展固件接口)硬件支持GPT，使操作系统启动 管理分区创建分区使用 fdisk：创建MBR分区 gdisk：创建GPT分区 parted：高级分区操作 重新设置内存中的内核分区表版本 partprobe dmesg 列出加载到内核中的所有驱动 lsblk 查看生效的块设备（分区表） -f：列出文件系统 blkid 查看磁盘UUID partedparted的操作都是实时生效的，小心使用 用法：parted [选项]... [设备 [命令 [参数]...]...] parted /dev/sdb mklabel gpt|msdos parted /dev/sdb print 列出磁盘sdb分区信息 parted /dev/sdb mkpart primary 1 200 （默认M） parted /dev/sdb rm 1 parted –l 列出分区信息 分区工具fdisk和gdiskgdisk /dev/sdb 类fdisk 的GPT分区工具 fdisk -l [-u] [device...] 查看分区 fdisk /dev/sdb 管理分区 子命令： p 分区列表 t 更改分区类型 n 创建新分区 d 删除分区 v 校验分区 u 转换单位 w 保存并退出 q 不保存并退出 同步分区表查看内核是否已经识别新的分区 cat /proc/partations centos6通知内核重新读取硬盘分区表 新增分区用 partx -a /dev/DEVICE kpartx -a /dev/DEVICE -f: force 删除分区用 partx -d --nr M-N /dev/DEVICE CentOS 5，7: 使用partprobe partprobe [/dev/DEVICE] 删除分区表：dd if=/dev/zero of=/dev/sdb bs=1 count=512 文件系统文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构 在存储设备上组织文件的方法。 操作系统中负责管理和存储文件信息的软件结构称为文件管理系统，简称文件系统 从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。 具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，安全控制，日志，压缩，加密等 支持的文件系统：/lib/modules/uname –r/kernel/fs 各种文件系统： https://en.wikipedia.org/wiki/Comparison_of_file_systems 文件系统类型Linux文件系统： ext2(Extended file system) :适用于那些分区容量不是太大，更新也不频繁的情况 例如 /boot 分区 ext3:是 ext2的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中 恢复。它通常被用作通用的文件系统 ext4:是 ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使 用巨型文件(16TB)、最大1EB的文件系统，以及速度的提升 xfs：SGI，支持最大8EB的文件系统 btrfs（Oracle）, reiserfs, jfs（AIX）, swap 光盘：iso9660 Windows：FAT32, exFAT,NTFS Unix: FFS（fast）, UFS（unix）, JFS2 网络文件系统：NFS, CIFS 集群文件系统：GFS2, OCFS2（oracle） 分布式文件系统： fastdfs,ceph, moosefs, mogilefs, glusterfs, Lustre RAW：未经处理或者未经格式化产生的文件系统 根据其是否支持&quot;journal&quot;功能： 日志型文件系统: ext3, ext4, xfs, ... 非日志型文件系统: ext2, vfat 文件系统的组成部分： 内核中的模块：ext4, xfs, vfat 用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfat Linux的虚拟文件系统：VFS 查前支持的文件系统：cat /proc/filesystems 创建文件系统mkfs命令： (1)mkfs.FS_TYPE /dev/DEVICE ext4 xfs btrfs vfat (2)mkfs -t FS_TYPE /dev/DEVICE -L &apos;LABEL&apos; 设定卷标 mke2fs：ext系列文件系统专用管理工具 -t {ext2|ext3|ext4} 指定文件系统类型 -b {1024|2048|4096} 指定块大小 -L ‘LABEL’ 设置卷标 -j 相当于 -t ext3 -i # 为数据空间中每多少个字节创建一个inode；不应该小于block大小 -N # 指定分区中创建多少个inode -I 一个inode记录占用的磁盘空间大小，128 --4096 -m # 默认5%,为管理人员预留空间占总空间的百分比 -O FEATURE[,...] 启用指定特性 -O ^FEATURE 关闭指定特性 mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3 注意： centos7版本支持xfs、ext系列文件系统； 而centos6版本支持ext系列文件系统，若想要使用xfs文件系统，则需要安装工具：xfsprogs 文件系统标签指向设备的另一种方法 与设备无关 blkid：块设备属性信息查看 blkid [OPTION]... [DEVICE] -U UUID 根据指定的UUID来查找对应的设备 -L LABEL 根据指定的LABEL来查找对应的设备 e2label：管理ext系列文件系统的LABEL e2label DEVICE [LABEL] findfs ：查找分区 findfs [options] LABEL=&lt;label&gt; findfs [options] UUID=&lt;uuid&gt; tune2fstune2fs：重新设定ext系列文件系统可调整参数的值 -l：查看指定文件系统超级块信息；super block -L &apos;LABEL&apos;：修改卷标 -m #：修预留给管理员的空间百分比 -j: 将ext2升级为ext3 -O: 文件系统属性启用或禁用,–O ^has_journal -o: 调整文件系统的默认挂载选项 –o ^acl -U UUID: 修改UUID号 注意:centos7系统默认具有acl权限，centos6系统需要手动设置acl功能 如：tune2fs -o acl /dev/sdb1 文件系统检测和修复常发生于死机或者非正常关机之后 挂载为文件系统标记为“no clean” 注意：一定在umount下修复 fsck: 文件系统检查 FS_TYPE一定要与分区上已经文件类型相同 一定要umount状态 fsck.FS_TYPE fsck -t FS_TYPE -p: 自动修复错误 -r: 交互式修复错误 e2fsck：ext系列文件专用的检测修复工具 -y：自动回答为yes -f：强制修复 xfs_info 查看xfs文件系统的信息 挂载mount挂载:将额外文件系统与根文件系统某现存的目录建立起关联关系，进而使得此目录做为其它文件访问入口的行为 卸载:为解除此关联关系的过程 把设备关联挂载点：mount Point mount 卸载时：可使用设备，也可以使用挂载点 umount 挂载点下原有文件在挂载完成后会被临时隐藏 挂载点目录一般为空 一个文件夹只能挂载一个设备（只生效一个） 一个设备可以挂载多个文件夹 空文件夹充当挂载点 mount 查看内核追踪到的已挂载的所有设备 cat /proc/mounts mount:通过查看/etc/mtab文件显示当前已挂载的所有设备 用法：mount mount [-fnrsvw] [-t vfstype] [-o options] 设备 挂载点 device：指明要挂载的设备； (1) 设备文件：例如/dev/sda5 (2) 卷标：-L &apos;LABEL&apos;, 例如-L &apos;MYDATA&apos; 3) UUID, -U &apos;UUID&apos;：例如-U &apos;0c50523c-43f1-45e7-85c0-a126711d406e&apos; (4) 伪文件系统名称：proc, sysfs, devtmpfs, configfs dir：挂载点 事先存在；建议使用空目录 进程正在使用中的设备无法被卸载 mount常用命令选项 -r 只读方式挂载 -w 读写挂载 默认 -n 不更新/etc/mtab -t 指定文件系统 一般不用 系统可以自动识别 -a 自动挂载/etc/fstab中的设备 -B | --bind 目录挂载到目录 -o：选项 acl：启用acl noacl：关闭acl remount：重新挂载 ro：只读 async：异步模式 sync：同步模式 loop：可以挂载文件模拟的loop设备 atime/noatime：包含目录和文件 diratime/nodiratime：目录的访问时间戳 auto/noauto：是否支持自动挂载,是否支持-a选项 exec/noexec：是否支持将文件系统上运行应用程序 dev/nodev：是否支持在此文件系统上使用设备文件 suid/nosuid：是否支持suid和sgid权限 user/nouser：是否允许普通用户挂载此设备 /etc/fstab使用 defaults：相当于rw, suid, dev, exec, auto, nouser, async 示例： loop 用文件模拟文件系统(即文件挂载到目录) 1.先创建需要大小的文件，如100M大小 dd if=/dev/zero of=/data/p1 bs=1M count=100 2.然后创建文件系统 mkfs.ext4 /data/p1 blkid /data/p1 查看文件类型 mkdir /mnt/p1 mount -o loop /data/p1 /mnt/p1 centos6中需加上-o loop选项即可挂载，centos7系统下不需要-o loop选项即可挂载 在centos6版本中，使用文件模拟文件系统，挂载时需要启用loop功能(即mount -o loop) 在centos6中默认启用loop设备默认有8个，超出此范围无法继续使用loop设备 centos7系统loop设备会自动生成，因此没有此限制 解决方法：修改内核参数(针对centos6版本) 在/boot/grub/grub.conf文件中，kernel行最后添加max_loop=N(该数字可自定义)即可，修改完毕重启设备，loop设备即可超过8个。 losetup -a 查看当前挂载的loop设备 losetup /dev/loop# loopfile 绑定文件到loop设备 如果新增加的loop使用完，可以使用mknod创建特殊文件 mknod /dev/loop100 b 7 100 其中b是指块设备；7是指设备主编号；100是指设备次编号 卸载查看挂载情况 findmnt MOUNT_POINT|device 查看正在访问指定文件系统的进程 lsof MOUNT_POINT fuser -v MOUNT_POINT 终止所有在正访问指定的文件系统的进程 fuser -km MOUNT_POINT 卸载 umount DEVICE umount MOUNT_POINT 注意：在卸载分区前，要先查看是否有其他用户在使用该分区，如果有，则可以终止访问该文件系统的用户，然后卸载 挂载点和/etc/fstab配置文件系统体系 被mount、fsck和其他程序使用 系统重启时保留文件系统提示 可以在设备栏使用文件系统卷标 使用mount -a命令挂载/etc/fstab中的所有文件系统 /etc/fstab每行定义一个要挂载的文件系统 1、要挂载的设备或伪文件系统 设备文件 LABEL：LABEL=&quot;&quot; UUID：UUID=&quot;&quot; 伪文件系统名称：proc, sysfs 2、挂载点 3、文件系统类型：ext4,xfs,nfs,none 4、挂载选项：defaults，acl，bind 5、转储频率：0：不做备份1：每天转储2：每隔一天转储 6、fsck检查的文件系统的顺序：允许的数字是0, 1, 和2 0：不自检 1：首先自检；一般只有rootfs才用 2：非rootfs使用 注意：在挂载时，尽量使用设备的uuid挂载，，因为设备名称、卷标会被更改，因此使用设备名称挂载不稳定，而每个设备的uuid是唯一的，因此使用uuid挂载比较稳定。 示例： 实验1：当/etc/fstab表中要挂载的分区被删除 当分区被误删除，该分区会被其他分区自动顶替，系统无法正常启动。一旦出现这种情况，系统所有分区默认只有读权限，无法更改fstab表。 解决方法： 使用(mount -o remount,rw /)重新挂载根分区，并使其具有写权限，更改fstab表，恢复即可。 /etc/fstab表中 0 0，最后一个0表示检查次序，如果/etc/fstab表中，最后一项写成&quot;0 0&quot;不检测系统分区，相对来说比较安全，不会出现系统无法启动的情况 实验2：将/home目录迁移到一个独立分区中 1、创建分区，创建文件系统(即格式化)，同步分区表 如：该分区为/dev/sda2 2、想要迁移数据，需要把数据复制到该分区中，要想使用该分区，则需要将该分区挂载到一个挂载点才能使用 挂载到一个临时挂载点(如：/mnt/home) mkdir /mnt/home mount /dev/sda2 /mnt/home 复制之前，要保证该分区没有其他人在访问，不再向该分区写入数据 使用命令init 1(单用户模式) 进入维护模式，一旦进入该模式，该设备会被断网，无法远程，需要到物理机进行操作 3、复制文件 cp -a /home /mnt/home 4、挂载永久有效，需要写入/etc/fstab表中 /dev/sda2 /home xfs defaults 0 0 注意：此时的挂载点是/home而不是/mnt/home；/mnt/home是临时挂载点，随着系统重启而失效 mount -a 使fstab表立即生效 5、删除原/home下的文件 要删除原/home文件需要将/home取消挂载 umount /home 删除/home目录 rm -rf /home/* 6、重新挂载/home mount -a 最后，重启设备 管理虚拟内存交换分区是系统RAM的补充 基本设置包括： 创建交换分区或者文件 使用mkswap写入特殊签名 在/etc/fstab文件中添加适当的条目 使用swapon -a 激活交换空间 /etc/fstab:pri=value free 查看内存和swap的信息 -m 以M为单位显示 -g 以G为单位显示 -h 以人类可以看懂的方式显示 mkswap /dev/sdb1 -L swap_sdb1 格式化 swapon DEV|LOOPFILE 激活swap分区 -s 查看当前的swap信息 -a 激活fstab表中配置的swap swapoff [OPTION]... [DEVICE] 禁用swap分区 SWAP的优先级可以指定swap分区0到32767的优先级，值越大优先级越高 如果用户没有指定，那么核心会自动给swap指定一个优先级，这个优先级从-1开始，每加入一个新的没有用户指定优先级的swap，会给这个优先级减一 先添加的swap的缺省优先级比较高，除非用户自己指定一个优先级，而用户指定的优先级(是正数)永远高于核心缺省指定的优先级(是负数) 优化性能：分布存放，高性能磁盘存放 示例： 1、增加swap分区大小 使用fdisk命令新建分区，并更改分区id为82 创建文件系统时使用mkswap 分区名 将更改写入/etc/fstab配置文件 swapon -a 使fstab表swap挂载立即生效 2、去掉新增的swap分区 swapoff 禁用swap分区 删除fstab表中swap挂载信息 删除swap分区 3.实验：增加分区或文件充当swap分区 创建需求大小的文件 dd if=/dev/zero if=swapfile bs=1G count=10 创建swap文件系统 mkswap /swapfile 写入fstab表 /swapfile swap swap defaults 0 0 激活fstab表 swapon -a 出于安全考虑，把/swapfile文件权限设置为600，即不允许别人对该文件进行写操作 常见工具eject 弹出光驱 -t 弹入光驱 将光盘制作成iso文件 cp /dev/sr0 /data/centos7.iso dd if=/dev/sr0 of=/data/centos7.iso mkisofs -r -o etc.iso /etc/ 将目录打包成iso文件 但不能引导 mkdvdiso.sh source /destination/DVD.iso 制作引导光盘 wodim –v –eject centos.iso 刻录光盘 lsusb 查看UBS 文件系统空间占用等信息的查看工具： df [OPTION]... [FILE]... -H：查看分区信息，大小以10^3来计算 -T：文件系统类型 -h: 查看分区信息，大小以2^10来计算 -i：inodesinstead of blocks，节点数使用情况 -P: 对于长格式文件名，以常规方式显示 如果文件名过长，一行会错行变成两行显示，加上-P则会恢复成一行显示 查看某目录总体空间占用状态： du 查看文件大小,列出当前目录下每个子目录的大小，文件大小单位为k,默认递归 du [OPTION]... DIR -h: human-readable -s: summary --max-depth du命令默认递归，使用该选项指定层级 dd 转换和复制文件 用法： dd if=/PATH/FROM/SRC of=/PATH/TO/DEST bs=#：block size, 复制单元大小 count=#：复制多少个bs of=file 写到所命名的文件而不是到标准输出 if=file 从所命名文件读取而不是从标准输入 bs=size 指定块大小（既是是ibs也是obs) ibs=size 一次读size个byte obs=size 一次写size个byte cbs=size 一次转化size个byte skip=blocks 从开头忽略blocks个ibs大小的块 seek=blocks 从开头忽略blocks个obs大小的块 count=n 只拷贝n个记录 conv=conversion[,conversion...] 用指定的参数转换文件 转换参数: ascii转换EBCDIC 为ASCII ebcdic转换ASCII 为EBCDIC lcase把大写字符转换为小写字符 ucase把小写字符转换为大写字符 nocreat不创建输出文件 noerror出错时不停止 notrunc不截短输出文件 sync 把每个输入块填充到ibs个字节，不足部分用空(NUL)字符补齐 备份MBR dd if=/dev/sda of=/tmp/mbr.bak bs=512 count=1 破坏MBR中的bootloader： dd if=/dev/zero of=/dev/sda bs=64 count=1 seek=446 从fileA读取数据128byte写入fileB，从fileA读取数据时，跳过前63byte开始读取；写入fileB时，跳过前31byte开始写入，并且当fileA向fileB文件写入数据结束后，fileB文件内容不会被截断，实现如下： dd if=fileA of=fileB bs=1 count=128 skip=63 seek=31 conv=notrunc 修复硬盘 dd if=/dev/sda of=/dev/sda 当硬盘较长时间（比如1,2年）放置不使用后 磁盘上会产生消磁点。当磁头读到这些区域时会遇到困难 并可能导致I/O错误。 当这种情况影响到硬盘的第一个扇区时可能导致硬盘报废。上边的命令有可能使这些数据起死回生,且这个过程是安全高效的 拷贝内存资料到硬盘 dd if=/dev/mem of=/root/mem.bin bs=1024 从光盘拷贝iso镜像 dd if=/dev/cdrom of=/root/cd.iso 销毁磁盘数据 dd if=/dev/urandom of=/dev/sda1 利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据，执行此操作以后， /dev/sda1将无法挂载，创建和拷贝操作无法执行 备份： dd if=/dev/sdx of=/dev/sdy 将本地的/dev/sdx整盘备份到/dev/sdy dd if=/dev/sdx of=/path/to/image 将/dev/sdx全盘数据备份到指定路径的image文件 dd if=/dev/sdx | gzip &gt;/path/to/image.gz 备份/dev/sdx全盘数据，并利用gzip压缩，保存到指定路径 恢复： dd if=/path/to/image of=/dev/sdx 将备份文件恢复到指定盘 gzip -dc /path/to/image.gz | dd of=/dev/sdx 将压缩的备份文件恢复到指定盘 测试硬盘写速度 dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000 测试硬盘读速度 dd if=/root/1Gb.file bs=64k | dd of=/dev/null]]></content>
  </entry>
  <entry>
    <title><![CDATA[网络配置]]></title>
    <url>%2F2018%2F01%2F%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[基本网络配置将Linux主机接入到网络，需要配置网络相关设置。 一般包括如下内容： 主机名 IP/netmask 路由：默认网关 DNS服务器 主DNS服务器 次DNS服务器 第三DNS服务器 主机名 hostname 注：linux主机名不具备网络功能，windows主机名具备网络功能 /etc/hosts 主机名存放位置 /etc/sysconfig/network centos6系统中主机名配置文件 centos6： 1、临时更改内存中主机名 hostname “主机名” 2、永久保存主机名： 方法1：编辑/etc/sysconfig/network [root@centos6 ~]#vim /etc/sysconfig/network NETWORKING=yes HOSTNAME=centos6.magedu.com 更改后需要重启才能生效 方法2：如果不重启想要生效 (1)hostname 主机名 更改内存中主机名 虽然该命令临时生效重启系统会失效，但是已经把配置文件做过更改，因此重启依然有效 (2)提示符中的主机名仍然没有变动，注销或使用命令exec bash即可更改 centos7： /etc/hostname 该文件是centos7系统主机名配置文件 (1)hostnamectl set-hostname 新主机名 (2)提示符中主机名没有更改，此时需要注销重登或使用exec bash CentOS 6网络管理接口命名方式：CentOS 6 以太网：eth[0,1,2,...] ppp：ppp[0,1,2,...] 网络接口识别并命名相关的udev配置文件： /etc/udev/rules.d/70-persistent-net.rules 查看网卡： dmesg |grep –i eth ethtool -i eth0 卸载网卡驱动： modprobe -r e1000 rmmod e1000 装载网卡驱动： modprobe e1000 静态指定: ifconfig, route, netstat ip: object {link, addr, route}, ss, tc system-config-network-tui，setup 配置文件 动态分配： DHCP: Dynamic Host Configuration Protocol CentOS 7网络配置网卡名称 Centos7：systemd对网络设备的命名方式 a、如果Firware或Bios为主板上集成的设备提供的索引信息可用 且可预测则根据此所以进行命名 例如eno1 b、如果Firware或Bios为主板PCI-E扩展槽所提供提供的索引信息可用 且可预测则根据此所以进行命名 例如ens1 c、如果硬件接口的物理位置信息可用 则根据此信息进行命名 例如enps2s0 d、如果用户显式启动 也可根据MAC地质进行命名 ex334ad23da e、如上述均不可用 则使用传统命名机制 采用传统命令方式： a) 编辑/etc/default/grub配置文件 GRUB_CMDLINE_LINUX=&quot;rhgb quiet net.ifnames=0&quot; 或：修改/boot/grub2/grub.cfg b) 为grub2生成其配置文件 grub2-mkconfig -o /etc/grub2.cfg c) 重启系统 取消传统命名方式 (1)修改/boot/grub2/grub.cfg文件，在第一个linux16行的行尾去掉net.ifnames=0 (2)重启设备即可 CentOS 7网络配置工具: 图形工具：nm-connection-editor 字符配置tui工具：nmtui 命令行工具：nmcli，ip ifconfig命令 ifconfig [interface] 查看启用的网卡信息 ifconfig -a 查看所有网卡信息(包括禁用的网卡) ifconfig IFACE [up|down] 启用|禁用网卡 ifconfig interface [aftype] options | address ... 临时给网卡配置ip地址 ifconfig IFACE IP/netmask [up] ifconfig IFACE IP netmask NETMASK 注意：立即生效 route命令以数字方式查看路由：route -n 添加路由：route add 语法：route add [-net|-host] target [netmask Nm] [gw Gw] [[dev] If] -net：是指网络路由，匹配某个网段 -host：是指主机路由，精确匹配某个ip地址 target：目标地址或网段 gw：gateway，网关 示例： 目标：192.168.1.3 网关：172.16.0.1 route add -host 192.168.1.3 gw 172.16.0.1 dev eth0 目标：192.168.0.0 网关：172.16.0.1 route add -net 192.168.0.0 netmask 255.255.255.0 gw 172.16.0.1 dev eth0 或route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0 添加默认路由，网关：172.16.0.1 route add -net 0.0.0.0 netmask 0.0.0.0 gw 172.16.0.1 或route add default gw 172.16.0.1 删除路由：route del 语法：route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If] 示例： 目标：192.168.1.3 网关：172.16.0.1 route del -host 192.168.1.3 目标：192.168.0.0 网关：172.16.0.1 route del -net 192.168.0.0 netmask 255.255.255.0 启用路由功能暂时开启路由功能(系统重启后值会变回0) echo 1 &gt; /proc/sys/net/ipv4/ip_ipforward 由于是内核文件 重启失效 可以修改/etc/sysctl.conf 使其永久有效 sysctl -p 重新读改过的文件 sysctl -a | grep “ip_forward” 配置动态路由通过守护进程获取动态路由 安装quagga包 支持多种路由协议：RIP、OSPF和BGP 命令vtysh配置 使用linux系统模拟路由器： (1)使用yum安装quagga软件包 (2)cd /etc/quagga 进入quagga文件夹 (3)cp ospfd.conf.sample ospfd.sapmle 根据模板复制配置文件 (4)service ospfd start 开启路由协议 (5)vtysh 开启命令行模式 然后即可模拟路由器(思科)进行配置 netstat显示网络连接 netstat通过遍历proc来获取socket信息 netstat 查看Linux路由表 查看侦听的端口 建立的连接 查看各种协议的统计信息 -t –tcp:查看跟tcp协议相关的连接 -u, –udp:查看跟udp协议相关的连接 -l:查看处于监听状态的连接 -a:查看所有状态下的连接 -n:以数字的格式显示ip和端口号 -p:显示与连接相关的进程的ID -i:显示所有接口的数据统计 常用组合： -tan, -uan, -tnl, -unl 显示路由表： netstat {--route|-r} [--numeric|-n] -r: 显示内核路由表 -n: 数字格式 显示接口统计数据： netstat {--interfaces|-I|-i} [iface] [--all|-a] [--extend|-e] [--program|-p] [--numeric|-n] netstat -i 显示接口信息 netstat –I=IFACE 显示指定的网卡信息 ifconfig -s eth0 显示指定的网卡信息 watch扫描程序执行结果 watch -n0.5 &apos;netstat -i eth0&apos; 监控网卡流量状态(每隔0.5s扫描一次该程序) watch -n0.5 &apos;netstat -I=eth0&apos; 监控指定网卡流量信息(每隔0.5s扫描一次该程序) ip配置Linux网络属性 link：只显示数据链路层地址，即mac地址 addr：对ip地址进行增删改 route：对路由进行更改 ip route add [ip/net|default] via [ip] {dev [if] src ip} ip route del [ip/net|default] ip route flush [dev if] [via] ip route show|list 注意： 配置完成后重启网络服务 route 添加的内容会被刷掉 例： ip route add 192.168.0.0/24 via 172.16.0.1 添加网络路由 ip route add 192.168.1.13 via 172.16.0.1 添加主机路由 ip link set dev device_name {up|down}:将指定的设备开启或关闭 ip link set dev device_name multicast {on|off}:启用或者禁用指定设备的多播功能 ip link set dev device_name name new_name:对指定的设备进行重命名 ip link set dev device_name mtu mtu_number:设置指定设备的MTU大小 ip link set dev device_name {up|down} ip link show:查看所有设备的属性 例：ip link set dev eth1 down ip addr [add|del] ip/mask [dev] [ifac] [label LABEL] ip addr flush dev ifac [label LABEL] ip addr show 将多个IP地址绑定到一个NIC上 eth0:1 、eth0:2、eth0:3 ip addr add 172.16.1.1/16 dev eth0 label eth0:0 给网卡eth0设置别名eth0:0 ip addr del 172.16.1.1/16 dev eth0 label eth0:0 删除网卡别名的ip地址 ip addr flush dev eth0 label eth0:0 删除网卡eth0的全部别名 ifup/ifdown命令依赖于网卡配置文件,linux系统中新增的网卡没有网卡配置文件，因此使用该命令，需要添加网卡的配置文件 ssss使用netlink与内核tcp_diag模块通信获取socket信息。 套接字socket文件：同一个主机两个应用程序发送数据，以套接字文件作为中转站，交换数据 查看建立的连接情况以及状态统计信息 -t:所建立的tcp连接 -u:所建立的udp连接 -n:数字格式显示ip和端口号 -l:查看已经处于监听状态的连接 -w: 裸套接字相关 -x：unix sock相关 -p:显示相关进程的pid -m:各个连接所占用的内存信息 -a:查看所有状态的信息 -e: 扩展的信息 -o：计时器信息 常用组合： -tan, -tanl, -tanlp, -uan ss [OPTION] [state TCP-STATE ] [ EXPRESSION ] TCP-STATE： LISTEN: 监听 ESTABLISHED：已建立的连接 FIN_WAIT_1 FIN_WAIT_2 SYN_SENT SYN_RECV CLOSED EXPRESSION: dport = sport = 示例：&apos;( dport = :ssh or sport = :ssh )&apos; ss -o state established &apos;( dport = :6868 or sport = :6868 )&apos; ss &apos;( dport = :ssh or sport = :ssh )&apos; ss -l 显示本地打开的所有端口 ss -pl 显示每个进程具体打开的socket ss -t -a 显示所有tcp socket ss -u -a 显示所有的UDP Socekt ss -o state established &apos;( dport = :ssh or sport = :ssh )&apos; 显示所有已建立的ssh连接 ss -o state established &apos;( dport = :http or sport = :http )&apos; 显示所有已建立的HTTP连接 ss -s 列出当前socket详细信息 网络配置文件IP、MASK、GW、DNS相关配置文件 /etc/sysconfig/networkscripts/ifcfg-IFACE TYPE=Ethernet BOOTPROTO=none DEFROUTE=yes NAME=ens32 UUID=df737a1c-f1fc-4baf-94ca-d2c82b81b7f3 PEERDNS=yes DEVICE=ens32 ONBOOT=yes IPADDR=192.168.80.40 PREFIX=24 GATEWAY=192.168.80.2 DNS1=192.168.80.2 PEERDNS详解: 当PEERDNS=yes，且BOOTPROTO=dhcp，从dhcp服务器获取一个dns地址，直接覆盖/etc/resolv.conf文件 当PEERDNS=no，且BOOTPROTO=dhcp，从dhcp获取的dns地址，不覆盖/etc/resolv.conf文件，而是由人工指定和维护 相当于windows系统中网卡设置为自动获取，但是dns可以设置为自动获取和手工指定 当dns设置为自动获取即为PEERDNS=yes;当dns设置为手工指定即为PEERDNS=no. 路由相关的配置文件：/etc/sysconfig/networkscripts/route-IFACE 10.0.0.0/8 via 72.167.0.1 或 ADDRESS#= NETMASK#= GATEWAY#= dns：/etc/reslov.conf /etc/hosts相比优先于DNS文件 /etc/nsswitch.conf 更改二者的优先级 正向解析：FQDN--&gt;IP dig -t A FQDN host -t A FQDN 反向解析：IP--&gt;FQDN dig -x IP host -t PTR IP nmclinmcli命令 命令Command 用法Use nmcli dev status 列出所有设备 nmcli con show 列出所有连接 nmcli con up “ethN” 启用网卡 nmcli con down “ethN” 临时禁用网卡；如果ONBOOT=yes，系统重启会重新开启 nmcli con off 禁用所有网卡 nmcli con add… 增加新的网卡 nmcli con mod “ethN” 修改网卡的配置信息 nmcli con del “ethN” 删除网卡 nmcli con mod命令与ifcfg-*文件对应关系 nmcli con mod ifcfg-*文件 ipv4.method manual BOOTPROTO=none ipv4.method auto BOOTPROTO=dhcp ipv4.addresses “192.0.2.1/24 192.0.2.254” IPADDR0=192.0.2.1 PREFIX0=24 GATEWAY0=192.0.2.254 ipv4.dns 8.8.8.8 DNS0=8.8.8.8 ipv4.dns-search example.com DOMAIN=example.com ipv4.ignore-auto-dns true PEERDNS=no connection.autoconnect yes ONBOOT=yes connection.id eth0 NAME=eth0 connection.interface-name eth0 DEVICE=eth0 802-3-ethernet.mac-address… HWADDR… 例： 设备即网络接口，连接是对网络接口的配置。一个网络接口可有多个连接配置，但同时只有一个连接配置生效 显示所有包括不活动连接 nmcli con show 显示所有活动连接 nmcli con show --active 显示网络连接配置 nmcli con show ens32 显示设备状态 nmcli dev status 显示网络接口属性 nmcli dev show eth0 创建新连接eth0，IP自动通过dhcp获取 nmcli con add con-name etho type Ethernet ifname eth0 删除连接 nmcli con del default 创建新连接eth0 ，指定静态IP，不自动连接 nmcli con add con-name eth0 ifname eth0 autoconnect no type Ethernet ipv4.addresses 172.25.X.10/24 ipv4.gateway 172.25.X.254 启用static连接配置 nmcli con up eth0 查看帮助 nmcli con add help 修改连接设置 nmcli con mod eth0 connection.autoconnect no nmcli con mod eth0 ipv4.dns 172.25.X.254 nmcli con mod eth0 +ipv4.dns 8.8.8.8 nmcli con mod eth0 -ipv4.dns 8.8.8.8 nmcli con mod eth0 ipv4.addresses “172.25.X.10/24 172.25.X.254” nmcli con mod eth0 +ipv4.addresses 10.10.10.10/16 DNS设置，存放在/etc/resolv.conf文件中 PEERDNS=no 表示当IP通过dhcp自动获取时，dns仍是手动设置，不自动获取。 等价于下面命令： nmcli con mod eth0 ipv4.ignore-auto-dns yes 设备别名为每个设备别名生成独立的接口配置文件 关闭NetworkManager服务 ifcfg-ethX:xxx 必须使用静态联网 DEVICE=eth0:0 IPADDR=10.10.10.10 NETMASK=255.0.0.0 ONPARENT=yes 注意：service network restart 生效 参考：/usr/share/doc/initscripts-*/sysconfig.txt 注意：网卡别名配置文件ifcfg-ethX:xxx必须使用静态地址，而网卡主配置文件ifcfg-ethX既能使用自动获取的ip地址，又能使用静态地址，但如果该网卡存在别名，则必须使用自动获取的ip地址 网络接口配置-bondingBonding 将多块网卡绑定同一IP地址对外提供服务，可以实现高可用或者负载均衡。直接给两块网卡设置同一IP地址是不可以的。通过bonding，虚拟一块网卡对外提供连接，物理网卡的被修改为相同的MAC地址 Bonding工作模式： Mode 0 (balance-rr) 轮询（Round-robin）策略：两个网卡同时工作，两个网卡交替传输数据。本模式提供负载均衡和容错的能力 Mode 1 (active-backup) 活动-备份（主备）策略：只有一个网卡被激活，当活动的网卡失败时才会激活其他网卡。为了避免交换机发生混乱此时绑定的MAC地址只有一个外部端口上可见 Mode 3 (broadcast) 广播策略：在所有的网卡上同一时间传送同样的数据,提供容错能力 active-backup、balance-tlb 和 balance-alb模式不需要交换机的任何特殊配置。其他绑定模式需要配置交换机以便整合链接。如：Cisco 交换机需要在模式 0、2 和 3 中使用 EtherChannel，但在模式4中需要LACP和 EtherChannel 方法一： 创建bonding设备的配置文件 /etc/sysconfig/network-scripts/ifcfg-bond0 DEVICE=bond0 IPADDR=X.X.X.X PREFIX=XX BOOTPROTO=none BONDING_OPTS= “miimon=100 mode=0” 创建被绑定的网卡设备的配置文件 /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 BOOTPROTO=none MASTER=bond0 SLAVE=yes USERCTL=no /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1 BOOTPROTO=none MASTER=bond0 SLAVE=yes USERCTL=no 注意：配置文件创建完成后，需要重启网络服务才能生效 miimon 是用来进行链路监测的。 如果miimon=100，那么系统每100ms监测一次链路连接状态，如果有一条线路不通就转入另一条线路 查看bond0状态：/proc/net/bonding/bond0 删除Bond ifconfig bond0 down 禁用bond0网卡 rmmod bonding 卸载绑定网卡的驱动程序 rm -rf ifconfig-bond0 删除bond0网络配置文件 方法二：nmcli实现bonding 添加bonding接口 nmcli con add type bond con-name mybond0 ifname mybond0 mode active-backup 添加从属接口 nmcli con add type bond-slave ifname ens7 master mybond0 nmcli con add type bond-slave ifname ens3 master mybond0 注：如无为从属接口提供连接名 则该名称是接口名称加类型构成 要启动绑定 则必须首先启动从属接口 nmcli con up bond-slave-eth0 nmcli con up bond-slave-eth1 启动绑定 nmcli con up mybond0 网络组Network Teaming网络组：是将多个网卡聚合在一起方法，从而实现冗错和提高吞吐量 网络组不同于旧版中bonding技术，提供更好的性能和扩展性 网络组由内核驱动和teamd守护进程实现. 多种方式runner broadcast 广播模式 roundrobin 轮询模式 activebackup 主备模式 loadbalance 负载均衡模式 lacp (implements the 802.3ad Link Aggregation Control Protocol) 网络组规则 启动网络组接口不会自动启动网络组中的port接口 启动网络组接口中的port接口总会自动启动网络组接口 禁用网络组接口会自动禁用网络组中的port接口 没有port接口的网络组接口可以启动静态IP连接 启用DHCP连接时，没有port接口的网络组会等待port接口的加入 方法一： nmcli connection add type team ifname team0 con-name team0 config {&quot;runner&quot;:{&quot;name&quot;:&quot;activebackup&quot;}} nmcli connection modify team0 ipv4.addresses 172.12.12.0/24 nmcli connection modify team0 ipv4.method manual nmcli connection add type team-slave ifname eth1 con-name team0-1 master team0 nmcli connection add type team-slave ifname eth2 con-name team0-2 master team0 systemctl restart network teamdctl team0 state; nmcli dev dis eth1 查看网络组team0状态 方法二： cp /usr/share/doc/teamd-1.27/example_ifcfgs/1/* /etc/sysconfig/network-scripts/ 网络组team0配置文件 /etc/sysconfig/network-scripts/ifcfg-team0 DEVICE=team0 DEVICETYPE=Team TEAM_CONFIG=&quot;{&quot;runner&quot;: {&quot;name&quot;: &quot;broadcast&quot;}}&quot; BOOTPROTO=none IPADDR0=172.25.5.100 PREFIX0=24 NAME=team0 ONBOOT=yes 网络组port接口team0-eth*配置文件 /etc/sysconfig/network-scripts/ifcfg-team0-eth1 DEVICE=eth1 DEVICETYPE=TeamPort TEAM_MASTER=team0 NAME=team0-eth1 ONBOOT=yes systemctl restart network teamdctl team0 state 删除网络组 (1)禁用网络组team0 nmcli connection down team0 (2)查看网络组team0状态 teamdctl team0 state nmcli connection show (3)删除网络组port接口team0-port0，team0-port1 nmcli connectioni delete team0-eth0 nmcli connectioni delete team0-eth1 (4)查看网络状态 nmcli connection show 测试网络工具在命令行下测试网络的连通性 显示主机名 hostname 测试网络连通性 ping mtr 显示正确的路由表 ip route 确定名称服务器使用： nslookup host dig 跟踪路由 traceroute tracepath 网络客户端工具 ftp，lftp：子命令：get、mget、ls、help wget [option]... [URL]... 可用于下载网络服务器上的文件，支持http，ftp协议，后跟文件完整路径， 如：wget http://172.20.0.1/pub/file1 -q: 静默模式 -c: 断点续传 -P：保存在指定目录 -O: 保存为指定的文件名 --limit-rate=: 指定传输速率，单位K,M等]]></content>
  </entry>
  <entry>
    <title><![CDATA[用户、组管理]]></title>
    <url>%2F2018%2F01%2F%E7%94%A8%E6%88%B7%E3%80%81%E7%BB%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[模型Authentication 认证 Authorization 授权 Accouting | Auditin 审计 用户user配置文件/etc/default/useradd 每个用户都有一个唯一uid user都一个家目录 /home/ 管理员 root ：0 普通用户 ： 系统用户： 1-499 centos6 1-999 centos7 登录用户： 500+ centos6 1000+ centos7 用户组 group管理员组 ：root 0 普通组：gid 系统组： 1-499 centos6 1-999 centos7 普通组： 500+ centos6 1000+ centos7 组类别： 优先使用基本组 用户只能属于一个基本组 用户的默认组 主组：用户必须属于一个且只有一个主组 附加组：一个用户可以属于零个或多个附加组 私有组 创建用户时如果没有指定基本组 系统会创建和用户同名的一个组 /etc/group (users::20:root,sam 组名:口令:组标识号:组内用户列表) 用户和组的配置文件/etc/passwd：用户及其属性信息(名称、UID、主组ID等） /etc/group：组及其属性信息 /etc/shadow：用户密码及其相关属性 /etc/gshadow：组密码及其相关属性，极少情况下为Group设密码 passwd文件格式root:x:0:0:root:/root:/bin/bash login name：登录用名（wang） passwd：密码 (x) UID：用户身份编号 (1000) GID：登录默认所在组编号 (1000) GECOS：用户全名或注释 home directory：用户主目录 (/home/wang) shell：用户默认使用shell (/bin/bash) shadow文件格式tom:$6$7I175sndgdfg:17800:0:99999:7::: 登录用名 用户密码:一般用sha512加密 从1970年1月1日起到密码最近一次被更改的时间 密码再过几天可以被变更（0表示随时可被变更） 密码再过几天必须被变更（99999表示永不过期） 密码过期前几天系统提醒用户（默认为一周） 密码过期几天后帐号会被锁定 从1970年1月1日算起，多少天后帐号失效 密码策略查看用户密码加密类型 /etc/login.defs md5 128位 修改加密方式不需要之前密码加密方式 更改加密算法： authconfig --passalgo=sha256 -–update 显示passwd密码 pwunconv 隐藏passwd密码 pwconv 明文加密 grub2-mkpasswd-pbkdf2 产生随机数openssl rand -base64 10 echo | openssl passwd -stdin head -c 32 /dev/random | base64 head -c 32 /dev/urandom | base64 head -c 32 /dev/urandom | md5sum |head -c 8 echo $RANDOM 用户默认策略/etc/login.defs 用户密码策略 /etc/default/useradd 这个文件可以修改新建用户的默认属性 /etc/skel 家目录模板 cp /etc/skel/ /home/user -a cp -r /etc/skel/.[^.]* /home/USER 恢复删除家目录 用户管理命令用户过期时间（MD5 $1;sha512 $6） 用户创建useradd [options] LOGIN -r 创建系统账户，CentOS 6: ID&lt;500，CentOS 7: ID&lt;1000 -N 不创建与用户同名的基本用户组 -m 强制创建家目录 -M 不创建家目录，用于非系统用户 -s 指定用户的shell -d 指定用户的家目录 -k 指定/etc/skel文件 -u 指定用户uid -g 指定用户gid -G 添加指定用户的附加组，组须事先存在 -o 忽略uid的检查，配合-u 选项 用户属性修改usermod [OPTION] login -c 填写用户账户的备注信息 -d -m 参数-m与参数-d连用 可重新指定用户的家目录并自动把旧的数据转移过去 -e 账户的到期时间 格式为YYYY-MM-DD -g 变更所属用户组 -G 新附加组，原来的附加组将会被 覆盖；若保留原有，则要同时使用-a选项 -L 锁定用户禁止其登录系统 -U 解锁用户 允许其登录系统 -s 变更默认终端 -u 修改用户的UID -f INACTIVE: 设定非活动期限 设置密码passwd [OPTIONS] UserName -d 删除用户密码 -l 锁定用户 -u 解锁用户 -e 强制用户下次登陆更改密码 -S 显示用户密码锁定状态 及加密算法 -n mindays：指定最短使用期限 -x maxdays：最大使用期限 -w warndays：提前多少天开始警告 -i inactivedays：非活动期限 --stdin 标准输入修改用户密码 如echo &quot;New&quot; | passwd --stdin Username 修改用户密码策略chage [OPTION]... LOGIN -d 设置最近一次更改密码时间 -E 设置账户过期时间 -I 设置密码过期时间 -l --list 列出用户账户密码信息 -m 设置用户最短密码使用时间 -M 设置用户最常密码使用时间 -W 设置密码更改警告时间 示例： chage -d 0 tom 下一次登录强制重设密码 chage -m 0 –M 42 –W 14 –I 7 tom chage -E 2016-09-10 tom 其他命令1.userdel -r 删除家目录 2.chsh 改变登陆shell 3.chfn 改变用户描述信息 vipw 直接打开/etc/passwd文件 4.finger 查看用户描述信息 安装使用 rpm -ivh finger-0.17-52.el7.x86_64.rpm 5.pwck 检查用户完整性 6.newusers 批量创建用户 7.chpasswd 批量创建用户密码 批量创建用户 user001:x:600:100:user:/home/user001:/bin/bash 1.newusers &lt; user.txt 2.pwunconv 将shadow密码解码 回写到/etc/passwd中 将shadow中密码删掉 3.chpasswd &lt; passwd.txt 8.pwconv 将密码编码到shadow中 9.给文件加锁!以免在编辑文件时！其他用户也在同时使用文件！而造成其他用户修改的不成功 vipw 修改/etc/passwd文件 vipw –s 修改/etc/shadow文件 管理组命令创建组groupadd [OPTION]... group_name -g 指明GID -r 创建系统组 groups 显示组,查看用户所属组列表 组属性修改groupmod [OPTION]... group -n group_name: 新名字 -g GID: 新的GID 组删除groupdel GROUP 更改组密码gpasswd [OPTION] GROUP -a ：将用户添加至组中 -d ：将用户从组中删除 -A ：设置组的管理员 newgrp命令：临时切换主组 如果用户本不属于此组，则需要组密码 更改和查看组成员groupmems -a ：指定用户加入组 -g ：更改为指定GID -d ：从组中删除用户 -l：显示组成员列表 -p :从组中清除所有成员 其他命令grpck 检查组完整性 vigr 修改/etc/groups文件 vigr –s 修改/etc/gshadow文件 示例： 1.解决用userdel删除不掉用户的问题 一般我们移除，都是先把用户从组中删除，再依次把组删掉，但是这里出现了问题： root@ per# userdel -r mysql userdel： user mysql is currently used by process 1748 root@ per# groupdel mysql groupdel：不能移除用户“mysql”的主组 删除该用户就提醒用户当前在进程运行，删除他的组也报错。 解决方法： 可使用vipw命令： # vipw 找到之前创建的用户，用dd删除那行（记得保存：wq or ：x）。 # vipw -s 找到那个用户所属组，也dd干掉即可（记得保存：wq or ：x） 使用vipw -s的原因只有一个，就是必须保证数据的一致性，不然可能会造成系统崩溃等问题 2.恢复家目录 # cp /etc/skel/ /home/wangcai -a ·# ls -al ··# chmod 700 wangcai/]]></content>
  </entry>
  <entry>
    <title><![CDATA[标准IO和管道]]></title>
    <url>%2F2018%2F01%2F%E6%A0%87%E5%87%86IO%E5%92%8C%E7%AE%A1%E9%81%93%2F</url>
    <content type="text"><![CDATA[三种I/O设备打开的文件都有一个fd: file descriptor (文件描述符) 查看文件描述符： (1)在一个窗口随便打开一个文件或程序 [root@centos7 ~]#vim /etc/fstab (2)在另外一个窗口查看该进程的进程号 [root@admin ~]# ps aux | grep vim root 12205 0.1 1.1 151708 5288 pts/0 S+ 17:32 0:00 vim /etc/fstab (3)查看文件描述符 ll /proc/12205/fd linux给程序提供三种I/O设备 标准输入（STDIN）－0 默认接受来自键盘的输入 标准输出（STDOUT）－1 默认输出到终端窗口 标准错误（STDERR）－2 默认输出到终端窗口 I/O重定向：改变默认位置 管道重定向管道技术 1.在管道后面的命令 都不应该再跟文件名 2.在管道中只有标准输出才传递给下一个命令 标准错误输出直接输出到终端 可以把标准错误输出给重定向 find /etc -name &quot;*.conf&quot; 2&gt; /dev/null | grep rc 3.有些命令不支持管道技术 xargs让ls支持管道技术 [han@WebServer ~]$ which cat | xargs ls -l ls | tee [-a ] 1.txt 把命令1保存到文件并显示，输入给命令2 重定向 标准输入（STDIN）－0 默认接受来自键盘的输入 标准输出（STDOUT）－1 默认输出到终端窗口 标准错误（STDERR）－2 默认输出到终端窗口 &amp;&gt; 覆盖重定向 &amp;&gt;&gt;追加重定向 &gt;文件内容会被覆盖 &gt;&gt; 原有内容基础上，追加内容 2&gt; 覆盖重定向错误输出数据流 2&gt;&gt; 追加重定向错误输出数据流 set –C 禁止将内容覆盖已有文件,但可追加 set +C 允许覆盖 &gt;| 强制覆盖 &lt;&lt;终止词:把多行发送给STDIN，即多行内容重定向,直到终止词位置的所有文本都发送给STDIN,被称为就地文本（heretext） 示例： 把错误信息放一个文件夹，正确信息放一个文件夹 ls /data/ &gt; a.txt 2&gt;b.txt 把所有的输出信息全部放在一个文件夹 ls /data/ &amp;&gt; a.tt 2&amp;&gt;1是把错误信息输出为正确信息 ls /data/ &gt; c.txt 2&amp;&gt;1 把多个命令重定向到文件里 (ls;ll) &gt; d.txt 把file文件内容输入给cat命令 按ctrl+d离开，可以使用文件来代替键盘的输入 把filea文件内容输入给cat，然后把cat结果重定向到fileb文件 Cat &gt; filea &lt; fileb 终止词后不能有空格 mail -s &quot;Please Call&quot; admin@ma.com &lt;&lt;END &gt; 123 &gt; END 1加到100 echo {1..100} |tr &apos; &apos; +|bc]]></content>
  </entry>
  <entry>
    <title><![CDATA[管理软件]]></title>
    <url>%2F2018%2F01%2F%E7%AE%A1%E7%90%86%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[软件包分类Debian dpkg 软件包管理器 能够实现软件包安装卸载 必须组织成一定的格式 deb格式 使用dpkg管理deb包 dpkg 归档文件 能够查找 删除软件 myprog守护进程 依赖用户 安装程序创建用户 卸载程序删除用户 触发式脚本 实现自动化管理 apt-get 能够解决deb依赖关系 查看Linux内核 uname 查看linux操作系统版本和CPU类型 -a, --all 如下次序输出所有信息。其中若-p 和-i 的探测结果不可知则被省略 -s, --kernel-name 输出内核名称 -n, --nodename 输出网络节点上的主机名 -r, --kernel-release 输出内核发行号 -v, --kernel-version 输出内核版本 -m, --machine 输出主机的硬件架构名称 -p, --processor 输出处理器类型或&quot;unknown&quot; -i, --hardware-platform 输出硬件平台或&quot;unknown&quot; -o, --operating-system 输出操作系统名称 rpm管理1.rpm选项: -ivh 安装并显示进度 -Uvh（安装）升级 -fvh（存在）升级 -evh卸载 –qa 查询安装所有的软件 -qi 查看软件详细信息 -ql 查看软件生成的文件 -qc 查看配置文件位置 -qd 查看帮助文件位置 -qs 显示软件安装的文件所有状态 -qf 查看文件由哪个程序安装 -q –script 查看安装包相关脚本 [install-options] --root=/path 指定安装的程序包的目录 --test 测试安装 --nodeps 忽略依赖关系 --replacepkgs | replacefiles --force 重装 覆盖配置文件 强制安装 --nodiget 不检查包完整性 --noscripts 不检查程序安装包 --oldpackage 降级 查询未安装的软件包会产生哪些文件 rpm -qlp http.rpm 查看未安装软件包详细信息 rpm -qip http.rpm 2.包检验： [root@server ~]# #rpm -V mailx S.5....T. c /etc/mail.rc S ：(file Size differs) 文件的容量大小是否被改变 M ：(Mode differs) 文件的类型或文件的属性 (rwx) 是否被改变？如是否可运行等参数已被改变 5 ：(MD5 sum differs) MD5 这一种指纹码的内容已经不同 D ：(Device major/minor number mis-match) 装置的主/次代码已经改变 L ：(readLink(2) path mis-match) Link 路径已被改变 U ：(User ownership differs) 文件的所属人已被改变 G ：(Group ownership differs) 文件的所属群组已被改变 T ：(mTime differs) 文件的创建时间已被改变 3.导入所需要公钥 rpm -K 检查包的完整性和签名 rpm -K –nodigest *.rpm 只检测软件包签名 rpm -K –nosignature *.rpm 只检测软件完整 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 CentOS 7 发行版光盘提供：RPM-GPG-KEY-CentOS-7 rpm -qa &quot;gpg-pubkey*&quot; 4.数据库重建 /var/lib/rpm rpm --initdb |--rebuilddb initdb: 初始化 如果事先不存在数据库，则新建之 否则，不执行任何操作 rebuilddb：重建已安装的包头的数据库索引目录 5.rpm解包 rpm2cpio PACKAGE_FILE | cpio -idv [file] 释放包内文件 rpm2cpio 包文件|cpio –itv 预览包内文件 6.rpm包升级 rpm {-U|--upgrade} [install-options] PACKAGE_FILE... rpm {-F|--freshen} [install-options] PACKAGE_FILE... upgrade：安装有旧版程序包，则“升级” 如果不存在旧版程序包，则“安装” freshen：安装有旧版程序包，则“升级” 如果不存在旧版程序包，则不执行升级操作 rpm -Uvh PACKAGE_FILE ... rpm -Fvh PACKAGE_FILE ... --oldpackage：降级 --force: 强制安装 注意： (1) 不要对内核做升级操作；Linux支持多内核版本并存 因此 对直接安装新版 本内核 (2) 如果原程序包的配置文件安装后曾被修改升级时新版本的提供的同一个配置文件并不会直接覆盖老版本的配置文件 而把新版本的文件重命名 (FILENAME.rpmnew)后保留 yumyum客户端配置文件： 日志 ：/var/log/yum.log /etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 仓库指向的定义： [repositoryID] name=Some name for this repository baseurl=url://path/to/repository/ enabled={1|0} gpgcheck={1|0} gpgkey=URL enablegroups={1|0} failovermethod={roundrobin|priority} roundrobin：意为随机挑选，默认值 priority:按顺序访问 cost= 默认为1000 yum 仓库创建yum仓库： createrepo [options] 注意：自研的软件，想要创建yum仓库，制作自定义yum仓库，即根据rpm包创建repodata (1)先把rpm包放入一个目录中，进入软件包目录中 (2)使用命令 createrepo . (3)生成repodata文件 (4)根据路径指定路径，创建yum仓库 可用yum源： 阿里云repo文件： http://mirrors.aliyun.com/repo/ CentOS系统的yum源 阿里云：https://mirrors.aliyun.com/centos/$releasever/os/x86_64/ 清华大学：https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/x86_64/ EPEL的yum源: 阿里云：https://mirrors.aliyun.com/epel/$releasever/x86_64 yum-config-manageryum-config-manager --disable “仓库名&quot; 禁用仓库 yum-config-manager --enable “仓库名” 启用仓库 生成.repo文件 yum-config-manager --add-repo= http://172.16.0.1/cobbler/ks_mirror/7/ yum 命令1.安装 yum install package1 安装指定的安装包package1 yum groupinsall group1 安装程序组group1 --nogpgcheck：禁止进行gpg check -y: 自动回答为“yes” -q：静默模式 --disablerepo=repoidglob：临时禁用此处指定的repo --enablerepo=repoidglob：临时启用此处指定的repo --noplugins：禁用所有插件 2.更新和升级 yum update 全部更新 yum update package1 更新指定程序包package1 yum check-update 检查可更新的程序 yum upgrade package1 升级指定程序包package1 yum groupupdate group1 升级程序组group1 3.查找和显示 yum info package1 显示安装包信息package1 yum list 显示所有已经安装和可以安装的程序包 yum list package1 显示指定程序包安装情况package1 yum groupinfo group1 显示程序组group1信息 包组列表中 软件包前没有任何符号，表示已经安装，且不是通过包组安装，是独立安装的 = 软件已经安装，是随着包组安装的 + 软件包没有安装，会随着包组自动安装 - 软件包没有安装，不会随着包组一块安装 yum search string 根据关键字string查找安装包 yum deplist package1 查看程序package1依赖情况 yum provides 列出软件包提供哪些文件 4.删除程序 yum remove | erase package1 删除程序包package1 yum groupremove group1 删除程序组group1 5.清除缓存 yum clean packages 清除缓存目录下的软件包 yum clean headers 清除缓存目录下的 headers yum clean oldheaders 清除缓存目录下旧的 headers yum clean, yum clean all yum5. 编译安装 C\C++：make项目管理 configure脚本 --&gt; Makefile.in --&gt; Makefile C语言源代码编译三步骤 1. ./configure脚本 (1)传递相应的参数 指定启用特性等 生成相应的Makefile (2)检查依赖的软件包 2. Make 3. Makeinstll 例： 1、安装开发包组 yum -y groupinstall &quot;development tools&quot; 2、安装源码编译http服务所需的依赖包(所需依赖包并不固定，在编译安装过程中根据提示进行安装) yum -y install apr-devel apr-util-devel pcre-devel openssl-devel 3、进入源码包所在目录，解压http源码包 cd /root tar -xvf httpd-2.4.25.tar.gz 4、进入已解压http源码包目录 cd httpd-2.4.25 5、以下开始源码编译三步骤： (1)指定http服务安装目录，配置文件安装目录以及开启ssl加密特性 ./configure --prefix=/app/httpd --sysconfdir=/etc/httpd2 --enable-ssl (2)make -j (3)make install 6、将apachectl所在目录加入PATH变量，在系统任何目录即可开启此服务 echo &apos;PATH=/app/httpd/bin:$PATH&apos; &gt; /etc/profile.d/httpd.sh 7、启动apache服务，关闭防火墙 apachectl start iptables -F 8、登录服务地址，进行测试]]></content>
  </entry>
  <entry>
    <title><![CDATA[网络基础]]></title>
    <url>%2F2018%2F01%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[网络基础PDU: Protocol Data Unit,协议数据单元是指对等层次之间传递的数据单位 CSMA/CD 载波多路访问/冲突检测 在 OSI 的第二层数据链路层 原理简单总结为：先听后发 边发边听 冲突停发 随机延迟后重发 集线器HUB 属于一层设备 所有端口在冲突域 以太网桥 交换机 属于二层设备 隔绝冲突域 通过mac地址进行通信 路由器 属于三层设备 分隔广播域 选择路径转发数据包 网络层次结构 TCP/IP模型与OSI模型TCP/IP是一个Protocol Stack，包括TCP、IP、UDP、ICMP、RIP、TELNET、FTP、SMTP、ARP等许多协议 和ISO参考模型的分层有对应关系 应用层：为各种应用提供服务,见应用层的网络服务协议有：HTTP，HTTPS，FTP，POP3、SMTP等。 表示层：对数据进行解密和压缩,编码和转换功能 会话层：建立数据传输的通道 建立会话 传输层： 为上层协议提供端到端的可靠和透明的数据传输服务,利用传输协议和端口,对数据进行分段和传输,到达目的地址进行重组,包括处理差错控制和流量控制等问题。 该层向高层屏蔽了下层数据通信的细节，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。 我们通常说的，TCP UDP就是在这一层。 PDU叫做段 segment 网络层：对接收的数据进行IP的解封与封装 PDU叫做包 packet 数据链路层：对接收的数据进行MAC解封与封装 PDU叫做帧 frame 数据链路层又分为2个子层：逻辑链路控制子层（LLC）和媒体访问控制子层（MAC）。 MAC子层处理CSMA/CD算法、数据出错校验、成帧等 LLC子层定义了一些字段使上次协议能共享数据链路层。 在实际使用中，LLC子层并非必需的 物理层：编码为0 1的比特流 介质位数据的传输 PDU是bit 下层为上层提供服务 帧结构：8位前导符 6位目的MAC 6位源MAC 2位类型 （46~1500字节 Data） 4位FCS 通信特点：对等通信 工作原理 TCPTCP特性： 工作在传输层 面向连接协议 全双工协议 半关闭 错误检查 将数据打包成段，排序 确认机制 数据恢复，重传 流量控制，滑动窗口 拥塞控制，慢启动和拥塞避免算法 tcp：传输控制协议 面向连接协议 0-65536 0-1023系统分配或特权端口 1024-49151用户或注册端口 49152-65535动态端口。客户端随机使用端口 定义：/proc/sys/net/ipv4/ip_local_port_range TCP包头 1、端口号：用来标识同一台计算机的不同的应用进程。 1）源端口：源端口和IP地址的作用是标识报文的返回地址。 2）目的端口：端口指明接收方计算机上的应用程序接口。 TCP报头中的源端口号和目的端口号同IP数据报中的源IP与目的IP唯一确定一条TCP连接。 2、序号和确认号：是TCP可靠传输的关键部分。 表示本报文段所发送数据的第一个字节的编号。在TCP连接中所传送的字节流的每一个字节都会按顺序编号。 由于序列号由32位表示，所以每2^32个字节，就会出现序列号回绕，再次从0开始,建立连接时，SYN报文的ACK标志位为0 3、数据偏移：4bits,表示TCP报文段的首部长度 由于首部可能含有可选项内容，因此TCP报头的长度是不确定的，报头不包含任何任选字段则长度为20字节， 4位首部长度字段所能表示的最大值为1111，转化为10进制为15，15*32/8 =60 所以数据偏移也就是TCP首部最大60字节 首部长度也叫数据偏移，是因为首部长度实际上指示了数据区在报文段中的起始偏移值。 4、保留：为将来定义新的用途保留，现在一般置0。 5、控制位：URG ACK PSH RST SYN FIN，共6个，每一个标志位表示一个控制功能。 1）URG：紧急指针标志，URG=1时表示紧急指针有效，为0则忽略紧急指针。 2）ACK：确认序号标志，ACK=1时表示确认号有效，为0表示报文中不含确认信息，忽略确认号字段。 3）PSH：push标志，PSH=1表示是带有push标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队。 4）RST：重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请求。 5）SYN：同步序号，用于建立连接过程，在连接请求中，SYN=1和ACK=0表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即SYN=1和ACK=1。 6）FIN：finish标志，用于释放连接，FIN=1时表示发送方已经没有数据发送了，即关闭本方数据流。 6、窗口：滑动窗口大小 用来告知发送端接受端的缓存大小，以此控制发送端发送数据的速率，从而达到流量控制 窗口大小时一个16bit字段，因而窗口大小最大为65535。 7、校验和：奇偶校验 此校验和是对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得 由发送端计算和存储，并由接收端进行验证。 8、紧急指针：只有当 URG=1时紧急指针才有效。 紧急指针是一个正的偏移量，和顺序号字段中的值相加表示紧急数据最后一个字节的序号 TCP的紧急方式是发送端向另一端发送紧急数据的一种方式。 9、选项和填充：最常见的可选字段是最长报文大小，又称为MSS（Maximum Segment Size） 每个连接方通常都在通信的第一个报文段（为建立连接而设置SYN=1的那个段）中指明这个选项，它表示本端所能接受的最大报文段的长度。 选项长度不一定是32位的整数倍，所以要加填充位，即在这个字段中加入额外的零，以保证TCP头是32的整数倍。 10、数据部分： TCP报文段中的数据部分是可选的。 在一个连接建立和一个连接终止时，双方交换的报文段仅有TCP首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。 在处理超时的许多情况中，也会发送不带任何数据的报文段。 11.紧急指针：标记紧急数据在数据字段中的位置 12.选项部分：其最大长度可根据TCP首部长度进行推算。TCP首部长度用4位表示，选项部分最长为：(2^4-1)*4-20=40字节 常见选项： 最大报文段长度：Maxium Segment Size，MSS，通常1460字节 窗口扩大：Window Scale 时间戳： Timestamps MSS （Maximum Segment Size） 最大报文段长度 数据字段的长度加上TCP首部的长度才等于整个TCP报文段的长度。 MSS不宜设的太大也不宜设的太小。若选择太小，极端情况下，TCP报文段只含有1字节数据，在IP层传输的数据报的开销至少有40字节（包括TCP报文段的首部和IP数据报的首 部）。这样，网络的利用率就不会超过1/41。 若TCP报文段非常长，那么在IP层传输时就有可能要分解成多个短数据报片。在终点要把收到的各个短数据报片装配成原来的TCP报文段。当传输出错时还要进行重传，这些也都会使开销增大。 因此 MSS应尽可能大，只要在IP层传输时不需要再分片就行。 在连接建立过程中，双方都把自己能够支持的MSS写入这一字段。 MSS只出现在SYN报文中。即：MSS 出现在SYN=1的报文段中 MTU和MSS值的关系：MTU=MSS+IP Header+TCP Header 1500=1460+20+20 窗口扩大 为了扩大窗口，由于TCP首部的窗口大小字段长度是16位，所以其表示的最大数是 65535。 但是随着时延和带宽比较大的通信产生（如卫星通信），需要更大的窗口来满足性能和吞吐率，所以产生了这个窗口扩大选项 时间戳 可以用来计算RTT(往返时间)，发送方发送TCP报文时，把当前的时间值放入时间 戳字段，接收方收到后发送确认报文时，把这个时间戳字段的值复制到确认报文中， 当发送方收到确认报文后即可计算出RTT。 也可以用来防止回绕序号PAWS，也可以说可以用来区分相同序列号的不同报文。因为序列号用32为表示，每2^32个序列号就会产生回绕，那么使用时间戳字段就很容易区分相同序列号的不同报文 TCP三次握手 a) client发送SYN=1 初始序列号seq=x的数据包到server client进入SYN_SENT状态 b) server收到数据包后 同时发送一个ACK=1,SYN=1,随机seq=y,ack=x+1的确认链接请求数据包到client 由LISTEN状态进入SYN_RCVD状态 c) client收到确认包后 进入ESTABLISHED状态 并发送ACK=1 ack=y+1,seq=y+1的确认包到server server收到后进入ESTABLISHED状态 TCP四次握手： a) client发送FIN=1释放链接请求包到server 进入FIN_WAIT1状态 b) server收到FIN请求包 发送ACK=1确认包给client 进入CLOSE_WAIT状态 c) server发送FIN=1数据包 关闭server与client数据传输 进入LAST_ACK状态 d) client收到FIN数据包 发送ACK=1数据包到server server进入CLOSED状态；client由FIN_WAIT2状态进入TIME_WAIT状态 并等待2MSL（TCP报文段在网络的生存时间）关闭 孤儿连接：如果不是为了在半关闭状态接受数据,client长时间停留在FIN_WAIT2状态并无益处 client执行半关闭后 未等服务器关闭连接就退出 此时client的连接由内核接受 防止长时间留在内核 /proc/sys/net/ipv4/tcp_max_orphans 指定内核接管孤儿连接数目 /proc/sys/net/ipv4/tcp_fin_timeout 指定孤儿连接在内核中生存的时间 TCP端口的十一种连接状态 TCP端口一共有十一种状态，CLOSE_WAIT表示是程序y关闭连接，而TIME_WAIT只占用一个socket连接，到时间之后会释放，因此大量的CLOSE_WAIT是比大量的TIME_WAIT影响更大，另外还有FIN_WAIT1和FIN_WAIT2，如果有FIN_WAIT2也表示服务有问题 以下是每个端口状态的含义： 1：CLOSED：端口默认是关闭状态。 2：LISTEN： 服务器程序开始监听一个端口，就是LISTEN状态。 3：SYN_RCVD：三次握手的第二次握手后的端口状态，是收到了客户端发送的SYN_SENT数据包之后的状态，这个状态很 短暂，正常在服务器上是很少看到的，除非服务器故意不发送最后一次握手数据包，服务器返回给客户端SYN确认之后就 会将在自己的端口置为SYN_RCVD。 4：SYN_SENT：SYN_SENT状态表示客户端已发送SYN=1的请求连接报文，发送之后客户端就会将自己的端口状态置为SYN_SENT。 5：ESTABLISHED：表示已经连接成功，客户端收到服务器的确认报文会回复服务器，然后就将端口置为ESTABLISHED， 服务器第三次收到客户端的Ack确认就会将端口置为ESTABLISHED并开始传输数据。 6：FIN_WAIT_1：出现在主动关闭方，FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，当任意一方想主动 关闭连接，向对方发送了FIN=1的断开连接请求报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文 后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马 上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 7：FIN_WAIT_2：出现在主动关闭方，当被动方回应FIN_WAIT_1的ACK报文后，则进入到FIN_WAIT_2状态 8：TIME_WAIT：出现在主动关闭方，表示收到了对方的FIN请求关闭报文，并发送出了ACK报文，就等2MSL后即可回到 CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到 TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 9：CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送 FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你 发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什 么情况下会出现此种情况呢？其实细 想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报 文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。 10：CLOSE_WAIT： 表示在等待关闭端口，这种状态存在于被动关闭的一方。 11：LAST_ACK： 是被动关闭方在主动关闭一方在发送FIN报文后，最后等待对方的ACK报文，当再次收到ACK报文后，也即可以进入到CLOSED可用状态了。 12：区分主动断开和被动端口方的端口状态： 主动端口方：SYN_SENT、FIN_WAIT1、FIN_WAIT2、CLOSING、TIME_WAIT 。 被动断开方：LISTEN、SYN_RCVD、CLOSE_WAIT、LAST_ACK 。 都具有的：CLOSED 、ESTABLISHED 。 拓展1.为什么连接建立需要三次握手 而不是两次握手？ 如果只有两次握手 服务端收到连接请求就进入ESTABLISHED状态 如果网络阻塞 客户端请求迟迟无法到达服务器 客户端超过应答时间后 上次请求将会失效 此时如果失效的连接到了服务器 服务器会等待下去 浪费连接资源 2.为什么连接的时候是三次握手 关闭的时候却是四次握手？ 当server收到client的SYN包请求报文时 server可以同时发送ACK应答和SYN同步请求报文 但是关闭连接时 当sever收到client发送FIN结束报文时 不可能立即关闭连接 只能先回复ACK应答包 当server所有的报文发完后 才会发送FIN报文 同时client也会确认。 3.为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？ 网络时不可靠的 为了保证发送的最后一个ACK报文段能够到达另一端 单个IP地址能接受的最大并发为六万多，1万个TIME_WAIT大约使用1MB的内存CPU占用更小，因此资源使用很小可以忽略不计 但是会占用一个socket，可以通过在负载上配置多个公网IP地址以提高高并发的问题， cat /proc/sys/net/ipv4/tcp_tw_recycle 0 #用于快速回收处于TIME_WAIT状态的socket以便重新分，在负载服务器不能打开，会导致通过nat上网的后续用户 无法打开网页，因为后面的访问用户时间戳小于前面的用户，会导致数据包被负载服务器丢弃，可以在内网使用，但是通常建议关闭 cat /proc/sys/net/ipv4/tcp_tw_reuse 0 #kernel会复用处于TIME_WAIT状态的socket，即允许将TIME_WAIT状态得socket用于直接新的TCP连接，负载服务器建议打开 cat /proc/sys/net/ipv4/tcp_timestamps 1 #记录数据包的时间戳，判断是新的数据包还是旧的，如果是旧的就丢弃，配合上面两个选项的时候一定要打开才生效。 TCP超时重传异常网络状况下（开始出现超时或丢包），TCP控制数据传输以保证其承诺的可靠服务 TCP服务必须能够重传超时时间内未收到确认的TCP报文段。 为此，TCP模块为每个TCP报文段都维护一个重传定时器，该定时器在TCP报文段第一次被发送时 启动。 如果超时时间内未收到接收方的应答，TCP模块将重传TCP报文段并重置定时器。 至于下次重传的超时时间如何选择，以及最多执行多少次重传，就是TCP的重传策略 与TCP超时重传相关的两个内核参数： /proc/sys/net/ipv4/tcp_retries1 制定在底层ip接管之前最少重传次数 默认值是3 /proc/sys/net/ipv4/tcp_retries2 指定连接放弃前TCP最多重传次数 默认值是15 固定窗口发送相同大小的数据包 TCP滑动窗口通过动态改变窗口的大小来调节两台主机之间数据传输 可靠：对发送的数据进行确认 流控制：窗口大小随链路变化 随着接收者对收到数据的确认，滑动窗口随时向右移动。 窗口两端的相关运动增加或减少着窗口大小 TCP在传送数据时，第一次发数据发送方的窗口大小是由链路带宽决定的，但是接受方在接收到发送方的数据后，返回ack确认报文，同时也告诉了发送方自己的窗口大小，此时发送发第二次发送数据时，会改变自己的窗口大小和接受方一致。 当窗口过大时，会导致不必要的数据来拥塞我们的链路，但是窗口太小时，会造成很大的延时，比如为1时，发送方没发送一个数据，接受方就会返回一个ack报文，在发送方未接收到接受方的确认报文ack之前不会进行下一次发送。当链路变好了或者变差了这个窗口还会发生变话，并不是第一次协商好了以后就永远不变了。 拥塞控制网络中的带宽、交换结点中的缓存和处理机等，都是网络的资源。 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可承受的能力，网络的性 能就会变坏。此情况称为拥塞 TCP为提高网络利用率，降低丢包率，并保证网络资源对每条数据流的公平性。 即所谓的拥塞控制 慢起动(slow start)、拥塞避免(congestion avoidance)、快速重传(fast retransmit)、快速恢复(fast recovery) 拥塞控制算法： /proc/sys/net/ipv4/tcp_congestion_control Syn半连接和accept全连接队列Linux内核协议栈为一个tcp连接管理使用两个队列，一个是半链接队列（用来保存处于SYN_SENT和SYN_RECV状态的请求），一个是accpetd队列（用来保存处于established状态，但是应用层没有调用accept取走的请求）。 半连接状态: 指TCP状态SYN_RCVD的状态。服务器处于Listen状态时收到客户端SYN报文时放入半连接队列中，即 SYN queue 全连接队列 accept queue(min(somaxconn, backlog)), 保存 ESTAB 的状态 /proc/sys/net/ipv4/tcp_max_syn_backlog 未完成连接队列大小,默认是128,建议调整1024以上 /proc/sys/net/core/somaxconn 完成队列大小,默认是128,建议调整大小1024以上 通过 ss -lnt 的 Send-Q 确认: LISTEN 状态: Recv-Q 表示的当前等待服务端调用accept完成三次握手的listen backlog数值，也就是说，当客户端通过connect()去连接正在listen()的服务端时，这些连接会一直处于这个queue里面直到被服务端accept() Send-Q 表示的则是最大的 listen backlog 数值，这就就是上面提到的 min(backlog, somaxconn) 的值。 非 LISTEN 状态: Recv-Q 表示 receive queue 中的 bytes 数量 Send-Q 表示 send queue 中的 bytes 数值 backlog参数这个和具体的应用程序有关，比如nginx默认为511 可以通过适当的增大 nginx 的 backlog 以及 somaxconn 来增大队列: listen 80 backlog=1638; Tomcat默认为100，也可通过server.xml中的&lt;Connector acceptCount=&quot;300&quot;/&gt;来调整 UDP工作在传输层 提供不可靠的网络访问 非面向连接协议 有限的错误检查 传输性能高 无数据恢复特性 UDP包头 IPIP PDU 报头 版本:占4位,指 IP 协议的版本目前的IP协议版本号为4 首部长度:占4位,可表示的最大数值是15个单位，一个单位为4字节，因此IP的首部长度的最大值是60字节 区分服务:占8位,用来获得更好的服务,在旧标准中叫做服务类型,但实际上一直未被使用过.后改名为区分服务.只有在使用区分服务(DiffServ)时,这个字段才起作 用.一般的情况下不使用 总长度:占16位,指首部和数据之和的长度,单位为字节,因此数据报的最大长度为65535 字节.总长度必须不超过最大传送单元MTU 标识:占16位,它是一个计数器,通常，每发送一个报文，该值会加1，也用于数据包分片，在同一个包的若干分片中，该值是相同的 标志(flag):占3位,目前只有后两位有意义 DF： Don’t Fragment 中间的一位，只有当 DF=0 时才允许分片 MF： More Fragment 最后一位，MF=1表示后面还有分片,MF=0 表示最后 片偏移:占12位,指较长的分组在分片后，该分片在原分组中的相对位置.片偏移以8个字节为偏移单位 生存时间:占8位,记为TTL (Time To Live)数据报在网络中可通过的路由器数的最大值,TTL 字段是由发送端初始设置一个8bit字段.推荐的初始值由分配数字RFC指定,当前值为64.发送 ICMP 回显应答时经常把TTL设为最大值255 协议:占8位,指出此数据报携带的数据使用何种协议以便目的主机的IP层将数据部分上交给哪个处理过程, 1表示为ICMP协议, 2表示为IGMP协议, 6表示为 TCP 协议, 17表示为UDP协议 首部检验和:占16位,只检验数据报的首部不检验数据部分.这里不采用CRC检验码而采用简单的计算方法 源地址和目的地址:都各占4字节,分别记录源地址和目的地址 IP PDU 报头示例: ICMP报文：包括IP头部（20字节）、ICMP头部（8字节）和ICMP报文 以太网帧格式 最大帧应该是1526字节，但是实际上我们抓包得到的最大帧是1514字节，为什么不是1526字节呢？ 原因是当数据帧到达网卡时，在物理层上网卡要先去掉前导同步码和帧开始定界符，然后对帧进行CRC检验，如果帧校验和出错，就丢弃此帧。 如果校验和正确，就判断帧的目的硬件地址是否符合自己的接收条件（目的地址是自己的物理硬件地址、广播地址、可接收的多播硬件地址等） 如果符合，就将帧交给“设备驱动程序”做进一步处理。 这时我们抓包的软件才能抓到数据，因此，抓包软件抓到的是去掉前导同步码、帧开始分界符、FCS之外的数据，其最大值是6 + 6 + 2 + 1500 = 1514。 以太网规定，以太网帧数据域部分最小为46字节，也就是以太网帧最小是 6 + 6 + 2 + 46 + 4 = 64。 除去4个字节的FCS，抓包时就是60字节。 当数据字段的长度小于46字节时，MAC子层就会在数据字段的后面填充以满足数据帧长不小于64字节。 由于填充数据是由MAC子层负责，也就是设备驱动程序。不同的抓包程序和设备驱动程序所处的优先层次可能不同，抓包程序的优先级可能比设备驱动程序更高， 因此不同的抓包工具抓到的数据帧的大小可能不同。（比如，wireshark抓到的可能没有填充数据段，而sniffer抓到的就有填充数据段） IP地址32位 网络ID 主机ID A类 1~126 0 0000000~01111111 网络数：126 每个网络中的主机数：2^24-2 默认子网掩码：255.0.0.0 B类 128~191 10 000000~10111111 网络数：2^14 每个网络中的主机数：2^16-2 默认子网掩码：255.255.0.0 C类 192~223 110 00000~11011111 网络数：2^21 每个网络中的主机数：2^8-2 默认子网掩码：255.255.255.0 D类 224~239 1110 0000~11101111 组播地址 172.16~172.31.255.255 私网地址 192.168 私网地址 169.254. 自动分配 127回环地址 10.0.0.0 私网地址 CIDR：无类域间路由 超网 子网掩码向左移 VLSM：变长子网掩码 子网掩码向右移 0.0.0.0不是一个真正意义上的IP地址。它表示所有不清楚的主机和目的网络 IPv6地址为128位长，但通常写作8组，每组为四个十六进制数的形式。 例如： 2001:0db8:85a3:08d3:1319:8a2e:0370:7344 MAC地址，Media Access Control，介质访问控制,也叫硬件地址，长度是48比特（6字节），由16进制的数字组成 前24位前24位叫做组织唯一标志符 后24位厂家自己分配的]]></content>
  </entry>
  <entry>
    <title><![CDATA[启动流程排错]]></title>
    <url>%2F2017%2F12%2F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E6%8E%92%E9%94%99%2F</url>
    <content type="text"><![CDATA[grub legacystage 1：mbr的前446字节 破坏之后，将无法引导系统，此时只能从其它启动介质启动系统， stage 1.5：存放在磁盘MBR之后的扇区，让stage1中的bootloader能识别stage2所在的分区上的文件系统 注意：能看到启动菜单实际就已经过了1.5阶段了，进入2阶段stage 2：一般是挂载至/boot/grub/目录下 根据stage2阶段文件定义内容找grub.conf文件然后根据这个文件里定义的内容找boot下的内vmlinuz…与驱动模块initramfs…，至此由bootloader到grub然后由grub加载内核文件与模块系统引导启动 注意：硬盘设备能识别，并不代表硬盘上的文件系统能识别，因为文件系统是额外附加的一层软件组织的文件结构，所以要能够对接一种文件系统，必须要用到文件系统驱动；对应的应用程序必须能识别和理解这样的文件系统才可以，这种程序就称为文件系统驱动；grub的1.5阶段就是给gurb提供了文件系统驱动的，从而就能够访问对应的第二阶段和内核所在的分区了，这通常是一个基本磁盘分区；所以grub第二阶段以及内核和ramdisk文件通常都会放在一个基本磁盘分区上；因为grub驱动不了逻辑卷这种高级接口。 grub.conf配置文件 default=5 timeout=5 #password //明文加密 #password --md5 //使用grub-md5-crypt生成 #password --encrypted //使用grub-crypt生成 hiddenmenu title root (hd0,0) kernel /vmlinuz ro root=/dev/sda2 可添加 许多内核支持使用的cmd参数 例如：max_loop=100 selinux=0 init=/path/to/init initrd /initramfs.img grub加密grub-md5-crypt grub-crypt 例：破解root口令启动系统时，设置其运行级别1 进入单用户模式： 1.编辑grub菜单(选定要编辑的title，而后使用a 或 e 命令) 2.在选定的kernel后附加 1, s, S，single 都可以 3.在kernel所在行，键入“b”命令 修改开机背景图片分辨率为640X480 转换图片类型 which convert rpm -qf /usr/bin/convert convert -resize 640x480 -colors 14 文件 文件.xpm gzip 文件.xpm mv 文件.xpm.gz /boot/grub/ 修改内核配置文件 vim /boot/grub/grub.conf 添加 splashimage=(hd0,0)/grub/文件.xpm.gz 重启查看 报错：Error19 kernel must be loade before initrd救援模式e--》进入内核--》位置出错d删除initrd--》o增加一个新行--》e编辑 grub edit&gt; initrd /initramfs-2.6.32-.. b重启 删除/boot/grub/grub.conf重启恢复手动在grub命令行接口启动系统 grub&gt; root (hd#,#) grub&gt; kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICE grub&gt; initrd /initramfs-VERSION-RELEASE.img grub&gt; boot 进入系统手写配置文件 破坏gurb的第一阶段及修复破坏MBR引导grub分区表中的446个字节 hexdump -C /dev/sda -n 446 dd if=/dev/zero of=/dev/sda bs=1 count=446 方法： 未重启前使用本地修复 grub-install /dev/DISK boot所在分区磁盘 启动光盘的救援模式，之后使用grub-install命令修复， grub-install --root-directory=DIR /dev/DISK sync 注意： 默认在/boot/grub/目录下生效的文件只有grub.conf，其它的文件可以不存在，但如果用grub-install修复之后，此必须存在grub.conf和其它相关的文件，没有则无法引导系统 grub的1.5阶段后续的27个扇区，系统初始化是没有1.5阶段的扇区的可能在磁盘的其他位置，修复以后会在27个扇区中 备份及破坏MBR分区修复备份 dd if=/dev/sda of=/root/mbr bs=1 count=446 破坏 dd if=/dev/zero of=/dev/sda bs=1 count=446 使用grub命令交互式修复 要指定/boot分区位置 grub grub&gt; root (hd0,0) grub&gt; setup (hd0) 查看是否修复 hexdump -C -n 446 /dev/sda 注意：此修复是有依赖的依赖于/boot/grub/下的文件，不成功可以用使用grub-install方法修复 界面为Error 15 救援模式grub-install boot分区文件丢失的恢复步骤1. 使用其它启动介质启动系统，进入系统的救援模式 2. 挂载启动介质目录至指定的目录 3. 安装内核文件 rpm -ivh /Package/kernel-Version-release.rpm --root /系统的根目录 --force 4. 修复grub grub-install --root-directory=/系统的根目录 /根目录所在的分区 5. 生成grub.conf /etc/fstab文件丢失且boot分区文件丢失(ext分区)1. 使用其它启动介质启动系统，进入系统的救援模式 2. blkid，fdisk -l 查看现有的分区信息 3. 手动挂载根目录至指定的分区 4. 手动创建/etc/fstab 5. 重启 6. 其它步骤同上 /etc/fstab文件丢失且boot分区文件丢失(lvm分区)1. 使用其它启动介质启动系统，进入系统的救援模式 2. 查看lvm的根分区目录 lvs 3. 激活lvm根分区 vgchange -ay 4. 手动挂载根目录至指定的分区 5. 手动创建/etc/fstab 6. 其它步骤同上 系统配置文件丢失/etc/inittab丢失 在救援模式下执行： 1.有备份恢复 chroot /mnt/sysimage cp /etc/inittab.bak /etc/inittab 2.无备份恢复 chroot /mnt/sysimage rpm -qf /etc/inittab 查询到此文件来自initscripts包 exit 退出chroot模式 mount /dev/sr0 /mnt/source 挂载存放RPM包的安装光盘 rpm –ivh force /mnt/Packages/initscripts-9.03.49-1.el6.centos.x86_64.rpm 3.只提取RPM包中的/etc/inittab文件进行恢复 rpm2cpio /mnt/source/Packages/initscripts-9.03.491.el6.centos.x86_64.rpm| cpio -idv ./etc/inittab cp etc/inittab /mnt/sysimage/etc 注意:此命令执行时不能将文件直接恢复至/etc目录，只能提取到当前目录下，且恢复的文件名称所在路径要写完整的路径。提取文件成功后，将其复制到根分区所在的/mnt/sysimage目录下相应位置即可]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>排错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础]]></title>
    <url>%2F2017%2F12%2Flinux%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[终端类型terminal物理终端（/dev/console ） 控制台console 虚拟终端(tty：teletypewriters，/dev/tty# #为[1-6]) tty可有n个，Ctrl+Alt+F[1-6] 图形终端（/dev/tty7 ）startx, xwindows CentOS 6: Ctrl + Alt + F7 CentOS 7: 在哪个终端启动，即位于哪个虚拟终端 串行终端（/dev/ttyS# ） ttyS 模拟终端（pty：pseudo-tty，/dev/pts/# ） pty, SSH远程连接 查看当前的终端设备命令： tty 交互式接口交互式接口：启动终端后，在终端设备附加一个交互式应用程序 GUI：Graphic User Interface X protocol, window manager, desktop Desktop: GNOME (C, 图形库gtk)， KDE (C++,图形库qt) XFCE (轻量级桌面) 相互间应用程序不兼容，因为底层开发库不同 CLI：Command Line Interface（命令行） shell程序 字符集和编码ASCII码：一共规定了128个字符的编码，占用了一个字节的后面7位，最前面的一位统一规定为0 Unicode：用于表示世界上所有语言中的所有字符。 每一个符号都给予一个独一无二的编码数字，是一个很大的集合，现在的规模可以容纳100多 万个符号。 Unicode仅仅只是一个字符集，规定了每个字符对应的二进制代码，至于这个二进制代码如何存储则没有规定 Unicode：编码方案： UTF-8：变长，1到4个字节，根据字符的不同变换长度 UTF-16：变长，2或4个字节 UTF-32：固定长度，4个字节 UTF-8 ：是目前互联网上使用最广泛的一种 Unicode 编码方式，可变长存储 shellShell是Linux系统的用户界面，提供了用户与内核进行交互操作的一种接口。 它接收用户输入的命令并把它送入内核去执行 也被称为LINUX的命令解释器（command interpreter） shell是一种高级程序设计语言 sh、csh、tcsh、ksh、bash、zsh，默认使用bash 查看当前使用的shell echo $SHELL 查看Linux可用的shell cat /etc/shells 命令提示符命令提示符：prompt # 管理员$ 普通用户 显示提示符格式 echo $PS1 修改提示符格式 PS1=&quot;\[\e[1;5;41;33m\][\u@\h \W]\\$\[\e[0m\]&quot; \e \033 \u 当前用户 \h 主机名简称 \H 主机名 \w 当前工作目录 \W 当前工作目录基名 \t 24小时时间格式 \T 12小时时间格式 \! 命令历史数 \# 开机后命令历史数 0m 颜色结束 字体颜色31-37 背景颜色41-47 闪烁5 高显1 保存于 .bashrc或/etc/bashrc 修改登录信息(登录之前显示的) /etc/issue d 本地端时间的日期； l 显示第几个终端机介面； m 显示硬体的等级 (i386/i486/i586/i686...)； n 显示主机的网路名称； O 显示 domain name； r 作业系统的版本 (相当于 uname -r) t 显示本地端时间的时间； S 作业系统的名称； v 作业系统的版本 登陆显示信息(登录之后显示) cat /etc/motd 内部命令和外部命令alias ---- 内部 --hash表（记录外部命令的路径）---$PATH --命令找不到 内部命令 shell程序自带的命令 help 内部命令列表 enable cmd 启用内部命令 enable –n cmd 禁用内部命令 enable –n 查看所有禁用的内部命令 外部命令 在系统的某个路径下的可执行程序 外部命令查找依赖于 PATH变量 查看外部命令搜索路径 查看PATH变量 echo $PATH 查看是内部命令还是外部命令 type COMMAND 查看命令所在的目录 which Hash缓存表 系统初始hash表为空，当外部命令执行时，默认会从PATH路径下寻找该命令，找到后会将这条命令的路径记录到hash表中，当再次使用该命令时，shell解释器首先会查看hash表，存在将行之，如果不存在，将会去PATH路径下寻找。 利用hash缓存表可大大提高命令的调用速率 hash常见用法 hash 显示hash缓存 hash –l 显示hash缓存，可作为输入使用 hash –p path name 将命令全路径path起别名为name hash –t name 打印缓存中name的路径 hash –d name 清除name缓存 hash –r 清除缓存 缓存cache：将刚用硬盘的数据放在内存中，下次用此数据，不需要从硬盘找，直接内存取出hash 注意：如果在将外部命令执行过一次的情况下，把该命令的路径进行更改，那么该命令将无法执行。 原因：因为在执行命令，shell会首先查看hash缓存，会根据缓存中的路径执行该命令，但此时该命令的路径已经改变，因此会发生错误。 解决方法：清除缓存即可 命令别名显示当前shell进程所有可用的命令别名 alias 定义别名NAME，其相当于执行命令VALUE alias NAME=&apos;VALUE&apos; 在命令行中定义的别名，仅对当前shell进程有效 如果想永久有效，要定义在配置文件中 仅对当前用户：~/.bashrc 对所有用户有效：/etc/bashrc 编辑配置给出的新配置不会立即生效 bash进程重新读取配置文件 source /path/to/config_file . /path/to/config_file 撤消别名：unalias unalias[-a] name [name ...] -a 取消所有别名 如果别名同原命令同名，如果要执行原命令，可使用 \ALIASNAME &quot;ALIASNAME&quot; &apos;ALIASNAME&apos; command ALIASNAME /path/commmand 注意：别名、内部命令、外部命令优先级：从大到小分别是别名、内部命令、外部命令 命令格式COMMAND [OPTIONS...] [ARGUMENTS...] 选项：用于启用或关闭命令的某个或某些功能 短选项：-c 例如：-l, -h 长选项：--word 例如：--all, --human-readable 参数：命令的作用对象，比如文件名，用户名等 注意： 多个选项以及多参数和命令之间使用空白字符分隔 取消和结束命令执行：Ctrl+c，Ctrl+d 多个命令可以用;符号分开 一个命令可以用\分成多行 命令行历史保存你输入的命令历史。可以用它来重复执行命令 登录shell时，会读取命令历史文件中记录下的命令 ~/.bash_history 登录进shell后新执行的命令只会记录在缓存中；这些命令会用户退出时&quot;追加&quot;至命令历史文件中 重复前一个命令，有4种方法 重复前一个命令使用上方向键，并回车执行 按!! 并回车执行 输入!-1 并回车执行 按Ctrl+p并回车执行 !:0 执行前一条命令（去除参数） Ctrl + n 显示当前历史中的下一条命令，但不执行 Ctrl + j 执行当前命令 !n 执行history命令输出对应序号n的命令 !-n 执行history历史中倒数第n个命令 !string 重复前一个以&quot;string&quot;开头的命令 !?string 重复前一个包含string的命令 !string:p仅打印命令历史，而不执行 !$:p 打印输出!$ （上一条命令的最后一个参数）的内容 !*:p打印输出!*（上一条命令的所有参数）的内容 ^string删除上一条命令中的第一个string ^string1^string2将上一条命令中的第一个string1替换为string2 !:gs/string1/string2将上一条命令中所有的string1都替换为string2 使用up（向上）和down（向下）键来上下浏览从前输入的命令 ctrl-r来在命令历史中搜索命令 (reverse-i-search）`&apos;： Ctrl+g：从历史搜索模式退出 要重新调用前一个命令中最后一个参数 !$ 表示 Esc, .（点击Esc键后松开，然后点击. 键） Alt+ .（按住Alt键的同时点击. 键 调用历史参数command !^ 利用上一个命令的第一个参数做cmd的参数 command !$ 利用上一个命令的最后一个参数做cmd的参数 command !* 利用上一个命令的全部参数做cmd的参数 command !:n 利用上一个命令的第n个参数做cmd的参数 command !n:^ 调用第n条命令的第一个参数 command !n:$ 调用第n条命令的最后一个参数 command !n:m调用第n条命令的第m个参数 command !n:* 调用第n条命令的所有参数 command !string:^ 从命令历史中搜索以string 开头的命令，并获取它的第一个参数 command !string:$ 从命令历史中搜索以string 开头的命令,并获取它的最后一个参数 command !string:n 从命令历史中搜索以string 开头的命令，并获取它的第n个参数 command !string:* 从命令历史中搜索以string 开头的命令，并获取它的所有参数 historyhistory 查看历史命令 常用选项： -c: 清空命令历史 -d offset: 删除历史中指定的第offset个命令 n: 显示最近的n条历史 -a: 追加本次会话新执行的命令历史列表至历史文件 -r: 读历史文件附加到历史列表 -w: 保存历史列表到指定的历史文件 -n: 读历史文件中未读过的行到历史列表 -p: 展开历史参数成多行，但不存在历史列表中 -s: 展开历史参数成一行，附加在历史列表后 相关环境变量HISTSIZE：命令历史记录的条数 HISTFILE：指定历史文件，默认为~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数 HISTTIMEFORMAT=&quot;%F %T&quot; 显示时间 HISTIGNORE=&quot;str1:str2*:… &quot; 忽略str1命令，str2开头的历史 控制命令历史的记录方式： 环境变量：HISTCONTROL ignoredups 默认，忽略重复的命令，连续且相同为&quot;重复&quot; ignorespace 忽略所有以空白开头的命令 ignoreboth 相当于ignoredups, ignorespace的组合 erasedups 删除重复命令 export 变量名=&quot;值&quot; 存放在/etc/profile 或~/.bash_profile echo $HISTTIMEFORMAT 查看变量 bash的快捷键Ctrl + l 清屏，相当于clear命令 Ctrl + o 执行当前命令，并重新显示本命令 Ctrl + s 阻止屏幕输出，锁定 Ctrl + q 允许屏幕输出 Ctrl + c 终止命令 Ctrl + z 挂起命令 Ctrl + a 光标移到命令行首，相当于Home Ctrl + e 光标移到命令行尾，相当于End Ctrl + f 光标向右移动一个字符 Ctrl + b 光标向左移动一个字符 Alt + f 光标向右移动一个单词尾 Alt + b 光标向左移动一个单词首 Ctrl + xx 光标在命令行首和光标之间移动 Ctrl + u 从光标处删除至命令行首 Ctrl + k 从光标处删除至命令行尾 Alt + r 删除当前整行 Ctrl + w 从光标处向左删除至单词首 Alt + d 从光标处向右删除至单词尾 Ctrl + d 删除光标处的一个字符 Ctrl + h 删除光标前的一个字符 Ctrl + y 将删除的字符粘贴至光标后 Alt + c 从光标处开始向右更改为首字母大写的单词 Alt + u 从光标处开始，将右边一个单词更改为大写 Alt + l 从光标处开始，将右边一个单词更改为小写 Ctrl + t 交换光标处和之前的字符位置 Alt + t 交换光标处和之前的单词位置 Alt + N 提示输入指定字符后，重复显示该字符N次 注意：Alt组合快捷键经常和其它软件冲突 日期和时间linux系统的两种时钟 系统时钟：由Linux内核通过CPU的工作频率进行的 硬件时钟：主板 相关命令： date 显示和设置时间和日期 date -u 显示格林尼治时间 date 月日时分年秒（时间格式） 设置时间 date +%Y%m%d或+%F 显示年月日 date +%H%M%S或+%T 显示时分秒 date +&quot;%F %T&quot; 选项带有空格，需用引号 date -d &apos;-2 day&apos; 显示前天时间 date -d &apos;2 day&apos; 显示后天时间 date -d &apos;-2 day&apos; +%F 只显示前天的年月日 date -d &apos;-2 day&apos; +%a（或%u） 只显示前天是星期几 date -f 文件 批量处理文件 date -d &quot;具体日期&quot; +%s 将1970年1月1日到该具体日期的时间转换为秒 date -d @秒数 +&quot;%F %T&quot; 把秒数转换为时间和日期 clock，hwclock 显示硬件时间 -s 以硬件时间为准，更改系统时间 -w 以系统时间为准，更改硬件时间 时区：/etc/localtime cat /etc/localtime 查看时区 设置时区： timedatectl set-timezones （centos7系统） tzselect （centos6系统） cal 显示日历 -m 显示当月日历 -y 显示当年日历 ntpdate 时钟服务器ip地址 校准服务器时间 常用命令关机：halt，poweroff，shutdown 用法： shutdown [OPTIONS...] [TIME] [WALL...] shutdown 选项 关机时间 关机提示 -r：reboot -h：halt -c：cancel 取消关机 TIME：无指定，默认相当于+1，单位为分钟 now：立刻关机，相当于+0 +m：相对时间表示法，几分钟之后；例如+3 hh：mm：绝对时间表示，指明具体关机时间 shutdown –r now 现在重启 shutdown now 现在关机 shutdown +5 过5分钟关机 shutdown –c 取消关机命令执行 shutdown –h 02:23 &amp; 在2点23分关机 shutdown –r 02:25 &amp; 在2点25分重启 备注：系统提示(&quot;xxxx&quot;)只有在关机前15分钟内才会出现。 重启：reboot -f: 强制 ，不调用shutdown -p: 切断电原 screen命令 screen –S [SESSION] 创建新screen会话 screen –x [SESSION] 加入screen会话 exit 退出并关闭screen会话 Ctrl+a,d 剥离当前screen会话 screen -ls 显示所有已经打开的screen会话 screen -r [SESSION] 恢复某screen会话，只对当前会话没有加入其它用户有效 作用：解决断网中断会话正在操作的程序或命令问题 用户登录信息查看命令 whoami 显示当前登录有效用户 who 系统当前所有的登录会话 w 系统当前所有的登录会话及所做的操作 lscpu 查看cpu信息 runlevel 运行级别 sleep 休眠 ldd 查看调用库 lddconfig -p 显示本已经缓存的库文件 lsblk 查看磁盘块 init （0 关机 3 命令行 5 图形 6 重启） 切换状态 lsb_release -a mii-tool eth0|ens33 查看网卡连接状态 uname -r 查看内核 uptime 负载情况 iconv 编码转换 hexdump 进制查看 startx 启动图形界面 mandb 创建更新man缓存 locale 获取语言环境变量信息 cat /etc/DIR_COLORS 文件颜色信息 echo echo [-neE][字符串] 会将输入的字符串送往标准输出。输出的字符串间以空白字符隔开, 并在最后加上换行号 -E （默认）不支持 \ 解释功能 -n 不自动换行 -e 启用 \ 字符的解释功能，特别加以处理，而不会将它当成一般文字输出 \a 发出警告声 \b 退格键 \c 最后不加上换行符号 \n 换行且光标移至行首 \r 回车，即光标移至行首，但不换行 \t 插入tab \\ 插入\字符 \0nnn 插入nnn（八进制）所代表的ASCII字符 echo -e &apos;\033[43;31;5mmagedu\033[0m&apos; \xHH插入HH（十六进制）所代表的ASCII字 显示变量 echo &quot;$环境变量” &apos; &apos;（单引号） 既不识别变量，又不识别命令 最傻 &quot; &quot;（双引号） 只能识别变量，不识别命令 一般 ` `（反向单引号）相当于$（） 既识别变量，又识别命令 命令行扩展命令行扩展：$( ) 或` ` 把一个命令的输出打印给另一个命令的参数 echo &quot;This is $(hostname) &quot; This is server echo &quot;i am `whoami` &quot; i am root 括号扩展：{ } 打印重复字符串的简化形式 echo file{1,3,5} file1 file3 file5 echo {1..10} 显示1到10 echo {a..z} 显示a到z echo {000..20..2} 以三位数显示0到20，并且以2递增 获得帮助通过帮助查询命令使用 先查看是内部还是外部命令 type 如果是内部命令，使用help 内部命令 如果是外部命令，使用whatis查看该命令在man帮助第几章节 然后man 章节号 command 多层次的帮助 whatis command--help man and info /usr/share/doc/ Red Hat documentation 其它网站和搜索 内部命令 帮助用法： help command man bash 查看所有内部命令帮助，可通过关键字查询 外部命令 帮助用法： (1) COMMAND --help COMMAND -h (2) 使用手册(manual) man COMMAND (3) 信息页 info COMMAND (4) 程序自身的帮助文档 README INSTALL ChangeLog (5) 程序官方文档 官方站点：Documentation (6) 发行版的官方文档 (7) Google --help和-h选项 显示用法总结和参数列表 大多数命令都可以使用此帮助格式，但并非所有的命令都支持 符号说明： []表示可选项 CAPS或&lt;&gt;表示变化的数据 ...表示一个列表 x |y| z的意思是&quot;x或y或z&quot; -abc的意思是-a -b –c { } 表示分组 whatis显示命令的简短描述 使用数据库，系统刚安装后不可立即使用 需执行以下命令makewhatis| mandb制作数据库 使用示例：whatis cal或man -f cal man提供命令帮助的文件 手册页存放在/usr/share/man 几乎每个命令都有man的&quot;页面&quot; man页面分组为不同的&quot;章节&quot; 统称为Linux手册 man命令的配置文件：/etc/man.config| man_db.conf MANPATH /PATH/TO/SOMEWHERE: 指明man文件搜索位置 man -M/PATH/TO/SOMEWHERE COMMAND: 到指定位置下搜索COMMAND命令的手册页并显示 中文man需安装包man-pages-zh-CN man章节1: 用户命令 2: 系统调用 3: C库调用 4: 设备文件及特殊文件 5: 配置文件格式 6: 游戏 7: 杂项 8: 管理类的命令 9：Linux 内核API 备注：只需关注1（用户命令）、5（配置文件格式）、8（管理类的命令）章节 man帮助段落说明 NAME 名称及简要说明 SYNOPSIS 用法格式说明 []可选内容 &lt;&gt; 必选内容 a|b二选一 { }分组 ...同一内容可出现多次 DESCRIPTION 详细说明 OPTIONS 选项说明 EXAMPLES 示例 FILES 相关文件 AUTHOR 作者 COPYRIGHT版本信息 REPORTING BUGS bug信息 SEE ALSO 其它帮助参考 例： 在本机字符终端登录时，除显示原有信息外，再显示当前登录终端号，主机名和当前时间 在/etc/issue文件中写入以下内容 hostname is \n time is \t tty is \l 解题思路： (1)先查看issue章节号 whatis issue [root@centos7 ~]#whatis issue issue (5) - prelogin message and identification file (2)man 5 issue 发现没有先关信息，在查看SEE ALSO内容 SEE ALSO motd(5), agetty(8), mingetty(8) (3)man 8 agetty，发现issue文件用法 infoman常用于命令参考，GNU工具info适合通用文档参考 没有参数,列出所有的页面 info 页面的结构就像一个网站 每一页分为“节点” 链接节点之前* info [命令] 导航info页 方向键，PgUp，PgDn导航 Tab键移动到下一个链接 d 显示主题目录 Home 显示主题首部 Enter进入选定链接 n/p/u/l进入下/前/上一层/最后一个链接 s文字文本搜索 q退出info]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机基础]]></title>
    <url>%2F2017%2F11%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[编程语言：硬件级：微码编程，汇编语言 系统级：C，C++，... 应用级：Java, PHP, Python, Ruby, Perl, C#, ... Python： PVM Standard Library Web Framework：Django, Flask, ... Java：JVM，JDK bash：bash explainer ... 计算机系统计算机系统由硬件(Hardware)系统和软件(Software)系统两大部分组成 计算机硬件组成 冯诺依曼体系：1946年 计算机五大部件：运算器、控制器、存储、输入输出设备 cpucpu：运算器，控制器 主频：主频是CPU的时钟频率(CPU Clock Speed)，是CPU运算时的工作的频率（1秒内发生的同步脉冲数）的简称。单位是Hz。 外频：系统总线的工作频率， CPU与外部（主板芯片组）交换数据、指令的工作 时钟频率 倍频：倍频则是指CPU外频与主频相差的倍数 高速缓存（cache）：高速交换的存储器。CPU缓存分为一级，二级，三级缓存， 即L1，L2，L3 内存总线速度(Memory-Bus Speed): 一般等同于CPU的外频，指CPU与二级(L2) 高速缓存和内存之间的通信速度 地址总线宽度:决定了CPU可以访问的物理地址空间 主频=外频*倍频 cpu架构： RISC，精简指令集 CISC，复杂指令集 内存内存储器：ROM，RAM 内存带宽： 内存带宽是指内存与北桥芯片之间的数据传输率 单通道内存节制器一般都是64-bit的，8个二进制位相当于1个字节，换算成 字节是64/8=8，再乘以内存的运行频率，如果是DDR内存就要再乘以2 计算公式： 内存带宽=内存总线频率×数据总线位数/8 硬盘转速是指硬盘盘片每分钟转动的圈数，单位为rpm。现在硬盘的转速已经达到10000rpm，15000rpm 硬盘接口类型： IDE接口：硬盘接口规范，采用ATA技术规范 SCSI接口：应用于小型机上的高速数据传输技术 SATA接口： Serial ATA，提高传输速率，支持热插拔 SAS接口： Serial Attached SCSI，兼容SATA 目前主流的硬盘接口为SATA和SAS接口 存储基础知识DAS-----直接连接存储(Direct Attached Storage) NAS-----网络连接存储(Network Attached Storage) SAN-----存储区域网络(Storage Area Networks) 服务器服务器按应用功能可分为： Web服务器、数据库服务器、文件服务器、中间件应用服务器、日志服务器、 监控服务器、程序版本控制服务器、虚拟机服务器、邮件服务器、打印服务器、 域控制服务器、多媒体服务器、通讯服务器、ERP服务器等 服务器按外形分类： 塔式服务器、刀片式服务器、机架式服务器 塔式Tower服务器 外形以及结构和平时使用的立式PC差不多 目前较少使用 刀片式Blade服务器 在标准高度的机架式机箱内可插装多个卡式的服务器单元，实现高可用和高密度 更高的密度，集中管理，高性能，灵活扩展，按需配置 可以使用系统软件将这些母板集合成一个服务器集群。在集群模式下，所有的母板可以连接起来提供高速的网络环境，并同时共享资源，为相同的用户群服务 机架式服务器 1U：1.75英寸，44.45毫米；宽度，19英寸；深度，1000毫米 用户和内核空间 用户空间：User space 用户程序的运行空间。为了安全，它们是隔离的，即使用户的程序崩溃，内核也不受影响 只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（ system call），才能向内核发出指令 内核空间：Kernel space 是Linux 内核的运行空间 可以执行任意命令，调用系统的一切资源 使用time命令查看 用户空间user花费的空间，内核空间sys花费的空间，真实real花费的时间 服务器三大操作系统Windows Linux：GNU/Linux Unix：1969年Ken Thompson System: Bell Lab AIX （IBM） Solaris (SUN) HP-UX (HP) BSD: （BSRG）Berkeley System Distribution NetBSD OpenBSD FreeBS GNU提供软件/Linux提供内核 IEEE 电气和电子工程师协会定义的POSIX POSIX Portable Operating System Interface 可移植操作系统接口 定义了操作系统应该为应用程序提供的接口标准 API规范 应用程序接口规范 ABI Application Binary Interface 应用程序二进制接口 开源协议 Linux发行版本redhat与centos系统之间的区别 1.redhat 现在是免费下载 更新 安装软件 提供服务帮助。 2.CentOS 做到和redhat一模一样 1)去掉redhat里面的收费的项目和logo 2)开发相同功能的软件]]></content>
  </entry>
</search>
